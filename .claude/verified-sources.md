# Verified Sources for Praxis Library

**Last Updated:** February 2, 2026
**Policy:** Only .edu, .gov, peer-reviewed sources from 2025-2026

---

## Source Verification Status

| Category | Sources Found | Verified 2025-2026 |
|----------|---------------|-------------------|
| Stanford HAI | Yes | Yes |
| MIT Research | Yes | Yes |
| CMU Research | Yes | Yes |
| Harvard Research | Yes | Yes |
| NIST (.gov) | Yes | Yes |
| U.S. Dept of Education | Yes | Yes |
| U.S. Access Board | Yes | Yes |
| NIH/PMC | Yes | Yes |
| CAST.org (UDL) | Yes | Yes |
| EDUCAUSE | Yes | Yes |

---

## 1. STANFORD HAI (hai.stanford.edu)

### 2025 AI Index Report
**URL:** https://hai.stanford.edu/ai-index/2025-ai-index-report
**Type:** Annual Research Report
**Date:** 2025

**Verified Quotes/Statistics:**
- "In 2023, researchers introduced new benchmarks—MMMU, GPQA, and SWE-bench—to test the limits of advanced AI systems. Just a year later, performance sharply increased: scores rose by 18.8, 48.9, and 67.3 percentage points on MMMU, GPQA, and SWE-bench, respectively."
- "Nearly 90% of notable AI models in 2024 came from industry, up from 60% in 2023, while academia remains the top source of highly cited research."
- "The cost of querying an AI model that scores the equivalent of GPT-3.5 on MMLU dropped from $20.00 per million tokens in November 2022 to just $0.07 per million tokens by October 2024—a more than 280-fold reduction."
- "Between 2010 and 2023, the number of AI patents has grown steadily and significantly, ballooning from 3,833 to 122,511."
- "In 2023, 223 FDA-approved AI-enabled medical devices were approved, compared to just six in 2015."

**Use For Pages:** Prompt Basics (AI capabilities), Modern Methods (progress metrics), Implementation (industry adoption)

---

### Stanford Research on AI Bias
**URL:** https://hai.stanford.edu (Nature study reported October 2025)
**Type:** Research Study
**Date:** October 2025

**Verified Finding:**
- "Large language models carry deep-seated biases against older women in the workplace. When researchers asked AI to generate resumes, it consistently portrayed women as younger and less experienced, and gave higher scores to older men than to older women with identical qualifications."

**Use For Pages:** Ethics & Safety (bias section)

---

## 2. MIT RESEARCH

### MIT Media Lab - Advancing Humans with AI (AHA)
**URL:** https://aha.media.mit.edu/
**Type:** Research Initiative
**Date:** April 2025 Symposium Launch

**Verified Information:**
- "The Advancing Humans with AI program (AHA) is a multi-faculty initiative that aims to understand the human experience of pervasive AI and design the interaction between people and AI to foster human flourishing."
- "Rather than viewing AI as a replacement for human intelligence, the work envisions a future of dynamic collaboration—where intelligent systems empower people to work more effectively, think more clearly, and connect more meaningfully."

**Use For Pages:** Creativity, Implementation, Applied AI Hub

---

### MIT Sloan - Human-AI Collaboration Research
**URL:** https://mitsloan.mit.edu/ideas-made-to-matter/when-humans-and-ai-work-best-together-and-when-each-better-alone
**Type:** Research Study (Nature Human Behaviour)
**Date:** 2025

**Verified Finding:**
- "On average, AI-human combinations do not outperform the best human-only or AI-only system." (Based on review of 100+ studies)
- "Creation tasks were relatively unexplored—only 10% of papers reviewed looked at content creation. But in those cases, the average effect size for human-AI synergy was positive and significantly greater than that for decision-making tasks."

**Use For Pages:** Creativity, Implementation

---

### MIT Initiative on Digital Economy - Agentic AI
**URL:** https://mitsloan.mit.edu/ideas-made-to-matter/4-new-studies-about-agentic-ai-mit-initiative-digital-economy
**Type:** Research Studies
**Date:** 2025

**Verified Information:**
- Research developed a new experimental platform called Pairit (formerly MindMeld), which pairs people with either another person or an AI agent to perform collaborative tasks.
- "By 2027, 72 percent of employees will collaborate with GenAI in some capacity."

**Use For Pages:** Agentic Workflows, Implementation

---

## 3. CARNEGIE MELLON UNIVERSITY (CMU)

### ROPE: Requirement-Oriented Prompt Engineering
**URL:** https://www.cs.cmu.edu/news/2025/prompt-training
**Paper:** https://arxiv.org/html/2409.08775v3
**Type:** ACM Transactions on Computer-Human Interaction
**Date:** 2025

**Verified Quotes:**
- "ROPE shifts the focus of prompt writing from clever tricks and templates to clearly stating what the AI should do."
- "You need to be able to tell the model exactly what you want. You can't expect it to guess all your customized needs." — Christina Ma, Ph.D. student, Human-Computer Interaction Institute
- "ROPE is a human-LLM partnering strategy where humans maintain agency and control of the goals by specifying requirements for LLM prompts."
- "The paradigm focuses on the importance of crafting accurate and complete requirements to achieve better results, especially for complex, customized tasks."

**Use For Pages:** Prompt Basics, Foundations Index, Context & Structure

---

### CMU Course Information
**URL:** https://exec.cs.cmu.edu/custom/llms_and_prompt_engineering
**URL:** https://cmu-llms.org/
**Type:** Course Offerings
**Date:** 2025-2026

**Verified Information:**
- CMU offers course 17-630 Prompt Engineering
- Large Language Model Applications (11-766) is a graduate-level course

**Use For Pages:** Resources (educational links)

---

## 4. HARVARD RESEARCH

### D^3 Institute - Human-AI Collaboration
**URL:** https://d3.harvard.edu/the-creative-edge-how-human-ai-collaboration-is-reshaping-problem-solving/
**Type:** Working Paper
**Date:** January 2025

**Verified Findings:**
- "Human-guided, differentiated search approach produced more novel solutions without sacrificing value, highlighting the importance of human involvement in steering AI creativity."
- "While human ingenuity is vital for novel ideas, AI excels at generating high-quality, scalable solutions."
- "Humans have more diverse ideas, and people who use AI tend to produce more similar ideas."
- "Performers on the lower half of the skill spectrum exhibit the biggest performance gains (43%) when equipped with AI compared to performers on the top half of the skill spectrum (17%)."

**Use For Pages:** Creativity, Implementation

---

### Harvard Business School - The Cybernetic Teammate
**URL:** https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5188231
**Type:** Field Experiment
**Date:** March 2025

**Verified Finding:**
- "AI significantly enhances performance: individuals with AI matched the performance of teams without AI, demonstrating that AI can effectively replicate certain benefits of human collaboration."
- Study conducted with 776 professionals at Procter & Gamble on real product innovation challenges.

**Use For Pages:** Implementation, Case Studies

---

### Harvard Business Review Research
**URL:** https://hbr.org/2025/05/research-gen-ai-makes-people-more-productive-and-less-motivated
**URL:** https://hbr.org/2025/12/research-when-used-correctly-llms-can-unlock-more-creative-ideas
**Type:** Research Articles
**Date:** May 2025, December 2025

**Verified Findings:**
- "While gen AI collaboration boosts immediate task performance, it can undermine workers' intrinsic motivation and increase feelings of boredom when they turn to tasks in which they don't have this technological assistance."
- "AI won't replace humans, but humans with AI will replace humans without AI." — Karim Lakhani, Harvard Professor

**Use For Pages:** Creativity, Ethics (motivation concerns), Implementation

---

## 5. U.S. GOVERNMENT SOURCES (.gov)

### NIST - Cybersecurity Framework Profile for AI
**URL:** https://www.nist.gov/news-events/news/2025/12/draft-nist-guidelines-rethink-cybersecurity-ai-era
**Document:** https://nvlpubs.nist.gov/nistpubs/ir/2025/NIST.IR.8596.iprd.pdf
**Type:** Federal Guidelines
**Date:** December 2025

**Verified Information:**
- "The Cyber AI Profile centers on three overlapping focus areas: securing AI systems, conducting AI-enabled cyber defense, and thwarting AI-enabled cyberattacks."
- "The draft resulted from a yearlong effort on the part of NIST cybersecurity and AI experts, with more than 6,500 individuals joining the community of interest to contribute."
- Organizations should "maintain inventories covering models, agents, APIs/keys, datasets/metadata, and embedded AI integrations/permissions."

**Use For Pages:** Ethics & Safety, Implementation

---

### NIST - AI Standards
**URL:** https://www.nist.gov/artificial-intelligence/ai-standards
**Type:** Standards Development
**Date:** 2025

**Verified Information:**
- "NIST has developed a plan for global engagement on promoting and developing AI standards."
- Control Overlays for Securing AI Systems (COSAIS) concept paper from August 2025

**Use For Pages:** Ethics & Safety, Resources

---

### U.S. Department of Education - AI Guidance
**URL:** https://www.ed.gov/about/ed-overview/artificial-intelligence-ai-guidance
**Document:** https://www.ed.gov/media/document/opepd-ai-dear-colleague-letter-7222025-110427.pdf
**Type:** Federal Policy Guidance
**Date:** July 22, 2025

**Verified Information:**
- "Education entities are permitted to use federal education funds to develop or procure AI tools to expand access to personalized AI learning materials for all subjects and all grade levels."
- "AI use must be educator-led, ethical, accessible, transparent, and privacy-compliant."
- "AI tools or systems should be accessible for those who require digital accessibility accommodations, including children, educators, providers, and family members with disabilities."
- Response to April 23, 2025 Executive Order "Advancing Artificial Intelligence Education for American Youth"

**Use For Pages:** Ethics & Safety, Accessibility, Implementation, Resources

---

### U.S. Access Board - AI Accessibility
**URL:** https://www.access-board.gov/ai/
**Type:** Federal Agency
**Date:** 2025

**Verified Information:**
- "The U.S. Access Board was tasked by Executive Order 14110 (Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence) with actions to address equity and accessibility with respect to AI."
- Signed MOU on May 15, 2024, with AAPD and CDT
- "In 2024, the U.S. Department of Justice finalized new digital accessibility rules under Title II of the Americans with Disabilities Act."

**Use For Pages:** Accessibility & AI, Neurodivergence section

---

## 6. NATIONAL INSTITUTES OF HEALTH (NIH/PMC)

### AI and Assistive Technologies in Healthcare
**URL:** https://pmc.ncbi.nlm.nih.gov/articles/PMC11898476/
**Type:** Narrative Review
**Date:** 2025

**Verified Information:**
- "The integration of artificial intelligence (AI) into assistive technologies is an emerging field with transformative potential, aimed at enhancing autonomy and quality of life for individuals with disabilities and aging populations."

**Use For Pages:** Accessibility & AI, Neurodivergence

---

### AI for Neurodevelopmental Conditions
**URL:** https://pmc.ncbi.nlm.nih.gov/articles/PMC11659516/
**Type:** Systematic Review
**Date:** 2025

**Verified Information:**
- "Supports for adaptive functioning in individuals with neurodevelopmental conditions (NDCs) is of utmost importance to long-term outcomes."
- "15 studies meeting inclusion criteria, focusing on robotics, phones/computers and virtual reality. Studies most frequently recruited children diagnosed with autism and targeted social skills (47%), daily living skills (26%), and communication (16%)."

**Use For Pages:** Neurodivergence section, Accessibility & AI

---

### AI and Autism Care
**URL:** https://pmc.ncbi.nlm.nih.gov/articles/PMC10817661/
**Type:** Narrative Review
**Date:** 2025

**Verified Information:**
- "Autism increasingly requires a multidisciplinary approach that can effectively harmonize the realms of diagnosis and therapy, tailoring both to the individual."
- "Exciting developments at the intersection of AI and robotics, as well as wearable automated devices like smart glasses."

**Use For Pages:** Neurodivergence section

---

### Scoping Review on Inclusive AI Design for Neurodivergent Users
**URL:** https://www.tandfonline.com/doi/full/10.1080/17483107.2025.2579822
**Type:** Peer-reviewed Scoping Review
**Date:** November 2025

**Verified Information:**
- "117 peer-reviewed papers analysed across five themes: technical features, design strategies, user engagement, effectiveness, and ethical considerations."
- "AI applications are expanding quickly, especially in research on ASD (56% of studies), followed by ADHD (36%), and dyslexia (8%)."
- "Multimodal approaches that integrate various data types have improved diagnostic accuracy, with recent research showing they can detect ASD with up to 99.8% accuracy and ADHD with up to 97.4% accuracy."

**Use For Pages:** Neurodivergence section

---

## 7. CAST.org (UDL Organization)

### AI and Universal Design for Learning
**URL:** https://www.cast.org/what-we-do/artificial-intelligence/
**Document:** https://www.cast.org/wp-content/uploads/2025/03/UDL-AI-20250227-A11Y.pdf
**Type:** Educational Resource
**Date:** March 2025

**Verified Information:**
- "Artificial Intelligence and Universal Design for Learning offer powerful opportunities to enhance education by making learning more accessible, inclusive, and personalized."
- "Everyone brings unique perspectives and experiences to learning, and every brain is as different as a fingerprint."
- "AI-driven tools are transforming classrooms in the form of adaptive learning platforms, tutoring systems, lesson-planning assistants, and other education tools, but their true potential is realized when they are designed and implemented with UDL principles."
- "In December 2024, CAST partnered with Stanford University Accelerator for Learning in the planning and execution of a two-day AI + Learning Differences symposium and hackathon event."

**Use For Pages:** UDL pages, Accessibility & AI, Neurodivergence

---

## 8. EDUCAUSE

### AI Ethical Guidelines for Higher Education
**URL:** https://library.educause.edu/resources/2025/6/ai-ethical-guidelines
**Type:** Professional Guidelines
**Date:** June 2025

**Verified Principles:**
- **Beneficence:** Ensuring AI is used for the good of all students and faculty
- **Justice:** Promoting fairness in AI applications across all user groups
- **Respect for Autonomy:** Upholding individuals' rights to make informed decisions regarding AI interactions
- **Transparency and Explainability:** Providing clear, understandable information about how AI systems operate
- **Accountability and Responsibility:** Holding institutions and developers accountable for deployed AI systems
- **Privacy and Data Protection:** Safeguarding personal information against unauthorized access
- **Nondiscrimination and Fairness:** Preventing biases in AI algorithms

**Use For Pages:** Ethics & Safety

---

## 9. COGNITIVE LOAD & INSTRUCTIONAL DESIGN

### Cognitive Load Theory and AI
**URL:** https://pmc.ncbi.nlm.nih.gov/articles/PMC11852728/
**Type:** Systematic Review
**Date:** February 2025

**Verified Information:**
- "AI-driven adaptive learning systems can optimize cognitive load management by automatically adjusting instructional materials, scaffolding complex concepts, and providing immediate feedback."
- "Research findings indicate a considerable improvement in students' engagement and reduced cognitive overload, leading to overall improvements in learning outcomes."

**Use For Pages:** Context & Structure, Foundations pages

---

### AI and Multimedia Learning
**URL:** https://link.springer.com/article/10.1007/s44217-025-00592-6
**Type:** Conceptual Framework
**Date:** 2025

**Verified Information:**
- Framework proposes integrating AI with Cognitive Load Theory (CLT) and the Cognitive Theory of Multimedia Learning (CTML)
- "Supporting adaptive cognitive load management, AI-mediated schema creation, and human-AI collaborative learning"

**Use For Pages:** Context & Structure

---

## 10. CHAIN OF THOUGHT RESEARCH

### Wharton - Decreasing Value of Chain of Thought
**URL:** https://gail.wharton.upenn.edu/research-and-insights/tech-report-chain-of-thought/
**Paper:** https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5285532
**Type:** Technical Report
**Date:** June 2025

**Verified Findings:**
- "For non-reasoning models, CoT generally improves average performance by a small amount, particularly if the model does not inherently engage in step-by-step processing by default."
- "For dedicated reasoning models, the added benefits of explicit CoT prompting appear negligible and may not justify the substantial increase in processing time (20-80% increase)."
- "These findings challenge the assumption that CoT is universally beneficial."

**Use For Pages:** Chain of Thought page (with nuance), Modern Methods

---

## 11. AGENTIC AI RESEARCH

### Stanford CS329A - Self-Improving AI Agents
**URL:** https://cs329a.stanford.edu/
**Type:** University Course
**Date:** Autumn 2025

**Verified Information:**
- Course on Self-Improving AI Agents at Stanford

**Use For Pages:** Agentic Workflows

---

### Stanford Agents4Science Conference
**URL:** https://agents4science.stanford.edu/
**Type:** Academic Conference
**Date:** 2025

**Verified Information:**
- "Virtual Lab" concept involves a team of AI agents designed to mimic an actual university lab group
- "For successful papers at the conference, the AI should be the first author and do most of the work. Humans can be advisors."

**Use For Pages:** Agentic Workflows, Case Studies

---

### Stanford/Harvard/Berkeley - Adaptation of Agentic AI
**URL:** https://arxiv.org/pdf/2512.16301
**Type:** Research Paper
**Date:** December 2025

**Verified Information:**
- "These systems sit on top of large language models and connect to tools, memory, and external environments, yet still struggle with unreliable tool use, weak long-horizon planning, and poor generalization."
- Proposes 4-paradigm framework for adapting agentic AI

**Use For Pages:** Agentic Workflows

---

## 12. STRUCTURED PROMPTING / XML TAGS

### Anthropic Documentation
**URL:** https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/use-xml-tags
**Type:** Official Documentation
**Date:** Current (2025-2026)

**Verified Information:**
- Benefits include: "Clarity (clearly separating different parts of your prompt), Accuracy (reducing errors caused by the model misinterpreting parts of your prompt), Flexibility (easily finding, adding, removing, or modifying parts without rewriting everything), and Parseability"
- "There are no canonical 'best' XML tags that Claude has been trained with in particular, although it's recommended that tag names make sense with the information they surround."

**Use For Pages:** XML Containerization

---

### OpenAI Documentation
**URL:** https://platform.openai.com/docs/guides/prompt-engineering
**Type:** Official Documentation
**Date:** Current (2025-2026)

**Verified Information:**
- "When writing developer and user messages, you can help the model understand logical boundaries of your prompt and context data using a combination of Markdown formatting and XML tags."

**Use For Pages:** XML Containerization

---

### XML Prompting Research
**URL:** https://arxiv.org/abs/2509.08182
**Type:** Academic Paper
**Date:** September 2025

**Verified Information:**
- "XML Prompting as Grammar-Constrained Interaction: Fixed-Point Semantics, Convergence Guarantees, and Human-AI Protocols"
- Develops logic-first treatment of XML prompting

**Use For Pages:** XML Containerization

---

## 13. AI BIAS & FAIRNESS

### University of Melbourne Study
**Type:** Research Study
**Date:** 2025

**Verified Finding:**
- "AI-powered hiring tools struggled to accurately evaluate candidates with speech disabilities or heavy non-native accents, leading to unfair scoring."

**Use For Pages:** Ethics & Safety

---

### Credit Scoring Bias
**Type:** Research Study
**Date:** June 2025

**Verified Finding:**
- "Around 45% of consumer lenders and 65% of mortgage lenders in the US have integrated AI into their credit score models."
- "Female borrowers systematically receive lower credit scores despite lower observed default rates."

**Use For Pages:** Ethics & Safety

---

### Healthcare AI Disparities
**URL:** (Dermis journal)
**Type:** Research Study
**Date:** April 2025

**Verified Finding:**
- "Significant disparities in how AI identifies malignant lesions across demographics—most AI models are trained on datasets predominantly featuring fair-skinned patients."

**Use For Pages:** Ethics & Safety

---

## 14. STATE EDUCATION GUIDANCE

### California Department of Education
**URL:** https://www.cde.ca.gov/ci/pl/aiincalifornia.asp
**Type:** State Guidance
**Date:** 2025

**Verified Information:**
- California emphasizes "learning about AI—how it functions, its benefits, and its risks—and learning with AI, ensuring students and educators use emerging tools effectively and ethically."

**Use For Pages:** Implementation, Resources

---

### Georgia Department of Education
**Type:** State Framework
**Date:** January 2025

**Verified Information:**
- Framework for implementing AI in K-12 education, focusing on ethical, effective, and secure use.

**Use For Pages:** Implementation

---

### New Mexico AI Guidance
**Type:** State Guidance
**Date:** May 2025

**Verified Information:**
- "AI Guidance for K-12 Education 1.0 provides comprehensive guidance for schools and districts to responsibly integrate artificial intelligence into teaching and learning."

**Use For Pages:** Implementation

---

## SOURCES TO AVOID (Fabricated/Unverifiable)

The following source attributions were previously used but are NOT verifiable:

- ❌ "Stanford HAI, 2025" (generic quote without specific report)
- ❌ "MIT Media Lab, 2025" (generic quote without specific study)
- ❌ "MIT CSAIL, 2025" (generic quote without specific paper)
- ❌ Any percentage or statistic without a linked source
- ❌ Any quote that cannot be traced to a specific URL

---

## Usage Guidelines

1. **Always link to the source URL** when using quotes or statistics
2. **Use the exact wording** from verified sources
3. **Include publication date** in citations
4. **Prefer specific studies** over general institutional claims
5. **When in doubt, omit** - no fabricated sources

---

## Pull Quote Recommendations by Page

### Prompt Basics
**Recommended:** CMU ROPE research quote
> "You need to be able to tell the model exactly what you want. You can't expect it to guess all your customized needs."
> — Christina Ma, CMU Human-Computer Interaction Institute, 2025

### CRISP / CRISPE / COSTAR (Foundations)
**Recommended:** CAST UDL quote
> "Everyone brings unique perspectives and experiences to learning, and every brain is as different as a fingerprint."
> — CAST.org, 2025

### Chain of Thought
**Recommended:** Wharton research finding
> "For dedicated reasoning models, the added benefits of explicit CoT prompting appear negligible and may not justify the substantial increase in processing time."
> — Wharton Generative AI Labs, June 2025

### Creativity
**Recommended:** Harvard D^3 finding
> "While human ingenuity is vital for novel ideas, AI excels at generating high-quality, scalable solutions."
> — Harvard Digital Data Design Institute, January 2025

### Ethics & Safety
**Recommended:** EDUCAUSE principles
> "Transparency and Explainability: Providing clear, understandable information about how AI systems operate."
> — EDUCAUSE AI Ethical Guidelines, June 2025

### Accessibility & AI
**Recommended:** U.S. Dept of Education
> "AI tools or systems should be accessible for those who require digital accessibility accommodations, including children, educators, providers, and family members with disabilities."
> — U.S. Department of Education, July 2025

### Implementation
**Recommended:** MIT Sloan finding
> "By 2027, 72 percent of employees will collaborate with GenAI in some capacity."
> — MIT Initiative on the Digital Economy, 2025
