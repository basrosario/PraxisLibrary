<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="The complete history of AI from 1950 to 2026 — from Turing's first question through AI Winters, deep learning, transformers, and the agentic frontier. Covering AI 1.0 through AI 4.0, 58+ prompt engineering techniques, and 29 academic citations.">
    <!-- SEO Meta -->
    <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">
    <meta name="author" content="Praxis Library">
    <meta name="theme-color" content="#DC3545">
    <link rel="canonical" href="https://praxislibrary.com/foundations/">
    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="AI History: The Evolution of Human-Machine Communication - Praxis">
    <meta property="og:description" content="The complete history of AI from 1950 to 2026 — from Turing's first question through AI Winters, deep learning, transformers, and the agentic frontier. Covering AI 1.0 through AI 4.0, 58+ prompt engineering techniques, and 29 academic citations.">
    <meta property="og:url" content="https://praxislibrary.com/foundations/">
    <meta property="og:image" content="https://praxislibrary.com/assets/images/praxishome.png">
    <meta property="og:site_name" content="Praxis Library">
    <meta property="og:locale" content="en_US">
    <!-- Social Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="AI History: The Evolution of Human-Machine Communication - Praxis">
    <meta name="twitter:description" content="The complete history of AI from 1950 to 2026 — from Turing's first question through AI Winters, deep learning, transformers, and the agentic frontier. Covering AI 1.0 through AI 4.0, 58+ prompt engineering techniques, and 29 academic citations.">
    <meta name="twitter:image" content="https://praxislibrary.com/assets/images/praxishome.png">
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@type": "Article",
      "headline": "AI History: The Evolution of Human-Machine Communication",
      "description": "The complete history of AI from 1950 to 2026 — AI 1.0 through AI 4.0, covering Turing, AI Winters, deep learning, transformers, prompt engineering taxonomy, and the agentic frontier. 29 academic citations.",
      "url": "https://praxislibrary.com/foundations/",
      "inLanguage": "en-US",
      "isAccessibleForFree": true,
      "publisher": {
        "@type": "EducationalOrganization",
        "name": "Praxis Library",
        "alternateName": "The Open Standard in AI Literacy",
        "url": "https://praxislibrary.com",
        "logo": "https://praxislibrary.com/favicon.svg",
        "description": "A comprehensive, living library of 5,000+ AI terms, 177 techniques & frameworks, and interactive tools. The definitive open resource for AI literacy, prompt engineering, and human-AI communication.",
        "sameAs": [
          "https://www.tiktok.com/@thepraxislibrary",
          "https://www.facebook.com/profile.php?id=61587612308104",
          "https://github.com/PowerOfPraxis/PraxisLibrary"
        ],
        "knowsAbout": [
          "Artificial Intelligence",
          "AI Literacy",
          "Prompt Engineering",
          "AI Prompting Techniques",
          "AI Glossary",
          "Large Language Models",
          "Chain-of-Thought Prompting",
          "AI Education",
          "Human-AI Communication",
          "Neurodivergence and AI",
          "AI Safety",
          "AI Ethics"
        ]
      },
      "isPartOf": {
        "@type": "WebSite",
        "name": "Praxis Library",
        "url": "https://praxislibrary.com"
      }
    },
    {
      "@type": "BreadcrumbList",
      "itemListElement": [
        {
          "@type": "ListItem",
          "position": 1,
          "name": "Home",
          "item": "https://praxislibrary.com"
        },
        {
          "@type": "ListItem",
          "position": 2,
          "name": "AI History",
          "item": "https://praxislibrary.com/foundations/"
        },
        {
          "@type": "ListItem",
          "position": 3,
          "name": "AI History: The Evolution of Human-Machine Communication"
        }
      ]
    }
  ]
}
    </script>
    <!-- /SEO -->

<title>AI History: The Evolution of Human-Machine Communication - Praxis</title>
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <a href="#main-content" class="skip-link">Skip to main content</a>

    <!-- Header -->
        <header class="header" id="header">
        <div class="header-container">
            <a href="../index.html" class="logo">&lt;/Praxis <span>Library</span>&gt;</a>
            <nav class="nav" id="nav" aria-label="Main navigation">
                <a href="../foundations/index.html" class="nav-link active">History</a>
                <div class="nav-item has-dropdown">
                    <a href="../learn/index.html" class="nav-link" aria-expanded="false">Discover</a>
                                        <div class="mega-menu mega-menu--categories">
                        <div class="mega-menu-quick-links">
                            <a href="../learn/index.html">Prompt Engineering</a>
                            <a href="../learn/prompt-basics.html">Prompt Basics</a>
                            <a href="../learn/facts-fictions.html">Facts &amp; Fictions</a>
                            <a href="../pages/glossary.html">Glossary</a>
                        </div>
                    </div>
                </div>
                <div class="nav-item has-dropdown">
                    <a href="../tools/index.html" class="nav-link" aria-expanded="false">Readiness</a>
                    <div class="mega-menu">
                        <div class="mega-menu-section">
                            <h4>Tools</h4>
                            <a href="../quiz/index.html">Readiness Quiz</a>
                            <a href="../tools/analyzer.html">Prompt Analyzer</a>
                            <a href="../tools/guidance.html">Prompt Builder</a>
                            <a href="../tools/matcher.html">Technique Finder</a>
                            <a href="../tools/checklist.html">Preflight Checklist</a>
                            <a href="../tools/persona.html">Persona Architect</a>
                            <a href="../tools/hallucination.html">Hallucination Spotter</a>
                            <a href="../patterns/index.html">Patterns Library</a>
                            <a href="../pages/ai-safety.html">AI Safety</a>
                        </div>
                    </div>
                </div>
                <div class="nav-item has-dropdown">
                    <a href="../pages/resources.html" class="nav-link" aria-expanded="false">Resources</a>
                    <div class="mega-menu mega-menu--categories">
                        <div class="mega-menu-quick-links">
                            <a href="../pages/responsible-ai.html">Responsible AI</a>
                            <a href="../neurodivergence/resources.html">ND Resources</a>
                            <a href="../benchmarks/index.html">AI Benchmarks</a>
                            <a href="../pages/audit-report.html">Audit Report</a>
                            <a href="../pages/about.html">About Praxis</a>
                            <a href="../pages/faq.html">FAQs</a>
                        </div>
                    </div>
                </div>
            </nav>
            <button class="menu-toggle" id="menuToggle" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>
    </header>

    <main id="main-content">
        <!-- === HERO SECTION === -->
        <section class="page-hero page-hero--tall">
            <canvas id="page-hero-neural-bg" class="page-hero-neural-bg"></canvas>
            <div class="container">
                <nav class="breadcrumb fade-in" aria-label="Breadcrumb">
                    <a href="../index.html">Home</a>
                    <span class="separator">/</span>
                    <span class="current">AI History</span>
                </nav>
                <div class="hero-badge" data-aos="fade-down">
                    <span class="hero-badge__icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <circle cx="12" cy="12" r="10"/>
                            <polyline points="12 6 12 12 16 14"/>
                        </svg>
                    </span>
                    <span class="hero-badge__text">Research-Verified Timeline</span>
                </div>
                <h1 class="page-title fade-in">The History of Modern AI</h1>
                <p class="page-subtitle fade-in">From Alan Turing's 1950 question "Can machines think?" through the AI Winters, deep learning revolution, and transformer era — to the agentic and physical AI frontier of 2026. Every milestone below is backed by peer-reviewed research and 29 academic citations.</p>
            </div>
        </section>
        <!-- /HERO SECTION -->

        <!-- === SITE BADGES === -->
        <section class="section">
            <div class="container">
                <div class="content-badges fade-in-up">
                    <span class="content-badge content-badge--ai" data-badge-type="ai">
                        <span class="badge-label">AI for</span>
                        <span class="badge-value">Everybody</span>
                    </span>
                    <span class="content-badge content-badge--udl" data-badge-type="udl">
                        <span class="badge-label">Built With</span>
                        <span class="badge-value">UD/UDL</span>
                    </span>
                    <span class="content-badge content-badge--security" data-badge-type="security">
                        <span class="badge-label">Security</span>
                        <span class="badge-value">A+ 100%</span>
                    </span>
                    <span class="content-badge content-badge--performance" data-badge-type="performance">
                        <span class="badge-label">Performance</span>
                        <span class="badge-value">100%</span>
                    </span>
                    <span class="content-badge content-badge--claude" data-badge-type="claude">
                        <span class="badge-label">AI Assisted Building</span>
                        <span class="badge-value">Claude Code</span>
                    </span>
                    <a href="https://github.com/PowerOfPraxis/PraxisLibrary" target="_blank" rel="noopener noreferrer" class="content-badge content-badge--github" data-badge-type="github">
                        <span class="badge-label">Community</span>
                        <span class="badge-value">GitHub</span>
                    </a>
                </div>
            </div>
        </section>
        <!-- /SITE BADGES -->

        <!-- === ERA NAVIGATION === -->
        <div id="era-nav-sentinel"></div>
        <nav class="foundations-nav fade-in-up" aria-label="Era navigation">
            <a href="#era-genesis" class="foundations-nav__btn active">The Genesis<span>1950-65</span></a>
            <a href="#era-winters" class="foundations-nav__btn">Winters &amp; Revivals<span>1966-99</span></a>
            <a href="#era-deep-learning" class="foundations-nav__btn">Deep Learning<span>2000-16</span></a>
            <a href="#era-transformers" class="foundations-nav__btn">Transformers<span>2017-22</span></a>
            <a href="#era-prompting" class="foundations-nav__btn">Prompt Engineering<span>2022-24</span></a>
            <a href="#era-agentic" class="foundations-nav__btn">Agentic &amp; Physical AI<span>2024-26</span></a>
            <a href="#era-governance" class="foundations-nav__btn">Governance &amp; Future<span>2025+</span></a>
        </nav>
        <!-- /ERA NAVIGATION -->

        <!-- === ERA 1: THE GENESIS === -->
        <section class="section section-alt" id="era-genesis">
            <div class="container">
                <div class="era-header fade-in-up">
                    <span class="era-header__dates">1950 - 1965<span class="era-header__type">Information</span></span>
                    <h2 class="era-header__title">Era I: The Genesis</h2>
                    <p class="era-header__subtitle">AI 1.0 — When humanity first asked if machines could think, and built the first ones that could reason</p>
                </div>

                <div class="history-timeline fade-in-up">
                    <!-- 1950: Turing Test -->
                    <div class="history-event history-event--landmark" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">1950</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Question That Started It All</span>
                            <h3 class="history-event__title">Alan Turing Publishes "Computing Machinery and Intelligence"</h3>
                            <p class="history-event__text">English mathematician Alan Turing posed the question that would define a field: "Can machines think?" His paper introduced the "imitation game"—now known as the Turing Test—proposing that if a machine could convince a human interrogator it was human through conversation alone, it could be considered intelligent. This was not merely a technical benchmark but a philosophical maneuver to bypass the definition of "thinking" in favor of indistinguishability.</p>
                            <div class="history-event__quote">
                                <blockquote>"I propose to consider the question, 'Can machines think?'"</blockquote>
                                <cite>— Alan Turing, 1950<sup>[1]</sup></cite>
                            </div>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Established the behavioral standard for evaluating machine intelligence for the next century of research</span>
                            </div>
                        </div>
                    </div>

                    <!-- 1956: Dartmouth -->
                    <div class="history-event history-event--landmark" data-type="event">
                        <div class="history-event__marker">
                            <span class="history-event__year">1956</span>
                            <span class="history-event__type">Event</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Birth of a Field</span>
                            <h3 class="history-event__title">The Dartmouth Workshop: AI Gets Its Name</h3>
                            <p class="history-event__text">At Dartmouth College, John McCarthy, Marvin Minsky, Claude Shannon, and Nathaniel Rochester gathered for an eight-week summer workshop. McCarthy coined the term "Artificial Intelligence" in the proposal, founded on the conjecture that "every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it."</p>
                            <div class="history-event__participants">
                                <span class="history-event__participants-label">Key Participants:</span>
                                <div class="history-event__participant-list">
                                    <span>John McCarthy</span>
                                    <span>Marvin Minsky</span>
                                    <span>Claude Shannon</span>
                                    <span>Nathaniel Rochester</span>
                                    <span>Allen Newell</span>
                                    <span>Herbert Simon</span>
                                </div>
                            </div>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Established AI as an academic discipline and research field<sup>[2]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 1956: Logic Theorist -->
                    <div class="history-event history-event--framework" data-type="milestone">
                        <div class="history-event__marker">
                            <span class="history-event__year">1956</span>
                            <span class="history-event__type">Milestone</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The First Reasoning Program</span>
                            <h3 class="history-event__title">The Logic Theorist: Machine-Driven Mathematical Proof</h3>
                            <p class="history-event__text">Created by Allen Newell, Cliff Shaw, and Herbert Simon, the Logic Theorist proved 38 of the first 52 theorems in Whitehead and Russell's Principia Mathematica. It was the first operational program to mimic human-like analytical reasoning, effectively launching the field of automated theorem proving.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Demonstrated that machines could perform non-numerical reasoning<sup>[12]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 1957: GPS -->
                    <div class="history-event" data-type="milestone">
                        <div class="history-event__marker">
                            <span class="history-event__year">1957</span>
                            <span class="history-event__type">Milestone</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">Universal Problem Solving</span>
                            <h3 class="history-event__title">The General Problem Solver (GPS)</h3>
                            <p class="history-event__text">Also by Newell and Simon at RAND Corporation, GPS introduced "means-ends analysis" — a heuristic that minimized the distance between a current state and a goal state. While theoretically universal, it suffered from the "combinatorial explosion" when applied to complex, real-world problems — a limitation that would define AI's first major challenge.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Pioneered heuristic search strategies still used in AI planning today<sup>[13]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 1958: LISP -->
                    <div class="history-event history-event--framework" data-type="milestone">
                        <div class="history-event__marker">
                            <span class="history-event__year">1958</span>
                            <span class="history-event__type">Milestone</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Language of AI</span>
                            <h3 class="history-event__title">LISP: John McCarthy Creates AI's Lingua Franca</h3>
                            <p class="history-event__text">Unlike Fortran, which was designed for number crunching, LISP (List Processor) was designed for symbol manipulation. It introduced recursion and the ability to process lists of symbols, becoming the dominant programming language of AI research for decades. LISP's flexibility made it the foundation for expert systems, natural language processing, and knowledge representation.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Defined the programming paradigm for AI research through the 1990s<sup>[14]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 1958: Perceptron -->
                    <div class="history-event history-event--landmark" data-type="milestone">
                        <div class="history-event__marker">
                            <span class="history-event__year">1958</span>
                            <span class="history-event__type">Milestone</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Ancestor of Neural Networks</span>
                            <h3 class="history-event__title">The Perceptron: Frank Rosenblatt's Brain-Inspired Machine</h3>
                            <p class="history-event__text">At the Cornell Aeronautical Laboratory, Frank Rosenblatt invented the Perceptron — a probabilistic model inspired by biological neurons, capable of learning from inputs. The media hype was enormous: Rosenblatt promised it would eventually "walk, talk, see, write, reproduce itself and be conscious of its existence." This hype cycle would later haunt the field.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Planted the seed for all modern neural networks and deep learning<sup>[15]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 1959: Samuel Checkers -->
                    <div class="history-event" data-type="milestone">
                        <div class="history-event__marker">
                            <span class="history-event__year">1959</span>
                            <span class="history-event__type">Milestone</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">Machines That Learn</span>
                            <h3 class="history-event__title">Arthur Samuel's Checkers Program: Early Machine Learning</h3>
                            <p class="history-event__text">Arthur Samuel at IBM created a checkers program that learned to play by playing against itself — one of the earliest demonstrations of machine learning. It disproved the widely held notion that computers could only do what they were explicitly told to do, showing they could improve through experience.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Coined the term "machine learning" and proved computers could learn from data<sup>[16]</sup></span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /ERA 1 -->

        <!-- === ERA 2: WINTERS & REVIVALS === -->
        <section class="section" id="era-winters">
            <div class="container">
                <div class="era-header fade-in-up">
                    <span class="era-header__dates">1966 - 1999<span class="era-header__type">Information</span></span>
                    <h2 class="era-header__title">Era II: Winters &amp; Revivals</h2>
                    <p class="era-header__subtitle">The first chatbot, two devastating winters, and the research that survived them</p>
                </div>

                <div class="history-timeline fade-in-up">
                    <!-- 1966: ELIZA -->
                    <div class="history-event" data-type="milestone">
                        <div class="history-event__marker">
                            <span class="history-event__year">1966</span>
                            <span class="history-event__type">Milestone</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The First Chatbot</span>
                            <h3 class="history-event__title">ELIZA: When Machines First Talked Back</h3>
                            <p class="history-event__text">MIT professor Joseph Weizenbaum created ELIZA, the world's first chatbot. Using simple pattern matching and substitution, ELIZA simulated a Rogerian psychotherapist. The response shocked even Weizenbaum — his secretary reportedly asked him to leave the room so she could speak with the program privately.</p>
                            <div class="history-event__quote">
                                <blockquote>"ELIZA created the most remarkable illusion of having understood."</blockquote>
                                <cite>— Joseph Weizenbaum<sup>[3]</sup></cite>
                            </div>
                            <div class="history-event__insight">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <path d="M12 16v-4"/>
                                    <path d="M12 8h.01"/>
                                </svg>
                                <span>ELIZA demonstrated that humans readily attribute understanding to machines — a phenomenon still relevant in prompt engineering today.</span>
                            </div>
                        </div>
                    </div>

                    <!-- 1966: ALPAC Report -->
                    <div class="history-event history-event--period" data-type="event">
                        <div class="history-event__marker">
                            <span class="history-event__year">1966</span>
                            <span class="history-event__type">Event</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Report That Froze a Field</span>
                            <h3 class="history-event__title">The ALPAC Report: Machine Translation Fails</h3>
                            <p class="history-event__text">The Automatic Language Processing Advisory Committee (ALPAC), convened by the U.S. government, released a damning report concluding that Machine Translation was slower, less accurate, and more expensive than human translation. The report famously noted that "The spirit is willing but the flesh is weak" was translated as "The vodka is strong but the meat is rotten." This led to a near-total cessation of U.S. government funding for computational linguistics.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Initiated the first "AI Winter" — a pattern of hype, disappointment, and funding collapse that would repeat<sup>[17]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 1969: Perceptrons Book -->
                    <div class="history-event history-event--period" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">1969</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Book That Killed Neural Networks</span>
                            <h3 class="history-event__title">"Perceptrons" by Minsky &amp; Papert</h3>
                            <p class="history-event__text">In a pivotal academic critique, Marvin Minsky and Seymour Papert published Perceptrons, which mathematically proved the limitations of single-layer neural networks — specifically their inability to solve non-linear problems like the XOR function. The book effectively froze funding for connectionist (neural network) research for over a decade, channeling all resources into symbolic AI.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Halted neural network research for 15+ years — would not recover until backpropagation in 1986<sup>[18]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 1973: Lighthill Report -->
                    <div class="history-event history-event--period" data-type="event">
                        <div class="history-event__marker">
                            <span class="history-event__year">1973</span>
                            <span class="history-event__type">Event</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The UK AI Collapse</span>
                            <h3 class="history-event__title">The Lighthill Report: Britain Abandons AI</h3>
                            <p class="history-event__text">In the UK, Sir James Lighthill's report to the Science Research Council criticized AI's failure to manage "combinatorial explosion" in real-world domains. His devastating assessment led to the dismantling of nearly all AI research funding in Britain, except at a few universities like Edinburgh. The combined impact of the ALPAC and Lighthill reports deepened the first AI Winter across the Western world.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Ended UK AI funding for a decade — established "combinatorial explosion" as AI's defining challenge<sup>[19]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 1980s: Expert Systems -->
                    <div class="history-event history-event--landmark" data-type="period">
                        <div class="history-event__marker">
                            <span class="history-event__year">1980s</span>
                            <span class="history-event__type">Period</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The AI Spring</span>
                            <h3 class="history-event__title">Expert Systems: Narrow AI Finds Commercial Success</h3>
                            <p class="history-event__text">AI found a new lease on life by narrowing its scope. Instead of "General Intelligence," researchers focused on encoding the specific knowledge of human experts into rule-based programs. Systems like MYCIN (diagnosing bacterial infections with 600 rules, outperforming junior doctors) and DENDRAL (inferring chemical structures) demonstrated real commercial viability. This success attracted billions in corporate and military funding.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Proved narrow AI had commercial value — but set the stage for another crash<sup>[20]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 1981: Fifth Generation -->
                    <div class="history-event" data-type="event">
                        <div class="history-event__marker">
                            <span class="history-event__year">1981</span>
                            <span class="history-event__type">Event</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The AI Arms Race</span>
                            <h3 class="history-event__title">Japan's Fifth Generation Computer Systems (FGCS)</h3>
                            <p class="history-event__text">Japan's Ministry of International Trade and Industry (MITI) launched a massive 10-year initiative to create "fifth generation" supercomputers based on massive parallelism and logic programming (Prolog). This spurred panicked reactions from the West, leading to the MCC consortium in the US and the Alvey program in the UK. The project would ultimately fail to meet its lofty goals.</p>
                        </div>
                    </div>

                    <!-- 1986: Backpropagation -->
                    <div class="history-event history-event--landmark" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">1986</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Return of Neural Networks</span>
                            <h3 class="history-event__title">Backpropagation: The Algorithm That Saved Connectionism</h3>
                            <p class="history-event__text">In a landmark paper, Rumelhart, Hinton, and Williams popularized the "backpropagation of errors" algorithm. This allowed multi-layer neural networks to learn internal representations, effectively solving the XOR problem that Minsky and Papert had identified in 1969. Backpropagation reignited interest in neural networks, though they remained computationally expensive for decades.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Resurrected neural network research — the foundational algorithm behind all modern deep learning<sup>[21]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 1987-1993: Second Winter -->
                    <div class="history-event history-event--period" data-type="period">
                        <div class="history-event__marker">
                            <span class="history-event__year">1987-93</span>
                            <span class="history-event__type">Period</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Second AI Winter</span>
                            <h3 class="history-event__title">The Lisp Machine Collapse</h3>
                            <p class="history-event__text">The market for specialized Lisp machines — hardware optimized for running AI code — collapsed when general-purpose workstations from Sun Microsystems and PCs became powerful enough to run the same software at a fraction of the cost. Companies like Symbolics and Lisp Machines Inc. failed. Combined with the failure of Japan's Fifth Generation project, this triggered another massive withdrawal of funding.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Proved that AI hardware monocultures are fragile — general-purpose computing won<sup>[22]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 1997: Deep Blue -->
                    <div class="history-event" data-type="event">
                        <div class="history-event__marker">
                            <span class="history-event__year">1997</span>
                            <span class="history-event__type">Event</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">Machine vs. World Champion</span>
                            <h3 class="history-event__title">Deep Blue Defeats Garry Kasparov</h3>
                            <p class="history-event__text">IBM's Deep Blue defeated World Chess Champion Garry Kasparov in a six-game match. While a landmark for public perception of AI, it was technically a victory for "brute-force" search (alpha-beta pruning) and custom hardware rather than "learning" or "intelligence" in the modern cognitive sense. Kasparov later became an advocate for human-AI collaboration.</p>
                            <div class="history-event__insight">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <path d="M12 16v-4"/>
                                    <path d="M12 8h.01"/>
                                </svg>
                                <span>Deep Blue could evaluate 200 million positions per second but had no understanding of chess strategy — a key distinction between computation and intelligence.</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /ERA 2 -->

        <!-- === ERA 3: THE DEEP LEARNING REVOLUTION === -->
        <section class="section section-alt" id="era-deep-learning">
            <div class="container">
                <div class="era-header fade-in-up">
                    <span class="era-header__dates">2000 - 2016<span class="era-header__type">Information</span></span>
                    <h2 class="era-header__title">Era III: The Deep Learning Revolution</h2>
                    <p class="era-header__subtitle">AI 2.0 — Big data, GPUs, and the rediscovery of neural networks</p>
                </div>

                <div class="history-timeline fade-in-up">
                    <!-- 2000s: Probabilistic Reasoning -->
                    <div class="history-event history-event--period" data-type="period">
                        <div class="history-event__marker">
                            <span class="history-event__year">2000s</span>
                            <span class="history-event__type">Period</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Statistical Turn</span>
                            <h3 class="history-event__title">Probabilistic Reasoning Replaces Rigid Logic</h3>
                            <p class="history-event__text">As the limitations of symbolic AI became clear, the field adopted probabilistic methods. Hidden Markov Models (HMMs) revolutionized speech recognition, Support Vector Machines (SVMs) became the standard for classification tasks, and Bayesian networks provided a rigorous mathematical foundation for reasoning under uncertainty. The convergence of massive internet datasets ("Big Data") and GPU computing set the stage for the deep learning breakthrough.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Shifted AI from hand-crafted rules to data-driven learning<sup>[23]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 2012: AlexNet -->
                    <div class="history-event history-event--landmark" data-type="milestone">
                        <div class="history-event__marker">
                            <span class="history-event__year">2012</span>
                            <span class="history-event__type">Milestone</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Moment Everything Changed</span>
                            <h3 class="history-event__title">AlexNet Wins ImageNet: Deep Learning Arrives</h3>
                            <p class="history-event__text">The pivotal turning point occurred at the ImageNet Large Scale Visual Recognition Challenge. A team led by Geoffrey Hinton (using a deep convolutional neural network named AlexNet) achieved a top-5 error rate of 15.3%, crushing the next best entry at 26.2% by a massive 11-point margin. This proved the superiority of deep learning over manual feature extraction and triggered the modern AI gold rush.</p>
                            <div class="history-event__authors">
                                <span class="history-event__authors-label">Authors:</span>
                                <span>Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton (University of Toronto)</span>
                            </div>
                            <div class="history-event__stats">
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">15.3%</span>
                                    <span class="history-event__stat-label">Top-5 error rate</span>
                                </div>
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">11pts</span>
                                    <span class="history-event__stat-label">Margin over 2nd place</span>
                                </div>
                            </div>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Launched the modern deep learning era — every major AI company pivoted to neural networks<sup>[24]</sup></span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /ERA 3 -->

        <!-- === ERA 4: THE TRANSFORMER ERA === -->
        <section class="section" id="era-transformers">
            <div class="container">
                <div class="era-header fade-in-up">
                    <span class="era-header__dates">2017 - 2022<span class="era-header__type">Information</span></span>
                    <h2 class="era-header__title">Era IV: The Transformer Era</h2>
                    <p class="era-header__subtitle">A new architecture, the birth of large language models, and the ChatGPT moment</p>
                </div>

                <div class="history-timeline fade-in-up">
                    <!-- 2017: Attention Is All You Need -->
                    <div class="history-event history-event--landmark" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">2017</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Paper That Changed AI</span>
                            <h3 class="history-event__title">"Attention Is All You Need" — The Transformer Architecture</h3>
                            <p class="history-event__text">Vaswani et al. at Google published what would become one of the most cited papers in AI history. The Transformer architecture replaced recurrent neural networks with a novel "attention mechanism" that could process entire sequences at once, allowing for massive parallelization in training and enabling the creation of Large Language Models (LLMs).</p>
                            <div class="history-event__authors">
                                <span class="history-event__authors-label">Authors:</span>
                                <span>Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, Polosukhin</span>
                            </div>
                            <div class="history-event__stats">
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">173,000+</span>
                                    <span class="history-event__stat-label">Citations (as of 2025)</span>
                                </div>
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">Top 10</span>
                                    <span class="history-event__stat-label">Most-cited papers of 21st century</span>
                                </div>
                            </div>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Enabled GPT, BERT, and all modern large language models<sup>[4]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 2018: GPT-1 -->
                    <div class="history-event" data-type="event">
                        <div class="history-event__marker">
                            <span class="history-event__year">2018</span>
                            <span class="history-event__type">Event</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The First GPT</span>
                            <h3 class="history-event__title">GPT-1: "Improving Language Understanding by Generative Pre-Training"</h3>
                            <p class="history-event__text">OpenAI introduced the first Generative Pre-trained Transformer. With 117 million parameters trained on BookCorpus, GPT-1 pioneered the "pre-train then fine-tune" paradigm. Though modest by today's standards, it proved that unsupervised pre-training could dramatically improve downstream task performance.</p>
                            <div class="history-event__stats">
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">117M</span>
                                    <span class="history-event__stat-label">Parameters</span>
                                </div>
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">12</span>
                                    <span class="history-event__stat-label">Transformer layers</span>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- 2019: GPT-2 -->
                    <div class="history-event" data-type="event">
                        <div class="history-event__marker">
                            <span class="history-event__year">2019</span>
                            <span class="history-event__type">Event</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">Scale Matters</span>
                            <h3 class="history-event__title">GPT-2: Too Dangerous to Release?</h3>
                            <p class="history-event__text">OpenAI scaled up by 10x in both parameters and training data. GPT-2's ability to generate coherent, multi-paragraph text was so striking that OpenAI initially withheld the full model, citing concerns about potential misuse. This "staged release" sparked debate about AI safety and responsible development.</p>
                            <div class="history-event__stats">
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">1.5B</span>
                                    <span class="history-event__stat-label">Parameters</span>
                                </div>
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">40GB</span>
                                    <span class="history-event__stat-label">Training data (WebText)</span>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- 2020: GPT-3 -->
                    <div class="history-event history-event--landmark" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">2020</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">NeurIPS 2020</span>
                            <h3 class="history-event__title">"Language Models are Few-Shot Learners" — The GPT-3 Paper</h3>
                            <p class="history-event__text">Brown et al. demonstrated that sufficiently large language models could perform new tasks from just a few examples in the prompt — no fine-tuning required. This "in-context learning" discovery was the birth of modern prompt engineering. The paper showed that the way you frame a request fundamentally changes the output.</p>
                            <div class="history-event__authors">
                                <span class="history-event__authors-label">Lead Authors:</span>
                                <span>Tom Brown, Benjamin Mann, Nick Ryder et al. (OpenAI)</span>
                            </div>
                            <div class="history-event__stats">
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">175B</span>
                                    <span class="history-event__stat-label">Parameters</span>
                                </div>
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">Few-Shot</span>
                                    <span class="history-event__stat-label">Learning paradigm</span>
                                </div>
                            </div>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Established that prompting is a valid alternative to fine-tuning<sup>[5]</sup></span>
                            </div>
                            <a href="../learn/few-shot-learning.html" class="history-event__link">Learn Few-Shot Prompting &rarr;</a>
                        </div>
                    </div>

                    <!-- 2020-2022: Instruction Tuning -->
                    <div class="history-event history-event--framework" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">2020-22</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">From Text Completors to Assistants</span>
                            <h3 class="history-event__title">Instruction Tuning: Aligning Models With Human Intent</h3>
                            <p class="history-event__text">Models like GPT-3 demonstrated that scaling up parameters led to emergent capabilities, but base models were difficult to control. The introduction of Instruction Tuning (InstructGPT, FLAN) was a critical milestone. By fine-tuning models on datasets of (instruction, output) pairs, researchers aligned the models with user intent — transforming them from unpredictable "text completors" into controllable "assistants."</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Made LLMs usable for everyday tasks — the bridge between research and product<sup>[25]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- November 2022: ChatGPT -->
                    <div class="history-event history-event--landmark" data-type="event">
                        <div class="history-event__marker">
                            <span class="history-event__year">Nov 30, 2022</span>
                            <span class="history-event__type">Event</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Day Everything Changed</span>
                            <h3 class="history-event__title">ChatGPT Launches to the Public</h3>
                            <p class="history-event__text">OpenAI released ChatGPT, a dialogue-optimized model using Reinforcement Learning from Human Feedback (RLHF). This marked the "Netscape moment" for AI, moving it from research labs to public utility. The world discovered prompt engineering overnight. It reached 100 million users in two months — the fastest-growing consumer application in history.</p>
                            <div class="history-event__stats">
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">1M</span>
                                    <span class="history-event__stat-label">Users in 5 days</span>
                                </div>
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">100M</span>
                                    <span class="history-event__stat-label">Users in 2 months</span>
                                </div>
                            </div>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Brought prompt engineering from research labs to everyday users<sup>[10]</sup></span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /ERA 4 -->

        <!-- === ERA 5: THE PROMPT ENGINEERING ERA === -->
        <section class="section section-alt" id="era-prompting">
            <div class="container">
                <div class="era-header fade-in-up">
                    <span class="era-header__dates">2022 - 2024<span class="era-header__type">Information</span></span>
                    <h2 class="era-header__title">Era V: The Prompt Engineering Era</h2>
                    <p class="era-header__subtitle">The Schulhoff Taxonomy — 58 text-based and 40 multimodal techniques catalogued</p>
                </div>

                <div class="history-timeline fade-in-up">
                    <!-- January 2022: Chain-of-Thought -->
                    <div class="history-event history-event--framework" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">Jan 2022</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">arXiv:2201.11903</span>
                            <h3 class="history-event__title">"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"</h3>
                            <p class="history-event__text">Wei et al. at Google Brain discovered that adding intermediate reasoning steps to prompts dramatically improved performance on complex tasks. By showing the AI how to "think step by step," accuracy on math and reasoning tasks jumped significantly. This foundational technique spawned an entire family of reasoning architectures.</p>
                            <div class="history-event__quote">
                                <blockquote>"Chain of thought prompting... significantly improves the ability of large language models to perform complex reasoning."</blockquote>
                                <cite>— Wei et al., 2022<sup>[6]</sup></cite>
                            </div>
                            <a href="../learn/chain-of-thought.html" class="history-event__link">Learn Chain-of-Thought &rarr;</a>
                        </div>
                    </div>

                    <!-- May 2022: Zero-Shot CoT -->
                    <div class="history-event history-event--framework" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">May 2022</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">arXiv:2205.11916</span>
                            <h3 class="history-event__title">"Large Language Models are Zero-Shot Reasoners"</h3>
                            <p class="history-event__text">Kojima et al. made a startling discovery: simply adding "Let's think step by step" to any prompt dramatically improved reasoning performance — no examples needed. Five words that improved reasoning by 30-50%. The most powerful prompting techniques are often surprisingly simple.</p>
                            <div class="history-event__quote">
                                <blockquote>"LLMs are decent zero-shot reasoners by simply adding 'Let's think step by step' before each answer."</blockquote>
                                <cite>— Kojima et al., 2022<sup>[8]</sup></cite>
                            </div>
                        </div>
                    </div>

                    <!-- October 2022: ReAct -->
                    <div class="history-event history-event--framework" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">Oct 2022</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">arXiv:2210.03629</span>
                            <h3 class="history-event__title">"ReAct: Synergizing Reasoning and Acting in Language Models"</h3>
                            <p class="history-event__text">Yao et al. from Princeton and Google unified reasoning and action-taking. ReAct prompts alternate between "Thought" and "Action," creating transparent, verifiable problem-solving traces. This became the blueprint for all modern AI agents.</p>
                            <div class="history-event__stats">
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">+34%</span>
                                    <span class="history-event__stat-label">ALFWorld success</span>
                                </div>
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">+10%</span>
                                    <span class="history-event__stat-label">WebShop success</span>
                                </div>
                            </div>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Enabled AI agents to reason, act, and self-correct<sup>[9]</sup></span>
                            </div>
                            <a href="../learn/react.html" class="history-event__link">Learn ReAct &rarr;</a>
                        </div>
                    </div>

                    <!-- 2024: The Prompt Report -->
                    <div class="history-event history-event--landmark" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">2024</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">Academic Synthesis</span>
                            <h3 class="history-event__title">"The Prompt Report" — The Schulhoff Taxonomy</h3>
                            <p class="history-event__text">Schulhoff et al. published the most comprehensive survey of prompting techniques to date, identifying 58 distinct text-based prompting techniques and 40 multimodal techniques. This moved the field beyond casual "prompt engineering" into rigorous "prompt architecture" — a legitimate research discipline with taxonomies, benchmarks, and formal evaluation methods.</p>
                            <div class="history-event__stats">
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">58</span>
                                    <span class="history-event__stat-label">Text techniques</span>
                                </div>
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">40</span>
                                    <span class="history-event__stat-label">Multimodal techniques</span>
                                </div>
                            </div>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Significance:</span>
                                <span>Prompt engineering recognized as a legitimate research discipline<sup>[11]</sup></span>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- === FRAMEWORKS DIRECTORY (SCHULHOFF TAXONOMY) === -->
                <div class="era-frameworks fade-in-up">
                    <h3 class="era-frameworks__title">The Complete Prompt Engineering Taxonomy</h3>
                    <p class="era-frameworks__subtitle">177+ Praxis Library techniques across 7 Schulhoff categories</p>

                    <!-- Input Manipulation & ICL -->
                    <div class="era-frameworks__category">
                        <h4 class="era-frameworks__category-title">Input Manipulation &amp; In-Context Learning</h4>
                        <div class="era-frameworks__grid">
                            <div class="era-frameworks__item">
                                <a href="../learn/few-shot-learning.html" class="era-frameworks__link">Few-Shot Learning</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/zero-shot.html" class="era-frameworks__link">Zero-Shot</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/one-shot.html" class="era-frameworks__link">One-Shot</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/role-prompting.html" class="era-frameworks__link">Role Prompting</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/knn-prompting.html" class="era-frameworks__link">KNN Prompting</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/vote-k.html" class="era-frameworks__link">Vote-k</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/example-selection.html" class="era-frameworks__link">Example Selection</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/complexity-prompting.html" class="era-frameworks__link">Complexity-Based</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                        </div>
                    </div>

                    <!-- Thought Generation & Reasoning -->
                    <div class="era-frameworks__category">
                        <h4 class="era-frameworks__category-title">Thought Generation &amp; Reasoning</h4>
                        <div class="era-frameworks__grid">
                            <div class="era-frameworks__item">
                                <a href="../learn/chain-of-thought.html" class="era-frameworks__link">Chain-of-Thought</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/zero-shot-cot.html" class="era-frameworks__link">Zero-Shot CoT</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/auto-cot.html" class="era-frameworks__link">Auto-CoT</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/tab-cot.html" class="era-frameworks__link">Tab-CoT</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/contrastive-cot.html" class="era-frameworks__link">Contrastive CoT</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/faithful-cot.html" class="era-frameworks__link">Faithful CoT</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/structured-cot.html" class="era-frameworks__link">Structured CoT</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/step-back.html" class="era-frameworks__link">Step-Back Prompting</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/thread-of-thought.html" class="era-frameworks__link">Thread of Thought</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/program-of-thought.html" class="era-frameworks__link">Program of Thought</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                        </div>
                    </div>

                    <!-- Decomposition & Planning -->
                    <div class="era-frameworks__category">
                        <h4 class="era-frameworks__category-title">Decomposition &amp; Planning</h4>
                        <div class="era-frameworks__grid">
                            <div class="era-frameworks__item">
                                <a href="../learn/least-to-most.html" class="era-frameworks__link">Least-to-Most</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/plan-and-solve.html" class="era-frameworks__link">Plan-and-Solve</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/decomp.html" class="era-frameworks__link">Decomposed Prompting</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/tree-of-thought.html" class="era-frameworks__link">Tree of Thought</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/graph-of-thought.html" class="era-frameworks__link">Graph of Thought</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/self-ask.html" class="era-frameworks__link">Self-Ask</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                        </div>
                    </div>

                    <!-- Ensembling & Self-Consistency -->
                    <div class="era-frameworks__category">
                        <h4 class="era-frameworks__category-title">Ensembling &amp; Self-Consistency</h4>
                        <div class="era-frameworks__grid">
                            <div class="era-frameworks__item">
                                <a href="../learn/self-consistency.html" class="era-frameworks__link">Self-Consistency</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/universal-self-consistency.html" class="era-frameworks__link">Universal Self-Consistency</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/diverse-prompting.html" class="era-frameworks__link">DiVeRSe</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/demo-ensembling.html" class="era-frameworks__link">Demo Ensembling</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/max-mutual-info.html" class="era-frameworks__link">Max Mutual Information</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/cosp.html" class="era-frameworks__link">COSP</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                        </div>
                    </div>

                    <!-- Self-Correction & Criticism -->
                    <div class="era-frameworks__category">
                        <h4 class="era-frameworks__category-title">Self-Correction &amp; Criticism</h4>
                        <div class="era-frameworks__grid">
                            <div class="era-frameworks__item">
                                <a href="../learn/self-refine.html" class="era-frameworks__link">Self-Refine</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/reflexion.html" class="era-frameworks__link">Reflexion</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/chain-of-verification.html" class="era-frameworks__link">Chain-of-Verification</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/reversing-cot.html" class="era-frameworks__link">Reversing CoT</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/self-calibration.html" class="era-frameworks__link">Self-Calibration</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/self-verification.html" class="era-frameworks__link">Self-Verification</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/critic.html" class="era-frameworks__link">CRITIC</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                        </div>
                    </div>

                    <!-- Structured & Applied Techniques -->
                    <div class="era-frameworks__category">
                        <h4 class="era-frameworks__category-title">Structured &amp; Applied Techniques</h4>
                        <div class="era-frameworks__grid">
                            <div class="era-frameworks__item">
                                <a href="../learn/crisp.html" class="era-frameworks__link">CRISP</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/crispe.html" class="era-frameworks__link">CRISPE</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/costar.html" class="era-frameworks__link">COSTAR</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/react.html" class="era-frameworks__link">ReAct</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/flipped-interaction.html" class="era-frameworks__link">Flipped Interaction</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/prompt-chaining.html" class="era-frameworks__link">Prompt Chaining</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/constrained-output.html" class="era-frameworks__link">Constrained Output</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/prompt-mining.html" class="era-frameworks__link">Prompt Mining</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                        </div>
                    </div>

                    <!-- Additional Techniques -->
                    <div class="era-frameworks__category">
                        <h4 class="era-frameworks__category-title">Advanced &amp; Multimodal Techniques</h4>
                        <div class="era-frameworks__grid">
                            <div class="era-frameworks__item">
                                <a href="../learn/s2a.html" class="era-frameworks__link">S2A (System 2 Attention)</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/simtom.html" class="era-frameworks__link">SimToM</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/emotion-prompting.html" class="era-frameworks__link">Emotion Prompting</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/style-prompting.html" class="era-frameworks__link">Style Prompting</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/rar.html" class="era-frameworks__link">RaR (Rephrase and Respond)</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/re2.html" class="era-frameworks__link">RE2 (Re-Reading)</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/dense-prompting.html" class="era-frameworks__link">Dense Prompting</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/active-prompting.html" class="era-frameworks__link">Active Prompting</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/memory-of-thought.html" class="era-frameworks__link">Memory of Thought</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/cumulative-reasoning.html" class="era-frameworks__link">Cumulative Reasoning</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/analogical-reasoning.html" class="era-frameworks__link">Analogical Reasoning</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/meta-reasoning.html" class="era-frameworks__link">Meta-Reasoning</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/recursion-of-thought.html" class="era-frameworks__link">Recursion of Thought</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/modality/code/self-debugging.html" class="era-frameworks__link">Self-Debugging</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/modality/code/code-prompting.html" class="era-frameworks__link">Code Prompting</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                            <div class="era-frameworks__item">
                                <a href="../learn/modality/code/structured-output.html" class="era-frameworks__link">Structured Output</a>
                                <span class="framework-status framework-status--active">2026 Verified - Active Prompting Technique</span>
                            </div>
                        </div>
                    </div>
                </div>
                <!-- /FRAMEWORKS DIRECTORY -->
            </div>
        </section>
        <!-- /ERA 5 -->

        <!-- === ERA 6: AGENTIC & PHYSICAL AI === -->
        <section class="section" id="era-agentic">
            <div class="container">
                <div class="era-header fade-in-up">
                    <span class="era-header__dates">2024 - 2026<span class="era-header__type">Information</span></span>
                    <h2 class="era-header__title">Era VI: Agentic &amp; Physical AI</h2>
                    <p class="era-header__subtitle">AI 2.0 maturity meets AI 3.0 — from chatbots to autonomous agents and embodied intelligence</p>
                </div>

                <div class="history-timeline fade-in-up">
                    <!-- 2023: GPT-4 -->
                    <div class="history-event history-event--landmark" data-type="event">
                        <div class="history-event__marker">
                            <span class="history-event__year">Mar 2023</span>
                            <span class="history-event__type">Event</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">Multimodal AI</span>
                            <h3 class="history-event__title">GPT-4: Vision, Reasoning, and Beyond</h3>
                            <p class="history-event__text">OpenAI released GPT-4, capable of understanding both text and images. The model showed remarkable improvements in reasoning, coding, and following complex instructions. Professional applications exploded as organizations integrated AI into core workflows.</p>
                        </div>
                    </div>

                    <!-- 2023-2024: Competition -->
                    <div class="history-event" data-type="period">
                        <div class="history-event__marker">
                            <span class="history-event__year">2023-24</span>
                            <span class="history-event__type">Period</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Model Wars</span>
                            <h3 class="history-event__title">Competition Accelerates Innovation</h3>
                            <p class="history-event__text">Anthropic launched Claude, Google released Gemini, and open-source models like Llama matured rapidly. Each model brought different strengths — Claude's constitutional AI approach, Gemini's multimodal native design, Llama's accessibility. Competition drove rapid improvement across the board.</p>
                        </div>
                    </div>

                    <!-- 2025: Agentic Tipping Point -->
                    <div class="history-event history-event--landmark" data-type="milestone">
                        <div class="history-event__marker">
                            <span class="history-event__year">2025</span>
                            <span class="history-event__type">Milestone</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Agentic Tipping Point</span>
                            <h3 class="history-event__title">Agentic AI Moves From Pilots to Production</h3>
                            <p class="history-event__text">Deloitte and MIT CISR identified 2025 as the year Agentic AI moved from pilots to production. The MIT Enterprise AI Maturity Model was updated to include "Agentic" as a distinct class alongside Analytical, Generative, and Robotic AI. Autonomous systems capable of setting goals, planning multi-step actions, using tools, and self-correcting began deploying in enterprise environments.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Defined four new AI business types: Customer Proxy, Modular Creator, Orchestrator, and Existing+<sup>[26]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- Late 2025: GenAI Mass Adoption -->
                    <div class="history-event history-event--landmark" data-type="milestone">
                        <div class="history-event__marker">
                            <span class="history-event__year">Late 2025</span>
                            <span class="history-event__type">Milestone</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Majority Threshold</span>
                            <h3 class="history-event__title">GenAI Outpaces the PC and the Internet</h3>
                            <p class="history-event__text">By late 2025, 54.6% of U.S. adults ages 18&ndash;64 had used generative AI &mdash; up from 44.6% just one year earlier. The Federal Reserve Bank of St. Louis confirmed that this adoption rate surpassed the historical diffusion curves of both the personal computer and the early internet in a comparable three-year window. ChatGPT alone scaled from its 100-million-user launch to over 800 million weekly active users. Workers spent 5.7% of their hours using generative AI, yielding an estimated 1.3% productivity boost across the U.S. economy.<sup><a href="#cite-30">[30]</a></sup><sup><a href="#cite-31">[31]</a></sup></p>
                            <div class="history-event__stats">
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">54.6%</span>
                                    <span class="history-event__stat-label">U.S. adult adoption</span>
                                </div>
                                <div class="history-event__stat">
                                    <span class="history-event__stat-value">800M</span>
                                    <span class="history-event__stat-label">Weekly active users</span>
                                </div>
                            </div>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Generative AI became a majority technology faster than any previous computing paradigm<sup><a href="#cite-30">[30]</a></sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 2025: Prompt Optimization -->
                    <div class="history-event history-event--framework" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">2025</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">From Prompting to Optimization</span>
                            <h3 class="history-event__title">DSPy, MIPRO, and byLLM: The End of Manual Prompting</h3>
                            <p class="history-event__text">The field shifted from human-written prompts to programmatic optimization. Stanford's DSPy treats prompts as optimization parameters — developers define "signatures" (Input &rarr; Output) and the compiler optimizes the prompts automatically. The University of Michigan's byLLM framework allows developers to integrate LLMs into code without manual prompt engineering, using code structure to generate context-aware prompts.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Moved from "prompt engineering" to "prompt compilation" — a fundamental paradigm shift<sup>[27]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- 2026: AgentFlow -->
                    <div class="history-event history-event--framework" data-type="research">
                        <div class="history-event__marker">
                            <span class="history-event__year">2026</span>
                            <span class="history-event__type">Research</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">ICLR 2026</span>
                            <h3 class="history-event__title">In-the-Flow Optimization: AgentFlow &amp; Flow-GRPO</h3>
                            <p class="history-event__text">Stanford's AgentFlow architecture introduced Flow-GRPO (Group Refined Policy Optimization), allowing agents to optimize their decision-making policies during the execution of a task — "in-the-flow." A "Verifier" module scores trajectory outcomes and broadcasts scores to update the planner's policy in real-time. This bridges the gap between fixed LLMs and Reinforcement Learning.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>The cutting edge of 2026 — agents that learn and improve while working<sup>[28]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- Physical AI -->
                    <div class="history-event history-event--landmark" data-type="period">
                        <div class="history-event__marker">
                            <span class="history-event__year">2024-26</span>
                            <span class="history-event__type">Period</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">AI 3.0: Physical AI</span>
                            <h3 class="history-event__title">Intelligence Enters the Physical World</h3>
                            <p class="history-event__text">The extension of intelligence into physical bodies (robots) defines AI 3.0, characterized by sensor fusion, SLAM (Simultaneous Localization and Mapping), and end-to-end deep control. Robots are no longer confined to cages but are inspecting power grids, assisting in surgery, and navigating city streets. Techniques like Agentic Lab integrate multi-agent reasoning with physical laboratory equipment, allowing AI to design experiments, execute them with robotic arms, and iteratively refine hypotheses without human intervention.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>The transition from AI 2.0 (software agents) to AI 3.0 (embodied agents) is underway<sup>[29]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- Current state -->
                    <div class="history-event history-event--current" data-type="current">
                        <div class="history-event__marker">
                            <span class="history-event__year">Now</span>
                            <span class="history-event__type">Current</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">The Present</span>
                            <h3 class="history-event__title">AI Communication as a Core Skill</h3>
                            <p class="history-event__text">With more than half of U.S. adults now using generative AI and 800 million people engaging weekly, the question is no longer &ldquo;Can machines think?&rdquo; but &ldquo;How do we communicate effectively with thinking machines?&rdquo; Prompt engineering has evolved from an arcane research technique to an essential professional skill. The next milestones will not be about better chatbots &mdash; they will be about agents that can navigate, reason, and act in the physical world.</p>
                            <div class="history-event__cta">
                                <a href="../learn/index.html" class="btn btn-primary">Explore All 177 Techniques & Frameworks &rarr;</a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /ERA 6 -->

        <!-- === AI GENERATIONS TABLE === -->
        <section class="section section-alt">
            <div class="container">
                <span class="section-eyebrow fade-in-up">The AI Taxonomy</span>
                <h2 class="section-title fade-in-up">Four Generations of Artificial Intelligence</h2>
                <p class="section-subtitle fade-in-up">From symbolic reasoning to embodied autonomy — the genealogical stratigraphy of AI</p>

                <div class="era-gen-table-wrapper fade-in-up">
                    <table class="era-gen-table">
                        <thead>
                            <tr>
                                <th>Generation</th>
                                <th>Core Goal</th>
                                <th>Dominant Technique</th>
                                <th>Hardware</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>AI 1.0 (1950s-2010s)</td>
                                <td>Reasoning &amp; Logic</td>
                                <td>Symbolic Rules, Expert Systems</td>
                                <td>CPU, Lisp Machines</td>
                            </tr>
                            <tr>
                                <td>AI 2.0 (2010s-2023)</td>
                                <td>Perception &amp; Generation</td>
                                <td>Deep Learning, Transformers</td>
                                <td>GPU, TPU</td>
                            </tr>
                            <tr>
                                <td>AI 3.0 (2024-Present)</td>
                                <td>Embodiment &amp; Agency</td>
                                <td>Sensor Fusion, Agentic Workflows</td>
                                <td>Edge Compute, Robotics</td>
                            </tr>
                            <tr>
                                <td>AI 4.0 (Future)</td>
                                <td>Autonomy &amp; Consciousness</td>
                                <td>Neuro-symbolic, Meta-RL</td>
                                <td>Neuromorphic Chips</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </section>
        <!-- /AI GENERATIONS TABLE -->

        <!-- === ERA 7: GOVERNANCE & FUTURE === -->
        <section class="section" id="era-governance">
            <div class="container">
                <div class="era-header fade-in-up">
                    <span class="era-header__dates">2025+<span class="era-header__type">Information</span></span>
                    <h2 class="era-header__title">Era VII: Governance &amp; the Future</h2>
                    <p class="era-header__subtitle">As AI shifts from passive processing to active physical agency, the steward's role evolves from archivist to safety overseer</p>
                </div>

                <div class="history-timeline fade-in-up">
                    <!-- NIST AI RMF -->
                    <div class="history-event history-event--landmark" data-type="policy">
                        <div class="history-event__marker">
                            <span class="history-event__year">2025</span>
                            <span class="history-event__type">Policy</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">Federal Safety Standards</span>
                            <h3 class="history-event__title">NIST AI Risk Management Framework: Agent Hijacking</h3>
                            <p class="history-event__text">The National Institute of Standards and Technology (NIST) expanded its AI Risk Management Framework to specifically address Agentic AI. New guidelines focus on "Agent Hijacking" — scenarios where an autonomous agent is manipulated into performing malicious actions via adversarial prompts injected into its environment (e.g., a website performing a "prompt injection" on a visiting agent).</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>Established federal safety standards for autonomous AI systems<sup>[30]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- FDA Agentic AI -->
                    <div class="history-event" data-type="policy">
                        <div class="history-event__marker">
                            <span class="history-event__year">2025</span>
                            <span class="history-event__type">Policy</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">Government Adoption</span>
                            <h3 class="history-event__title">FDA Deploys Agentic AI for Regulatory Workflows</h3>
                            <p class="history-event__text">In a landmark move, the U.S. Food and Drug Administration deployed Agentic AI for internal workflows, including pre-market reviews and inspections. The FDA also launched an "Agentic AI Challenge" to further develop these capabilities. This established a precedent for the federal use of autonomous systems in critical regulatory pipelines.</p>
                            <div class="history-event__impact">
                                <span class="history-event__impact-label">Impact:</span>
                                <span>First federal agency to deploy agentic AI for critical regulatory decisions<sup>[31]</sup></span>
                            </div>
                        </div>
                    </div>

                    <!-- Emerging Risks -->
                    <div class="history-event history-event--period" data-type="period">
                        <div class="history-event__marker">
                            <span class="history-event__year">2025-26</span>
                            <span class="history-event__type">Period</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">Critical Vulnerabilities</span>
                            <h3 class="history-event__title">Emerging Risks: The Reality Gap &amp; Spurious Correlations</h3>
                            <p class="history-event__text">Two critical vulnerabilities emerged in 2025-2026. The "Reality Gap" in Physical AI — the discrepancy between simulation training and real-world physics — remains a major safety concern. Research also confirmed that LLMs are highly sensitive to prompt formatting (the "Lost in the Middle" phenomenon), leading the industry to adopt rigorous validation frameworks like DSPy and Qually before deployment.</p>
                        </div>
                    </div>

                    <!-- AI 4.0 -->
                    <div class="history-event history-event--period" data-type="outlook">
                        <div class="history-event__marker">
                            <span class="history-event__year">Future</span>
                            <span class="history-event__type">Outlook</span>
                        </div>
                        <div class="history-event__content">
                            <span class="history-event__label">AI 4.0: The Speculative Frontier</span>
                            <h3 class="history-event__title">Self-Directed Adaptive Systems &amp; Machine Consciousness</h3>
                            <p class="history-event__text">While still theoretical, the 2025-2026 literature has shifted toward "Neuro-symbolic integration" and "Meta-Reinforcement Learning" (Meta-RL) to create systems that do not just learn tasks but learn how to learn tasks. AI 4.0 envisions self-directed systems capable of setting their own meta-goals, orchestrating their own training, and potentially exhibiting machine consciousness. The focus is on self-directed adaptive systems running on neuromorphic chips.</p>
                            <div class="history-event__insight">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <path d="M12 16v-4"/>
                                    <path d="M12 8h.01"/>
                                </svg>
                                <span>The timeline of AI is not a linear ascent but a punctuated equilibrium — defined by the Winters of 1966 and 1987 as much as by the Springs of 2012 and 2023.</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /ERA 7 -->

        <!-- === KEY INSIGHTS === -->
        <section class="section">
            <div class="container">
                <span class="section-eyebrow fade-in-up">Lessons from History</span>
                <h2 class="section-title fade-in-up">What 75 Years of AI Taught Us</h2>
                <p class="section-subtitle fade-in-up">Patterns and principles from the research</p>

                <div class="insight-cards fade-in-up">
                    <div class="insight-card">
                        <div class="insight-card__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M9 17H7a5 5 0 0 1 0-10h2"/>
                                <path d="M15 7h2a5 5 0 1 1 0 10h-2"/>
                                <line x1="8" y1="12" x2="16" y2="12"/>
                            </svg>
                        </div>
                        <h3 class="insight-card__title">Scale Unlocks Capabilities</h3>
                        <p class="insight-card__text">From GPT-1 to GPT-4, each 10x increase in scale revealed new emergent abilities. In-context learning, chain-of-thought reasoning, and instruction following all "emerged" at sufficient scale.</p>
                    </div>

                    <div class="insight-card">
                        <div class="insight-card__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <path d="M8 14s1.5 2 4 2 4-2 4-2"/>
                                <line x1="9" y1="9" x2="9.01" y2="9"/>
                                <line x1="15" y1="9" x2="15.01" y2="9"/>
                            </svg>
                        </div>
                        <h3 class="insight-card__title">Humans Anthropomorphize</h3>
                        <p class="insight-card__text">From ELIZA in 1966 to ChatGPT today, humans consistently attribute understanding to machines. Good prompt engineering works with this tendency, not against it.</p>
                    </div>

                    <div class="insight-card">
                        <div class="insight-card__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polygon points="12 2 2 7 12 12 22 7 12 2"/>
                                <polyline points="2 17 12 22 22 17"/>
                                <polyline points="2 12 12 17 22 12"/>
                            </svg>
                        </div>
                        <h3 class="insight-card__title">Techniques Compound</h3>
                        <p class="insight-card__text">Each prompting technique builds on those before. Chain-of-Thought enabled Self-Consistency. ReAct combined reasoning with action. The best results often combine multiple frameworks.</p>
                    </div>

                    <div class="insight-card">
                        <div class="insight-card__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M2 3h6a4 4 0 0 1 4 4v14a3 3 0 0 0-3-3H2z"/>
                                <path d="M22 3h-6a4 4 0 0 0-4 4v14a3 3 0 0 1 3-3h7z"/>
                            </svg>
                        </div>
                        <h3 class="insight-card__title">Simple Ideas Win</h3>
                        <p class="insight-card__text">"Let's think step by step"—five words that improved reasoning by 30-50%. The most powerful prompting techniques are often surprisingly simple. Clarity beats complexity.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- /KEY INSIGHTS -->

        <!-- === CITATIONS === -->
        <section class="section section-alt">
            <div class="container">
                <span class="section-eyebrow fade-in-up">Academic Sources</span>
                <h2 class="section-title fade-in-up">Citations &amp; References</h2>
                <p class="section-subtitle fade-in-up">All claims on this page are backed by peer-reviewed research, institutional archives, and primary sources</p>

                <div class="era-gen-table-wrapper fade-in-up">
                    <table class="era-gen-table era-gen-table--citations">
                        <thead>
                            <tr>
                                <th>#</th>
                                <th>Author(s)</th>
                                <th>Title</th>
                                <th>Source</th>
                                <th>Year</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr id="cite-1">
                                <td>1</td>
                                <td>Turing, A.M.</td>
                                <td><a href="https://doi.org/10.1093/mind/LIX.236.433" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Computing Machinery and Intelligence</a></td>
                                <td>Mind, 59(236), 433-460</td>
                                <td>1950</td>
                            </tr>
                            <tr id="cite-2">
                                <td>2</td>
                                <td>Dartmouth College</td>
                                <td><a href="https://home.dartmouth.edu/about/artificial-intelligence-ai-coined-dartmouth" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Artificial Intelligence (AI) Coined at Dartmouth</a></td>
                                <td>Dartmouth College Archives</td>
                                <td>1956</td>
                            </tr>
                            <tr id="cite-3">
                                <td>3</td>
                                <td>Weizenbaum, J.</td>
                                <td><a href="https://dl.acm.org/doi/10.1145/365153.365168" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">ELIZA — A Computer Program For the Study of Natural Language Communication</a></td>
                                <td>Communications of the ACM, 9(1), 36-45</td>
                                <td>1966</td>
                            </tr>
                            <tr id="cite-4">
                                <td>4</td>
                                <td>Vaswani, A., Shazeer, N., et al.</td>
                                <td><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Attention Is All You Need</a></td>
                                <td>NeurIPS 2017</td>
                                <td>2017</td>
                            </tr>
                            <tr id="cite-5">
                                <td>5</td>
                                <td>Brown, T.B., Mann, B., et al.</td>
                                <td><a href="https://arxiv.org/abs/2005.14165" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Language Models are Few-Shot Learners</a></td>
                                <td>NeurIPS 2020</td>
                                <td>2020</td>
                            </tr>
                            <tr id="cite-6">
                                <td>6</td>
                                <td>Wei, J., Wang, X., et al.</td>
                                <td><a href="https://arxiv.org/abs/2201.11903" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Chain-of-Thought Prompting Elicits Reasoning in LLMs</a></td>
                                <td>Google Research</td>
                                <td>2022</td>
                            </tr>
                            <tr id="cite-7">
                                <td>7</td>
                                <td>Wang, X., Wei, J., et al.</td>
                                <td><a href="https://arxiv.org/abs/2203.11171" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Self-Consistency Improves Chain of Thought Reasoning</a></td>
                                <td>Google Research</td>
                                <td>2022</td>
                            </tr>
                            <tr id="cite-8">
                                <td>8</td>
                                <td>Kojima, T., Gu, S.S., et al.</td>
                                <td><a href="https://arxiv.org/abs/2205.11916" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Large Language Models are Zero-Shot Reasoners</a></td>
                                <td>NeurIPS 2022</td>
                                <td>2022</td>
                            </tr>
                            <tr id="cite-9">
                                <td>9</td>
                                <td>Yao, S., Zhao, J., et al.</td>
                                <td><a href="https://arxiv.org/abs/2210.03629" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">ReAct: Synergizing Reasoning and Acting in LLMs</a></td>
                                <td>Princeton / Google Research</td>
                                <td>2022</td>
                            </tr>
                            <tr id="cite-10">
                                <td>10</td>
                                <td>OpenAI</td>
                                <td><a href="https://openai.com/index/chatgpt/" target="_blank" rel="noopener noreferrer" data-added="2026-02-14">Introducing ChatGPT</a></td>
                                <td>OpenAI</td>
                                <td>2022</td>
                            </tr>
                            <tr id="cite-11">
                                <td>11</td>
                                <td>Schulhoff, S., et al.</td>
                                <td><a href="https://arxiv.org/abs/2406.06608" target="_blank" rel="noopener noreferrer" data-added="2025-01-15">The Prompt Report: A Systematic Survey of Prompting Techniques</a></td>
                                <td>arXiv preprint</td>
                                <td>2024</td>
                            </tr>
                            <tr id="cite-12">
                                <td>12</td>
                                <td>Newell, A., Shaw, J.C., Simon, H.A.</td>
                                <td><a href="https://ieeexplore.ieee.org/document/1056797" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">The Logic Theory Machine</a></td>
                                <td>IRE Transactions on Information Theory, 2(3), 61-79</td>
                                <td>1956</td>
                            </tr>
                            <tr id="cite-13">
                                <td>13</td>
                                <td>Newell, A., Simon, H.A.</td>
                                <td><a href="https://digitalcollections.library.cmu.edu/node/31390" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">GPS, A Program that Simulates Human Thought</a></td>
                                <td>RAND Corporation</td>
                                <td>1961</td>
                            </tr>
                            <tr id="cite-14">
                                <td>14</td>
                                <td>Samuel, A.L.</td>
                                <td><a href="https://ieeexplore.ieee.org/document/5392560" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Some Studies in Machine Learning Using the Game of Checkers</a></td>
                                <td>IBM Journal of R&amp;D, 3(3), 210-229</td>
                                <td>1959</td>
                            </tr>
                            <tr id="cite-15">
                                <td>15</td>
                                <td>ALPAC</td>
                                <td><a href="https://nap.nationalacademies.org/catalog/9547/language-and-machines-computers-in-translation-and-linguistics" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Language and Machines: Computers in Translation and Linguistics</a></td>
                                <td>National Academy of Sciences / NRC</td>
                                <td>1966</td>
                            </tr>
                            <tr id="cite-16">
                                <td>16</td>
                                <td>Minsky, M., Papert, S.</td>
                                <td><a href="https://mitpress.mit.edu/9780262630221/perceptrons/" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Perceptrons: An Introduction to Computational Geometry</a></td>
                                <td>MIT Press</td>
                                <td>1969</td>
                            </tr>
                            <tr id="cite-17">
                                <td>17</td>
                                <td>Lighthill, J.</td>
                                <td><a href="https://www.aiai.ed.ac.uk/events/lighthill1973/lighthill.pdf" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Artificial Intelligence: A General Survey</a></td>
                                <td>Science Research Council, UK</td>
                                <td>1973</td>
                            </tr>
                            <tr id="cite-18">
                                <td>18</td>
                                <td>Stanford AI100</td>
                                <td><a href="https://ai100.stanford.edu/about/history" target="_blank" rel="noopener noreferrer" data-added="2026-02-14">History of AI</a></td>
                                <td>Stanford AI100</td>
                                <td>2016</td>
                            </tr>
                            <tr id="cite-19">
                                <td>19</td>
                                <td>Rumelhart, D.E., Hinton, G.E., Williams, R.J.</td>
                                <td><a href="https://doi.org/10.1038/323533a0" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Learning Representations by Back-propagating Errors</a></td>
                                <td>Nature, 323(6088), 533-536</td>
                                <td>1986</td>
                            </tr>
                            <tr id="cite-20">
                                <td>20</td>
                                <td>Crevier, D.</td>
                                <td><a href="https://archive.org/details/aitumultuoushist00crev" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">AI: The Tumultuous History of the Search for Artificial Intelligence</a></td>
                                <td>Basic Books</td>
                                <td>1993</td>
                            </tr>
                            <tr id="cite-21">
                                <td>21</td>
                                <td>Stanford HAI</td>
                                <td><a href="https://hai.stanford.edu/ai-index/2025-ai-index-report" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">AI Index Report 2025</a></td>
                                <td>Stanford HAI</td>
                                <td>2025</td>
                            </tr>
                            <tr id="cite-22">
                                <td>22</td>
                                <td>Krizhevsky, A., Sutskever, I., Hinton, G.E.</td>
                                <td><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">ImageNet Classification with Deep Convolutional Neural Networks</a></td>
                                <td>NeurIPS 2012</td>
                                <td>2012</td>
                            </tr>
                            <tr id="cite-23">
                                <td>23</td>
                                <td>Ouyang, L., Wu, J., et al.</td>
                                <td><a href="https://arxiv.org/abs/2203.02155" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">Training Language Models to Follow Instructions with Human Feedback</a></td>
                                <td>OpenAI / NeurIPS 2022</td>
                                <td>2022</td>
                            </tr>
                            <tr id="cite-24">
                                <td>24</td>
                                <td>MIT Sloan / IDE</td>
                                <td><a href="https://mitsloan.mit.edu/ideas-made-to-matter/4-new-studies-about-agentic-ai-mit-initiative-digital-economy" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">Agentic AI: 4 New Studies from MIT Initiative on the Digital Economy</a></td>
                                <td>MIT Sloan School of Management</td>
                                <td>2025</td>
                            </tr>
                            <tr id="cite-25">
                                <td>25</td>
                                <td>Dantanarayana, J.L., et al.</td>
                                <td><a href="https://arxiv.org/abs/2405.08965" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">byLLM: Meaning-Typed Language Abstraction for AI-Integrated Programming</a></td>
                                <td>arXiv / ACM PACMPL</td>
                                <td>2025</td>
                            </tr>
                            <tr id="cite-26">
                                <td>26</td>
                                <td>Stanford University</td>
                                <td><a href="https://agentflow.stanford.edu/" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">AgentFlow: In-the-Flow Agentic System Optimization</a></td>
                                <td>ICLR 2026</td>
                                <td>2026</td>
                            </tr>
                            <tr id="cite-27">
                                <td>27</td>
                                <td>Stanford REAL Lab</td>
                                <td><a href="https://real.stanford.edu/" target="_blank" rel="noopener noreferrer" data-added="2026-02-14">Robotics &amp; Embodied Artificial Intelligence Lab</a></td>
                                <td>Stanford REAL</td>
                                <td>2024</td>
                            </tr>
                            <tr id="cite-28">
                                <td>28</td>
                                <td>NIST</td>
                                <td><a href="https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">AI Risk Management Framework: Generative AI Profile</a></td>
                                <td>NIST Technical Series</td>
                                <td>2025</td>
                            </tr>
                            <tr id="cite-29">
                                <td>29</td>
                                <td>U.S. FDA</td>
                                <td><a href="https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-enabled-medical-devices" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">Artificial Intelligence-Enabled Medical Devices</a></td>
                                <td>FDA.gov</td>
                                <td>2025</td>
                            </tr>
                            <tr id="cite-30">
                                <td>30</td>
                                <td>Federal Reserve Bank of St. Louis</td>
                                <td><a href="https://www.stlouisfed.org/on-the-economy/2025/nov/state-generative-ai-adoption-2025" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">The State of Generative AI Adoption in 2025</a></td>
                                <td>Federal Reserve Bank of St. Louis</td>
                                <td>2025</td>
                            </tr>
                            <tr id="cite-31">
                                <td>31</td>
                                <td>Virginia Division of Legislative Services</td>
                                <td><a href="https://dls.virginia.gov/commissions/jcots/materials/snapshot_%20ai_chatbot_june2025.pdf" target="_blank" rel="noopener noreferrer" data-added="2026-02-13">AI Chatbot Snapshot &mdash; JCOTS</a></td>
                                <td>Virginia.gov</td>
                                <td>2025</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>
        </section>
        <!-- /CITATIONS -->

        <!-- === CTA SECTION === -->
        <section class="section">
            <div class="container">
                <div class="cta-corporate cta-corporate--dark" data-aos="fade-up">
                    <canvas id="cta-neural-bg" class="neural-canvas-secondary"></canvas>
                    <span class="cta-corporate__eyebrow">Ready to Learn?</span>
                    <h2 class="cta-corporate__title">Master the Techniques</h2>
                    <p class="cta-corporate__text">You've seen how AI evolved across four generations — from symbolic reasoning to agentic autonomy. Now learn the 177 techniques & frameworks that emerged from 76 years of research.</p>
                    <div class="cta-corporate__actions">
                        <a href="../learn/index.html" class="cta-corporate__btn cta-corporate__btn--primary">Explore All 177 Techniques & Frameworks</a>
                        <a href="../learn/prompt-basics.html" class="cta-corporate__btn cta-corporate__btn--secondary">Start with Basics</a>
                    </div>
                </div>
            </div>
        </section>
        <!-- /CTA SECTION -->
    </main>

    <!-- Footer -->
        <footer class="footer">
    <canvas id="footer-neural-bg" class="footer-neural-bg"></canvas>
    <div class="container">
        <div class="footer-grid">
            <div class="footer-brand">
                <a href="../index.html" class="footer-logo">&lt;/Praxis <span>Library</span>&gt;</a>
                <p>From Prompting to Production. Built on Proven Techniques &amp; Frameworks.</p>
            </div>

            <div class="footer-links">
                <h4>Techniques</h4>
                <a href="../learn/prompt-basics.html">Prompt Basics</a>
                <a href="../learn/crisp.html">CRISP Framework</a>
                <a href="../learn/crispe.html">CRISPE Framework</a>
                <a href="../learn/costar.html">CO-STAR Framework</a>
                <a href="../learn/react.html">ReAct Framework</a>
                <a href="../learn/flipped-interaction.html">Flipped Interaction</a>
                <a href="../learn/chain-of-thought.html">Chain-of-Thought</a>
            </div>

            <div class="footer-links">
                <h4>AI Readiness Tools</h4>
                <a href="../tools/analyzer.html">Prompt Analyzer</a>
                <a href="../tools/matcher.html">Technique Finder</a>
                <a href="../tools/checklist.html">Preflight Checklist</a>
                <a href="../tools/guidance.html">Prompt Builder</a>
                <a href="../tools/persona.html">Persona Architect</a>
                <a href="../tools/hallucination.html">Hallucination Spotter</a>
                <a href="../quiz/index.html">Readiness Quiz</a>
                <a href="../patterns/index.html">Patterns Library</a>
                <a href="../pages/ai-safety.html">AI Safety</a>
            </div>

            <div class="footer-links">
                <h4>Resources</h4>
                <a href="../pages/responsible-ai.html">Responsible AI</a>
                <a href="../neurodivergence/resources.html">ND Resources</a>
                <a href="../benchmarks/index.html">AI Benchmarks</a>
                <a href="../pages/audit-report.html">Audit Report</a>
                <a href="../pages/about.html">About Praxis</a>
                <a href="../pages/faq.html">FAQs</a>
            </div>
        </div>

        <div class="footer-bottom">
            <p>AI for Everyone</p>
            <p class="footer-quote">&ldquo;True innovation in AI isn&rsquo;t just about companies adopting AI as a new technology&mdash;it&rsquo;s about people learning about, adapting to, and adopting Artificial Intelligence into their daily lives to empower and unlock their own human potential.&rdquo; <span class="footer-quote-author">&mdash; Basiliso (Bas) Rosario</span></p>
        </div>

        <div class="footer-policies">
            <a href="../pages/responsible-ai.html">Responsible AI</a>
            <a href="../pages/use-policy.html">Use Policy</a>
            <a href="../pages/site-policy.html">Site Policy</a>
            <a href="../pages/security-policy.html">Security Policy</a>
            <a href="../pages/data-retention-policy.html">Data Retention</a>
        </div>
    </div>
</footer>

    <!-- Back to Top Bar -->
    <button class="back-to-top-bar" aria-label="Back to top">
        <span class="back-to-top-arrow">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M18 15l-6-6-6 6"/>
            </svg>
        </span>
        <span class="back-to-top-text">Back to Top</span>
    </button>

    <!-- Badge Lightbox -->
    <div class="badge-lightbox-overlay" aria-hidden="true"></div>
    <div class="badge-lightbox" role="dialog" aria-modal="true" aria-labelledby="badge-lightbox-title">
        <header class="badge-lightbox-header">
            <h2 class="badge-lightbox-title" id="badge-lightbox-title"></h2>
            <button class="badge-lightbox-close" aria-label="Close dialog">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor">
                    <path d="M18 6L6 18M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
            </button>
        </header>
        <div class="badge-lightbox-content"></div>
    </div>

    <!-- Accessibility Dashboard -->
    <div class="adl-dim-overlay" aria-hidden="true"></div>
    <button class="adl-toggle" aria-label="Accessibility options" aria-expanded="false" aria-controls="adl-panel">
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <circle cx="12" cy="12" r="10"/>
            <circle cx="12" cy="10" r="3"/>
            <path d="M12 13v6M9 17l3 3 3-3"/>
        </svg>
    </button>
    <div class="adl-panel" id="adl-panel" role="dialog" aria-label="Accessibility Settings">
        <div class="adl-panel-header">
            <span class="adl-panel-title">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <circle cx="12" cy="12" r="10"/>
                    <circle cx="12" cy="10" r="3"/>
                    <path d="M12 13v6M9 17l3 3 3-3"/>
                </svg>
                Accessibility
            </span>
            <button class="adl-close" aria-label="Close accessibility panel">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M18 6L6 18M6 6l12 12"/>
                </svg>
            </button>
        </div>
        <div class="adl-control">
            <span class="adl-label">Text Size</span>
            <div class="adl-btn-group">
                <button class="adl-btn is-active" data-scale="1" aria-label="Normal text size">1x</button>
                <button class="adl-btn" data-scale="2" aria-label="Large text size">2x</button>
                <button class="adl-btn" data-scale="3" aria-label="Extra large text size">3x</button>
            </div>
        </div>
        <div class="adl-control">
            <div class="adl-switch-wrapper">
                <span class="adl-switch-label">High Contrast</span>
                <label class="adl-switch">
                    <input type="checkbox" id="adl-contrast-toggle" aria-label="Toggle high contrast mode">
                    <span class="adl-switch-track"></span>
                </label>
            </div>
        </div>
        <div class="adl-control adl-readaloud">
            <span class="adl-label">Read Aloud</span>
            <div class="adl-readaloud-controls">
                <button class="adl-play-btn" aria-label="Play or pause reading">
                    <svg class="play-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M8 5v14l11-7z"/></svg>
                    <svg class="pause-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M6 4h4v16H6V4zm8 0h4v16h-4V4z"/></svg>
                </button>
                <div class="adl-speed-group">
                    <button class="adl-speed-btn" data-speed="slow">Slow</button>
                    <button class="adl-speed-btn is-active" data-speed="normal">Normal</button>
                    <button class="adl-speed-btn" data-speed="fast">Fast</button>
                </div>
            </div>
            <div class="adl-reading-indicator"></div>
        </div>
        <div class="adl-control">
            <span class="adl-label">Screen Dimming</span>
            <div class="adl-range-wrapper">
                <input type="range" class="adl-range" id="adl-dim-slider" min="0" max="50" value="0" aria-label="Screen dimming level">
                <span class="adl-range-value">0%</span>
            </div>
        </div>
        <button class="adl-reset" aria-label="Reset accessibility settings to defaults">Reset to Defaults</button>
    </div>

    <script src="../app.js" defer></script>
</body>
</html>

