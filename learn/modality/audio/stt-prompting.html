<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Speech-to-Text Prompting: Learn techniques for guiding AI transcription models with text prompts that control language, vocabulary, speaker labeling, formatting, and domain-specific accuracy.">
    <!-- SEO Meta -->
    <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">
    <meta name="author" content="Praxis Library">
    <meta name="theme-color" content="#DC3545">
    <link rel="canonical" href="https://praxislibrary.com/learn/modality/audio/stt-prompting.html">
    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="Speech-to-Text Prompting - Praxis">
    <meta property="og:description" content="Speech-to-Text Prompting: Learn techniques for guiding AI transcription models with text prompts that control language, vocabulary, speaker labeling, formatting, and domain-specific accuracy.">
    <meta property="og:url" content="https://praxislibrary.com/learn/modality/audio/stt-prompting.html">
    <meta property="og:image" content="https://praxislibrary.com/assets/images/praxishome.png">
    <meta property="og:site_name" content="Praxis Library">
    <meta property="og:locale" content="en_US">
    <!-- Social Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Speech-to-Text Prompting - Praxis">
    <meta name="twitter:description" content="Speech-to-Text Prompting: Learn techniques for guiding AI transcription models with text prompts that control language, vocabulary, speaker labeling, formatting, and domain-specific accuracy.">
    <meta name="twitter:image" content="https://praxislibrary.com/assets/images/praxishome.png">
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@type": [
        "LearningResource",
        "Article"
      ],
      "headline": "Speech-to-Text Prompting",
      "name": "Speech-to-Text Prompting",
      "description": "Speech-to-Text Prompting: Learn techniques for guiding AI transcription models with text prompts that control language, vocabulary, speaker labeling, formatting, and domain-specific accuracy.",
      "url": "https://praxislibrary.com/learn/modality/audio/stt-prompting.html",
      "inLanguage": "en-US",
      "learningResourceType": "Tutorial",
      "educationalLevel": "Beginner to Advanced",
      "educationalUse": "AI Prompt Engineering",
      "isAccessibleForFree": true,
      "publisher": {
        "@type": "EducationalOrganization",
        "name": "Praxis Library",
        "alternateName": "The Open Standard in AI Literacy",
        "url": "https://praxislibrary.com",
        "logo": "https://praxislibrary.com/favicon.svg",
        "description": "A comprehensive, living library of 5,000+ AI terms, 177 techniques & frameworks, and interactive tools. The definitive open resource for AI literacy, prompt engineering, and human-AI communication.",
        "sameAs": [
          "https://www.tiktok.com/@thepraxislibrary",
          "https://www.facebook.com/profile.php?id=61587612308104",
          "https://github.com/PowerOfPraxis/PraxisLibrary"
        ],
        "knowsAbout": [
          "Artificial Intelligence",
          "AI Literacy",
          "Prompt Engineering",
          "AI Prompting Techniques",
          "AI Glossary",
          "Large Language Models",
          "Chain-of-Thought Prompting",
          "AI Education",
          "Human-AI Communication",
          "Neurodivergence and AI",
          "AI Safety",
          "AI Ethics"
        ]
      },
      "isPartOf": {
        "@type": "WebSite",
        "name": "Praxis Library",
        "url": "https://praxislibrary.com"
      },
      "about": [
        {
          "@type": "Thing",
          "name": "Prompt Engineering"
        },
        {
          "@type": "Thing",
          "name": "AI Communication"
        }
      ]
    },
    {
      "@type": "BreadcrumbList",
      "itemListElement": [
        {
          "@type": "ListItem",
          "position": 1,
          "name": "Home",
          "item": "https://praxislibrary.com"
        },
        {
          "@type": "ListItem",
          "position": 2,
          "name": "Discover",
          "item": "https://praxislibrary.com/learn/"
        },
        {
          "@type": "ListItem",
          "position": 3,
          "name": "Modality",
          "item": "https://praxislibrary.com/learn/modality/"
        },
        {
          "@type": "ListItem",
          "position": 4,
          "name": "Audio",
          "item": "https://praxislibrary.com/learn/modality/audio/"
        },
        {
          "@type": "ListItem",
          "position": 5,
          "name": "Speech-to-Text Prompting"
        }
      ]
    }
  ]
}
    </script>
    <!-- /SEO -->

<title>Speech-to-Text Prompting - Praxis</title>
    <link rel="icon" type="image/svg+xml" href="../../../favicon.svg">
    <link rel="stylesheet" href="../../../styles.css">
</head>
<body>
    <a href="#main-content" class="skip-link">Skip to main content</a>

        <header class="header" id="header">
        <div class="header-container">
            <a href="../../../index.html" class="logo">&lt;/Praxis <span>Library</span>&gt;</a>
            <nav class="nav" id="nav" aria-label="Main navigation">
                <a href="../../../foundations/index.html" class="nav-link">History</a>
                <div class="nav-item has-dropdown">
                    <a href="../../index.html" class="nav-link active" aria-expanded="false">Discover</a>
                                        <div class="mega-menu mega-menu--categories">
                        <div class="mega-menu-quick-links">
                            <a href="../../index.html">Prompt Engineering</a>
                            <a href="../../prompt-basics.html">Prompt Basics</a>
                            <a href="../../facts-fictions.html">Facts &amp; Fictions</a>
                            <a href="../../../pages/glossary.html">Glossary</a>
                        </div>
                    </div>
                </div>
                <div class="nav-item has-dropdown">
                    <a href="../../../tools/index.html" class="nav-link" aria-expanded="false">Readiness</a>
                    <div class="mega-menu">
                        <div class="mega-menu-section">
                            <h4>Tools</h4>
                            <a href="../../../quiz/index.html">Readiness Quiz</a>
                            <a href="../../../tools/analyzer.html">Prompt Analyzer</a>
                            <a href="../../../tools/guidance.html">Prompt Builder</a>
                            <a href="../../../tools/matcher.html">Technique Finder</a>
                            <a href="../../../tools/checklist.html">Preflight Checklist</a>
                            <a href="../../../tools/persona.html">Persona Architect</a>
                            <a href="../../../patterns/index.html">Patterns Library</a>
                            <a href="../../../pages/ai-safety.html">AI Safety</a>
                        </div>
                    </div>
                </div>
                <div class="nav-item has-dropdown">
                    <a href="../../../pages/resources.html" class="nav-link" aria-expanded="false">Resources</a>
                    <div class="mega-menu mega-menu--categories">
                        <div class="mega-menu-quick-links">
                            <a href="../../../pages/responsible-ai.html">Responsible AI</a>
                            <a href="../../../neurodivergence/resources.html">ND Resources</a>
                            <a href="../../../benchmarks/index.html">AI Benchmarks</a>
                            <a href="../../../pages/audit-report.html">Audit Report</a>
                            <a href="../../../pages/about.html">About Praxis</a>
                            <a href="../../../pages/faq.html">FAQs</a>
                        </div>
                    </div>
                </div>
            </nav>
            <button class="menu-toggle" id="menuToggle" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>
    </header>

    <main id="main-content">
        <!-- === HERO SECTION === -->
        <section class="page-hero">
            <canvas id="page-hero-neural-bg" class="page-hero-neural-bg"></canvas>
            <div class="container">
                <nav class="breadcrumb fade-in" aria-label="Breadcrumb">
                    <a href="../../../index.html">Home</a>
                    <span class="separator">/</span>
                    <a href="../../index.html">Discover</a>
                    <span class="separator">/</span>
                    <span class="current">Speech-to-Text Prompting</span>
                </nav>
                <div class="hero-badge">
                    <span class="hero-badge__text">Audio Techniques</span>
                </div>
                <h1 class="page-title fade-in">Speech-to-Text Prompting</h1>
                <p class="page-subtitle fade-in">Techniques for guiding AI transcription models with text prompts that control language detection, domain vocabulary, speaker attribution, and output formatting &mdash; transforming raw audio into structured, accurate, and context-aware transcriptions.</p>
            </div>
        </section>
        <!-- /HERO SECTION -->

        <!-- === HISTORICAL CONTEXT === -->
        <section class="section">
            <div class="container">
                <div class="highlight-box highlight-box--warning fade-in-up">
                    <div class="highlight-box__content">
                        <span class="highlight-box__title">Technique Context: 2022</span>
                        <p><strong>Introduced:</strong> Speech recognition has evolved from Hidden Markov Models (1970s&ndash;2000s) through deep learning approaches (2010s) to transformer-based systems like OpenAI Whisper (2022). Modern STT models accept text prompts that guide transcription behavior &mdash; specifying language, domain vocabulary, speaker labeling, and formatting. Earlier systems like CMU Sphinx and Google&rsquo;s DeepSpeech required extensive acoustic model training and offered no prompt-level control. The introduction of Whisper demonstrated that a single large-scale model trained on 680,000 hours of multilingual audio could match or exceed specialized systems, and critically, that a simple text prompt could steer its transcription behavior without retraining.</p>
                        <p><strong>Modern LLM Status:</strong> STT prompting is now a <strong>core capability in production audio pipelines</strong> and continues to expand in sophistication. Whisper, AssemblyAI, Deepgram, and cloud provider APIs (Google Cloud Speech-to-Text, Azure Speech Services) all support prompt-guided transcription. The techniques covered here &mdash; vocabulary hints, speaker diarization directives, formatting instructions, and language specification &mdash; remain essential because even the best models produce inconsistent output without explicit guidance. Domain-specific terminology, proper nouns, and multi-speaker scenarios all benefit substantially from well-crafted transcription prompts. These foundations extend naturally into real-time captioning, meeting summarization, and multimodal audio-text workflows.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- /HISTORICAL CONTEXT -->

        <!-- === THE CONCEPT === -->
        <section class="section section-alt">
            <div class="container">
                <div class="split-section split-section--center fade-in-up">
                    <div class="split-section__content">
                        <span class="split-section__badge">The Core Insight</span>
                        <h2 class="split-section__title">Control How Speech Becomes Text</h2>
                        <p class="split-section__text">Speech-to-text prompting controls how spoken audio is converted into written text. Unlike traditional transcription systems that operate as black boxes, modern STT models accept text prompts that shape every aspect of the output &mdash; from vocabulary selection and punctuation style to speaker identification and timestamp granularity. The prompt acts as a configuration layer between raw audio and the final transcript.</p>
                        <p class="split-section__text"><strong>The core insight is that a well-crafted prompt transforms raw transcription into structured, contextualized text with proper formatting, speaker attribution, and domain-specific vocabulary.</strong> Without prompting, a medical dictation might render &ldquo;epigastric&rdquo; as &ldquo;epic gastric&rdquo; and miss critical speaker transitions between physician and patient. With prompting, the same audio produces a properly formatted clinical note with correct terminology and labeled dialogue turns.</p>
                        <p class="split-section__text">Think of it like briefing a court reporter before a trial versus dropping them into the courtroom cold. The briefed reporter knows the case names, the legal terminology that will arise, who the speakers are, and what format the transcript should take. The unbriefed reporter captures words but misses context. STT prompting is that briefing &mdash; it prepares the model to hear what matters and structure what it captures.</p>
                    </div>
                    <div class="split-section__visual">
                        <div class="highlight-box highlight-box--info">
                            <div class="highlight-box__content">
                                <span class="highlight-box__title">Why Prompting Transforms Transcription Quality</span>
                                <p>When an STT model processes audio without prompt guidance, it relies entirely on its general training data to resolve ambiguous sounds, proper nouns, and formatting decisions. This produces transcripts with generic punctuation, inconsistent capitalization, no speaker labels, and frequent errors on domain-specific terms. A structured prompt redirects this behavior by providing the <strong>transcription context</strong> the model needs: what domain the audio comes from, what vocabulary to expect, how many speakers are present, and what output format is required. The difference between a usable transcript and one that requires extensive manual correction often comes down entirely to the quality of the accompanying text prompt.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /THE CONCEPT -->

        <!-- === HOW IT WORKS === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">The STT Prompting Process</h2>
                <p class="section-subtitle fade-in-up">Four steps from spoken audio to structured transcription</p>

                <div class="element-timeline fade-in-up">
                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">1</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Provide Audio Input</h3>
                            <p class="element-timeline__text">Supply the audio file or stream that needs transcription. Audio quality directly impacts transcription accuracy &mdash; clean recordings with minimal background noise, consistent volume levels, and clear speech produce the best results. Supported formats typically include WAV, MP3, FLAC, M4A, and OGG. For longer recordings, consider whether the API supports chunked processing or requires the full file upfront, as this affects both latency and memory usage.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>Upload a 45-minute meeting recording in WAV format at 16kHz sample rate, ensuring all participants used dedicated microphones to minimize crosstalk and ambient noise.</p>
                            </div>
                        </div>
                    </div>

                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">2</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Specify Transcription Parameters</h3>
                            <p class="element-timeline__text">Define the language, domain context, and vocabulary hints that guide the model&rsquo;s recognition behavior. This is where prompting has the greatest impact on accuracy. Provide a list of expected proper nouns, technical terms, acronyms, and domain-specific vocabulary that the model would otherwise misinterpret. Specify the source language explicitly rather than relying on automatic detection, especially for multilingual content or heavily accented speech.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>&ldquo;Language: English. Domain: cardiology. Expected terms: echocardiogram, troponin, STEMI, percutaneous coronary intervention, ejection fraction. Speaker names: Dr. Patel, Nurse Thompson, Patient Rodriguez.&rdquo;</p>
                            </div>
                        </div>
                    </div>

                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">3</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Define Output Format</h3>
                            <p class="element-timeline__text">Specify how the transcribed text should be structured and presented. This includes timestamp granularity (per-word, per-sentence, or per-paragraph), speaker diarization labels, punctuation preferences, paragraph segmentation rules, and whether to include filler words or verbal hesitations. Format instructions prevent the model from producing a raw wall of text that requires extensive post-processing to become usable.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>&ldquo;Format output with speaker labels on each line (e.g., DR. PATEL:). Include timestamps at the start of each speaker turn in [HH:MM:SS] format. Use standard medical punctuation. Omit filler words (um, uh, like). Break into paragraphs at topic changes.&rdquo;</p>
                            </div>
                        </div>
                    </div>

                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">4</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Post-Process Results</h3>
                            <p class="element-timeline__text">Review and refine the transcription output. Even with optimal prompting, some corrections may be needed &mdash; particularly for overlapping speech, mumbled passages, or unusual proper nouns not included in the vocabulary hints. Use confidence scores (when available) to identify low-certainty segments that need human review. Chain the STT output into downstream tasks like summarization, action item extraction, or translation for maximum value from the transcription pipeline.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>&ldquo;Review segments with confidence below 0.85. Cross-reference medication names against the hospital formulary. Feed the verified transcript into the meeting summary generator with action items extraction enabled.&rdquo;</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /HOW IT WORKS -->

        <!-- === VISUAL: THE COMPARISON === -->
        <section class="section section-alt">
            <div class="container">
                <h2 class="section-title fade-in-up">See the Difference</h2>
                <p class="section-subtitle fade-in-up">Why prompted transcription dramatically outperforms default output</p>

                <div class="comparison-panel fade-in-up">
                    <div class="comparison-panel__side comparison-panel__side--before">
                        <div class="comparison-panel__header">
                            <span class="comparison-panel__icon">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <path d="M12 8v4M12 16h.01"/>
                                </svg>
                            </span>
                            <h3 class="comparison-panel__title">Default Transcription</h3>
                        </div>
                        <div class="comparison-panel__content">
                            <div class="comparison-panel__prompt">
                                <span class="comparison-panel__label">Input</span>
                                <p>Audio file uploaded with no prompt or parameters.</p>
                            </div>
                            <div class="comparison-panel__result">
                                <span class="comparison-panel__label">Output</span>
                                <p>so the patient came in yesterday complaining of chest pain and we ran an echo cardiogram and the ejection fraction was about 35% which is um pretty concerning so i think we need to start him on ace inhibitors and get a cardiology consult dr patel what do you think yeah i agree lets also check the trow ponin levels and schedule a follow up for next week</p>
                            </div>
                        </div>
                        <div class="comparison-panel__verdict comparison-panel__verdict--weak">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <path d="M8 12h8"/>
                            </svg>
                            <span>No speaker labels, misspelled terms, no punctuation, filler words included</span>
                        </div>
                    </div>

                    <div class="comparison-panel__divider">
                        <span>VS</span>
                    </div>

                    <div class="comparison-panel__side comparison-panel__side--after">
                        <div class="comparison-panel__header">
                            <span class="comparison-panel__icon">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M13 2L3 14h9l-1 8 10-12h-9l1-8z"/>
                                </svg>
                            </span>
                            <h3 class="comparison-panel__title">Prompted Transcription</h3>
                        </div>
                        <div class="comparison-panel__content">
                            <div class="comparison-panel__prompt">
                                <span class="comparison-panel__label">Prompt</span>
                                <p>Domain: cardiology. Speakers: Dr. Chen, Dr. Patel. Terms: echocardiogram, ejection fraction, ACE inhibitors, troponin. Format: speaker labels, timestamps, omit fillers.</p>
                            </div>
                            <div class="comparison-panel__result">
                                <span class="comparison-panel__label">Output</span>
                                <p><strong>[00:00:12] DR. CHEN:</strong> So the patient came in yesterday complaining of chest pain. We ran an echocardiogram and the ejection fraction was about 35%, which is pretty concerning. I think we need to start him on ACE inhibitors and get a cardiology consult.<br><strong>[00:00:34] DR. CHEN:</strong> Dr. Patel, what do you think?<br><strong>[00:00:36] DR. PATEL:</strong> Yeah, I agree. Let&rsquo;s also check the troponin levels and schedule a follow-up for next week.</p>
                            </div>
                        </div>
                        <div class="comparison-panel__verdict comparison-panel__verdict--strong">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <path d="M8 12l3 3 5-5"/>
                            </svg>
                            <span>Speaker-labeled, timestamped, correct terminology, properly punctuated</span>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /THE COMPARISON -->
        <!-- === RAI TIP === -->
        <section class="section-tip fade-in-up">
            <div class="container">
                <div class="section-tip__content">
                    <div class="section-tip__icon">
                        <span class="section-tip__stop-text" aria-hidden="true">STOP</span>
                    </div>
                    <div class="section-tip__text">
                        <h3 class="section-tip__title">Practice Responsible AI</h3>
                        <p>Always verify AI-generated content before use. AI systems can produce confident but incorrect responses. When using AI professionally, transparent disclosure is both best practice and increasingly a legal requirement.</p>
                        <p><strong>48 US states</strong> now require AI transparency in key areas. Critical thinking remains your strongest tool against misinformation.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- /RAI TIP -->

<!-- === EXAMPLES IN ACTION === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">STT Prompting in Action</h2>
                <p class="section-subtitle fade-in-up">See how domain-specific prompts transform transcription accuracy</p>

                <div class="accordion fade-in-up" id="stt-prompting-accordion">
                    <div class="accordion-item">
                        <button class="accordion-header" aria-expanded="false">
                            <span class="accordion-title">Medical Dictation</span>
                            <span class="accordion-icon"><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polyline points="6 9 12 15 18 9"/></svg></span>
                        </button>
                        <div class="accordion-content">
                            <div class="technique-demo">
                                <div class="technique-demo__prompt">
                                    <span class="technique-demo__tag">Prompt</span>
                                    <p>&ldquo;Transcribe this clinical dictation. Domain: orthopedic surgery. Expected terminology: anterior cruciate ligament, arthroscopic, meniscectomy, femoral condyle, tibial plateau, MRI, ACL reconstruction. Speaker: Dr. Vasquez (single speaker). Format: structured clinical note with sections for Chief Complaint, History of Present Illness, Physical Examination, Assessment, and Plan. Use standard medical abbreviations where appropriate.&rdquo;</p>
                                </div>
                                <div class="technique-demo__response">
                                    <span class="technique-demo__tag">Why This Works</span>
                                    <p>Medical dictation is one of the highest-value applications of STT prompting because clinical terminology is dense, phonetically similar to common words, and critically important to get right. The prompt provides the surgical subspecialty to activate relevant vocabulary, lists specific terms the model will encounter, specifies single-speaker mode to avoid false diarization, and defines the clinical note structure. Without this guidance, &ldquo;meniscectomy&rdquo; might become &ldquo;men is sectomy&rdquo; and the output would be an unstructured paragraph rather than a formatted clinical document ready for the electronic health record.</p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <button class="accordion-header" aria-expanded="false">
                            <span class="accordion-title">Legal Deposition</span>
                            <span class="accordion-icon"><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polyline points="6 9 12 15 18 9"/></svg></span>
                        </button>
                        <div class="accordion-content">
                            <div class="technique-demo">
                                <div class="technique-demo__prompt">
                                    <span class="technique-demo__tag">Prompt</span>
                                    <p>&ldquo;Transcribe this legal deposition recording. Speakers: Attorney Williams (questioning), Witness Margaret Foster, Attorney Chen (objecting counsel). Domain: contract law. Case terminology: breach of fiduciary duty, indemnification clause, Section 4.2(b), Meridian Holdings LLC, promissory estoppel. Format: legal transcript with line numbers, speaker labels in caps, timestamps every 5 minutes, and verbatim transcription including false starts and verbal pauses marked as (pause) or (inaudible).&rdquo;</p>
                                </div>
                                <div class="technique-demo__response">
                                    <span class="technique-demo__tag">Why This Works</span>
                                    <p>Legal depositions demand verbatim accuracy that differs fundamentally from other transcription contexts. The prompt specifies all participants and their roles (which enables correct attribution of overlapping exchanges), provides case-specific terminology and party names that would otherwise be garbled, and defines legal transcript formatting conventions. Critically, it requests verbatim transcription with pause markers rather than cleaned-up text &mdash; in legal contexts, hesitations and false starts can be material evidence. The section reference (4.2(b)) ensures alphanumeric designations are rendered correctly rather than interpreted as natural language.</p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <button class="accordion-header" aria-expanded="false">
                            <span class="accordion-title">Technical Lecture</span>
                            <span class="accordion-icon"><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polyline points="6 9 12 15 18 9"/></svg></span>
                        </button>
                        <div class="accordion-content">
                            <div class="technique-demo">
                                <div class="technique-demo__prompt">
                                    <span class="technique-demo__tag">Prompt</span>
                                    <p>&ldquo;Transcribe this university lecture recording. Domain: machine learning and natural language processing. Speaker: Professor Nakamura (primary), with occasional student questions (label as STUDENT). Expected terms: transformer architecture, attention mechanism, BERT, GPT, tokenization, softmax, backpropagation, cross-entropy loss, epoch, batch normalization. Format: paragraph breaks at topic transitions, mathematical expressions written in plain text (e.g., softmax of x equals e to the x divided by the sum of e to the x), timestamps at paragraph starts.&rdquo;</p>
                                </div>
                                <div class="technique-demo__response">
                                    <span class="technique-demo__tag">Why This Works</span>
                                    <p>Technical lectures combine domain jargon with mathematical expressions that generic STT models handle poorly. The prompt provides the academic field and specific terminology list, distinguishes the primary speaker from student questions, and critically addresses how to render mathematical notation in text form. Without this guidance, spoken mathematics becomes garbled (&ldquo;softmax of x&rdquo; might be transcribed as &ldquo;soft max of ex&rdquo;) and model names like &ldquo;BERT&rdquo; or &ldquo;GPT&rdquo; may be lowercased or misinterpreted as common words. The paragraph-break instruction at topic transitions produces readable lecture notes rather than a continuous text block.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /EXAMPLES IN ACTION -->

        <!-- === WHEN TO USE === -->
        <section class="section section-alt">
            <div class="container">
                <h2 class="section-title fade-in-up">When to Use STT Prompting</h2>
                <p class="section-subtitle fade-in-up">Best for domain-specific, multi-speaker, and format-critical transcription</p>

                <div class="split-section fade-in-up">
                    <div class="split-section__content">
                        <h3 class="split-section__subtitle">Perfect For</h3>
                        <div class="feature-list">
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Multi-Speaker Meetings</strong>
                                    <p>Conference calls, panel discussions, and group meetings where speaker identification and turn-taking attribution are essential for producing actionable meeting transcripts and minutes.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Domain-Specific Transcription</strong>
                                    <p>Medical, legal, scientific, and technical recordings where specialized vocabulary must be rendered correctly and generic models would produce frequent terminology errors.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Accessibility Captioning</strong>
                                    <p>Generating accurate captions for videos, live events, and educational content where transcript quality directly impacts comprehension for deaf and hard-of-hearing audiences.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Content Repurposing</strong>
                                    <p>Converting podcasts, interviews, webinars, and spoken presentations into written articles, blog posts, documentation, or searchable archives that retain the original structure and meaning.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="split-section__content">
                        <h3 class="split-section__subtitle">Skip It When</h3>
                        <div class="feature-list">
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Simple Single-Speaker Audio</strong>
                                    <p>When the audio is a single clear speaker with no technical vocabulary, standard transcription without prompting typically produces adequate results. The overhead of crafting a prompt adds complexity without proportional benefit.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Hardware-Dependent Real-Time Subtitles</strong>
                                    <p>When latency constraints require sub-100ms response times for live broadcasting subtitles, dedicated hardware encoders and embedded ASR systems outperform prompt-based API approaches.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Extremely Noisy Environments</strong>
                                    <p>When background noise overwhelms the speech signal &mdash; construction sites, concerts, or heavily degraded archival recordings &mdash; prompting cannot compensate for fundamentally unrecoverable audio quality.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Non-Speech Audio Analysis</strong>
                                    <p>For tasks focused on music transcription, environmental sound classification, or audio event detection, use audio classification or music generation frameworks rather than speech-to-text prompting.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /WHEN TO USE -->

        <!-- === USE CASES === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">Use Cases</h2>
                <p class="section-subtitle fade-in-up">Where STT prompting delivers the most value</p>

                <div class="use-case-showcase fade-in-up">
                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M22 12h-4l-3 9L9 3l-3 9H2"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Medical Transcription</h3>
                        <p class="use-case-showcase__desc">Converting physician dictations, patient consultations, and clinical rounds into structured medical records with correct ICD codes, drug names, anatomical terminology, and SOAP note formatting for electronic health record integration.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/>
                                <polyline points="14 2 14 8 20 8"/>
                                <line x1="16" y1="13" x2="8" y2="13"/>
                                <line x1="16" y1="17" x2="8" y2="17"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Legal Documentation</h3>
                        <p class="use-case-showcase__desc">Producing court-ready deposition transcripts, witness statements, and hearing records with verbatim accuracy, proper legal formatting, speaker attribution, and timestamp precision required by judicial proceedings.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"/>
                                <path d="M19 10v2a7 7 0 0 1-14 0v-2"/>
                                <line x1="12" y1="19" x2="12" y2="23"/>
                                <line x1="8" y1="23" x2="16" y2="23"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Podcast Production</h3>
                        <p class="use-case-showcase__desc">Generating searchable transcripts, show notes, and chapter markers from podcast recordings &mdash; with host and guest labels, topic segmentation, and clean formatting suitable for publishing alongside audio episodes.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <circle cx="12" cy="10" r="3"/>
                                <path d="M12 13v6M9 17l3 3 3-3"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Accessibility Captioning</h3>
                        <p class="use-case-showcase__desc">Creating accurate closed captions and subtitles for video content, live events, and educational materials &mdash; ensuring deaf and hard-of-hearing audiences receive complete, correctly timed, and properly attributed text representations of spoken content.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M17 21v-2a4 4 0 0 0-4-4H5a4 4 0 0 0-4 4v2"/>
                                <circle cx="9" cy="7" r="4"/>
                                <path d="M23 21v-2a4 4 0 0 0-3-3.87"/>
                                <path d="M16 3.13a4 4 0 0 1 0 7.75"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Interview Processing</h3>
                        <p class="use-case-showcase__desc">Transcribing research interviews, journalistic conversations, and hiring panels with speaker diarization, question-answer pairing, and thematic segmentation that enables efficient qualitative analysis and quote extraction.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M2 3h6a4 4 0 0 1 4 4v14a3 3 0 0 0-3-3H2z"/>
                                <path d="M22 3h-6a4 4 0 0 0-4 4v14a3 3 0 0 1 3-3h7z"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Lecture Notes</h3>
                        <p class="use-case-showcase__desc">Converting university lectures and conference presentations into structured study materials with topic headings, key concept highlighting, technical term accuracy, and paragraph segmentation that follows the speaker&rsquo;s logical progression.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- /USE CASES -->

        <!-- === FRAMEWORK POSITIONING === -->
        <section class="section section-alt">
            <div class="container">
                <h2 class="section-title fade-in-up">Where STT Prompting Fits</h2>
                <p class="section-subtitle fade-in-up">STT prompting bridges raw audio input and structured text output in the audio processing stack</p>

                <div class="evolution-timeline fade-in-up">
                    <div class="era-marker">
                        <span class="era-marker__year">Audio Prompting</span>
                        <span class="era-marker__title">Audio Understanding</span>
                        <span class="era-marker__desc">General audio analysis and comprehension</span>
                    </div>
                    <div class="era-marker era-marker--active">
                        <span class="era-marker__year">Speech-to-Text</span>
                        <span class="era-marker__title">Transcription Control</span>
                        <span class="era-marker__desc">Guided conversion of speech to structured text</span>
                    </div>
                    <div class="era-marker">
                        <span class="era-marker__year">Text-to-Speech</span>
                        <span class="era-marker__title">Speech Synthesis</span>
                        <span class="era-marker__desc">Generating natural spoken audio from text</span>
                    </div>
                    <div class="era-marker">
                        <span class="era-marker__year">Voice Cloning</span>
                        <span class="era-marker__title">Voice Replication</span>
                        <span class="era-marker__desc">Reproducing specific voice characteristics</span>
                    </div>
                </div>

                <div class="callout tip fade-in-up">
                    <div class="callout-title">Chain STT with Downstream Processing</div>
                    <p>Speech-to-text prompting is most powerful when treated as the first stage of a multi-step pipeline. Feed your prompted transcription output into summarization frameworks to generate meeting minutes, chain it with translation models for multilingual workflows, or pipe it into structured extraction prompts to pull action items, decisions, and key quotes from lengthy recordings. The quality of every downstream step depends directly on the accuracy of the initial transcription &mdash; making STT prompting the critical foundation of any audio-to-insight workflow.</p>
                </div>
            </div>
        </section>
        <!-- /FRAMEWORK POSITIONING -->

        <!-- === RELATED FRAMEWORKS === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">Related Techniques</h2>
                <p class="section-subtitle fade-in-up">Explore complementary audio processing techniques</p>

                <a href="audio-prompting.html" class="evolution-callout fade-in-up">
                    <span class="evolution-callout__icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M13 2L3 14h9l-1 8 10-12h-9l1-8z"/>
                        </svg>
                    </span>
                    <div class="evolution-callout__content">
                        <span class="evolution-callout__label">Foundation</span>
                        <span class="evolution-callout__title">Audio Prompting Basics</span>
                        <span class="evolution-callout__desc">The foundational framework for working with audio inputs in AI models &mdash; covering general principles of audio understanding, analysis, and prompt construction that underpin all specialized audio techniques including STT.</span>
                    </div>
                    <span class="evolution-callout__arrow">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M5 12h14M12 5l7 7-7 7"/>
                        </svg>
                    </span>
                </a>

                <a href="tts-prompting.html" class="evolution-callout fade-in-up">
                    <span class="evolution-callout__icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M17 2l4 4-4 4"/>
                            <path d="M3 11v-1a4 4 0 0 1 4-4h14"/>
                            <path d="M7 22l-4-4 4-4"/>
                            <path d="M21 13v1a4 4 0 0 1-4 4H3"/>
                        </svg>
                    </span>
                    <div class="evolution-callout__content">
                        <span class="evolution-callout__label">Inverse</span>
                        <span class="evolution-callout__title">Text-to-Speech Prompting</span>
                        <span class="evolution-callout__desc">The mirror discipline &mdash; crafting prompts that control how text is converted into spoken audio, including voice selection, prosody, pacing, and emotional tone. Understanding both directions deepens command of the speech-text boundary.</span>
                    </div>
                    <span class="evolution-callout__arrow">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M5 12h14M12 5l7 7-7 7"/>
                        </svg>
                    </span>
                </a>

                <a href="audio-classification.html" class="evolution-callout fade-in-up">
                    <span class="evolution-callout__icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/>
                            <polyline points="14 2 14 8 20 8"/>
                            <line x1="16" y1="13" x2="8" y2="13"/>
                            <line x1="16" y1="17" x2="8" y2="17"/>
                        </svg>
                    </span>
                    <div class="evolution-callout__content">
                        <span class="evolution-callout__label">Complement</span>
                        <span class="evolution-callout__title">Audio Classification</span>
                        <span class="evolution-callout__desc">Focuses on categorizing and labeling audio content by type, emotion, speaker identity, or event &mdash; a natural preprocessing step that can inform STT prompts by identifying the audio domain and speaker characteristics before transcription begins.</span>
                    </div>
                    <span class="evolution-callout__arrow">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M5 12h14M12 5l7 7-7 7"/>
                        </svg>
                    </span>
                </a>
            </div>
        </section>
        <!-- /RELATED FRAMEWORKS -->

        <!-- === CTA SECTION === -->
        <section class="section">
            <div class="container">
                <div class="cta-corporate cta-corporate--dark fade-in-up">
                    <canvas id="cta-neural-bg" class="cta-corporate__canvas"></canvas>
                    <div class="cta-corporate__content">
                        <h2 class="cta-corporate__title">Explore Speech-to-Text Prompting</h2>
                        <p class="cta-corporate__text">Apply structured transcription techniques to your own audio content or build domain-specific STT prompts with our tools.</p>
                        <div class="cta-corporate__actions">
                            <a href="../../../tools/guidance.html" class="btn btn-primary">Prompt Builder</a>
                            <a href="../../../foundations/index.html" class="btn btn-secondary">All Foundations</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /CTA SECTION -->
    </main>

    <!-- === FOOTER === -->
    <footer class="footer">
        <canvas id="footer-neural-bg" class="footer-neural-bg"></canvas>
        <div class="container">
            <div class="footer-grid">
                <div class="footer-brand">
                    <a href="../../../index.html" class="footer-logo">&lt;/Praxis <span>Library</span>&gt;</a>
                    <p>Master the Art of AI Communication theory through proven frameworks.</p>
                </div>

                <div class="footer-links">
                    <h4>Techniques</h4>
                    <a href="../../prompt-basics.html">Prompt Basics</a>
                    <a href="../../crisp.html">CRISP Framework</a>
                    <a href="../../crispe.html">CRISPE Framework</a>
                    <a href="../../costar.html">CO-STAR Framework</a>
                    <a href="../../react.html">ReAct Framework</a>
                    <a href="../../flipped-interaction.html">Flipped Interaction</a>
                    <a href="../../chain-of-thought.html">Chain-of-Thought</a>
                </div>

                <div class="footer-links">
                    <h4>AI Readiness Tools</h4>
                <a href="../../../tools/analyzer.html">Prompt Analyzer</a>
                <a href="../../../tools/matcher.html">Technique Finder</a>
                <a href="../../../tools/checklist.html">Preflight Checklist</a>
                <a href="../../../tools/guidance.html">Prompt Builder</a>
                <a href="../../../tools/persona.html">Persona Architect</a>
                <a href="../../../tools/hallucination.html">Hallucination Spotter</a>
                <a href="../../../quiz/index.html">Readiness Quiz</a>
                </div>

                <div class="footer-links">
                    <h4>Resources</h4>
                <a href="../../../patterns/index.html">Patterns Library</a>
                <a href="../../../pages/ai-safety.html">AI Safety</a>
                <a href="../../../pages/responsible-ai.html">Responsible AI</a>
                    <a href="../../../pages/faq.html">FAQ</a>
                    <a href="../../../pages/glossary.html">Glossary</a>
                    <a href="../../../pages/security.html">Security</a>
                    <a href="../../../pages/performance.html">Performance</a>
                    <a href="../../../pages/about.html">About</a>
                </div>
            </div>

            <div class="footer-bottom">
                <p>AI for Everybody</p>
                <p class="footer-quote">&ldquo;True innovation in AI isn&rsquo;t just about companies adopting AI as a new technology&mdash;it&rsquo;s about people learning about, adapting to, and adopting Artificial Intelligence into their daily lives to empower and unlock their own human potential.&rdquo; <span class="footer-quote-author">&mdash; Basiliso (Bas) Rosario</span></p>
            </div>

            <div class="footer-policies">
            <a href="../../../pages/responsible-ai.html">Responsible AI</a>
                <a href="../../../pages/use-policy.html">Use Policy</a>
                <a href="../../../pages/site-policy.html">Site Policy</a>
                <a href="../../../pages/security-policy.html">Security Policy</a>
                <a href="../../../pages/data-retention-policy.html">Data Retention</a>
            </div>
        </div>
    </footer>
    <!-- /FOOTER -->

    <!-- === BACK TO TOP === -->
    <button class="back-to-top-bar" aria-label="Back to top">
        <span class="back-to-top-arrow">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M18 15l-6-6-6 6"/>
            </svg>
        </span>
        <span class="back-to-top-text">Back to Top</span>
    </button>
    <!-- /BACK TO TOP -->

    <!-- === ACCESSIBILITY DASHBOARD === -->

    <!-- =============================================
         BADGE LIGHTBOX - Modal popup for badge info
         ============================================= -->
    <div class="badge-lightbox-overlay" aria-hidden="true"></div>
    <div class="badge-lightbox" role="dialog" aria-modal="true" aria-labelledby="badge-lightbox-title">
        <header class="badge-lightbox-header">
            <h2 class="badge-lightbox-title" id="badge-lightbox-title"></h2>
            <button class="badge-lightbox-close" aria-label="Close dialog">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor">
                    <path d="M18 6L6 18M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
            </button>
        </header>
        <div class="badge-lightbox-content"></div>
    </div>
    <!-- /BADGE LIGHTBOX -->

    <div class="adl-dim-overlay" aria-hidden="true"></div>
    <button class="adl-toggle" aria-label="Accessibility options" aria-expanded="false" aria-controls="adl-panel">
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <circle cx="12" cy="12" r="10"/>
            <circle cx="12" cy="10" r="3"/>
            <path d="M12 13v6M9 17l3 3 3-3"/>
        </svg>
    </button>
    <div class="adl-panel" id="adl-panel" role="dialog" aria-label="Accessibility Settings">
        <div class="adl-panel-header">
            <span class="adl-panel-title">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <circle cx="12" cy="12" r="10"/>
                    <circle cx="12" cy="10" r="3"/>
                    <path d="M12 13v6M9 17l3 3 3-3"/>
                </svg>
                Accessibility
            </span>
            <button class="adl-close" aria-label="Close accessibility panel">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M18 6L6 18M6 6l12 12"/>
                </svg>
            </button>
        </div>
        <div class="adl-control">
            <span class="adl-label">Text Size</span>
            <div class="adl-btn-group">
                <button class="adl-btn is-active" data-scale="1" aria-label="Normal text size">1x</button>
                <button class="adl-btn" data-scale="2" aria-label="Large text size">2x</button>
                <button class="adl-btn" data-scale="3" aria-label="Extra large text size">3x</button>
            </div>
        </div>
        <div class="adl-control">
            <div class="adl-switch-wrapper">
                <span class="adl-switch-label">High Contrast</span>
                <label class="adl-switch">
                    <input type="checkbox" id="adl-contrast-toggle" aria-label="Toggle high contrast mode">
                    <span class="adl-switch-track"></span>
                </label>
            </div>
        </div>
        <div class="adl-control adl-readaloud">
            <span class="adl-label">Read Aloud</span>
            <div class="adl-readaloud-controls">
                <button class="adl-play-btn" aria-label="Play or pause reading">
                    <svg class="play-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M8 5v14l11-7z"/></svg>
                    <svg class="pause-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M6 4h4v16H6V4zm8 0h4v16h-4V4z"/></svg>
                </button>
                <div class="adl-speed-group">
                    <button class="adl-speed-btn" data-speed="slow">Slow</button>
                    <button class="adl-speed-btn is-active" data-speed="normal">Normal</button>
                    <button class="adl-speed-btn" data-speed="fast">Fast</button>
                </div>
            </div>
            <div class="adl-reading-indicator"></div>
        </div>
        <div class="adl-control">
            <span class="adl-label">Screen Dimming</span>
            <div class="adl-range-wrapper">
                <input type="range" class="adl-range" id="adl-dim-slider" min="0" max="50" value="0" aria-label="Screen dimming level">
                <span class="adl-range-value">0%</span>
            </div>
        </div>
        <button class="adl-reset" aria-label="Reset accessibility settings to defaults">Reset to Defaults</button>
    </div>
    <!-- /ACCESSIBILITY DASHBOARD -->

    <script src="../../../app.js" defer></script>
</body>
</html>