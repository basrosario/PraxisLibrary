<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Video QA: Learn techniques for prompting AI models to answer specific questions about video content, combining visual understanding with temporal reasoning.">
    <!-- SEO Meta -->
    <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">
    <meta name="author" content="Praxis Library">
    <meta name="theme-color" content="#DC3545">
    <link rel="canonical" href="https://praxislibrary.com/learn/modality/video/video-qa.html">
    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="Video QA - Praxis">
    <meta property="og:description" content="Video QA: Learn techniques for prompting AI models to answer specific questions about video content, combining visual understanding with temporal reasoning.">
    <meta property="og:url" content="https://praxislibrary.com/learn/modality/video/video-qa.html">
    <meta property="og:image" content="https://praxislibrary.com/assets/images/praxishome.png">
    <meta property="og:site_name" content="Praxis Library">
    <meta property="og:locale" content="en_US">
    <!-- Social Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Video QA - Praxis">
    <meta name="twitter:description" content="Video QA: Learn techniques for prompting AI models to answer specific questions about video content, combining visual understanding with temporal reasoning.">
    <meta name="twitter:image" content="https://praxislibrary.com/assets/images/praxishome.png">
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@type": [
        "LearningResource",
        "Article"
      ],
      "headline": "Video QA",
      "name": "Video QA",
      "description": "Video QA: Learn techniques for prompting AI models to answer specific questions about video content, combining visual understanding with temporal reasoning.",
      "url": "https://praxislibrary.com/learn/modality/video/video-qa.html",
      "inLanguage": "en-US",
      "learningResourceType": "Tutorial",
      "educationalLevel": "Beginner to Advanced",
      "educationalUse": "AI Prompt Engineering",
      "isAccessibleForFree": true,
      "publisher": {
        "@type": "EducationalOrganization",
        "name": "Praxis Library",
        "alternateName": "The Open Standard in AI Literacy",
        "url": "https://praxislibrary.com",
        "logo": "https://praxislibrary.com/favicon.svg",
        "description": "A comprehensive, living library of 5,000+ AI terms, 117 prompting frameworks, and interactive tools. The definitive open resource for AI literacy, prompt engineering, and human-AI communication.",
        "sameAs": [
          "https://www.tiktok.com/@thepraxislibrary",
          "https://www.facebook.com/profile.php?id=61587612308104",
          "https://github.com/PowerOfPraxis/PraxisLibrary"
        ],
        "knowsAbout": [
          "Artificial Intelligence",
          "AI Literacy",
          "Prompt Engineering",
          "AI Prompting Frameworks",
          "AI Glossary",
          "Large Language Models",
          "Chain-of-Thought Prompting",
          "AI Education",
          "Human-AI Communication",
          "Neurodivergence and AI",
          "AI Safety",
          "AI Ethics"
        ]
      },
      "isPartOf": {
        "@type": "WebSite",
        "name": "Praxis Library",
        "url": "https://praxislibrary.com"
      },
      "about": [
        {
          "@type": "Thing",
          "name": "Prompt Engineering"
        },
        {
          "@type": "Thing",
          "name": "AI Communication"
        }
      ]
    },
    {
      "@type": "BreadcrumbList",
      "itemListElement": [
        {
          "@type": "ListItem",
          "position": 1,
          "name": "Home",
          "item": "https://praxislibrary.com"
        },
        {
          "@type": "ListItem",
          "position": 2,
          "name": "Discover",
          "item": "https://praxislibrary.com/learn/"
        },
        {
          "@type": "ListItem",
          "position": 3,
          "name": "Modality",
          "item": "https://praxislibrary.com/learn/modality/"
        },
        {
          "@type": "ListItem",
          "position": 4,
          "name": "Video",
          "item": "https://praxislibrary.com/learn/modality/video/"
        },
        {
          "@type": "ListItem",
          "position": 5,
          "name": "Video QA"
        }
      ]
    }
  ]
}
    </script>
    <!-- /SEO -->

<title>Video QA - Praxis</title>
    <link rel="icon" type="image/svg+xml" href="../../../favicon.svg">
    <link rel="stylesheet" href="../../../styles.css">
</head>
<body>
    <a href="#main-content" class="skip-link">Skip to main content</a>

        <header class="header" id="header">
        <div class="header-container">
            <a href="../../../index.html" class="logo">&lt;/Praxis <span>Library</span>&gt;</a>
            <nav class="nav" id="nav" aria-label="Main navigation">
                <a href="../../../foundations/index.html" class="nav-link">AI Foundations</a>
                <div class="nav-item has-dropdown">
                    <a href="../../index.html" class="nav-link active" aria-expanded="false">Discover</a>
                                        <div class="mega-menu mega-menu--categories">
                        <div class="mega-menu-quick-links">
                            <a href="../../../pages/glossary.html">Glossary</a>
                            <a href="../../index.html">Discover</a>
                            <a href="../../prompt-basics.html">Prompt Basics</a>
                            <a href="../../facts-fictions.html">Facts &amp; Fictions</a>
                        </div>
                        <div class="mega-menu-group">
                            <span class="mega-menu-group__label">Techniques</span>
                            <a href="../../structured-frameworks.html" class="mega-menu-group__link">Structured Frameworks</a>
                            <a href="../../in-context-learning.html" class="mega-menu-group__link">In-Context Learning</a>
                            <a href="../../reasoning-cot.html" class="mega-menu-group__link">Reasoning &amp; CoT</a>
                            <a href="../../decomposition.html" class="mega-menu-group__link">Decomposition</a>
                            <a href="../../self-correction.html" class="mega-menu-group__link">Self-Correction</a>
                            <a href="../../ensemble-methods.html" class="mega-menu-group__link">Ensemble Methods</a>
                            <a href="../../prompting-strategies.html" class="mega-menu-group__link">Prompting Strategies</a>
                        </div>
                        <div class="mega-menu-group">
                            <span class="mega-menu-group__label">Modality</span>
                            <a href="../code/" class="mega-menu-group__link">Code</a>
                            <a href="../image/" class="mega-menu-group__link">Image</a>
                            <a href="../audio/" class="mega-menu-group__link">Audio</a>
                            <a href="../video/" class="mega-menu-group__link">Video</a>
                            <a href="../3d/" class="mega-menu-group__link">3D</a>
                        </div>
                    </div>
                </div>
                <div class="nav-item has-dropdown">
                    <a href="../../../tools/index.html" class="nav-link" aria-expanded="false">AI Readiness</a>
                    <div class="mega-menu">
                        <div class="mega-menu-section">
                            <h4>Tools</h4>
                            <a href="../../../quiz/index.html">Readiness Quiz</a>
                            <a href="../../../tools/analyzer.html">Prompt Analyzer</a>
                            <a href="../../../tools/guidance.html">Prompt Builder</a>
                            <a href="../../../tools/matcher.html">Framework Finder</a>
                            <a href="../../../tools/checklist.html">Preflight Checklist</a>
                            <a href="../../../tools/persona.html">Persona Architect</a>
                            <a href="../../../patterns/index.html">Patterns Library</a>
                            <a href="../../../pages/ai-safety.html">AI Safety</a>
                        </div>
                    </div>
                </div>
                <div class="nav-item has-dropdown">
                    <a href="../../../pages/resources.html" class="nav-link" aria-expanded="false">Resources</a>
                    <div class="mega-menu mega-menu--multi-column">
                        <div class="mega-menu-section">
                            <h4>Guides</h4>
                            <a href="../../../pages/glossary.html">Glossary</a>
                            <a href="../../../pages/chatgpt-guide.html">ChatGPT Guide</a>
                            <a href="../../../pages/faq.html">FAQ</a>
                        </div>
                        <div class="mega-menu-section">
                            <h4>Principles</h4>
                            <a href="../../../pages/ai-for-everybody.html">AI for Everybody</a>
                            <a href="../../../pages/universal-design.html">Universal Design</a>
                            <a href="../../../pages/ai-assisted-building.html">AI Assisted</a>
                            <a href="../../../pages/security.html">Security</a>
                            <a href="../../../pages/performance.html">Performance</a>
                        </div>
                        <div class="mega-menu-section mega-menu-section--featured">
                            <h4>AI &amp; ND</h4>
                            <a href="../../../neurodivergence/index.html">ND Hub</a>
                            <a href="../../../neurodivergence/adhd.html">AI for ADHD</a>
                            <a href="../../../neurodivergence/autism.html">AI for Autism</a>
                            <a href="../../../neurodivergence/dyslexia.html">AI for Dyslexia</a>
                            <a href="../../../neurodivergence/tools.html">AI Tools</a>
                            <a href="../../../neurodivergence/resources.html">ND Resources</a>
                        </div>
                        <div class="mega-menu-section">
                            <h4>About</h4>
                            <a href="../../../pages/about.html">About Praxis</a>
                        </div>
                    </div>
                </div>
            </nav>
            <button class="menu-toggle" id="menuToggle" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>
    </header>

    <main id="main-content">
        <!-- === HERO SECTION === -->
        <section class="page-hero">
            <canvas id="page-hero-neural-bg" class="page-hero-neural-bg"></canvas>
            <div class="container">
                <nav class="breadcrumb fade-in" aria-label="Breadcrumb">
                    <a href="../../../index.html">Home</a>
                    <span class="separator">/</span>
                    <a href="../../index.html">Discover</a>
                    <span class="separator">/</span>
                    <span class="current">Video QA</span>
                </nav>
                <div class="hero-badge">
                    <span class="hero-badge__text">Video Frameworks</span>
                </div>
                <h1 class="page-title fade-in">Video QA</h1>
                <p class="page-subtitle fade-in">Techniques for asking and answering specific questions about video content using AI &mdash; combining visual understanding with temporal reasoning to extract precise information from moving imagery.</p>
            </div>
        </section>
        <!-- /HERO SECTION -->

        <!-- === HISTORICAL CONTEXT === -->
        <section class="section">
            <div class="container">
                <div class="highlight-box highlight-box--warning fade-in-up">
                    <div class="highlight-box__content">
                        <span class="highlight-box__title">Framework Context: 2023&ndash;2024</span>
                        <p><strong>Introduced:</strong> Video question answering emerged as a distinct discipline within multimodal AI during 2023&ndash;2024, as frontier models gained the ability to process video inputs alongside text. While academic research into Video QA dates back to datasets like ActivityNet-QA (2019) and TVQA (2018), the practical ability to upload a video and ask natural language questions about its content became accessible through models like Gemini 1.5 Pro and GPT-4o. These systems moved beyond static frame analysis to genuine temporal understanding &mdash; tracking actions across time, identifying cause-and-effect sequences, and answering questions that require synthesizing information from multiple moments in a video.</p>
                        <p><strong>Modern LLM Status:</strong> Video QA is <strong>rapidly maturing in frontier multimodal models</strong> but remains more challenging than image-based QA due to the temporal dimension. Models must process not just what appears in a single frame but how visual elements change, interact, and progress over time. The core prompting techniques &mdash; framing precise questions, specifying temporal scope, defining expected answer formats, and grounding responses in observable evidence &mdash; are essential because vague video questions produce superficial descriptions rather than targeted answers. The principles covered here apply across educational content analysis, sports video review, surveillance interpretation, and any domain where answering questions about what happened in a video matters.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- /HISTORICAL CONTEXT -->

        <!-- === THE CONCEPT === -->
        <section class="section section-alt">
            <div class="container">
                <div class="split-section split-section--center fade-in-up">
                    <div class="split-section__content">
                        <span class="split-section__badge">The Core Insight</span>
                        <h2 class="split-section__title">Ask Questions About What You See Moving</h2>
                        <p class="split-section__text">Video QA combines visual understanding with temporal reasoning to answer specific questions about video content. Unlike static image QA where the model examines a single frozen moment, video QA requires the model to track objects, actions, and events across time &mdash; understanding not just what is present in a frame, but what happened before, what is happening now, and what consequences follow.</p>
                        <p class="split-section__text"><strong>The core insight is that effective video QA requires combining visual understanding with temporal reasoning to answer questions that span across frames and moments.</strong> A vague question like &ldquo;What&rsquo;s in this video?&rdquo; produces a shallow summary. But when you specify the temporal scope, the type of information you need, and the level of detail expected, the model shifts from passive description to active investigation &mdash; scanning across the timeline to locate the precise moments and visual evidence that answer your question.</p>
                        <p class="split-section__text">Think of it like the difference between asking a witness &ldquo;What did you see?&rdquo; versus &ldquo;Between 2:15 and 2:30 PM, did the person in the red jacket hand anything to the person at the counter?&rdquo; The first invites a rambling narrative. The second directs attention to a specific timeframe, specific subjects, and a specific action &mdash; producing a focused, verifiable answer grounded in observable evidence.</p>
                    </div>
                    <div class="split-section__visual">
                        <div class="highlight-box highlight-box--info">
                            <div class="highlight-box__content">
                                <span class="highlight-box__title">Why Temporal Precision Transforms Video Analysis</span>
                                <p>When a model receives a video with an open-ended question, it defaults to a chronological summary &mdash; narrating what it sees from beginning to end with minimal depth. Structured video QA prompts redirect this behavior by defining the <strong>temporal scope</strong> (which part of the video matters), the <strong>analytical focus</strong> (what kind of information is needed), and the <strong>evidence standard</strong> (how the answer should be grounded in observable content). The difference between a generic video description and a precise, timestamped answer to a specific question often comes down entirely to how the question itself is structured.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /THE CONCEPT -->

        <!-- === HOW IT WORKS === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">The Video QA Process</h2>
                <p class="section-subtitle fade-in-up">Four steps from video input to precise, evidence-grounded answers</p>

                <div class="element-timeline fade-in-up">
                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">1</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Frame the Question</h3>
                            <p class="element-timeline__text">Craft a specific, answerable question about the video content. The best video QA questions target observable facts &mdash; actions taken, objects present, sequences of events, spatial relationships, or changes over time. Avoid questions that require knowledge the video cannot provide. A well-framed question tells the model exactly what kind of information to look for, which prevents it from defaulting to a general narration of everything it sees.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>&ldquo;How many times does the presenter switch from the slide deck to a live demo during this conference talk, and what topic does each demo illustrate?&rdquo;</p>
                            </div>
                        </div>
                    </div>

                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">2</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Specify Temporal Scope</h3>
                            <p class="element-timeline__text">Define which portion of the video the model should focus on. This can be an explicit time range, a relative reference like &ldquo;the opening segment&rdquo; or &ldquo;the final five minutes,&rdquo; or a conditional scope like &ldquo;every moment where the instructor demonstrates a technique.&rdquo; Temporal scoping is critical because videos can be long, and without boundaries the model may spread its attention too thin or focus on irrelevant sections, producing answers that miss the specific moments you care about.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>&ldquo;Focus on the segment between 4:30 and 8:15. During this section, what safety equipment is the worker wearing, and does it change at any point?&rdquo;</p>
                            </div>
                        </div>
                    </div>

                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">3</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Define Answer Format</h3>
                            <p class="element-timeline__text">Specify how you want the answer structured. Should the model provide a brief yes/no with justification, a timestamped list of observations, a comparative analysis of different moments, or a detailed narrative with visual evidence cited? The answer format shapes how the model organizes its analysis. A format that requires timestamps forces temporal precision. A format that requires visual evidence prevents hallucinated or assumed details from contaminating the response.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>&ldquo;Answer in a table with columns: Timestamp, Action Observed, Participants Involved, and Outcome. Include only moments where a clear decision or handoff occurs.&rdquo;</p>
                            </div>
                        </div>
                    </div>

                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">4</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Validate and Refine</h3>
                            <p class="element-timeline__text">Review the model&rsquo;s response and ask follow-up questions to verify accuracy, fill gaps, or drill deeper into specific moments it identified. Validation is especially important in video QA because temporal hallucination &mdash; where the model confidently describes events that did not occur at the stated timestamp &mdash; is a known failure mode. Ask the model to re-examine specific claims, provide additional visual evidence for its answers, or compare its observations against information from other parts of the video.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>&ldquo;You mentioned the second speaker begins at 12:40. Go back and verify: is the speaker transition at exactly that timestamp, or does it occur earlier? Describe the visual cues that mark the transition.&rdquo;</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /HOW IT WORKS -->

        <!-- === VISUAL: THE COMPARISON === -->
        <section class="section section-alt">
            <div class="container">
                <h2 class="section-title fade-in-up">See the Difference</h2>
                <p class="section-subtitle fade-in-up">Why structured video questions produce dramatically better answers</p>

                <div class="comparison-panel fade-in-up">
                    <div class="comparison-panel__side comparison-panel__side--before">
                        <div class="comparison-panel__header">
                            <span class="comparison-panel__icon">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <path d="M12 8v4M12 16h.01"/>
                                </svg>
                            </span>
                            <h3 class="comparison-panel__title">Vague Prompt</h3>
                        </div>
                        <div class="comparison-panel__content">
                            <div class="comparison-panel__prompt">
                                <span class="comparison-panel__label">Prompt</span>
                                <p>What happens in this video?</p>
                            </div>
                            <div class="comparison-panel__result">
                                <span class="comparison-panel__label">Response</span>
                                <p>This is a video of a cooking demonstration. Someone makes a dish with vegetables and sauce. They use a pan and some seasoning. The video is about 10 minutes long.</p>
                            </div>
                        </div>
                        <div class="comparison-panel__verdict comparison-panel__verdict--weak">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <path d="M8 12h8"/>
                            </svg>
                            <span>Generic summary, no timestamps, no specific techniques, no actionable detail</span>
                        </div>
                    </div>

                    <div class="comparison-panel__divider">
                        <span>VS</span>
                    </div>

                    <div class="comparison-panel__side comparison-panel__side--after">
                        <div class="comparison-panel__header">
                            <span class="comparison-panel__icon">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M13 2L3 14h9l-1 8 10-12h-9l1-8z"/>
                                </svg>
                            </span>
                            <h3 class="comparison-panel__title">Structured Video QA Prompt</h3>
                        </div>
                        <div class="comparison-panel__content">
                            <div class="comparison-panel__prompt">
                                <span class="comparison-panel__label">Prompt</span>
                                <p>At what points in this cooking video does the chef adjust the heat, and what visual cues indicate each temperature change? List each instance with the timestamp, the direction of adjustment, and what is happening to the food at that moment.</p>
                            </div>
                            <div class="comparison-panel__result">
                                <span class="comparison-panel__label">Response</span>
                                <p><strong>[1:22]</strong> Heat increased to high &mdash; chef turns dial clockwise; oil in pan begins to shimmer and lightly smoke.<br><strong>[3:05]</strong> Heat reduced to medium &mdash; visible flame decreases; chef adds garlic which sizzles gently rather than popping.<br><strong>[5:48]</strong> Heat reduced to low &mdash; chef turns dial to minimum; sauce transitions from active bubbling to slow simmer.<br><strong>[8:30]</strong> Heat turned off &mdash; chef removes pan from burner; residual steam visible as sauce settles.</p>
                            </div>
                        </div>
                        <div class="comparison-panel__verdict comparison-panel__verdict--strong">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <path d="M8 12l3 3 5-5"/>
                            </svg>
                            <span>Timestamped, evidence-grounded, specific to the question asked</span>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /THE COMPARISON -->
        <!-- === NLP TIP === -->
        <section class="section-tip fade-in-up">
            <div class="container">
                <div class="section-tip__content">
                    <div class="section-tip__icon">
                        <svg viewBox="-3 -3 30 30" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" aria-hidden="true">
                            <path d="M9 18h6M10 22h4M12 2a7 7 0 0 0-4 12.7V17h8v-2.3A7 7 0 0 0 12 2z"/>
                            <path d="M12 -1.5v2.5M6.3 2.5L4.5 0.7M17.7 2.5l1.8-1.8M3.2 7.5L1 6.5M20.8 7.5L23 6.5"/>
                        </svg>
                    </div>
                    <div class="section-tip__text">
                        <h3 class="section-tip__title">Natural Language Works Too</h3>
                        <p>While structured frameworks and contextual labels are powerful tools, <strong>LLMs are exceptionally good at understanding natural language.</strong> As long as your prompt contains the actual contextual information needed to create, answer, or deliver the response you&rsquo;re looking for &mdash; the who, what, why, and constraints &mdash; the AI can produce complete and accurate results whether you use a formal framework or plain conversational language. But even in 2026, with the best prompts, <strong>verifying AI output is always a necessary step.</strong></p>
                    </div>
                </div>
            </div>
        </section>
        <!-- /NLP TIP -->


        <!-- === EXAMPLES IN ACTION === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">Video QA in Action</h2>
                <p class="section-subtitle fade-in-up">See how structured questions unlock precise answers from video content</p>

                <div class="accordion fade-in-up" id="video-qa-accordion">
                    <div class="accordion-item">
                        <button class="accordion-header" aria-expanded="false">
                            <span class="accordion-title">Lecture Comprehension</span>
                            <span class="accordion-icon"><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polyline points="6 9 12 15 18 9"/></svg></span>
                        </button>
                        <div class="accordion-content">
                            <div class="technique-demo">
                                <div class="technique-demo__prompt">
                                    <span class="technique-demo__tag">Prompt</span>
                                    <p>&ldquo;Watch this 30-minute university lecture on machine learning. Identify every moment where the professor writes a mathematical formula on the whiteboard. For each formula, provide: (a) the timestamp when it first appears, (b) the formula itself transcribed into text, (c) the concept the professor is explaining when they write it, and (d) whether the professor verbally explains each variable or assumes prior knowledge.&rdquo;</p>
                                </div>
                                <div class="technique-demo__response">
                                    <span class="technique-demo__tag">Why This Works</span>
                                    <p>This prompt targets a specific, observable class of events &mdash; formula appearances on the whiteboard &mdash; and defines four precise data points to extract for each occurrence. By requiring both the visual content (the formula) and the contextual audio (the professor&rsquo;s explanation), the prompt forces the model to synchronize its visual and auditory analysis. The question about whether variables are explained versus assumed adds an evaluative layer that transforms raw extraction into educational assessment, making the output useful for study guide creation or lecture quality review.</p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <button class="accordion-header" aria-expanded="false">
                            <span class="accordion-title">Sports Analysis</span>
                            <span class="accordion-icon"><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polyline points="6 9 12 15 18 9"/></svg></span>
                        </button>
                        <div class="accordion-content">
                            <div class="technique-demo">
                                <div class="technique-demo__prompt">
                                    <span class="technique-demo__tag">Prompt</span>
                                    <p>&ldquo;Analyze this basketball game highlight reel. For each scoring play: (a) identify the timestamp, (b) describe the offensive formation used in the 5 seconds before the shot, (c) count how many passes occurred in the possession, (d) note whether the shot was contested or open, and (e) identify if the scorer was assisted or created their own shot. Present the results in a structured table.&rdquo;</p>
                                </div>
                                <div class="technique-demo__response">
                                    <span class="technique-demo__tag">Why This Works</span>
                                    <p>This prompt demonstrates temporal reasoning at its most demanding &mdash; each answer requires the model to look backward in time from the scoring event to analyze the possession that led to it. By specifying five distinct analytical dimensions per play and requesting a tabular format, the prompt prevents the model from producing a play-by-play narration and instead forces structured decomposition. The 5-second lookback window gives the model a concrete temporal scope, and the distinction between contested and open shots requires spatial reasoning about defender positioning relative to the scorer at the moment of the shot.</p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <button class="accordion-header" aria-expanded="false">
                            <span class="accordion-title">Training Video Assessment</span>
                            <span class="accordion-icon"><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polyline points="6 9 12 15 18 9"/></svg></span>
                        </button>
                        <div class="accordion-content">
                            <div class="technique-demo">
                                <div class="technique-demo__prompt">
                                    <span class="technique-demo__tag">Prompt</span>
                                    <p>&ldquo;Review this employee training video on laboratory safety procedures. For each safety procedure demonstrated: (a) provide the timestamp range, (b) name the procedure, (c) list the specific steps shown, (d) identify any steps that appear to be skipped or performed incorrectly compared to standard lab safety protocols, and (e) note whether the narrator verbally emphasizes each step or glosses over it. Conclude with an overall assessment of whether this video adequately covers the essential safety procedures for a chemistry lab.&rdquo;</p>
                                </div>
                                <div class="technique-demo__response">
                                    <span class="technique-demo__tag">Why This Works</span>
                                    <p>This prompt combines video comprehension with domain knowledge application. By asking the model to compare what it observes in the video against standard protocols, the prompt creates a gap analysis rather than a simple description. The requirement to note skipped or incorrect steps transforms passive viewing into active evaluation. The distinction between what is shown visually and what the narrator emphasizes verbally tests whether the audio and visual channels are consistent &mdash; a common quality issue in training materials where demonstrations may not match the accompanying narration.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /EXAMPLES IN ACTION -->

        <!-- === WHEN TO USE === -->
        <section class="section section-alt">
            <div class="container">
                <h2 class="section-title fade-in-up">When to Use Video QA</h2>
                <p class="section-subtitle fade-in-up">Best for extracting specific answers from video content</p>

                <div class="split-section fade-in-up">
                    <div class="split-section__content">
                        <h3 class="split-section__subtitle">Perfect For</h3>
                        <div class="feature-list">
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Educational Content Review</strong>
                                    <p>Extracting specific facts, formulas, or explanations from recorded lectures, tutorials, and online courses &mdash; turning hours of video into targeted study material focused on exactly what you need to learn.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Compliance and Safety Audits</strong>
                                    <p>Answering specific questions about whether safety procedures were followed, compliance requirements were met, or standard operating procedures were demonstrated correctly in recorded operations.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Sports and Performance Analysis</strong>
                                    <p>Querying game footage for specific plays, techniques, formations, or player behaviors &mdash; extracting structured analytical data from video that would require extensive manual review.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Meeting and Presentation Review</strong>
                                    <p>Answering targeted questions about recorded meetings or presentations &mdash; who said what, when specific topics were discussed, what visual materials were shown, and what decisions were reached.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="split-section__content">
                        <h3 class="split-section__subtitle">Skip It When</h3>
                        <div class="feature-list">
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Real-Time Video Processing</strong>
                                    <p>If you need answers about live video streams with sub-second latency &mdash; such as real-time surveillance alerts or live sports commentary &mdash; dedicated video analytics pipelines outperform prompt-based QA approaches.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Pixel-Level Precision</strong>
                                    <p>When you need exact measurements, pixel coordinates, or frame-perfect timing &mdash; such as motion capture data or VFX alignment &mdash; specialized computer vision tools provide the precision that language-based QA cannot match.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Audio-Only Questions</strong>
                                    <p>If your question is purely about what was said &mdash; with no visual component &mdash; audio prompting or speech-to-text techniques are more efficient and avoid the overhead of video processing entirely.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Video Generation Tasks</strong>
                                    <p>When the goal is to create, edit, or generate video content rather than analyze existing footage, video generation and editing prompting frameworks are the appropriate tools.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /WHEN TO USE -->

        <!-- === USE CASES === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">Use Cases</h2>
                <p class="section-subtitle fade-in-up">Where video QA delivers the most value</p>

                <div class="use-case-showcase fade-in-up">
                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M2 3h6a4 4 0 0 1 4 4v14a3 3 0 0 0-3-3H2z"/>
                                <path d="M22 3h-6a4 4 0 0 0-4 4v14a3 3 0 0 1 3-3h7z"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Lecture Analysis</h3>
                        <p class="use-case-showcase__desc">Querying recorded lectures for specific concepts, formulas, or explanations &mdash; enabling students and researchers to locate and extract precisely the information they need without watching entire recordings.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M12 22s8-4 8-10V5l-8-3-8 3v7c0 6 8 10 8 10z"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Safety Compliance</h3>
                        <p class="use-case-showcase__desc">Reviewing operational footage to answer whether specific safety protocols were followed, protective equipment was worn, and emergency procedures were correctly demonstrated during recorded activities.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <polygon points="10 8 16 12 10 16 10 8"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Sports Film Review</h3>
                        <p class="use-case-showcase__desc">Answering tactical questions about game footage &mdash; identifying formations, counting specific play types, tracking player positioning, and extracting structured performance data from recorded competitions.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/>
                                <polyline points="14 2 14 8 20 8"/>
                                <line x1="16" y1="13" x2="8" y2="13"/>
                                <line x1="16" y1="17" x2="8" y2="17"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Medical Training Review</h3>
                        <p class="use-case-showcase__desc">Querying recorded surgical procedures or clinical demonstrations to verify whether specific techniques were performed correctly, instrument handling followed protocol, and sterile field requirements were maintained.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <rect x="2" y="3" width="20" height="14" rx="2" ry="2"/>
                                <line x1="8" y1="21" x2="16" y2="21"/>
                                <line x1="12" y1="17" x2="12" y2="21"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Product Demo Assessment</h3>
                        <p class="use-case-showcase__desc">Analyzing recorded product demonstrations to answer specific questions about feature coverage, messaging consistency, and whether all key selling points were effectively communicated and visually supported.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"/>
                                <circle cx="12" cy="12" r="3"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Surveillance Review</h3>
                        <p class="use-case-showcase__desc">Answering targeted questions about security footage &mdash; identifying specific individuals, tracking movement patterns, determining sequence of events, and locating the precise moments when incidents occurred.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- /USE CASES -->

        <!-- === FRAMEWORK POSITIONING === -->
        <section class="section section-alt">
            <div class="container">
                <h2 class="section-title fade-in-up">Where Video QA Fits</h2>
                <p class="section-subtitle fade-in-up">Video QA bridges visual understanding and targeted information extraction</p>

                <div class="evolution-timeline fade-in-up">
                    <div class="era-marker">
                        <span class="era-marker__year">Image QA</span>
                        <span class="era-marker__title">Static Visual Questions</span>
                        <span class="era-marker__desc">Questions about single images</span>
                    </div>
                    <div class="era-marker era-marker--active">
                        <span class="era-marker__year">Video QA</span>
                        <span class="era-marker__title">Temporal Visual Questions</span>
                        <span class="era-marker__desc">Questions spanning time and motion</span>
                    </div>
                    <div class="era-marker">
                        <span class="era-marker__year">Video Captioning</span>
                        <span class="era-marker__title">Narrative Description</span>
                        <span class="era-marker__desc">Continuous description of video content</span>
                    </div>
                    <div class="era-marker">
                        <span class="era-marker__year">Temporal Reasoning</span>
                        <span class="era-marker__title">Causal Understanding</span>
                        <span class="era-marker__desc">Cause-effect and sequence analysis</span>
                    </div>
                </div>

                <div class="callout tip fade-in-up">
                    <div class="callout-title">Combine with Other Video Techniques</div>
                    <p>Video QA works best as part of a layered analysis strategy. Start with video captioning to get a broad understanding of the content, then use video QA to drill into specific moments or answer targeted questions that the caption missed. Layer in temporal reasoning when your questions involve cause-and-effect relationships or require the model to understand why something happened based on what came before. The QA format is particularly powerful because it forces both the prompter and the model to focus on specific, answerable questions rather than open-ended description.</p>
                </div>
            </div>
        </section>
        <!-- /FRAMEWORK POSITIONING -->

        <!-- === RELATED FRAMEWORKS === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">Related Frameworks</h2>
                <p class="section-subtitle fade-in-up">Explore complementary video techniques</p>

                <a href="video-prompting.html" class="evolution-callout fade-in-up">
                    <span class="evolution-callout__icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M13 2L3 14h9l-1 8 10-12h-9l1-8z"/>
                        </svg>
                    </span>
                    <div class="evolution-callout__content">
                        <span class="evolution-callout__label">Foundation</span>
                        <span class="evolution-callout__title">Video Prompting Basics</span>
                        <span class="evolution-callout__desc">The foundational techniques for prompting AI models to process, analyze, and reason about video content &mdash; establishing the core principles that Video QA builds upon for targeted question answering.</span>
                    </div>
                    <span class="evolution-callout__arrow">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M5 12h14M12 5l7 7-7 7"/>
                        </svg>
                    </span>
                </a>

                <a href="temporal-reasoning.html" class="evolution-callout fade-in-up">
                    <span class="evolution-callout__icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/>
                            <polyline points="14 2 14 8 20 8"/>
                            <line x1="16" y1="13" x2="8" y2="13"/>
                            <line x1="16" y1="17" x2="8" y2="17"/>
                        </svg>
                    </span>
                    <div class="evolution-callout__content">
                        <span class="evolution-callout__label">Evolution</span>
                        <span class="evolution-callout__title">Temporal Reasoning</span>
                        <span class="evolution-callout__desc">Extends video QA with deeper cause-and-effect analysis, sequence understanding, and the ability to answer questions that require reasoning about how events unfold and influence each other across time.</span>
                    </div>
                    <span class="evolution-callout__arrow">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M5 12h14M12 5l7 7-7 7"/>
                        </svg>
                    </span>
                </a>

                <a href="video-captioning.html" class="evolution-callout fade-in-up">
                    <span class="evolution-callout__icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M17 2l4 4-4 4"/>
                            <path d="M3 11v-1a4 4 0 0 1 4-4h14"/>
                            <path d="M7 22l-4-4 4-4"/>
                            <path d="M21 13v1a4 4 0 0 1-4 4H3"/>
                        </svg>
                    </span>
                    <div class="evolution-callout__content">
                        <span class="evolution-callout__label">Parallel</span>
                        <span class="evolution-callout__title">Video Captioning</span>
                        <span class="evolution-callout__desc">Focuses on generating continuous descriptions of video content rather than answering specific questions &mdash; useful for accessibility, content indexing, and creating a narrative overview before drilling into QA.</span>
                    </div>
                    <span class="evolution-callout__arrow">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M5 12h14M12 5l7 7-7 7"/>
                        </svg>
                    </span>
                </a>
            </div>
        </section>
        <!-- /RELATED FRAMEWORKS -->

        <!-- === CTA SECTION === -->
        <section class="section">
            <div class="container">
                <div class="cta-corporate cta-corporate--dark fade-in-up">
                    <canvas id="cta-neural-bg" class="cta-corporate__canvas"></canvas>
                    <div class="cta-corporate__content">
                        <h2 class="cta-corporate__title">Start Asking Better Video Questions</h2>
                        <p class="cta-corporate__text">Apply structured video QA techniques to extract precise answers from your video content, or build multimodal prompts with our tools.</p>
                        <div class="cta-corporate__actions">
                            <a href="../../../tools/guidance.html" class="btn btn-primary">Prompt Builder</a>
                            <a href="../../../foundations/index.html" class="btn btn-secondary">All Foundations</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /CTA SECTION -->
    </main>

    <!-- === FOOTER === -->
    <footer class="footer">
        <canvas id="footer-neural-bg" class="footer-neural-bg"></canvas>
        <div class="container">
            <div class="footer-grid">
                <div class="footer-brand">
                    <a href="../../../index.html" class="footer-logo">&lt;/Praxis <span>Library</span>&gt;</a>
                    <p>Master the Art of AI Communication theory through proven frameworks.</p>
                </div>

                <div class="footer-links">
                    <h4>Discover</h4>
                    <a href="../../prompt-basics.html">Prompt Basics</a>
                    <a href="../../crisp.html">CRISP Framework</a>
                    <a href="../../crispe.html">CRISPE Framework</a>
                    <a href="../../costar.html">COSTAR Framework</a>
                    <a href="../../react.html">ReAct Framework</a>
                    <a href="../../flipped-interaction.html">Flipped Interaction</a>
                    <a href="../../chain-of-thought.html">Chain-of-Thought</a>
                </div>

                <div class="footer-links">
                    <h4>AI Readiness Tools</h4>
                <a href="../../../tools/analyzer.html">Prompt Analyzer</a>
                <a href="../../../tools/matcher.html">Framework Finder</a>
                <a href="../../../tools/checklist.html">Preflight Checklist</a>
                <a href="../../../tools/guidance.html">Prompt Builder</a>
                <a href="../../../tools/persona.html">Persona Architect</a>
                <a href="../../../tools/hallucination.html">Hallucination Spotter</a>
                <a href="../../../quiz/index.html">Readiness Quiz</a>
                </div>

                <div class="footer-links">
                    <h4>Resources</h4>
                <a href="../../../patterns/index.html">Patterns Library</a>
                <a href="../../../pages/ai-safety.html">AI Safety</a>
                <a href="../../../pages/chatgpt-guide.html">ChatGPT Guide</a>
                    <a href="../../../pages/faq.html">FAQ</a>
                    <a href="../../../pages/glossary.html">Glossary</a>
                    <a href="../../../pages/security.html">Security</a>
                    <a href="../../../pages/performance.html">Performance</a>
                    <a href="../../../pages/ai-for-everybody.html">AI for Everybody</a>
                    <a href="../../../pages/universal-design.html">Universal Design</a>
                    <a href="../../../pages/ai-assisted-building.html">AI Assisted</a>
                    <a href="../../../pages/about.html">About</a>
                </div>
            </div>

            <div class="footer-bottom">
                <p>AI for Everybody</p>
                <p class="footer-quote">&ldquo;True innovation in AI isn&rsquo;t just about companies adopting AI as a new technology&mdash;it&rsquo;s about people learning about, adapting to, and adopting Artificial Intelligence into their daily lives to empower and unlock their own human potential.&rdquo; <span class="footer-quote-author">&mdash; Basiliso (Bas) Rosario</span></p>
            </div>

            <div class="footer-policies">
                <a href="../../../pages/use-policy.html">Use Policy</a>
                <a href="../../../pages/site-policy.html">Site Policy</a>
                <a href="../../../pages/security-policy.html">Security Policy</a>
                <a href="../../../pages/data-retention-policy.html">Data Retention</a>
            </div>
        </div>
    </footer>
    <!-- /FOOTER -->

    <!-- === BACK TO TOP === -->
    <button class="back-to-top-bar" aria-label="Back to top">
        <span class="back-to-top-arrow">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M18 15l-6-6-6 6"/>
            </svg>
        </span>
        <span class="back-to-top-text">Back to Top</span>
    </button>
    <!-- /BACK TO TOP -->

    <!-- === ACCESSIBILITY DASHBOARD === -->

    <!-- =============================================
         BADGE LIGHTBOX - Modal popup for badge info
         ============================================= -->
    <div class="badge-lightbox-overlay" aria-hidden="true"></div>
    <div class="badge-lightbox" role="dialog" aria-modal="true" aria-labelledby="badge-lightbox-title">
        <header class="badge-lightbox-header">
            <h2 class="badge-lightbox-title" id="badge-lightbox-title"></h2>
            <button class="badge-lightbox-close" aria-label="Close dialog">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor">
                    <path d="M18 6L6 18M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
            </button>
        </header>
        <div class="badge-lightbox-content"></div>
    </div>
    <!-- /BADGE LIGHTBOX -->

    <div class="adl-dim-overlay" aria-hidden="true"></div>
    <button class="adl-toggle" aria-label="Accessibility options" aria-expanded="false" aria-controls="adl-panel">
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <circle cx="12" cy="12" r="10"/>
            <circle cx="12" cy="10" r="3"/>
            <path d="M12 13v6M9 17l3 3 3-3"/>
        </svg>
    </button>
    <div class="adl-panel" id="adl-panel" role="dialog" aria-label="Accessibility Settings">
        <div class="adl-panel-header">
            <span class="adl-panel-title">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <circle cx="12" cy="12" r="10"/>
                    <circle cx="12" cy="10" r="3"/>
                    <path d="M12 13v6M9 17l3 3 3-3"/>
                </svg>
                Accessibility
            </span>
            <button class="adl-close" aria-label="Close accessibility panel">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M18 6L6 18M6 6l12 12"/>
                </svg>
            </button>
        </div>
        <div class="adl-control">
            <span class="adl-label">Text Size</span>
            <div class="adl-btn-group">
                <button class="adl-btn is-active" data-scale="1" aria-label="Normal text size">1x</button>
                <button class="adl-btn" data-scale="2" aria-label="Large text size">2x</button>
                <button class="adl-btn" data-scale="3" aria-label="Extra large text size">3x</button>
            </div>
        </div>
        <div class="adl-control">
            <div class="adl-switch-wrapper">
                <span class="adl-switch-label">High Contrast</span>
                <label class="adl-switch">
                    <input type="checkbox" id="adl-contrast-toggle" aria-label="Toggle high contrast mode">
                    <span class="adl-switch-track"></span>
                </label>
            </div>
        </div>
        <div class="adl-control adl-readaloud">
            <span class="adl-label">Read Aloud</span>
            <div class="adl-readaloud-controls">
                <button class="adl-play-btn" aria-label="Play or pause reading">
                    <svg class="play-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M8 5v14l11-7z"/></svg>
                    <svg class="pause-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M6 4h4v16H6V4zm8 0h4v16h-4V4z"/></svg>
                </button>
                <div class="adl-speed-group">
                    <button class="adl-speed-btn" data-speed="slow">Slow</button>
                    <button class="adl-speed-btn is-active" data-speed="normal">Normal</button>
                    <button class="adl-speed-btn" data-speed="fast">Fast</button>
                </div>
            </div>
            <div class="adl-reading-indicator"></div>
        </div>
        <div class="adl-control">
            <span class="adl-label">Screen Dimming</span>
            <div class="adl-range-wrapper">
                <input type="range" class="adl-range" id="adl-dim-slider" min="0" max="50" value="0" aria-label="Screen dimming level">
                <span class="adl-range-value">0%</span>
            </div>
        </div>
        <button class="adl-reset" aria-label="Reset accessibility settings to defaults">Reset to Defaults</button>
    </div>
    <!-- /ACCESSIBILITY DASHBOARD -->

    <script src="../../../app.js" defer></script>
</body>
</html>