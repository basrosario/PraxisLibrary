<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Video Prompting Basics: Learn foundational techniques for prompting AI models to analyze, understand, generate, and reason about video content in multimodal contexts.">
    <!-- SEO Meta -->
    <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">
    <meta name="author" content="Praxis Library">
    <meta name="theme-color" content="#DC3545">
    <link rel="canonical" href="https://praxislibrary.com/learn/modality/video/video-prompting.html">
    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="Video Prompting Basics - Praxis">
    <meta property="og:description" content="Video Prompting Basics: Learn foundational techniques for prompting AI models to analyze, understand, generate, and reason about video content in multimodal contexts.">
    <meta property="og:url" content="https://praxislibrary.com/learn/modality/video/video-prompting.html">
    <meta property="og:image" content="https://praxislibrary.com/assets/images/praxishome.png">
    <meta property="og:site_name" content="Praxis Library">
    <meta property="og:locale" content="en_US">
    <!-- Social Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Video Prompting Basics - Praxis">
    <meta name="twitter:description" content="Video Prompting Basics: Learn foundational techniques for prompting AI models to analyze, understand, generate, and reason about video content in multimodal contexts.">
    <meta name="twitter:image" content="https://praxislibrary.com/assets/images/praxishome.png">
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@type": [
        "LearningResource",
        "Article"
      ],
      "headline": "Video Prompting Basics",
      "name": "Video Prompting Basics",
      "description": "Video Prompting Basics: Learn foundational techniques for prompting AI models to analyze, understand, generate, and reason about video content in multimodal contexts.",
      "url": "https://praxislibrary.com/learn/modality/video/video-prompting.html",
      "inLanguage": "en-US",
      "learningResourceType": "Tutorial",
      "educationalLevel": "Beginner to Advanced",
      "educationalUse": "AI Prompt Engineering",
      "isAccessibleForFree": true,
      "publisher": {
        "@type": "EducationalOrganization",
        "name": "Praxis Library",
        "alternateName": "The Open Standard in AI Literacy",
        "url": "https://praxislibrary.com",
        "logo": "https://praxislibrary.com/favicon.svg",
        "description": "A comprehensive, living library of 5,000+ AI terms, 177 techniques & frameworks, and interactive tools. The definitive open resource for AI literacy, prompt engineering, and human-AI communication.",
        "sameAs": [
          "https://www.tiktok.com/@thepraxislibrary",
          "https://www.facebook.com/profile.php?id=61587612308104",
          "https://github.com/PowerOfPraxis/PraxisLibrary"
        ],
        "knowsAbout": [
          "Artificial Intelligence",
          "AI Literacy",
          "Prompt Engineering",
          "AI Prompting Techniques",
          "AI Glossary",
          "Large Language Models",
          "Chain-of-Thought Prompting",
          "AI Education",
          "Human-AI Communication",
          "Neurodivergence and AI",
          "AI Safety",
          "AI Ethics"
        ]
      },
      "isPartOf": {
        "@type": "WebSite",
        "name": "Praxis Library",
        "url": "https://praxislibrary.com"
      },
      "about": [
        {
          "@type": "Thing",
          "name": "Prompt Engineering"
        },
        {
          "@type": "Thing",
          "name": "AI Communication"
        }
      ]
    },
    {
      "@type": "BreadcrumbList",
      "itemListElement": [
        {
          "@type": "ListItem",
          "position": 1,
          "name": "Home",
          "item": "https://praxislibrary.com"
        },
        {
          "@type": "ListItem",
          "position": 2,
          "name": "Discover",
          "item": "https://praxislibrary.com/learn/"
        },
        {
          "@type": "ListItem",
          "position": 3,
          "name": "Modality",
          "item": "https://praxislibrary.com/learn/modality/"
        },
        {
          "@type": "ListItem",
          "position": 4,
          "name": "Video",
          "item": "https://praxislibrary.com/learn/modality/video/"
        },
        {
          "@type": "ListItem",
          "position": 5,
          "name": "Video Prompting Basics"
        }
      ]
    }
  ]
}
    </script>
    <!-- /SEO -->

<title>Video Prompting Basics - Praxis</title>
    <link rel="icon" type="image/svg+xml" href="../../../favicon.svg">
    <link rel="stylesheet" href="../../../styles.css">
</head>
<body>
    <a href="#main-content" class="skip-link">Skip to main content</a>

        <header class="header" id="header">
        <div class="header-container">
            <a href="../../../index.html" class="logo">&lt;/Praxis <span>Library</span>&gt;</a>
            <nav class="nav" id="nav" aria-label="Main navigation">
                <a href="../../../foundations/index.html" class="nav-link">History</a>
                <div class="nav-item has-dropdown">
                    <a href="../../index.html" class="nav-link active" aria-expanded="false">Discover</a>
                                        <div class="mega-menu mega-menu--categories">
                        <div class="mega-menu-quick-links">
                            <a href="../../index.html">Prompt Engineering</a>
                            <a href="../../prompt-basics.html">Prompt Basics</a>
                            <a href="../../facts-fictions.html">Facts &amp; Fictions</a>
                            <a href="../../../pages/glossary.html">Glossary</a>
                        </div>
                    </div>
                </div>
                <div class="nav-item has-dropdown">
                    <a href="../../../tools/index.html" class="nav-link" aria-expanded="false">Readiness</a>
                    <div class="mega-menu">
                        <div class="mega-menu-section">
                            <h4>Tools</h4>
                            <a href="../../../quiz/index.html">Readiness Quiz</a>
                            <a href="../../../tools/analyzer.html">Prompt Analyzer</a>
                            <a href="../../../tools/guidance.html">Prompt Builder</a>
                            <a href="../../../tools/matcher.html">Technique Finder</a>
                            <a href="../../../tools/checklist.html">Preflight Checklist</a>
                            <a href="../../../tools/persona.html">Persona Architect</a>
                            <a href="../../../patterns/index.html">Patterns Library</a>
                            <a href="../../../pages/ai-safety.html">AI Safety</a>
                        </div>
                    </div>
                </div>
                <div class="nav-item has-dropdown">
                    <a href="../../../pages/resources.html" class="nav-link" aria-expanded="false">Resources</a>
                    <div class="mega-menu mega-menu--categories">
                        <div class="mega-menu-quick-links">
                            <a href="../../../pages/responsible-ai.html">Responsible AI</a>
                            <a href="../../../neurodivergence/resources.html">ND Resources</a>
                            <a href="../../../benchmarks/index.html">AI Benchmarks</a>
                            <a href="../../../pages/audit-report.html">Audit Report</a>
                            <a href="../../../pages/about.html">About Praxis</a>
                            <a href="../../../pages/faq.html">FAQs</a>
                        </div>
                    </div>
                </div>
            </nav>
            <button class="menu-toggle" id="menuToggle" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>
    </header>

    <main id="main-content">
        <!-- === HERO SECTION === -->
        <section class="page-hero">
            <canvas id="page-hero-neural-bg" class="page-hero-neural-bg"></canvas>
            <div class="container">
                <nav class="breadcrumb fade-in" aria-label="Breadcrumb">
                    <a href="../../../index.html">Home</a>
                    <span class="separator">/</span>
                    <a href="../../index.html">Discover</a>
                    <span class="separator">/</span>
                    <span class="current">Video Prompting Basics</span>
                </nav>
                <div class="hero-badge">
                    <span class="hero-badge__text">Video Techniques</span>
                </div>
                <h1 class="page-title fade-in">Video Prompting Basics</h1>
                <p class="page-subtitle fade-in">Foundational techniques for guiding AI models to analyze, understand, generate, and reason about video &mdash; turning moving images into structured, temporal insights through carefully crafted multimodal prompts.</p>
            </div>
        </section>
        <!-- /HERO SECTION -->

        <!-- === HISTORICAL CONTEXT === -->
        <section class="section">
            <div class="container">
                <div class="highlight-box highlight-box--warning fade-in-up">
                    <div class="highlight-box__content">
                        <span class="highlight-box__title">Technique Context: 2023&ndash;2024</span>
                        <p><strong>Introduced:</strong> Video understanding in AI models emerged as a practical capability during 2023&ndash;2024, as frontier models gained the ability to process temporal visual sequences alongside text. Google&rsquo;s Gemini 1.5 Pro demonstrated long-context video comprehension by ingesting entire films and answering detailed questions about plot, characters, and scene transitions. OpenAI&rsquo;s GPT-4o introduced native video frame analysis, while Sora (previewed in early 2024) showcased generative video capabilities that demonstrated deep understanding of physics, motion, and scene composition. Video prompting as a distinct discipline &mdash; where users combine text instructions with video inputs to guide model analysis &mdash; builds on earlier image prompting foundations but introduces the critical dimension of time, requiring models to reason about change, motion, causality, and narrative across sequences of frames.</p>
                        <p><strong>Modern LLM Status:</strong> Video understanding is <strong>rapidly advancing in frontier models</strong> but remains more computationally demanding than image or audio analysis. Gemini models process video natively with extended context windows, GPT-4o analyzes video through frame sampling, and specialized models handle video generation and editing. The core techniques &mdash; specifying temporal scope, defining what visual changes to track, structuring output around events rather than static descriptions &mdash; are essential because models without explicit video guidance tend to describe individual frames rather than analyzing the temporal narrative. The principles covered here form the foundation for more advanced video techniques like video generation prompting, temporal reasoning, and video question answering.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- /HISTORICAL CONTEXT -->

        <!-- === THE CONCEPT === -->
        <section class="section section-alt">
            <div class="container">
                <div class="split-section split-section--center fade-in-up">
                    <div class="split-section__content">
                        <span class="split-section__badge">The Core Insight</span>
                        <h2 class="split-section__title">Guide the Model&rsquo;s Eye Through Time</h2>
                        <p class="split-section__text">Video prompting combines text instructions with video inputs to enable AI models to analyze, understand, summarize, and reason about moving images. Unlike image prompting where the model examines a single frozen moment, video prompting requires you to bridge three information channels &mdash; telling the model what to <strong>watch for</strong>, how to <strong>track changes across time</strong>, and how to <strong>structure its analysis</strong> of what unfolds across a sequence of frames.</p>
                        <p class="split-section__text"><strong>The core insight is that effective video prompting requires explicitly specifying WHAT to watch for, WHEN in the timeline to focus, and HOW to connect observations across time.</strong> A bare video upload with a vague question produces a flat description of a few sampled frames. But when you specify the analytical lens &mdash; motion tracking, scene transition analysis, narrative arc identification, behavioral pattern detection &mdash; the model shifts from passive frame description to active temporal reasoning and interpretation.</p>
                        <p class="split-section__text">Think of it like showing the same surveillance footage to a security analyst versus a film critic versus a sports coach. The security analyst tracks movement patterns, identifies anomalies, and timestamps suspicious activity. The film critic analyzes composition, pacing, and visual storytelling techniques. The sports coach breaks down player positioning, technique execution, and tactical decisions frame by frame. Video prompting is how you tell the model which kind of viewer to become.</p>
                    </div>
                    <div class="split-section__visual">
                        <div class="highlight-box highlight-box--info">
                            <div class="highlight-box__content">
                                <span class="highlight-box__title">Why Temporal Specificity Transforms Video Analysis</span>
                                <p>When a model receives video without clear instructions, it defaults to describing a handful of sampled frames &mdash; producing a series of disconnected static observations with no temporal thread. Structured video prompts redirect this behavior by defining the <strong>temporal analytical framework</strong> the model should apply: what time range to focus on, which visual changes matter, how to connect events across scenes, what level of temporal granularity is expected, and whether to prioritize motion, dialogue, environmental changes, or narrative structure. The difference between a generic &ldquo;this video shows people in an office&rdquo; and a structured analysis with scene-by-scene breakdowns, action timelines, and behavioral observations comes down entirely to the quality of the accompanying text prompt.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /THE CONCEPT -->

        <!-- === HOW IT WORKS === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">The Video Prompting Process</h2>
                <p class="section-subtitle fade-in-up">Four steps from video input to structured temporal analysis</p>

                <div class="element-timeline fade-in-up">
                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">1</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Provide the Video</h3>
                            <p class="element-timeline__text">Upload or reference the video input you want the model to analyze. This can be a recorded meeting, surveillance clip, tutorial, product demonstration, film excerpt, sports footage, or any other video format the model supports. Video quality and length both matter significantly &mdash; higher resolution allows the model to detect finer visual details and read on-screen text, while longer videos require more precise temporal scoping in your prompt to avoid shallow, overly general summaries that miss critical moments.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>Upload a product demonstration video, ensuring the footage is well-lit, the product is clearly visible throughout, and any on-screen text or UI elements are legible at the video&rsquo;s native resolution.</p>
                            </div>
                        </div>
                    </div>

                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">2</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Frame the Task</h3>
                            <p class="element-timeline__text">Specify exactly what type of analysis you need from the video. Are you asking the model to summarize the narrative, track specific objects or people, identify scene transitions, detect actions or events, assess visual quality, or extract information from on-screen elements? The task framing determines whether the model focuses on individual frames, motion between frames, audio-visual alignment, or the overarching story. A scene-by-scene breakdown and a motion analysis applied to the same video will produce fundamentally different outputs.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>&ldquo;Analyze this product demo video. Identify each distinct feature being demonstrated, note the timestamp range for each demonstration segment, describe the presenter&rsquo;s actions, and capture any on-screen text or UI labels that appear.&rdquo;</p>
                            </div>
                        </div>
                    </div>

                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">3</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Add Constraints</h3>
                            <p class="element-timeline__text">Define the output format, temporal resolution, and analytical depth you expect. Constraints prevent the model from producing a vague overview when you need frame-level precision. Specify whether you want timestamps or scene numbers, continuous narrative or segmented analysis, visual-only observations or audio-visual synthesis, and whether to track specific elements (people, objects, text overlays) across the entire duration or focus on key moments of change.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>&ldquo;Structure your response as: (1) Scene-by-scene breakdown with start and end timestamps, (2) For each scene, describe the visual setting, people present, and primary action, (3) List all on-screen text and graphics with their timestamps, (4) Provide a narrative summary connecting the scenes into a coherent storyline.&rdquo;</p>
                            </div>
                        </div>
                    </div>

                    <div class="element-timeline__item">
                        <div class="element-timeline__marker">
                            <span class="element-timeline__number">4</span>
                        </div>
                        <div class="element-timeline__content">
                            <h3 class="element-timeline__title">Iterate on Results</h3>
                            <p class="element-timeline__text">Refine based on the initial output. Zoom into specific time ranges, ask about particular visual elements that need deeper analysis, or request the model to compare different segments. Iterative prompting is especially powerful with video because each round can direct the model&rsquo;s attention to specific timestamps, particular people or objects, transitions between scenes, or subtle visual changes that were overlooked in the initial broad-pass analysis.</p>
                            <div class="element-timeline__example">
                                <span class="element-timeline__example-label">Example</span>
                                <p>&ldquo;You noted a scene transition around the 3:45 mark where the presenter moves from the dashboard view to the settings panel. Go back to that segment and describe exactly what UI elements changed, what buttons were clicked, and whether any error states or loading indicators appeared during the transition.&rdquo;</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /HOW IT WORKS -->

        <!-- === VISUAL: THE COMPARISON === -->
        <section class="section section-alt">
            <div class="container">
                <h2 class="section-title fade-in-up">See the Difference</h2>
                <p class="section-subtitle fade-in-up">Why structured video prompts produce dramatically better analysis</p>

                <div class="comparison-panel fade-in-up">
                    <div class="comparison-panel__side comparison-panel__side--before">
                        <div class="comparison-panel__header">
                            <span class="comparison-panel__icon">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <path d="M12 8v4M12 16h.01"/>
                                </svg>
                            </span>
                            <h3 class="comparison-panel__title">Vague Prompt</h3>
                        </div>
                        <div class="comparison-panel__content">
                            <div class="comparison-panel__prompt">
                                <span class="comparison-panel__label">Prompt</span>
                                <p>What happens in this video?</p>
                            </div>
                            <div class="comparison-panel__result">
                                <span class="comparison-panel__label">Response</span>
                                <p>This video shows a person giving a presentation in an office. They talk about a software product and show some screens. The video is about 5 minutes long and has some slides.</p>
                            </div>
                        </div>
                        <div class="comparison-panel__verdict comparison-panel__verdict--weak">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <path d="M8 12h8"/>
                            </svg>
                            <span>Vague, no timestamps, no scene detail, no actionable structure</span>
                        </div>
                    </div>

                    <div class="comparison-panel__divider">
                        <span>VS</span>
                    </div>

                    <div class="comparison-panel__side comparison-panel__side--after">
                        <div class="comparison-panel__header">
                            <span class="comparison-panel__icon">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M13 2L3 14h9l-1 8 10-12h-9l1-8z"/>
                                </svg>
                            </span>
                            <h3 class="comparison-panel__title">Structured Video Prompt</h3>
                        </div>
                        <div class="comparison-panel__content">
                            <div class="comparison-panel__prompt">
                                <span class="comparison-panel__label">Prompt</span>
                                <p>Analyze this product demo video scene by scene. For each segment, provide timestamps, describe the feature being demonstrated, note all on-screen UI elements, and identify the presenter&rsquo;s key claims.</p>
                            </div>
                            <div class="comparison-panel__result">
                                <span class="comparison-panel__label">Response</span>
                                <p><strong>[00:00&ndash;00:45] Introduction:</strong> Presenter at standing desk, company logo on screen. States product handles &ldquo;10x the data volume of competitors.&rdquo;<br><strong>[00:45&ndash;02:10] Dashboard Overview:</strong> Shows analytics dashboard with 4 widget panels. Clicks &ldquo;Real-time metrics&rdquo; tab; data refreshes within 2 seconds. On-screen label reads &ldquo;v3.2 Beta.&rdquo;<br><strong>[02:10&ndash;03:45] Import Feature:</strong> Drags CSV file into upload zone. Progress bar appears. 50,000 rows processed in 8 seconds. Error count: 0.<br><strong>[03:45&ndash;05:00] Settings and Wrap-up:</strong> Navigates to settings panel, toggles &ldquo;Auto-sync&rdquo; feature. Closing slide shows pricing tiers and a QR code linking to the trial page.</p>
                            </div>
                        </div>
                        <div class="comparison-panel__verdict comparison-panel__verdict--strong">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <path d="M8 12l3 3 5-5"/>
                            </svg>
                            <span>Structured, timestamped, scene-segmented, and detail-rich</span>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /THE COMPARISON -->
        <!-- === RAI TIP === -->
        <section class="section-tip fade-in-up">
            <div class="container">
                <div class="section-tip__content">
                    <div class="section-tip__icon">
                        <span class="section-tip__stop-text" aria-hidden="true">STOP</span>
                    </div>
                    <div class="section-tip__text">
                        <h3 class="section-tip__title">Practice Responsible AI</h3>
                        <p>Always verify AI-generated content before use. AI systems can produce confident but incorrect responses. When using AI professionally, transparent disclosure is both best practice and increasingly a legal requirement.</p>
                        <p><strong>48 US states</strong> now require AI transparency in key areas. Critical thinking remains your strongest tool against misinformation.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- /RAI TIP -->

<!-- === EXAMPLES IN ACTION === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">Video Prompting in Action</h2>
                <p class="section-subtitle fade-in-up">See how structured prompts unlock deeper video analysis</p>

                <div class="accordion fade-in-up" id="video-prompting-accordion">
                    <div class="accordion-item">
                        <button class="accordion-header" aria-expanded="false">
                            <span class="accordion-title">Video Content Analysis</span>
                            <span class="accordion-icon"><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polyline points="6 9 12 15 18 9"/></svg></span>
                        </button>
                        <div class="accordion-content">
                            <div class="technique-demo">
                                <div class="technique-demo__prompt">
                                    <span class="technique-demo__tag">Prompt</span>
                                    <p>&ldquo;Analyze this 10-minute marketing video. Break it into distinct scenes based on visual transitions, location changes, or topic shifts. For each scene, provide: (a) start and end timestamps, (b) visual setting and lighting description, (c) people present and their actions, (d) any on-screen text, graphics, or brand elements, (e) the apparent purpose of the scene within the overall narrative. After the scene breakdown, summarize the video&rsquo;s persuasive structure and identify the primary call to action.&rdquo;</p>
                                </div>
                                <div class="technique-demo__response">
                                    <span class="technique-demo__tag">Why This Works</span>
                                    <p>The prompt goes far beyond &ldquo;what is this video about&rdquo; by specifying scene segmentation criteria, five distinct analysis dimensions per scene, and a synthesis layer that evaluates the overall persuasive strategy. This transforms a passive viewing task into a structured content audit. Without these constraints, the model would likely describe one or two representative frames and offer a generic summary, missing the scene-level detail that makes the analysis actionable for marketing teams evaluating content effectiveness.</p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <button class="accordion-header" aria-expanded="false">
                            <span class="accordion-title">Surveillance Review</span>
                            <span class="accordion-icon"><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polyline points="6 9 12 15 18 9"/></svg></span>
                        </button>
                        <div class="accordion-content">
                            <div class="technique-demo">
                                <div class="technique-demo__prompt">
                                    <span class="technique-demo__tag">Prompt</span>
                                    <p>&ldquo;Review this 30-minute security camera recording from a retail store entrance. Track all individuals who enter and exit the frame. For each person, note: (a) approximate time of entry and exit, (b) direction of movement, (c) whether they are carrying bags or objects, (d) any interactions with other people. Flag any moments where the entrance is crowded (3 or more people simultaneously) or where someone appears to reverse direction unexpectedly. Provide a timeline of all flagged events at the end.&rdquo;</p>
                                </div>
                                <div class="technique-demo__response">
                                    <span class="technique-demo__tag">Why This Works</span>
                                    <p>This prompt layers object tracking, behavioral pattern detection, and anomaly flagging onto a continuous video stream. By defining specific tracking criteria (entry, exit, objects, interactions) and explicit anomaly thresholds (crowd size, direction reversals), the prompt transforms a tedious manual review into a structured audit log. The flagged-events timeline at the end creates an executive summary that highlights only the moments requiring human attention, dramatically reducing the time needed to review lengthy surveillance footage.</p>
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="accordion-item">
                        <button class="accordion-header" aria-expanded="false">
                            <span class="accordion-title">Educational Video Assessment</span>
                            <span class="accordion-icon"><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><polyline points="6 9 12 15 18 9"/></svg></span>
                        </button>
                        <div class="accordion-content">
                            <div class="technique-demo">
                                <div class="technique-demo__prompt">
                                    <span class="technique-demo__tag">Prompt</span>
                                    <p>&ldquo;Evaluate this instructional video on data visualization techniques. Assess the following dimensions: (a) clarity of visual demonstrations &mdash; can the viewer follow each step as shown on screen? (b) pacing &mdash; are transitions between topics too fast, too slow, or well-timed? (c) visual aid effectiveness &mdash; do charts, diagrams, and screen recordings reinforce the spoken explanation? (d) knowledge gaps &mdash; are there concepts mentioned but never visually demonstrated? Provide timestamped notes for any segments where the visual content contradicts or fails to support the narration.&rdquo;</p>
                                </div>
                                <div class="technique-demo__response">
                                    <span class="technique-demo__tag">Why This Works</span>
                                    <p>This prompt applies pedagogical evaluation criteria to video content, requiring the model to assess alignment between visual and auditory channels &mdash; a uniquely video-centric analytical task. By specifying four distinct quality dimensions and requesting contradiction detection, the prompt produces an instructional design review that would typically require a subject matter expert viewing the content multiple times. The timestamped contradiction notes are particularly valuable because they pinpoint exact moments where the video&rsquo;s educational effectiveness breaks down.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /EXAMPLES IN ACTION -->

        <!-- === WHEN TO USE === -->
        <section class="section section-alt">
            <div class="container">
                <h2 class="section-title fade-in-up">When to Use Video Prompting</h2>
                <p class="section-subtitle fade-in-up">Best for structured analysis of visual content that unfolds over time</p>

                <div class="split-section fade-in-up">
                    <div class="split-section__content">
                        <h3 class="split-section__subtitle">Perfect For</h3>
                        <div class="feature-list">
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Video Summarization and Scene Breakdown</strong>
                                    <p>Converting long-form video into structured scene-by-scene summaries with timestamps, key events, visual descriptions, and narrative arcs extracted automatically from the footage.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Action and Event Detection</strong>
                                    <p>Identifying specific actions, events, or behavioral patterns within video &mdash; from product interactions in user testing sessions to movement patterns in sports footage or workflow steps in process documentation.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Content Moderation and Compliance</strong>
                                    <p>Screening video uploads for policy violations, unsafe content, brand guideline adherence, or regulatory compliance &mdash; flagging specific timestamps and visual elements that require human review.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--positive">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M22 11.08V12a10 10 0 1 1-5.93-9.14"/>
                                    <polyline points="22 4 12 14.01 9 11.01"/>
                                </svg>
                                <div>
                                    <strong>Accessibility and Description</strong>
                                    <p>Generating audio descriptions, chapter markers, and text summaries for video content, making visual media accessible to blind and low-vision users or enabling searchable video archives.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="split-section__content">
                        <h3 class="split-section__subtitle">Skip It When</h3>
                        <div class="feature-list">
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Real-Time Video Processing</strong>
                                    <p>If you need live video analysis with sub-second latency &mdash; such as real-time object detection on a security feed or live sports tracking &mdash; dedicated streaming computer vision systems outperform prompt-based approaches.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Pixel-Level Video Editing</strong>
                                    <p>When the goal is to perform precise frame-by-frame editing, color grading, compositing, or visual effects work, video prompting analyzes existing content but does not replace professional video editing software.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Audio-Only Analysis</strong>
                                    <p>If the information you need exists entirely in the audio track with no visual component &mdash; such as analyzing a podcast that was uploaded as a video file &mdash; use audio prompting techniques for more efficient and focused results.</p>
                                </div>
                            </div>
                            <div class="feature-list__item feature-list__item--neutral">
                                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                    <circle cx="12" cy="12" r="10"/>
                                    <line x1="8" y1="12" x2="16" y2="12"/>
                                </svg>
                                <div>
                                    <strong>Static Image Tasks</strong>
                                    <p>If your content is a single frame, screenshot, or photograph with no temporal dimension, image prompting techniques are more appropriate and computationally efficient than video prompting workflows.</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /WHEN TO USE -->

        <!-- === USE CASES === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">Use Cases</h2>
                <p class="section-subtitle fade-in-up">Where video prompting delivers the most value</p>

                <div class="use-case-showcase fade-in-up">
                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polygon points="23 7 16 12 23 17 23 7"/>
                                <rect x="1" y="5" width="15" height="14" rx="2" ry="2"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Meeting Recording Analysis</h3>
                        <p class="use-case-showcase__desc">Analyzing recorded video meetings to identify speakers by visual presence, track presentation slides and screen shares, correlate spoken content with visual aids, and extract action items tied to specific visual cues shown during the discussion.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"/>
                                <circle cx="12" cy="12" r="3"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Security and Surveillance</h3>
                        <p class="use-case-showcase__desc">Reviewing security camera footage to detect unusual activity patterns, track individuals across camera views, identify crowd density changes, and generate timestamped incident reports &mdash; converting hours of footage into focused event summaries.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M2 3h6a4 4 0 0 1 4 4v14a3 3 0 0 0-3-3H2z"/>
                                <path d="M22 3h-6a4 4 0 0 0-4 4v14a3 3 0 0 1 3-3h7z"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Educational Content Review</h3>
                        <p class="use-case-showcase__desc">Evaluating instructional videos for pedagogical effectiveness &mdash; assessing whether visual demonstrations align with narration, pacing supports comprehension, key concepts are adequately visualized, and the content follows a logical teaching progression.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="12" cy="12" r="10"/>
                                <polygon points="10 8 16 12 10 16 10 8"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Sports and Performance Analysis</h3>
                        <p class="use-case-showcase__desc">Breaking down athletic performances, practice sessions, or competitive events to analyze technique execution, player positioning, tactical patterns, and critical decision points &mdash; providing coaches with structured performance data from video footage.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <rect x="2" y="3" width="20" height="14" rx="2" ry="2"/>
                                <line x1="8" y1="21" x2="16" y2="21"/>
                                <line x1="12" y1="17" x2="12" y2="21"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">UX and Usability Testing</h3>
                        <p class="use-case-showcase__desc">Analyzing screen recordings of user testing sessions to identify navigation patterns, moments of confusion or hesitation, task completion paths, and UI elements that cause friction &mdash; turning raw session recordings into structured usability findings.</p>
                    </div>

                    <div class="use-case-showcase__item">
                        <div class="use-case-showcase__icon">
                            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M12 22s8-4 8-10V5l-8-3-8 3v7c0 6 8 10 8 10z"/>
                            </svg>
                        </div>
                        <h3 class="use-case-showcase__title">Brand and Content Compliance</h3>
                        <p class="use-case-showcase__desc">Screening marketing videos, social media content, and advertisements for brand guideline adherence, regulatory compliance, proper disclosure placement, and content policy violations &mdash; providing timestamped compliance reports before publication.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- /USE CASES -->

        <!-- === FRAMEWORK POSITIONING === -->
        <section class="section section-alt">
            <div class="container">
                <h2 class="section-title fade-in-up">Where Video Prompting Fits</h2>
                <p class="section-subtitle fade-in-up">Video prompting bridges visual understanding and temporal reasoning in multimodal AI</p>

                <div class="evolution-timeline fade-in-up">
                    <div class="era-marker">
                        <span class="era-marker__year">Text Prompting</span>
                        <span class="era-marker__title">Language Only</span>
                        <span class="era-marker__desc">Pure text input and output</span>
                    </div>
                    <div class="era-marker">
                        <span class="era-marker__year">Image Prompting</span>
                        <span class="era-marker__title">Static Visual Understanding</span>
                        <span class="era-marker__desc">Text plus single-frame visual input</span>
                    </div>
                    <div class="era-marker era-marker--active">
                        <span class="era-marker__year">Video Prompting</span>
                        <span class="era-marker__title">Temporal Visual Reasoning</span>
                        <span class="era-marker__desc">Text plus motion and sequence analysis</span>
                    </div>
                    <div class="era-marker">
                        <span class="era-marker__year">Video Generation</span>
                        <span class="era-marker__title">Creative Synthesis</span>
                        <span class="era-marker__desc">Producing video from text descriptions</span>
                    </div>
                </div>

                <div class="callout tip fade-in-up">
                    <div class="callout-title">Combine Modalities for Richer Analysis</div>
                    <p>Video prompting works best when you integrate techniques from both image prompting and audio prompting. A video is fundamentally a sequence of images with an audio track, so the sharpest analyses combine visual scene description (from image prompting principles) with speech and sound analysis (from audio prompting principles) and add temporal reasoning on top. Apply structured frameworks like CRISP or COSTAR to define your analytical scope, then specify video-specific constraints: scene segmentation criteria, temporal resolution, motion tracking targets, and how to handle the interplay between what is seen and what is heard across the video&rsquo;s timeline.</p>
                </div>
            </div>
        </section>
        <!-- /FRAMEWORK POSITIONING -->

        <!-- === RELATED FRAMEWORKS === -->
        <section class="section">
            <div class="container">
                <h2 class="section-title fade-in-up">Related Techniques</h2>
                <p class="section-subtitle fade-in-up">Explore complementary video techniques</p>

                <a href="video-gen.html" class="evolution-callout fade-in-up">
                    <span class="evolution-callout__icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M13 2L3 14h9l-1 8 10-12h-9l1-8z"/>
                        </svg>
                    </span>
                    <div class="evolution-callout__content">
                        <span class="evolution-callout__label">Evolution</span>
                        <span class="evolution-callout__title">Video Generation Prompting</span>
                        <span class="evolution-callout__desc">Extends video prompting into the generative domain &mdash; crafting text prompts that control AI video creation including scene composition, camera movement, subject motion, temporal coherence, and visual style across generated sequences.</span>
                    </div>
                    <span class="evolution-callout__arrow">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M5 12h14M12 5l7 7-7 7"/>
                        </svg>
                    </span>
                </a>

                <a href="temporal-reasoning.html" class="evolution-callout fade-in-up">
                    <span class="evolution-callout__icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"/>
                            <polyline points="14 2 14 8 20 8"/>
                            <line x1="16" y1="13" x2="8" y2="13"/>
                            <line x1="16" y1="17" x2="8" y2="17"/>
                        </svg>
                    </span>
                    <div class="evolution-callout__content">
                        <span class="evolution-callout__label">Complement</span>
                        <span class="evolution-callout__title">Temporal Reasoning</span>
                        <span class="evolution-callout__desc">Focuses on the time dimension of video analysis &mdash; understanding causality between events, predicting what happens next, tracking state changes over time, and reasoning about the sequence and duration of actions within video content.</span>
                    </div>
                    <span class="evolution-callout__arrow">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M5 12h14M12 5l7 7-7 7"/>
                        </svg>
                    </span>
                </a>

                <a href="video-qa.html" class="evolution-callout fade-in-up">
                    <span class="evolution-callout__icon">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M17 2l4 4-4 4"/>
                            <path d="M3 11v-1a4 4 0 0 1 4-4h14"/>
                            <path d="M7 22l-4-4 4-4"/>
                            <path d="M21 13v1a4 4 0 0 1-4 4H3"/>
                        </svg>
                    </span>
                    <div class="evolution-callout__content">
                        <span class="evolution-callout__label">Parallel</span>
                        <span class="evolution-callout__title">Video Question Answering</span>
                        <span class="evolution-callout__desc">Specializes in asking and answering targeted questions about video content &mdash; from factual queries about visible objects and actions to inferential questions about character motivations, plot developments, and causal relationships within the footage.</span>
                    </div>
                    <span class="evolution-callout__arrow">
                        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                            <path d="M5 12h14M12 5l7 7-7 7"/>
                        </svg>
                    </span>
                </a>
            </div>
        </section>
        <!-- /RELATED FRAMEWORKS -->

        <!-- === CTA SECTION === -->
        <section class="section">
            <div class="container">
                <div class="cta-corporate cta-corporate--dark fade-in-up">
                    <canvas id="cta-neural-bg" class="cta-corporate__canvas"></canvas>
                    <div class="cta-corporate__content">
                        <h2 class="cta-corporate__title">Explore Video Prompting</h2>
                        <p class="cta-corporate__text">Apply structured video analysis techniques to your own footage or build multimodal prompts with our tools.</p>
                        <div class="cta-corporate__actions">
                            <a href="../../../tools/guidance.html" class="btn btn-primary">Prompt Builder</a>
                            <a href="../../../foundations/index.html" class="btn btn-secondary">All Foundations</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /CTA SECTION -->
    </main>

    <!-- === FOOTER === -->
    <footer class="footer">
        <canvas id="footer-neural-bg" class="footer-neural-bg"></canvas>
        <div class="container">
            <div class="footer-grid">
                <div class="footer-brand">
                    <a href="../../../index.html" class="footer-logo">&lt;/Praxis <span>Library</span>&gt;</a>
                    <p>Master the Art of AI Communication theory through proven frameworks.</p>
                </div>

                <div class="footer-links">
                    <h4>Techniques</h4>
                    <a href="../../prompt-basics.html">Prompt Basics</a>
                    <a href="../../crisp.html">CRISP Framework</a>
                    <a href="../../crispe.html">CRISPE Framework</a>
                    <a href="../../costar.html">CO-STAR Framework</a>
                    <a href="../../react.html">ReAct Framework</a>
                    <a href="../../flipped-interaction.html">Flipped Interaction</a>
                    <a href="../../chain-of-thought.html">Chain-of-Thought</a>
                </div>

                <div class="footer-links">
                    <h4>AI Readiness Tools</h4>
                <a href="../../../tools/analyzer.html">Prompt Analyzer</a>
                <a href="../../../tools/matcher.html">Technique Finder</a>
                <a href="../../../tools/checklist.html">Preflight Checklist</a>
                <a href="../../../tools/guidance.html">Prompt Builder</a>
                <a href="../../../tools/persona.html">Persona Architect</a>
                <a href="../../../tools/hallucination.html">Hallucination Spotter</a>
                <a href="../../../quiz/index.html">Readiness Quiz</a>
                </div>

                <div class="footer-links">
                    <h4>Resources</h4>
                <a href="../../../patterns/index.html">Patterns Library</a>
                <a href="../../../pages/ai-safety.html">AI Safety</a>
                <a href="../../../pages/responsible-ai.html">Responsible AI</a>
                    <a href="../../../pages/faq.html">FAQ</a>
                    <a href="../../../pages/glossary.html">Glossary</a>
                    <a href="../../../pages/security.html">Security</a>
                    <a href="../../../pages/performance.html">Performance</a>
                    <a href="../../../pages/about.html">About</a>
                </div>
            </div>

            <div class="footer-bottom">
                <p>AI for Everybody</p>
                <p class="footer-quote">&ldquo;True innovation in AI isn&rsquo;t just about companies adopting AI as a new technology&mdash;it&rsquo;s about people learning about, adapting to, and adopting Artificial Intelligence into their daily lives to empower and unlock their own human potential.&rdquo; <span class="footer-quote-author">&mdash; Basiliso (Bas) Rosario</span></p>
            </div>

            <div class="footer-policies">
            <a href="../../../pages/responsible-ai.html">Responsible AI</a>
                <a href="../../../pages/use-policy.html">Use Policy</a>
                <a href="../../../pages/site-policy.html">Site Policy</a>
                <a href="../../../pages/security-policy.html">Security Policy</a>
                <a href="../../../pages/data-retention-policy.html">Data Retention</a>
            </div>
        </div>
    </footer>
    <!-- /FOOTER -->

    <!-- === BACK TO TOP === -->
    <button class="back-to-top-bar" aria-label="Back to top">
        <span class="back-to-top-arrow">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M18 15l-6-6-6 6"/>
            </svg>
        </span>
        <span class="back-to-top-text">Back to Top</span>
    </button>
    <!-- /BACK TO TOP -->

    <!-- === ACCESSIBILITY DASHBOARD === -->

    <!-- =============================================
         BADGE LIGHTBOX - Modal popup for badge info
         ============================================= -->
    <div class="badge-lightbox-overlay" aria-hidden="true"></div>
    <div class="badge-lightbox" role="dialog" aria-modal="true" aria-labelledby="badge-lightbox-title">
        <header class="badge-lightbox-header">
            <h2 class="badge-lightbox-title" id="badge-lightbox-title"></h2>
            <button class="badge-lightbox-close" aria-label="Close dialog">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor">
                    <path d="M18 6L6 18M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
            </button>
        </header>
        <div class="badge-lightbox-content"></div>
    </div>
    <!-- /BADGE LIGHTBOX -->

    <div class="adl-dim-overlay" aria-hidden="true"></div>
    <button class="adl-toggle" aria-label="Accessibility options" aria-expanded="false" aria-controls="adl-panel">
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <circle cx="12" cy="12" r="10"/>
            <circle cx="12" cy="10" r="3"/>
            <path d="M12 13v6M9 17l3 3 3-3"/>
        </svg>
    </button>
    <div class="adl-panel" id="adl-panel" role="dialog" aria-label="Accessibility Settings">
        <div class="adl-panel-header">
            <span class="adl-panel-title">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <circle cx="12" cy="12" r="10"/>
                    <circle cx="12" cy="10" r="3"/>
                    <path d="M12 13v6M9 17l3 3 3-3"/>
                </svg>
                Accessibility
            </span>
            <button class="adl-close" aria-label="Close accessibility panel">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M18 6L6 18M6 6l12 12"/>
                </svg>
            </button>
        </div>
        <div class="adl-control">
            <span class="adl-label">Text Size</span>
            <div class="adl-btn-group">
                <button class="adl-btn is-active" data-scale="1" aria-label="Normal text size">1x</button>
                <button class="adl-btn" data-scale="2" aria-label="Large text size">2x</button>
                <button class="adl-btn" data-scale="3" aria-label="Extra large text size">3x</button>
            </div>
        </div>
        <div class="adl-control">
            <div class="adl-switch-wrapper">
                <span class="adl-switch-label">High Contrast</span>
                <label class="adl-switch">
                    <input type="checkbox" id="adl-contrast-toggle" aria-label="Toggle high contrast mode">
                    <span class="adl-switch-track"></span>
                </label>
            </div>
        </div>
        <div class="adl-control adl-readaloud">
            <span class="adl-label">Read Aloud</span>
            <div class="adl-readaloud-controls">
                <button class="adl-play-btn" aria-label="Play or pause reading">
                    <svg class="play-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M8 5v14l11-7z"/></svg>
                    <svg class="pause-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M6 4h4v16H6V4zm8 0h4v16h-4V4z"/></svg>
                </button>
                <div class="adl-speed-group">
                    <button class="adl-speed-btn" data-speed="slow">Slow</button>
                    <button class="adl-speed-btn is-active" data-speed="normal">Normal</button>
                    <button class="adl-speed-btn" data-speed="fast">Fast</button>
                </div>
            </div>
            <div class="adl-reading-indicator"></div>
        </div>
        <div class="adl-control">
            <span class="adl-label">Screen Dimming</span>
            <div class="adl-range-wrapper">
                <input type="range" class="adl-range" id="adl-dim-slider" min="0" max="50" value="0" aria-label="Screen dimming level">
                <span class="adl-range-value">0%</span>
            </div>
        </div>
        <button class="adl-reset" aria-label="Reset accessibility settings to defaults">Reset to Defaults</button>
    </div>
    <!-- /ACCESSIBILITY DASHBOARD -->

    <script src="../../../app.js" defer></script>
</body>
</html>