{
  "letter": "i",
  "count": 125,
  "terms": [
    {
      "id": "term-ian-goodfellow",
      "term": "Ian Goodfellow",
      "definition": "American computer scientist who invented generative adversarial networks (GANs) in 2014, introducing a framework where two neural networks compete to generate realistic synthetic data, revolutionizing generative AI.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ibm-research-ai",
      "term": "IBM Research AI",
      "definition": "AI research at IBM spanning decades from Arthur Samuel's checkers program (1959) through Deep Blue (1997) Watson (2011) and modern enterprise AI. IBM has been one of the longest-running corporate contributors to artificial intelligence research.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ibm-watson-jeopardy",
      "term": "IBM Watson Jeopardy",
      "definition": "IBM's Watson AI system that defeated human champions Ken Jennings and Brad Rutter on the quiz show Jeopardy! in February 2011, demonstrating advances in natural language processing and information retrieval.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-iccv",
      "term": "ICCV",
      "definition": "The International Conference on Computer Vision held biennially since 1987. One of the top three computer vision conferences alongside CVPR and ECCV. Many seminal papers in visual recognition and deep learning for vision have been presented here.",
      "tags": [
        "History",
        "Conferences"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-iclr",
      "term": "ICLR",
      "definition": "The International Conference on Learning Representations first held in 2013 founded by Yoshua Bengio and Yann LeCun. Pioneered open peer review and quickly became one of the most influential venues for deep learning research.",
      "tags": [
        "History",
        "Conferences"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-icml",
      "term": "ICML",
      "definition": "The International Conference on Machine Learning first held in 1980. One of the top-tier conferences in AI and machine learning alongside NeurIPS and ICLR. Organized by the International Machine Learning Society.",
      "tags": [
        "History",
        "Conferences"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-idefics",
      "term": "Idefics",
      "definition": "An open-access multimodal model based on Flamingo's architecture that processes interleaved image and text inputs. Trained on publicly available data. Available in multiple sizes for research and application development.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-idiom-detection",
      "term": "Idiom Detection",
      "definition": "The task of identifying non-compositional multi-word expressions whose meaning cannot be deduced from their individual words, such as 'kick the bucket' meaning 'to die.'",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-ieee-organization",
      "term": "IEEE (Organization)",
      "definition": "The Institute of Electrical and Electronics Engineers founded in 1963. The world's largest professional technical organization for electronic and electrical engineering. IEEE publishes influential AI journals and sponsors major conferences including CVPR.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ieee-ai-ethics-standards",
      "term": "IEEE AI Ethics Standards",
      "definition": "A family of standards developed by IEEE under the Ethically Aligned Design initiative, including IEEE 7000 series standards addressing transparency, data privacy, algorithmic bias, and autonomous systems ethics.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ifeval",
      "term": "IFEval",
      "definition": "Instruction Following Evaluation, a benchmark that tests language models' ability to follow specific verifiable formatting instructions such as word count constraints, bullet point requirements, and keyword inclusion, measuring instruction adherence precision.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-ijcai",
      "term": "IJCAI",
      "definition": "The International Joint Conference on Artificial Intelligence first held in 1969. The oldest and one of the most prestigious international AI conferences covering all topics in artificial intelligence. Held biennially until 2015 then annually.",
      "tags": [
        "History",
        "Conferences"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ilya-sutskever",
      "term": "Ilya Sutskever",
      "definition": "Russian-born AI researcher who co-founded OpenAI, served as its Chief Scientist, and co-designed AlexNet. He co-founded Safe Superintelligence Inc. in 2024, focusing on developing safe superintelligent AI.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-augmentation",
      "term": "Image Augmentation",
      "definition": "Techniques that artificially expand training datasets by applying random transformations to images, including rotation, flipping, cropping, color jittering, and elastic deformations, to improve model generalization.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-classification",
      "term": "Image Classification",
      "definition": "The fundamental computer vision task of assigning a categorical label to an entire image based on its visual content, typically using CNN or ViT architectures trained on labeled datasets.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-colorization",
      "term": "Image Colorization",
      "definition": "The task of automatically adding plausible colors to grayscale images using deep learning models that learn color distributions conditioned on visual content and semantic context.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-deblurring",
      "term": "Image Deblurring",
      "definition": "The task of recovering sharp images from blurred inputs caused by camera shake or object motion, using deep learning models that learn inverse degradation functions.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-denoising",
      "term": "Image Denoising",
      "definition": "The process of removing noise from degraded images using neural networks that learn to separate signal from noise, producing cleaner images while preserving fine details and textures.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-embedding",
      "term": "Image Embedding",
      "definition": "A dense vector representation of an image produced by a neural network encoder, capturing semantic and visual features in a compact form suitable for similarity search, classification, and retrieval.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-generation",
      "term": "Image Generation",
      "definition": "AI systems that create images from text descriptions or other inputs. Major models include DALL-E, Midjourney, and Stable Diffusion, using diffusion or GAN architectures.",
      "tags": [
        "Application",
        "Generative"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-inpainting",
      "term": "Image Inpainting",
      "definition": "The task of filling in missing or masked regions of an image with plausible content, using deep learning models that understand context, texture, and structural patterns to generate seamless completions.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-matting",
      "term": "Image Matting",
      "definition": "The task of estimating a precise alpha matte that defines the fractional opacity of foreground elements in an image, enabling accurate extraction of subjects with soft edges like hair and fur.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-registration",
      "term": "Image Registration",
      "definition": "The process of aligning two or more images of the same scene taken at different times, viewpoints, or by different sensors, by computing a spatial transformation that maps corresponding points.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-retrieval",
      "term": "Image Retrieval",
      "definition": "The task of finding images in a database that are visually similar to a query image, using learned embeddings and nearest-neighbor search in the embedding space.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-stitching",
      "term": "Image Stitching",
      "definition": "The process of combining multiple overlapping photographs into a single panoramic or wide-field image by estimating homographies, blending seams, and correcting exposure differences.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-image-upscaling",
      "term": "Image Upscaling",
      "definition": "The process of increasing image resolution using AI models that synthesize realistic high-frequency details, producing sharp, detailed results superior to traditional interpolation methods.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-imagebind",
      "term": "ImageBind",
      "definition": "A model by Meta AI that learns a joint embedding space across six modalities including images text audio depth thermal and IMU data. Uses image-paired data to bind all modalities without requiring all possible modality pairs.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-imagen",
      "term": "Imagen",
      "definition": "A text-to-image diffusion model by Google Brain that uses a large frozen text encoder and cascaded diffusion models. Demonstrated that scaling the language model component significantly improves image generation quality.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-imagenet",
      "term": "ImageNet",
      "definition": "A large-scale visual database with over 14 million labeled images across thousands of categories, historically serving as the primary benchmark dataset for training and evaluating image classification models.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-imagenet-dataset",
      "term": "ImageNet Dataset",
      "definition": "A large-scale visual recognition dataset created by Fei-Fei Li and colleagues containing over 14 million labeled images across more than 20000 categories. The ImageNet Large Scale Visual Recognition Challenge (ILSVRC) running from 2010 to 2017 drove major advances in computer vision.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-imagenet-moment",
      "term": "ImageNet Moment",
      "definition": "The pivotal moment in 2012 when Alex Krizhevsky's deep convolutional neural network (AlexNet) won the ImageNet Large Scale Visual Recognition Challenge by a dramatic margin. This event is widely considered the starting point of the modern deep learning revolution.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-img2img",
      "term": "Img2Img",
      "definition": "An image-to-image generation pipeline that takes an existing image as input, adds noise to its latent representation, and denoises it with a new text prompt, enabling style transfer and editing.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-imitation-learning",
      "term": "Imitation Learning",
      "definition": "A paradigm where an agent learns to perform tasks by observing expert demonstrations rather than through reward-based trial and error. Imitation learning includes behavioral cloning, DAgger, and inverse RL approaches.",
      "tags": [
        "Reinforcement Learning",
        "Imitation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-impact-assessment",
      "term": "Impact Assessment",
      "definition": "A systematic process for evaluating the potential effects of an AI system on individuals communities and society before and during deployment. Required by some regulations and considered best practice in responsible AI.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-implicit-differentiation",
      "term": "Implicit Differentiation",
      "definition": "A technique for computing gradients through fixed-point iterations or optimization problems without unrolling the computation graph. Enables memory-efficient backpropagation through iterative solvers and equilibrium models.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-implicit-neural-representation",
      "term": "Implicit Neural Representation",
      "definition": "A neural network that learns a continuous function mapping coordinates to signal values, representing signals like images, shapes, or scenes as the weights of a neural network.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-implicit-q-learning",
      "term": "Implicit Q-Learning (IQL)",
      "definition": "An offline RL method that avoids querying out-of-distribution actions by learning a value function using expectile regression and extracting a policy through advantage-weighted regression. IQL is simple and avoids explicit policy constraint mechanisms.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-importance-sampling",
      "term": "Importance Sampling",
      "definition": "A Monte Carlo technique that estimates properties of one distribution by sampling from a different, easier-to-sample proposal distribution and reweighting samples by the likelihood ratio between the target and proposal.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-importance-sampling-rl",
      "term": "Importance Sampling in RL",
      "definition": "A statistical technique used in off-policy RL to correct for the mismatch between the behavior policy that generated data and the target policy being evaluated. Importance sampling ratios reweight returns to produce unbiased estimates.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-impossibility-theorem-of-fairness",
      "term": "Impossibility Theorem of Fairness",
      "definition": "Mathematical results demonstrating that certain fairness criteria are mutually incompatible except in trivial cases, meaning that satisfying one fairness metric necessarily violates another.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-imputation",
      "term": "Imputation",
      "definition": "The process of replacing missing values in a dataset with estimated values, using methods such as mean, median, mode substitution, k-nearest neighbors, or model-based approaches like iterative imputation.",
      "tags": [
        "Machine Learning",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-in-context-learning",
      "term": "In-Context Learning",
      "definition": "An LLM's ability to learn from examples provided in the prompt without updating its weights. Enables few-shot and zero-shot task performance through careful prompt design.",
      "tags": [
        "Capability",
        "Prompting"
      ],
      "domain": "general",
      "link": "../learn/index.html",
      "related": []
    },
    {
      "id": "term-in-context-learning-discovery",
      "term": "In-Context Learning Discovery",
      "definition": "The finding that large language models can learn to perform new tasks by conditioning on a few examples provided in the input context without any gradient updates. Demonstrated prominently by GPT-3 (2020) in-context learning challenged traditional ML paradigms.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-incentive-design-for-ai-safety",
      "term": "Incentive Design for AI Safety",
      "definition": "The design of economic regulatory and social incentives to encourage AI developers and deployers to invest in safety measures. Addresses the market failure where safety costs are borne privately but benefits are shared.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-inception-network",
      "term": "Inception Network",
      "definition": "A CNN architecture that uses parallel convolutional filters of different sizes within the same layer (inception modules) to capture features at multiple scales simultaneously.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-inception-score",
      "term": "Inception Score",
      "definition": "A metric for evaluating the quality and diversity of generated images. Measures how confidently an Inception network classifies generated images and how diverse the predicted labels are. Higher scores indicate better quality and variety.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-inception-v3",
      "term": "Inception v3",
      "definition": "A refined version of the GoogLeNet architecture with factorized convolutions batch normalization and label smoothing. Widely used as a feature extractor and serves as the basis for computing the Inception Score metric for generative models.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-inception-v4",
      "term": "Inception v4",
      "definition": "An advanced version of the Inception architecture that combines Inception modules with residual connections. Achieves improved accuracy through deeper networks while maintaining computational efficiency.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-incident-reporting-for-ai",
      "term": "Incident Reporting for AI",
      "definition": "Mandatory or voluntary systems for reporting AI-related incidents accidents and near-misses. Enables pattern recognition and systemic improvement analogous to incident reporting in aviation and healthcare.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-inclusive-ai",
      "term": "Inclusive AI",
      "definition": "The practice of designing AI systems that work equitably for diverse populations including underrepresented groups people with disabilities and speakers of low-resource languages.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-incoder",
      "term": "InCoder",
      "definition": "A unified generative model for code that supports both code generation and infilling through a causal masking training objective. Can generate code left-to-right and fill in missing code segments in any position.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-incremental-indexing",
      "term": "Incremental Indexing",
      "definition": "A vector database operation that adds new vectors to an existing index without requiring a full rebuild, enabling near-real-time updates at the cost of potentially suboptimal index structure that may need periodic compaction.",
      "tags": [
        "Vector Database",
        "Maintenance"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-independent-component-analysis",
      "term": "Independent Component Analysis",
      "definition": "A computational method for separating a multivariate signal into additive, statistically independent non-Gaussian source components. It is widely used in blind source separation problems such as separating mixed audio signals.",
      "tags": [
        "Machine Learning",
        "Dimensionality Reduction"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-iql-marl",
      "term": "Independent Q-Learning (IQL-MARL)",
      "definition": "A simple multi-agent RL approach where each agent independently learns its own Q-function treating other agents as part of the environment. Despite theoretical limitations with non-stationarity, IQL often works well in practice.",
      "tags": [
        "Reinforcement Learning",
        "Multi-Agent"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-index-optimization",
      "term": "Index Optimization",
      "definition": "The process of tuning vector index parameters such as the number of clusters, graph connectivity, and quantization settings to achieve the optimal balance of query latency, recall accuracy, and memory consumption for a specific dataset and workload.",
      "tags": [
        "Vector Database",
        "Performance"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-index-refresh",
      "term": "Index Refresh",
      "definition": "The process of rebuilding or updating a vector index to incorporate new vectors, remove deleted ones, and optimize search structures, necessary to maintain query accuracy and performance as the underlying data collection evolves.",
      "tags": [
        "Vector Database",
        "Maintenance"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-indigenous-data-sovereignty",
      "term": "Indigenous Data Sovereignty",
      "definition": "The right of indigenous peoples to govern the collection ownership and application of data about their communities and territories. Particularly relevant when AI training data includes indigenous knowledge.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-individual-conditional-expectation",
      "term": "Individual Conditional Expectation",
      "definition": "A plot showing how the prediction for each individual instance changes as a feature varies, disaggregating the partial dependence plot to reveal heterogeneous effects and interaction patterns across observations.",
      "tags": [
        "Machine Learning",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-individual-fairness",
      "term": "Individual Fairness",
      "definition": "A fairness principle requiring that similar individuals receive similar predictions or outcomes, formalized as a Lipschitz condition: individuals who are close in a task-relevant metric should receive similar classifications.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-induction-head",
      "term": "Induction Head",
      "definition": "A pair of attention heads in transformers that work together to identify and continue repeated patterns in the input sequence, forming a key mechanism underlying in-context learning.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-inference",
      "term": "Inference",
      "definition": "Running a trained model to generate predictions or outputs on new data. Distinguished from training, inference is typically faster and less resource-intensive.",
      "tags": [
        "Process",
        "Production"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-inference-acceleration",
      "term": "Inference Acceleration",
      "definition": "The collection of hardware and software techniques that speed up neural network inference, including specialized accelerators, compiler optimizations, quantization, pruning, and caching. Inference acceleration targets both throughput and latency objectives.",
      "tags": [
        "Inference Infrastructure",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-inference-cost-optimization",
      "term": "Inference Cost Optimization",
      "definition": "Strategies for minimizing the financial cost of serving AI models at scale, including quantization, distillation, batching optimization, hardware selection, and traffic routing. Inference costs often dominate the total cost of AI deployment.",
      "tags": [
        "Inference Infrastructure",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-inference-optimization",
      "term": "Inference Optimization",
      "definition": "A collection of techniques that reduce the computational cost, memory footprint, and latency of running trained models in production, including quantization, pruning, caching, and batching strategies.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-infiniband",
      "term": "InfiniBand",
      "definition": "A high-speed networking technology widely used in AI supercomputer clusters for inter-node communication, offering low latency and high bandwidth (up to 400 Gb/s per port with NDR). InfiniBand supports RDMA for efficient GPU-direct data transfers across servers.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-infonce-loss",
      "term": "InfoNCE Loss",
      "definition": "Information Noise-Contrastive Estimation is a contrastive loss function that trains models to distinguish positive pairs from negative pairs. Forms the basis of contrastive learning methods like CPC SimCLR and CLIP. Maximizes mutual information between representations.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-information-bottleneck",
      "term": "Information Bottleneck",
      "definition": "A theoretical framework that characterizes the optimal tradeoff between compression and prediction. A representation should retain as little information about the input as possible while preserving information relevant to the output. Applied to understanding deep learning.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-information-extraction",
      "term": "Information Extraction",
      "definition": "The task of automatically extracting structured information such as entities, relations, and events from unstructured text, converting free-form text into organized knowledge.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-information-gain",
      "term": "Information Gain",
      "definition": "The reduction in entropy achieved by splitting a dataset on a particular feature. Decision tree algorithms like ID3 and C4.5 use information gain to select the feature that provides the most useful partition.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-information-hazard",
      "term": "Information Hazard",
      "definition": "Knowledge or information that could cause harm if widely disseminated. In AI includes detailed descriptions of attack methods capability evaluations of dangerous systems and instructions for misuse.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-information-theory",
      "term": "Information Theory",
      "definition": "A mathematical framework developed by Claude Shannon in 1948 for quantifying information. Key concepts including entropy mutual information and channel capacity provide theoretical foundations for data compression communications and machine learning.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-informative-prior",
      "term": "Informative Prior",
      "definition": "A prior distribution that encodes specific prior knowledge or strong beliefs about a parameter's likely values, substantially influencing the posterior distribution, especially when data is limited.",
      "tags": [
        "Statistics",
        "Bayesian Methods"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-informed-autonomy",
      "term": "Informed Autonomy",
      "definition": "The principle that individuals should have sufficient understanding of AI systems to make autonomous choices about their use. Goes beyond informed consent to encompass ongoing awareness and meaningful control.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-informed-consent-in-ai",
      "term": "Informed Consent in AI",
      "definition": "The ethical and legal requirement that individuals be clearly informed about how their data will be collected, processed, and used by AI systems, and that they voluntarily agree to such use.",
      "tags": [
        "Privacy",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-inner-alignment",
      "term": "Inner Alignment",
      "definition": "The problem of ensuring that a learned model's internal optimization objective matches the objective specified by the training process. A failure of inner alignment results in a mesa-optimizer with a different goal.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-inpainting-pipeline",
      "term": "Inpainting Pipeline",
      "definition": "A diffusion model workflow that regenerates only the masked portions of an image while maintaining consistency with the unmasked regions, used for object removal, replacement, and repair.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-input-validation-for-ai",
      "term": "Input Validation for AI",
      "definition": "Techniques for checking that inputs to an AI system fall within expected parameters before processing. A first line of defense against adversarial attacks out-of-distribution inputs and prompt injection.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-instance-normalization",
      "term": "Instance Normalization",
      "definition": "A normalization technique that normalizes each feature channel independently for each sample, originally developed for neural style transfer where per-instance statistics are important.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-instance-segmentation",
      "term": "Instance Segmentation",
      "definition": "A computer vision task that detects individual objects in an image and generates a pixel-level mask for each instance, combining object detection with semantic segmentation to distinguish separate objects of the same class.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-instant-ngp",
      "term": "Instant NGP",
      "definition": "Instant Neural Graphics Primitives, a technique using multi-resolution hash encoding that dramatically accelerates NeRF training from hours to seconds while maintaining high-quality novel view synthesis.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-instruct-model",
      "term": "Instruct Model",
      "definition": "An LLM fine-tuned to follow instructions rather than just complete text. Makes models more useful as assistants by teaching them to respond helpfully to user requests.",
      "tags": [
        "Model Type",
        "Training"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-instructgpt",
      "term": "InstructGPT",
      "definition": "An OpenAI model published in 2022 that used reinforcement learning from human feedback to align GPT-3 with user instructions, directly preceding and informing the development of ChatGPT.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-instruction-following",
      "term": "Instruction Following",
      "definition": "The ability of a language model to accurately interpret and execute natural language instructions, a capability developed through instruction tuning and reinforcement learning from human feedback.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-instruction-hierarchy",
      "term": "Instruction Hierarchy",
      "definition": "A structured approach to organizing prompt instructions by priority level, where system-level instructions take precedence over user-level instructions, enabling models to handle conflicting directives and resist prompt injection attacks.",
      "tags": [
        "Prompt Engineering",
        "Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-instruction-tuning",
      "term": "Instruction Tuning",
      "definition": "Fine-tuning LLMs on datasets of instructions and responses to improve their ability to follow user requests. A key technique for creating helpful AI assistants.",
      "tags": [
        "Training",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-instruction-tuning-alignment",
      "term": "Instruction Tuning Alignment",
      "definition": "The practice of writing prompts that align with the specific instruction format and conventions used during a model's fine-tuning phase, maximizing the benefit of the model's instruction-following training.",
      "tags": [
        "Prompt Engineering",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-instruction-based-prompting",
      "term": "Instruction-Based Prompting",
      "definition": "A prompting paradigm that provides explicit, imperative instructions to a language model describing the task to perform, leveraging instruction-tuned models' ability to follow natural language directives without requiring demonstrations or examples.",
      "tags": [
        "Prompt Engineering",
        "Fundamentals"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-instrumental-convergence",
      "term": "Instrumental Convergence",
      "definition": "The thesis that sufficiently advanced AI agents with a wide range of terminal goals will converge on pursuing certain instrumental sub-goals such as self-preservation, resource acquisition, and goal-content integrity.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-instrumental-variable",
      "term": "Instrumental Variable",
      "definition": "A variable used in causal inference that is correlated with the treatment variable but affects the outcome only through the treatment, enabling consistent estimation of causal effects in the presence of confounding.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-int4",
      "term": "INT4 Quantization",
      "definition": "An aggressive quantization scheme using only 4 bits per weight, achieving 8x compression over FP32. INT4 methods like GPTQ and AWQ use sophisticated calibration to minimize quality degradation despite the extremely low bit-width.",
      "tags": [
        "Model Optimization",
        "Inference Infrastructure"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-int8",
      "term": "INT8 Quantization",
      "definition": "The process of representing neural network weights and activations using 8-bit integers instead of floating-point, reducing memory by 4x compared to FP32. INT8 quantization enables faster inference through integer arithmetic while maintaining acceptable accuracy.",
      "tags": [
        "Model Optimization",
        "Inference Infrastructure"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-integrated-gradients",
      "term": "Integrated Gradients",
      "definition": "An attribution method that computes feature importance by integrating gradients along a straight path from a baseline to the actual input. Satisfies desirable axioms including sensitivity and implementation invariance. Model-agnostic for differentiable models.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-intel-gaudi-3",
      "term": "Intel Gaudi 3",
      "definition": "Intel's third-generation AI training accelerator featuring integrated 400GbE networking and high memory bandwidth. Gaudi 3 targets the competitive AI training market with a focus on price-performance efficiency.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-intent-detection",
      "term": "Intent Detection",
      "definition": "The task of classifying the purpose or goal behind a user's utterance in a dialogue system, determining whether the user wants to book, search, cancel, or perform other actions.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-intent-recognition",
      "term": "Intent Recognition",
      "definition": "Understanding what a user wants to accomplish from their input. A core NLP task for chatbots and virtual assistants, mapping user messages to predefined intents.",
      "tags": [
        "NLP Task",
        "Application"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-inter-annotator-agreement",
      "term": "Inter-Annotator Agreement",
      "definition": "A statistical measure of the degree to which independent human annotators make the same judgments when labeling or evaluating the same data, used to assess annotation reliability and task subjectivity.",
      "tags": [
        "Evaluation",
        "Methodology"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-inter-token-latency",
      "term": "Inter-Token Latency",
      "definition": "The time between consecutive token generations during the decode phase of LLM inference. Low inter-token latency is essential for streaming applications where users perceive generation speed in real-time.",
      "tags": [
        "Inference Infrastructure",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-interaction-feature",
      "term": "Interaction Feature",
      "definition": "A derived feature created by combining two or more existing features (typically through multiplication) to capture non-additive effects. It allows linear models to represent relationships that depend on the joint values of multiple predictors.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-internist-1",
      "term": "INTERNIST-1",
      "definition": "A medical diagnostic expert system developed by Jack Myers and Harry Pople at the University of Pittsburgh in the 1970s. It covered approximately 500 diseases and 3500 manifestations in internal medicine representing one of the largest early medical AI systems.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-internlm",
      "term": "InternLM",
      "definition": "A family of language models developed by Shanghai AI Laboratory. Features strong performance on Chinese and English tasks with specialized variants for code mathematics and long-context applications.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-internvl",
      "term": "InternVL",
      "definition": "A large-scale vision-language model that scales the vision encoder to match the capacity of large language models. Demonstrates that aligning a strong vision encoder with an LLM achieves competitive multimodal performance.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-interoperability-in-ai-safety",
      "term": "Interoperability in AI Safety",
      "definition": "The ability of different AI safety tools standards and governance frameworks to work together effectively. Important for avoiding fragmentation and ensuring consistent safety practices across the AI ecosystem.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-interpretability",
      "term": "Interpretability",
      "definition": "The degree to which humans can understand how a model makes decisions. Higher interpretability enables debugging, trust-building, and identifying potential issues.",
      "tags": [
        "Property",
        "Trust"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-interpretability-research",
      "term": "Interpretability Research",
      "definition": "The field of AI research focused on understanding how neural networks make decisions and what they have learned. Approaches include mechanistic interpretability probing studies visualization techniques and formal verification of neural network properties.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-intersection-over-union",
      "term": "Intersection over Union",
      "definition": "A metric (IoU) that measures the overlap between a predicted bounding box and a ground truth box by computing the area of their intersection divided by the area of their union, used to evaluate detection accuracy.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-intersectional-bias",
      "term": "Intersectional Bias",
      "definition": "Bias that affects individuals at the intersection of multiple protected characteristics such as race and gender in ways that are not captured by examining each characteristic independently.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-intrinsic-motivation",
      "term": "Intrinsic Motivation",
      "definition": "An internal reward signal generated by the agent itself to encourage exploration, independent of the environment's extrinsic reward. Intrinsic motivation methods include prediction error, information gain, and state visitation novelty.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-inverse-rl",
      "term": "Inverse Reinforcement Learning",
      "definition": "The problem of inferring an unknown reward function from observed expert behavior, recovering the objectives that explain the demonstrated policy. IRL is useful when specifying rewards explicitly is difficult but demonstrations are available.",
      "tags": [
        "Reinforcement Learning",
        "Imitation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-inverse-reward-design",
      "term": "Inverse Reward Design",
      "definition": "A framework that treats the specified reward function as an observation of the designer's true intent rather than the literal objective, reasoning about what reward the designer likely meant. This approach helps mitigate reward misspecification.",
      "tags": [
        "Reinforcement Learning",
        "Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-inverse-scaling",
      "term": "Inverse Scaling",
      "definition": "When larger models perform worse on certain tasks than smaller ones. Discovered through research challenges, revealing unexpected behaviors as models scale up.",
      "tags": [
        "Research",
        "Phenomenon"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-inverse-transform-sampling",
      "term": "Inverse Transform Sampling",
      "definition": "A method for generating random samples from any probability distribution given its inverse cumulative distribution function. It transforms uniform random variables into samples from the target distribution.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-inverted-residual-block",
      "term": "Inverted Residual Block",
      "definition": "A building block in MobileNetV2 that expands the channel dimension with a pointwise convolution, applies depthwise convolution, then projects back to a narrow output with a residual connection.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-iob-tagging",
      "term": "IOB Tagging",
      "definition": "A labeling scheme for sequence tagging that marks tokens as Inside, Outside, or Beginning of a named entity or chunk, enabling the identification of multi-word spans in text.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-iou-loss",
      "term": "IoU Loss",
      "definition": "Intersection over Union loss measures the overlap between predicted and ground truth bounding boxes or segmentation masks. Directly optimizes the IoU metric rather than using surrogate losses. Used in object detection and instance segmentation.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-ip-adapter",
      "term": "IP-Adapter",
      "definition": "An image prompt adapter for diffusion models that enables image-conditioned generation by injecting visual features through decoupled cross-attention, allowing style or subject transfer without fine-tuning.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ipo",
      "term": "IPO (Identity Preference Optimization)",
      "definition": "An alternative to DPO for preference learning that doesn't require a reference model. Simplifies the training process while maintaining alignment quality.",
      "tags": [
        "Training",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-iso-ai-standards",
      "term": "ISO AI Standards",
      "definition": "International standards developed by ISO/IEC JTC 1/SC 42 for artificial intelligence, including ISO/IEC 42001 for AI management systems and ISO/IEC 23894 for AI risk management.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-isolation-forest",
      "term": "Isolation Forest",
      "definition": "An ensemble-based anomaly detection algorithm that isolates observations by randomly selecting features and split values. Anomalies require fewer splits to isolate, resulting in shorter average path lengths in the ensemble of isolation trees.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-isotonic-calibration",
      "term": "Isotonic Calibration",
      "definition": "A non-parametric calibration method that fits an isotonic regression to map classifier scores to calibrated probabilities, using a monotonically increasing step function to preserve the ordering of predictions.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-isotonic-regression",
      "term": "Isotonic Regression",
      "definition": "A non-parametric regression technique that fits a non-decreasing (or non-increasing) step function to the data, minimizing the sum of squared errors subject to the monotonicity constraint.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-iterated-amplification",
      "term": "Iterated Amplification",
      "definition": "An AI alignment approach proposed by Paul Christiano where a human overseer is amplified by decomposing complex tasks into simpler subtasks handled by AI assistants, iteratively building more capable aligned systems.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-iteration",
      "term": "Iteration (Prompting)",
      "definition": "The practice of refining prompts through multiple attempts to achieve better results. Essential for getting the most out of AI, treating prompting as an iterative process.",
      "tags": [
        "Prompting",
        "Practice"
      ],
      "domain": "general",
      "link": "../tools/analyzer.html",
      "related": []
    },
    {
      "id": "term-iterative-dpo",
      "term": "Iterative DPO",
      "definition": "An extension of Direct Preference Optimization that performs multiple rounds of preference optimization. In each iteration new preference pairs are generated from the updated model creating a self-improving alignment loop.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-iterative-refinement-prompting",
      "term": "Iterative Refinement Prompting",
      "definition": "A technique where the model's initial output is fed back with critique instructions for progressive improvement across multiple rounds, with each iteration addressing specific weaknesses identified in the previous version.",
      "tags": [
        "Prompt Engineering",
        "Refinement"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-ivf-index",
      "term": "IVF Index",
      "definition": "Inverted File Index, a vector search structure that partitions the vector space into Voronoi cells using k-means clustering and searches only the nearest cells at query time, trading recall for dramatically reduced search scope.",
      "tags": [
        "Vector Database",
        "Index Structure"
      ],
      "domain": "general",
      "link": null,
      "related": []
    }
  ]
}