{
  "letter": "v",
  "count": 57,
  "terms": [
    {
      "id": "term-variational-autoencoder",
      "term": "VAE (Variational Autoencoder)",
      "definition": "A generative model that learns a latent space representation of data. Used in image generation and as components of larger systems like some diffusion models.",
      "tags": [
        "Architecture",
        "Generative"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-vae-decoder",
      "term": "VAE Decoder",
      "definition": "The decoder component of a Variational Autoencoder used in latent diffusion models to reconstruct high-resolution images from compressed latent representations produced by the diffusion process.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-validation",
      "term": "Validation",
      "definition": "Testing model performance on data not used in training to assess generalization. Validation sets help tune hyperparameters; test sets provide final performance estimates.",
      "tags": [
        "Process",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-validation-curve",
      "term": "Validation Curve",
      "definition": "A plot of training and validation scores as a function of a single hyperparameter, revealing the optimal hyperparameter value and whether the model is underfitting or overfitting at different settings.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-vall-e",
      "term": "VALL-E",
      "definition": "A neural codec language model for text-to-speech by Microsoft that can synthesize personalized speech from a 3-second reference recording. Treats TTS as a conditional language modeling task using discrete audio codec codes.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-value-alignment",
      "term": "Value Alignment",
      "definition": "The challenge of ensuring that an AI system's objectives and behaviors are consistent with human values and intentions. This is considered one of the core problems in AI safety research.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-value-function",
      "term": "Value Function",
      "definition": "A function that estimates the expected cumulative future reward from a given state (or state-action pair) under a particular policy. Value functions are central to many RL algorithms for evaluating how good it is to be in a state.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-value-iteration",
      "term": "Value Iteration",
      "definition": "A dynamic programming algorithm that computes the optimal value function by iteratively applying the Bellman optimality equation. Converges to the optimal policy and is simpler than policy iteration but may require more iterations.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-value-sensitive-design",
      "term": "Value-Sensitive Design",
      "definition": "A design methodology that accounts for human values in a principled and systematic manner throughout the design process, incorporating conceptual, empirical, and technical investigations.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-vanishing-gradient",
      "term": "Vanishing Gradient",
      "definition": "A problem in deep neural network training where gradients become exponentially small as they are backpropagated through many layers, causing early layers to learn extremely slowly or not at all.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-vanishing-gradient-problem",
      "term": "Vanishing Gradient Problem",
      "definition": "A difficulty encountered in training deep neural networks where gradients become exponentially small as they are propagated backward through many layers. Identified by Sepp Hochreiter in 1991 the problem motivated the development of LSTM ReLU and residual connections.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-vapnik-chervonenkis-theory",
      "term": "Vapnik-Chervonenkis Theory",
      "definition": "A theoretical framework in statistical learning theory that provides bounds on the generalization error of classifiers based on the VC dimension of the hypothesis class and the number of training samples.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-variance",
      "term": "Variance",
      "definition": "A measure of the dispersion of a set of values, computed as the average of the squared deviations from the mean. It quantifies how spread out the data points are in a distribution.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-variance-inflation-factor",
      "term": "Variance Inflation Factor",
      "definition": "A measure of how much the variance of a regression coefficient is inflated due to multicollinearity with other predictors. VIF values above 5 or 10 typically indicate problematic multicollinearity.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-variance-threshold",
      "term": "Variance Threshold",
      "definition": "A simple feature selection method that removes all features whose variance falls below a specified threshold. Features with near-zero variance provide little discriminative information and can be safely discarded.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-vae",
      "term": "Variational Autoencoder",
      "definition": "A generative model that learns a probabilistic mapping between data and a continuous latent space by optimizing a variational lower bound, enabling both generation and meaningful latent representations.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-variational-inference",
      "term": "Variational Inference",
      "definition": "An approximate Bayesian inference technique that transforms the inference problem into an optimization problem by finding the member of a tractable distribution family that is closest to the true posterior in KL divergence.",
      "tags": [
        "Machine Learning",
        "Bayesian Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-vc-dimension",
      "term": "VC Dimension",
      "definition": "Vapnik-Chervonenkis dimension, a measure of the capacity or complexity of a hypothesis class, defined as the largest set of points that can be shattered (perfectly classified in all possible labelings) by the class.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-vector",
      "term": "Vector",
      "definition": "An ordered list of numbers representing data in a mathematical space. Embeddings are vectors; vector similarity measures (cosine similarity) enable semantic search and comparison.",
      "tags": [
        "Math",
        "Representation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-vector-autoregression",
      "term": "Vector Autoregression",
      "definition": "A multivariate time series model where each variable is regressed on its own past values and the past values of all other variables in the system, capturing linear interdependencies among multiple time series.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-vector-database",
      "term": "Vector Database",
      "definition": "A database optimized for storing and searching high-dimensional vectors (embeddings). Essential for RAG systems, semantic search, and recommendation engines. Examples: Pinecone, Weaviate, Chroma.",
      "tags": [
        "Infrastructure",
        "Search"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-vector-database-sharding",
      "term": "Vector Database Sharding",
      "definition": "The horizontal partitioning of a vector index across multiple nodes or storage units to distribute data and query load, enabling vector databases to scale beyond single-machine memory and compute limits for billion-scale collections.",
      "tags": [
        "Vector Database",
        "Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-vector-index",
      "term": "Vector Index",
      "definition": "A specialized data structure optimized for efficient similarity search over high-dimensional vector collections, employing algorithms like HNSW, IVF, or tree-based methods to avoid exhaustive linear scanning.",
      "tags": [
        "Vector Database",
        "Index Structure"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-vector-institute",
      "term": "Vector Institute",
      "definition": "A Canadian AI research institute founded in 2017 in Toronto with Geoffrey Hinton as chief scientific advisor. The Vector Institute focuses on machine learning and deep learning research contributing to Toronto's emergence as a global AI research hub.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-vector-normalization",
      "term": "Vector Normalization",
      "definition": "The process of scaling vectors to unit length by dividing each component by the vector's L2 norm, ensuring that cosine similarity and dot product similarity become equivalent and enabling consistent distance comparisons across vectors of varying magnitudes.",
      "tags": [
        "Vector Database",
        "Preprocessing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-vector-similarity-join",
      "term": "Vector Similarity Join",
      "definition": "A database operation that finds all pairs of vectors across two collections whose similarity exceeds a given threshold, used for deduplication, clustering, and linking related entities across different embedding datasets.",
      "tags": [
        "Vector Database",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-vector-store",
      "term": "Vector Store",
      "definition": "A storage system specialized for persisting, indexing, and querying vector embeddings alongside their associated metadata and original content, serving as the core infrastructure component for embedding-based search and retrieval systems.",
      "tags": [
        "Vector Database",
        "Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-vector-jacobian-product",
      "term": "Vector-Jacobian Product",
      "definition": "An efficient computation that multiplies a vector by the Jacobian matrix without explicitly forming the full Jacobian. The fundamental operation of reverse-mode automatic differentiation and backpropagation.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-vectorized-environment",
      "term": "Vectorized Environment",
      "definition": "A technique for running multiple copies of an environment in parallel within a single process, enabling batch collection of experience for more efficient training. Vectorized environments reduce wall-clock time per sample.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-verification",
      "term": "Verification (AI Outputs)",
      "definition": "Checking AI outputs for accuracy and appropriateness before use. Essential for high-stakes applications. Can be done by humans, other AI systems, or automated checks.",
      "tags": [
        "Practice",
        "Safety"
      ],
      "domain": "safety",
      "link": "../tools/hallucination.html",
      "related": []
    },
    {
      "id": "term-verification-chain-prompting",
      "term": "Verification Chain Prompting",
      "definition": "A prompting technique that generates an initial response, then systematically creates and answers verification questions about specific claims in that response, using the verification results to produce a revised, more accurate final answer.",
      "tags": [
        "Prompt Engineering",
        "Verification"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-vgg",
      "term": "VGG",
      "definition": "A deep convolutional network architecture characterized by its use of very small 3x3 convolution filters throughout the entire network, demonstrating that depth with small filters improves performance.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-vgg-16",
      "term": "VGG-16",
      "definition": "A 16-layer variant of the VGG architecture with 138 million parameters. One of the most commonly used pretrained models for transfer learning and feature extraction despite being superseded in accuracy by newer architectures.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-vicuna",
      "term": "Vicuna",
      "definition": "An open-source chatbot fine-tuned from LLaMA on user-shared conversations from ShareGPT. Achieved quality close to ChatGPT according to GPT-4 evaluation. Demonstrated that strong chat models can be created from open base models.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-video-generation",
      "term": "Video Generation",
      "definition": "The synthesis of temporally coherent video sequences from text prompts, images, or other conditioning signals using extended diffusion or autoregressive models that handle both spatial and temporal dimensions.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-video-transformer",
      "term": "Video Transformer",
      "definition": "A transformer architecture adapted for video processing that handles both spatial and temporal dimensions through factored attention, tubelet embeddings, or space-time attention mechanisms.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-video-understanding",
      "term": "Video Understanding",
      "definition": "The comprehensive analysis of video content including action recognition, temporal event detection, scene classification, and narrative understanding across sequences of frames.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-vision-transformer",
      "term": "Vision Transformer",
      "definition": "A transformer architecture applied to images by splitting them into fixed-size patches, linearly embedding each patch, and processing the sequence of patch embeddings with standard transformer blocks.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-vision-language-model",
      "term": "Vision-Language Model (VLM)",
      "definition": "AI models that can process and reason about both images and text. Examples include GPT-4V, Claude with vision, and Gemini. Enable image understanding, captioning, and visual question answering.",
      "tags": [
        "Model Type",
        "Multimodal"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-visual-grounding",
      "term": "Visual Grounding",
      "definition": "The task of localizing a region or object in an image based on a natural language description, requiring the model to ground textual references to specific visual locations with bounding boxes or masks.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-visual-question-answering",
      "term": "Visual Question Answering",
      "definition": "A multimodal AI task that requires answering natural language questions about the content of an image, demanding both visual understanding and language reasoning capabilities.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-visual-relationship-detection",
      "term": "Visual Relationship Detection",
      "definition": "The task of identifying and classifying the interactions or spatial relationships between pairs of objects in an image, producing subject-predicate-object triplets that describe the visual scene.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-visual-slam",
      "term": "Visual SLAM",
      "definition": "Visual Simultaneous Localization and Mapping, a technique that estimates camera trajectory and builds a 3D map of the environment from a sequence of images in real-time, used in robotics and AR.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-viterbi-algorithm",
      "term": "Viterbi Algorithm",
      "definition": "A dynamic programming algorithm that finds the most likely sequence of hidden states in an HMM or CRF, used for optimal decoding in sequence labeling and speech recognition.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-vladimir-vapnik",
      "term": "Vladimir Vapnik",
      "definition": "Russian-American mathematician who co-developed the Vapnik-Chervonenkis (VC) theory of statistical learning and invented support vector machines (SVMs) in the 1990s. His work on structural risk minimization provided theoretical foundations for machine learning generalization.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-vllm",
      "term": "vLLM",
      "definition": "An open-source high-throughput LLM inference engine that implements PagedAttention and continuous batching to efficiently serve large language models with optimized memory management.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-vocab",
      "term": "Vocabulary (Model)",
      "definition": "The set of tokens a model can recognize and generate. Determined during tokenizer training. Larger vocabularies handle more languages but increase model size.",
      "tags": [
        "Technical",
        "Tokenization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-vocabulary-size",
      "term": "Vocabulary Size",
      "definition": "The total number of unique tokens in a model's tokenizer vocabulary, which affects model size, tokenization efficiency, and the balance between sequence length and token granularity.",
      "tags": [
        "NLP",
        "Tokenization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-voice-clone",
      "term": "Voice Cloning",
      "definition": "AI that replicates a specific person's voice from audio samples. Raises significant ethical concerns about consent and misuse for fraud or misinformation.",
      "tags": [
        "Application",
        "Ethics"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-voluntary-commitments-on-ai",
      "term": "Voluntary Commitments on AI",
      "definition": "Non-binding pledges by AI companies to the White House in 2023 to manage risks from AI, including commitments to safety testing, information sharing, watermarking, and research on societal risks.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-von-neumann-architecture",
      "term": "Von Neumann Architecture",
      "definition": "The computer architecture described by John von Neumann in 1945 that stores both program instructions and data in the same memory, becoming the dominant design paradigm for digital computers and enabling programmable AI systems.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-voronoi-partitioning",
      "term": "Voronoi Partitioning",
      "definition": "A spatial decomposition technique used in IVF indexes that divides the vector space into regions where each region contains all points closest to a specific centroid, enabling search to focus on the most promising partitions for a given query.",
      "tags": [
        "Vector Database",
        "Index Structure"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-voting-classifier",
      "term": "Voting Classifier",
      "definition": "An ensemble method that aggregates predictions from multiple classifiers using either majority voting (hard voting) or averaged predicted probabilities (soft voting) to produce a final classification.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-voxel",
      "term": "Voxel",
      "definition": "A volumetric pixel representing a value on a regular 3D grid, used as a discrete representation for 3D data in neural networks, analogous to pixels in 2D images.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-vq-vae",
      "term": "VQ-VAE",
      "definition": "Vector Quantized Variational Autoencoder, a model that uses discrete latent representations through vector quantization, enabling high-fidelity generation by combining discrete codes with powerful decoders.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-vq-vae-2",
      "term": "VQ-VAE-2",
      "definition": "An improved version of VQ-VAE that uses a hierarchical latent structure with multiple levels of quantization. Generates high-quality images comparable to GANs while maintaining the benefits of the VAE framework.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-vulnerability-exploitation-by-ai",
      "term": "Vulnerability Exploitation by AI",
      "definition": "AI systems that exploit the vulnerabilities of specific groups such as children, elderly, or persons with disabilities to materially distort their behavior, prohibited under the EU AI Act.",
      "tags": [
        "AI Ethics",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    }
  ]
}