{
  "letter": "s",
  "count": 515,
  "terms": [
    {
      "id": "term-s2orc",
      "term": "S2ORC",
      "definition": "The Semantic Scholar Open Research Corpus containing full text and metadata for 81 million academic papers. A comprehensive resource for scientific language modeling and information extraction.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Scientific"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-s3dis",
      "term": "S3DIS",
      "definition": "Stanford Large-Scale 3D Indoor Spaces a dataset of 6 large indoor areas with dense 3D point clouds annotated with 13 semantic categories. Used for 3D semantic segmentation benchmarking.",
      "tags": [
        "Benchmark",
        "3D",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-s4",
      "term": "S4",
      "definition": "Structured State Spaces for Sequence Modeling, a state space model that uses a special initialization based on the HiPPO framework and efficient computation via FFT to handle very long-range dependencies.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-s5",
      "term": "S5",
      "definition": "Simplified State Space Layers extends S4 with a simpler multi-input multi-output parameterization using parallel scan for efficient computation. Achieves competitive performance with a more straightforward implementation.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-safe-harbor-provisions",
      "term": "Safe Harbor Provisions",
      "definition": "Legal protections for AI developers who follow designated safety practices and standards. Provides regulatory certainty and incentivizes adoption of best practices by reducing liability exposure.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-safe-rl",
      "term": "Safe Reinforcement Learning",
      "definition": "RL methods that incorporate safety constraints to prevent the agent from taking dangerous or unacceptable actions during training and deployment. Safe RL uses constrained optimization, shielding, or risk-sensitive objectives.",
      "tags": [
        "Reinforcement Learning",
        "Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-saferlhf",
      "term": "SafeRLHF",
      "definition": "A dataset of human preference annotations focused on safety and helpfulness tradeoffs. Used for training AI systems to balance being helpful while avoiding harmful outputs.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Safety"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-safety-case",
      "term": "Safety Case",
      "definition": "A structured argument supported by evidence that an AI system is acceptably safe for its intended use in its intended environment. Adapted from safety-critical engineering disciplines.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-safety-culture-in-ai",
      "term": "Safety Culture in AI",
      "definition": "Organizational values norms and practices that prioritize safety in AI development. Includes psychological safety for reporting concerns resources for safety research and leadership commitment to responsible development.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-safety-filter",
      "term": "Safety Filter",
      "definition": "Systems that detect and block harmful content in AI inputs or outputs. Part of the safety stack protecting users from inappropriate, dangerous, or illegal content.",
      "tags": [
        "Safety",
        "Security"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-safety-margin",
      "term": "Safety Margin",
      "definition": "The difference between the conditions under which an AI system has been tested and validated and the most extreme conditions it might encounter in deployment. Larger safety margins provide more robust protection.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-safety-score",
      "term": "Safety Score",
      "definition": "A composite evaluation metric that aggregates measurements of harmful output generation including toxicity, bias, dangerous advice, and policy violations, providing an overall assessment of a model's safety alignment.",
      "tags": [
        "Evaluation",
        "Safety"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-safetybench",
      "term": "SafetyBench",
      "definition": "A comprehensive benchmark for evaluating the safety of large language models across multiple risk categories including ethics legality and physical harm.",
      "tags": [
        "Benchmark",
        "NLP",
        "Safety",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-saint",
      "term": "SAINT",
      "definition": "Self-Attention and Intersample Attention Transformer applies both row-wise and column-wise attention to tabular data. Captures feature-feature and sample-sample interactions for improved tabular learning.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-saliency-map",
      "term": "Saliency Map",
      "definition": "A visualization technique that highlights which parts of an input are most relevant to a model's prediction by computing gradients of the output with respect to the input. Simple to compute but can be noisy and difficult to interpret.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-salmonn",
      "term": "SALMONN",
      "definition": "Speech Audio Language Music Open Neural Network is a multimodal model that can perceive and understand speech and audio and music alongside text.",
      "tags": [
        "Models",
        "Technical",
        "Audio",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sam-2",
      "term": "SAM 2",
      "definition": "Segment Anything Model 2 extends the original SAM to video segmentation with streaming memory for tracking and segmenting objects across video frames.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sam-altman",
      "term": "Sam Altman",
      "definition": "American entrepreneur who became CEO of OpenAI, overseeing the development and launch of ChatGPT and GPT-4. His brief firing and reinstatement in November 2023 highlighted governance tensions at leading AI companies.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-sam-med2d",
      "term": "SAM-Med2D",
      "definition": "A specialized version of the Segment Anything Model fine-tuned on large-scale 2D medical imaging datasets for clinical image segmentation tasks.",
      "tags": [
        "Models",
        "Technical",
        "Medical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sambanova",
      "term": "SambaNova",
      "definition": "An AI hardware company producing reconfigurable dataflow architecture processors (SN series) that adapt their compute topology to different model architectures. SambaNova's dataflow approach streams data through the chip without traditional memory hierarchy bottlenecks.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-sammon-mapping",
      "term": "Sammon Mapping",
      "definition": "A nonlinear dimensionality reduction method that minimizes the stress function measuring the difference between original and projected interpoint distances. Weights errors by the inverse of original distances emphasizing local structure.",
      "tags": [
        "Algorithms",
        "Technical",
        "Dimensionality Reduction"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sample-complexity-rl",
      "term": "Sample Complexity",
      "definition": "The number of environment interactions needed for an RL algorithm to find a near-optimal policy with high probability. Sample complexity is a key measure of algorithmic efficiency, especially when interactions are expensive.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sampling",
      "term": "Sampling",
      "definition": "The process of selecting the next token during text generation. Methods include greedy (always pick highest probability), top-k, top-p (nucleus), and temperature-based sampling.",
      "tags": [
        "Generation",
        "Technical"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-samsum",
      "term": "SAMSum",
      "definition": "A dialogue summarization dataset containing 16000 messenger-style conversations with human-written summaries. Tests the ability to summarize informal conversational text.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-samsung-advanced-package",
      "term": "Samsung Advanced Package",
      "definition": "Samsung TSMC CoWoS-competitive advanced packaging technology offering 2.5D integration with silicon interposer. Enables multi-die GPU and HBM packaging for AI accelerator products.",
      "tags": [
        "Packaging",
        "Samsung",
        "Manufacturing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-samsung-ai-chip",
      "term": "Samsung AI Chip",
      "definition": "Samsung development of custom AI accelerator chips for use in its data centers and devices. Includes both training accelerators and mobile NPUs integrated into Exynos processors.",
      "tags": [
        "Accelerator",
        "Samsung",
        "Development"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-samsung-exynos",
      "term": "Samsung Exynos",
      "definition": "Samsung line of mobile system-on-chip processors incorporating NPU cores for on-device AI tasks. Used in select Samsung Galaxy smartphones and other devices.",
      "tags": [
        "Mobile",
        "Samsung",
        "SoC"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-samsung-foundry",
      "term": "Samsung Foundry",
      "definition": "Samsung semiconductor manufacturing division producing advanced chips at 3nm and below. Manufactures processors for various companies including some Qualcomm and Google AI chips.",
      "tags": [
        "Fabrication",
        "Foundry"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-samuels-checkers-program",
      "term": "Samuel's Checkers Program",
      "definition": "A checkers-playing program developed by Arthur Samuel at IBM beginning in 1959. The program used machine learning techniques including rote learning and generalization to improve its play. It is one of the earliest demonstrations of machine learning in practice.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-sandwich-prompting",
      "term": "Sandwich Prompting",
      "definition": "A prompt structure that places the core instruction both before and after the main context or input data, reinforcing adherence to instructions that might otherwise be lost in long contexts due to positional attention biases.",
      "tags": [
        "Prompt Engineering",
        "Structure"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-santacoder",
      "term": "SantaCoder",
      "definition": "A 1.1B parameter code generation model from the BigCode project trained on a filtered subset of The Stack dataset in Python and Java and JavaScript.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sapiens",
      "term": "Sapiens",
      "definition": "A family of human-centric vision models from Meta for body part segmentation and pose estimation and depth prediction and surface normal estimation.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sarcasm-detection",
      "term": "Sarcasm Detection",
      "definition": "The task of identifying sarcastic or ironic statements in text where the intended meaning differs from the literal meaning, a challenging problem requiring pragmatic understanding.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sarima",
      "term": "SARIMA",
      "definition": "Seasonal ARIMA, an extension of the ARIMA model that includes additional seasonal autoregressive, differencing, and moving average terms to capture periodic patterns in time series data.",
      "tags": [
        "Data Science",
        "Statistics"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sarsa",
      "term": "SARSA",
      "definition": "An on-policy temporal difference control algorithm that updates Q-values using the actual action taken by the current policy (State-Action-Reward-State-Action). Unlike Q-learning, SARSA learns the value of the policy being followed.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sasrec",
      "term": "SASRec",
      "definition": "Self-Attentive Sequential Recommendation uses a unidirectional Transformer to model sequential user behavior for next-item prediction tasks.",
      "tags": [
        "Models",
        "Technical",
        "Recommendation"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-satellite-imagery-analysis",
      "term": "Satellite Imagery Analysis",
      "definition": "The use of computer vision models to interpret aerial and satellite photographs for applications including land use classification, change detection, disaster assessment, and environmental monitoring.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-savitzky-golay-filter",
      "term": "Savitzky-Golay Filter",
      "definition": "A digital filter that smooths data by fitting successive subsets of adjacent points with a low-degree polynomial using least squares. Preserves higher moments of the data such as peak heights and widths.",
      "tags": [
        "Algorithms",
        "Technical",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-saycan",
      "term": "SayCan",
      "definition": "A framework from Google that grounds large language model knowledge in robotic affordances by combining language understanding with learned value functions for feasible actions.",
      "tags": [
        "Models",
        "Technical",
        "Robotics"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sbu-captions",
      "term": "SBU Captions",
      "definition": "Stony Brook University Captions a dataset of 1 million image-caption pairs collected from Flickr. Used for image captioning and vision-language pretraining.",
      "tags": [
        "Training Corpus",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-scaffold-algorithm",
      "term": "SCAFFOLD Algorithm",
      "definition": "A federated learning method that uses control variates to correct for client drift caused by heterogeneous data. Reduces the number of communication rounds needed for convergence compared to FedAvg.",
      "tags": [
        "Algorithms",
        "Technical",
        "Privacy"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-scalable-oversight",
      "term": "Scalable Oversight",
      "definition": "The challenge and research agenda of maintaining meaningful human oversight of AI systems as they become more capable and handle tasks too complex for humans to directly evaluate.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-scalar-quantization",
      "term": "Scalar Quantization",
      "definition": "A vector compression method that reduces memory usage by converting each floating-point vector component to a lower-precision representation such as 8-bit integers, achieving 4x compression from float32 with minimal accuracy loss.",
      "tags": [
        "Vector Database",
        "Quantization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-scale-ai",
      "term": "Scale AI",
      "definition": "A company specializing in data labeling and annotation services for AI training. Provides human feedback at scale, crucial for training and evaluating foundation models.",
      "tags": [
        "Company",
        "Data"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-scale-space-theory",
      "term": "Scale Space Theory",
      "definition": "A framework for multi-scale image analysis that represents an image at multiple levels of detail by progressive Gaussian blurring. Provides a principled way to handle structures at different scales.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-scaling-hypothesis",
      "term": "Scaling Hypothesis",
      "definition": "The hypothesis that increasing model size, training data, and compute leads to predictable and substantial improvements in AI capability, supported by empirical scaling laws discovered by Kaplan et al. at OpenAI.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-scaling-law",
      "term": "Scaling Law",
      "definition": "Empirical power-law relationships that predict how model performance improves as a function of compute budget, model size, and dataset size, guiding efficient resource allocation for training.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-scaling-laws",
      "term": "Scaling Laws",
      "definition": "Empirical relationships showing how model performance improves with more parameters, data, and compute. Guide decisions about where to invest resources in training larger models.",
      "tags": [
        "Research",
        "Training"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-scaling-laws-compute",
      "term": "Scaling Laws for Compute",
      "definition": "Empirical power-law relationships between model performance and compute budget, model size, and dataset size established by Kaplan et al. and Hoffmann et al. (Chinchilla). Scaling laws guide optimal allocation of training compute.",
      "tags": [
        "Model Optimization",
        "Distributed Computing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-scann-algorithm",
      "term": "ScaNN Algorithm",
      "definition": "Scalable Nearest Neighbors uses learned quantization and anisotropic vector quantization for approximate nearest-neighbor search. Achieves state-of-the-art speed-accuracy tradeoffs on benchmark datasets for maximum inner-product search.",
      "tags": [
        "Algorithms",
        "Technical",
        "Searching",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-scannet",
      "term": "ScanNet",
      "definition": "A richly annotated 3D reconstruction dataset of real-world indoor scenes containing 2.5 million RGB-D frames across 1513 scenes with semantic segmentation and object detection annotations.",
      "tags": [
        "Benchmark",
        "3D",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-scapegoat-tree-algorithm",
      "term": "Scapegoat Tree Algorithm",
      "definition": "A self-balancing binary search tree that rebalances by rebuilding the subtree rooted at a scapegoat node when it becomes unbalanced. Avoids storing balance information in nodes and achieves O(log n) amortized operations.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-scatter-search-algorithm",
      "term": "Scatter Search Algorithm",
      "definition": "A metaheuristic that maintains a reference set of diverse high-quality solutions and generates new candidates by combining them. Uses structured combination methods rather than randomized crossover found in genetic algorithms.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-scene-graph-generation",
      "term": "Scene Graph Generation",
      "definition": "The task of detecting objects in an image and predicting their pairwise relationships to construct a graph representation where nodes are objects and edges are visual relationships.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-scene-text-recognition",
      "term": "Scene Text Recognition",
      "definition": "The task of reading and transcribing text found in natural images (street signs, product labels, building facades), dealing with perspective distortion, partial occlusion, and diverse typography.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-scenedreamer",
      "term": "SceneDreamer",
      "definition": "A 3D scene generation model that creates unbounded 3D driving environments from a bird-eye-view layout for autonomous driving simulation and testing.",
      "tags": [
        "Models",
        "Technical",
        "Autonomous",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-scheduled-sampling",
      "term": "Scheduled Sampling",
      "definition": "A training technique that gradually transitions from teacher forcing to using the model's own predictions as inputs during training. Reduces the exposure bias gap between training and inference. The curriculum linearly interpolates between the two modes.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-schnet",
      "term": "SchNet",
      "definition": "A deep learning model for molecular property prediction that uses continuous-filter convolutional layers to learn representations respecting rotational and translational symmetry.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-scibench",
      "term": "SciBench",
      "definition": "A benchmark of college-level science problems from textbooks in mathematics physics and chemistry. Tests the ability to solve problems requiring scientific domain knowledge.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning",
        "Scientific"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-scibert",
      "term": "SciBERT",
      "definition": "A BERT model pretrained on a large corpus of scientific papers from the Semantic Scholar corpus. Outperforms BERT on scientific NLP tasks including named entity recognition relation extraction and document classification.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-scidocs",
      "term": "SCIDOCS",
      "definition": "A benchmark for evaluating scientific document embeddings across seven document-level tasks including citation prediction recommendation and classification.",
      "tags": [
        "Benchmark",
        "NLP",
        "Scientific"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-scienceqa",
      "term": "ScienceQA",
      "definition": "A multimodal science question answering benchmark with lectures explanations and multiple-choice questions. Covers diverse science topics with both text and image contexts.",
      "tags": [
        "Benchmark",
        "Multimodal",
        "Scientific"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-scifact",
      "term": "SciFact",
      "definition": "A dataset for scientific claim verification containing 1409 expert-annotated claims paired with evidence from scientific abstracts. Tests the ability to verify scientific statements.",
      "tags": [
        "Benchmark",
        "NLP",
        "Scientific"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sciglm",
      "term": "SciGLM",
      "definition": "A scientific language model fine-tuned on curated scientific question-answer pairs for enhanced reasoning in physics and chemistry and biology domains.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-scikit-learn",
      "term": "Scikit-learn",
      "definition": "A popular Python library for traditional machine learning algorithms. Provides simple APIs for classification, regression, clustering, and preprocessing. The go-to for non-deep-learning ML.",
      "tags": [
        "Framework",
        "ML"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sciq",
      "term": "SciQ",
      "definition": "A science question answering dataset of 13679 crowdsourced multiple-choice science exam questions with supporting passages. Tests scientific knowledge and reading comprehension.",
      "tags": [
        "Benchmark",
        "NLP",
        "Scientific"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-scirepeval",
      "term": "SciRepEval",
      "definition": "A benchmark for scientific document representation spanning 4 task formats across 24 scientific datasets. Tests the quality of learned representations of scientific text.",
      "tags": [
        "Benchmark",
        "NLP",
        "Scientific",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-score-function",
      "term": "Score Function",
      "definition": "The gradient of the log-likelihood function with respect to the parameter, used in maximum likelihood estimation and Fisher information calculations. Its expected value under the true distribution is zero.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-score-matching",
      "term": "Score Matching",
      "definition": "A method for estimating probability density functions by matching the gradient of the log-density (score function) rather than the density itself. Avoids computing the normalizing constant. Foundation of score-based generative models.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-score-based-generative-model",
      "term": "Score-Based Generative Model",
      "definition": "A generative model that learns the gradient of the log probability density (score function) of the data distribution, then uses Langevin dynamics or similar methods to generate samples.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-scratchpad-memory",
      "term": "Scratchpad Memory",
      "definition": "Software-managed on-chip memory providing fast deterministic access without cache hardware overhead. Used in AI accelerators to store intermediate computation results during inference.",
      "tags": [
        "Memory",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-script-theory",
      "term": "Script Theory",
      "definition": "A knowledge representation scheme proposed by Roger Schank and Robert Abelson in 1977 describing stereotyped sequences of events in particular contexts. Scripts like the restaurant script capture common knowledge about routine situations enabling story understanding.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-scrolls",
      "term": "SCROLLS",
      "definition": "Standardized CompaRison Over Long Language Sequences a benchmark of 7 tasks requiring reasoning over long texts. Tests language model capabilities on long-context NLU tasks.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sd3",
      "term": "SD3",
      "definition": "Stable Diffusion 3 is a next-generation text-to-image model from Stability AI using a Multimodal Diffusion Transformer (MMDiT) architecture with flow matching.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sdxl",
      "term": "SDXL",
      "definition": "Stable Diffusion XL, an improved latent diffusion model that uses a larger UNet with dual text encoders and an optional refiner model to generate higher-resolution, more detailed images.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sdxl-turbo",
      "term": "SDXL Turbo",
      "definition": "A distilled version of Stable Diffusion XL that generates high-quality images in a single step using Adversarial Diffusion Distillation.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sdxl-lightning",
      "term": "SDXL-Lightning",
      "definition": "A distilled version of SDXL that generates high-quality images in 1-4 steps using progressive and adversarial distillation techniques.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-seallm",
      "term": "SeaLLM",
      "definition": "A multilingual large language model tailored for Southeast Asian languages including Thai and Vietnamese and Indonesian and Malay.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-seam-carving-algorithm",
      "term": "Seam Carving Algorithm",
      "definition": "A content-aware image resizing technique that removes low-energy seams (connected paths of pixels) to reduce image dimensions. Preserves important visual content while allowing non-uniform size reduction.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-seamlessm4t",
      "term": "SeamlessM4T",
      "definition": "A multilingual and multimodal translation model from Meta AI supporting speech-to-speech and speech-to-text and text-to-speech translation across nearly 100 languages.",
      "tags": [
        "Models",
        "Technical",
        "Audio",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-seasonal-decomposition",
      "term": "Seasonal Decomposition",
      "definition": "A time series analysis technique that separates a time series into trend, seasonal, and residual components, either additively or multiplicatively, to better understand underlying patterns.",
      "tags": [
        "Data Science",
        "Statistics"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sebastian-thrun",
      "term": "Sebastian Thrun",
      "definition": "German-American computer scientist who led the Stanford Racing Team to victory in the 2005 DARPA Grand Challenge. Co-founder of Udacity and Google X. Former head of the Google self-driving car project that evolved into Waymo.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-secant-method",
      "term": "Secant Method",
      "definition": "A root-finding algorithm that uses a succession of secant lines to approximate the root of a function. Does not require derivative computation and converges superlinearly with an order of approximately 1.618.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-second",
      "term": "SECOND",
      "definition": "Sparsely Embedded Convolutional Detection is an efficient 3D object detection model that uses sparse convolutions on voxelized point clouds for fast inference.",
      "tags": [
        "Models",
        "Technical",
        "Autonomous",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-second-ai-winter",
      "term": "Second AI Winter",
      "definition": "The period from approximately 1987 to 1993 when enthusiasm for AI again collapsed following the failure of expert systems to scale, the collapse of the LISP machine market, and cuts to government AI funding.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-sector-specific-ai-regulation",
      "term": "Sector-Specific AI Regulation",
      "definition": "AI regulations tailored to specific industries such as healthcare finance transportation and education. Recognizes that different sectors have different risk profiles and existing regulatory frameworks.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-secure-aggregation-algorithm",
      "term": "Secure Aggregation Algorithm",
      "definition": "A cryptographic protocol that enables a server to compute the sum of client updates without learning individual contributions. Essential for privacy-preserving federated learning and secure voting systems.",
      "tags": [
        "Algorithms",
        "Technical",
        "Privacy"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-secure-multi-party-computation",
      "term": "Secure Multi-Party Computation",
      "definition": "A cryptographic protocol that allows multiple parties to jointly compute a function over their combined inputs while keeping each party's input private, used in privacy-preserving machine learning applications.",
      "tags": [
        "Privacy",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-seed-bench",
      "term": "SEED-Bench",
      "definition": "A multimodal benchmark evaluating large multimodal models across 19000 questions covering 12 evaluation dimensions from image to video understanding.",
      "tags": [
        "Benchmark",
        "Multimodal",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-seggpt",
      "term": "SegGPT",
      "definition": "A generalist model for segmentation in context that performs diverse segmentation tasks through in-context visual prompting without task-specific fine-tuning.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-segment-anything-model",
      "term": "Segment Anything Model",
      "definition": "A foundation model for image segmentation (SAM) trained on a massive dataset that can segment any object in any image given a prompt such as a point, bounding box, or text description.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-segment-anything-model-2",
      "term": "Segment Anything Model 2",
      "definition": "An extension of SAM that handles video segmentation in addition to images. Processes video frames with a memory mechanism for temporal consistency enabling object tracking and video segmentation with point or box prompts.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-segment-tree-algorithm",
      "term": "Segment Tree Algorithm",
      "definition": "A tree data structure for storing intervals or segments that supports range queries and point updates in O(log n) time. Each node represents an interval and stores an aggregate value for that range.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-selection-bias",
      "term": "Selection Bias",
      "definition": "A systematic error arising when the sample used for analysis is not representative of the population, due to the way observations were selected. It can lead to models that do not generalize to the true population.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-selection-sort",
      "term": "Selection Sort",
      "definition": "A simple sorting algorithm that repeatedly finds the minimum element from the unsorted portion and places it at the beginning. Always runs in O(n^2) time regardless of input order and is not stable.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Sorting"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-selectional-preference",
      "term": "Selectional Preference",
      "definition": "The tendency of predicates to semantically constrain their arguments, such as 'eat' preferring edible objects, used in NLP for disambiguation and semantic plausibility assessment.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-selective-context",
      "term": "Selective Context",
      "definition": "A prompt compression method that evaluates the informativeness of each lexical unit in a context using self-information scores from a causal language model, then filters out low-information content to reduce prompt length while retaining key details.",
      "tags": [
        "Prompt Engineering",
        "Compression"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-selective-search",
      "term": "Selective Search",
      "definition": "An object proposal generation method that combines multiple grouping strategies including color and texture and size similarity. Generates a diverse set of candidate regions for object detection pipelines.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-ask",
      "term": "Self-Ask",
      "definition": "A prompting technique where the model explicitly asks itself follow-up questions needed to answer a complex query, then answers each sub-question before synthesizing the final response, naturally decomposing multi-hop reasoning tasks.",
      "tags": [
        "Prompt Engineering",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-attention",
      "term": "Self-Attention",
      "definition": "An attention mechanism where a sequence attends to itself, allowing each position to consider all other positions. The core operation in transformer models.",
      "tags": [
        "Architecture",
        "Transformers"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-attention-mechanism",
      "term": "Self-Attention Mechanism",
      "definition": "A mechanism that allows each position in a sequence to attend to all other positions introduced as a key component of the Transformer architecture (Vaswani et al. 2017). Self-attention enables capturing long-range dependencies without recurrence or convolution.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-bleu",
      "term": "Self-BLEU",
      "definition": "A diversity metric that computes BLEU scores between pairs of generated sentences from the same model, where lower Self-BLEU indicates greater diversity and less repetition across the model's outputs.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-consistency",
      "term": "Self-Consistency",
      "definition": "A technique where AI generates multiple reasoning paths and selects the most common answer. Improves accuracy for complex reasoning by aggregating diverse approaches.",
      "tags": [
        "Prompting",
        "Reasoning"
      ],
      "domain": "general",
      "link": "../learn/index.html",
      "related": []
    },
    {
      "id": "term-self-driving-car-history",
      "term": "Self-Driving Car History",
      "definition": "The evolution of autonomous vehicles from early projects like Stanford Cart in 1961 and CMU's Navlab in 1986 through the DARPA Grand Challenges, Google's self-driving car project in 2009, and modern robotaxi services.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-instruct",
      "term": "Self-Instruct",
      "definition": "A framework and dataset for bootstrapping instruction-following data from a language model's own generations. Generates 52000 instructions and demonstrations from minimal seeds.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-organizing-map-algorithm",
      "term": "Self-Organizing Map Algorithm",
      "definition": "An unsupervised neural network that produces a low-dimensional discretized representation of the input space. Neurons on a grid compete to represent input patterns and neighboring neurons learn similar representations.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-play",
      "term": "Self-Play",
      "definition": "A training paradigm where an agent improves by playing against copies of itself, generating increasingly challenging opponents as its skill grows. Self-play creates an automatic curriculum and has driven breakthroughs in game-playing AI.",
      "tags": [
        "Reinforcement Learning",
        "Training Paradigms"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-play-algorithm",
      "term": "Self-Play Algorithm",
      "definition": "A training paradigm where an agent learns by playing against copies of itself. Gradually increases skill level without requiring human opponents and was instrumental in the success of AlphaGo and AlphaZero.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-polish-prompting",
      "term": "Self-Polish Prompting",
      "definition": "A technique that prompts the model to progressively refine and polish the given problem conditions before solving, enabling the model to simplify complex problems into more tractable formulations through iterative rewriting.",
      "tags": [
        "Prompt Engineering",
        "Refinement"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-rag",
      "term": "Self-RAG",
      "definition": "A framework where the language model learns to retrieve on demand, generate text, and critique its own output using special reflection tokens, adaptively deciding when retrieval is necessary.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-supervised-learning",
      "term": "Self-Supervised Learning",
      "definition": "A machine learning paradigm where the model generates its own supervisory signal from unlabeled data through pretext tasks. Examples include masked language modeling next-token prediction and contrastive learning. Foundation of modern pretrained models.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-supervised-learning-history",
      "term": "Self-Supervised Learning History",
      "definition": "The development of self-supervised learning where models learn representations from unlabeled data by solving pretext tasks. From autoencoders and word2vec through BERT's masked language modeling to contrastive learning methods like SimCLR and CLIP.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-training",
      "term": "Self-Training",
      "definition": "A semi-supervised learning method where a model trained on labeled data generates pseudo-labels for unlabeled data, then retrains on both real and pseudo-labeled examples, iteratively expanding the training set.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-self-training-vision",
      "term": "Self-Training for Vision",
      "definition": "A semi-supervised learning approach where a teacher model generates pseudo-labels for unlabeled images, and a student model is trained on the combination of labeled data and high-confidence pseudo-labels.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-selu",
      "term": "SELU",
      "definition": "Scaled Exponential Linear Unit that enables self-normalizing neural networks. Combines the ELU function with specific scale and alpha constants derived mathematically to ensure that activations converge toward zero mean and unit variance during training.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-caching",
      "term": "Semantic Caching",
      "definition": "A caching strategy that stores LLM responses indexed by the semantic meaning of queries rather than exact string matches, allowing cache hits for paraphrased or similar questions.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-chunking",
      "term": "Semantic Chunking",
      "definition": "A document splitting approach that determines chunk boundaries based on semantic similarity between consecutive sentences, creating new chunks when the topic or meaning shifts significantly rather than using fixed-size character or token counts.",
      "tags": [
        "Retrieval",
        "Preprocessing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-correspondence",
      "term": "Semantic Correspondence",
      "definition": "The task of finding matching points between images of different instances of the same object category, requiring understanding of semantic similarity rather than just visual appearance matching.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-kernel",
      "term": "Semantic Kernel",
      "definition": "Microsoft's open-source SDK for building AI applications with LLMs. Supports plugin architecture, memory, and planning for enterprise AI agent development.",
      "tags": [
        "Framework",
        "Application"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-map",
      "term": "Semantic Map",
      "definition": "A spatial representation that annotates each location with semantic labels indicating what type of object or surface occupies that space, used in robotics navigation and autonomous driving planning.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-networks",
      "term": "Semantic Networks",
      "definition": "A knowledge representation formalism using graphs of nodes connected by labeled edges to represent concepts and their relationships, first proposed by Ross Quillian in 1968 and widely used in early AI and natural language understanding.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-parsing",
      "term": "Semantic Parsing",
      "definition": "The task of mapping natural language utterances to formal meaning representations such as logical forms, SQL queries, or lambda calculus expressions that can be executed or reasoned over.",
      "tags": [
        "NLP",
        "Parsing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-role-labeling",
      "term": "Semantic Role Labeling",
      "definition": "The task of identifying the predicate-argument structure of a sentence by assigning semantic roles such as agent, patient, instrument, and location to constituents relative to the predicate.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-role-labeling-algorithm",
      "term": "Semantic Role Labeling Algorithm",
      "definition": "An algorithm that identifies the predicate-argument structure of sentences by assigning semantic roles to constituents. Determines who did what to whom and where and when for each predicate in the sentence.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-scholar-corpus",
      "term": "Semantic Scholar Corpus",
      "definition": "A comprehensive corpus of academic papers with metadata citations and abstracts maintained by AI2. Used for scientific information extraction and citation analysis.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Scientific"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-search",
      "term": "Semantic Search",
      "definition": "Search based on meaning rather than keyword matching. Uses embeddings to find conceptually similar content, enabling more relevant results for natural language queries.",
      "tags": [
        "Application",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-segmentation",
      "term": "Semantic Segmentation",
      "definition": "A computer vision task that assigns a class label to every pixel in an image, producing a dense prediction map that identifies what object category each pixel belongs to without distinguishing instances.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-segmentation-transformer",
      "term": "Semantic Segmentation Transformer",
      "definition": "Transformer-based architectures like SegFormer and Mask2Former that apply self-attention to image features for dense per-pixel classification, outperforming CNN-based segmenters on many benchmarks.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-textual-similarity",
      "term": "Semantic Textual Similarity",
      "definition": "The task of measuring the degree of semantic equivalence between two text segments on a continuous scale, going beyond binary paraphrase detection to capture graded similarity.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantic-web",
      "term": "Semantic Web",
      "definition": "A vision proposed by Tim Berners-Lee in 2001 for extending the World Wide Web with machine-readable metadata. The Semantic Web uses ontologies RDF and OWL to enable computers to understand and reason about web content connecting to AI knowledge representation.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-semantics",
      "term": "Semantics",
      "definition": "The branch of linguistics studying meaning in language, including word meaning, sentence meaning, and the relationship between linguistic expressions and what they refer to.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-semi-supervised-learning",
      "term": "Semi-Supervised Learning",
      "definition": "A learning paradigm that combines a small amount of labeled data with a large amount of unlabeled data during training. It leverages the structure in unlabeled data to improve model performance beyond what labeled data alone provides.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-semi-supervised-object-detection",
      "term": "Semi-Supervised Object Detection",
      "definition": "Detection training approaches that leverage both a small set of labeled images and a large pool of unlabeled images, using techniques like pseudo-labeling and consistency regularization.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-semiconductor",
      "term": "Semiconductor",
      "definition": "Material with electrical conductivity between a conductor and insulator typically silicon. Forms the physical foundation of all modern computing chips including AI processors and accelerators.",
      "tags": [
        "Fabrication",
        "Fundamentals"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-semiconductor-supply-chain",
      "term": "Semiconductor Supply Chain",
      "definition": "Global network of companies involved in designing manufacturing and packaging semiconductor chips. Concentration of advanced manufacturing in Taiwan poses supply chain risks for AI hardware.",
      "tags": [
        "Manufacturing",
        "Supply Chain",
        "Global"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-sensitivity",
      "term": "Sensitivity",
      "definition": "The proportion of actual positive cases correctly identified by a classifier, synonymous with recall and true positive rate. High sensitivity minimizes false negatives in the predictions.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sentence-boundary-detection",
      "term": "Sentence Boundary Detection",
      "definition": "The task of identifying where sentences begin and end in running text, handling ambiguous punctuation like periods in abbreviations, decimal numbers, and ellipses.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sentence-embedding",
      "term": "Sentence Embedding",
      "definition": "A fixed-length dense vector representation of an entire sentence that captures its semantic meaning, produced by methods like mean pooling over token embeddings or dedicated sentence encoders.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sentence-transformer",
      "term": "Sentence Transformer",
      "definition": "Models that encode entire sentences into single vectors, capturing semantic meaning. Popular for semantic search, similarity matching, and clustering text at the sentence level.",
      "tags": [
        "Model Type",
        "Embeddings"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sentence-bert",
      "term": "Sentence-BERT",
      "definition": "A modification of BERT that uses siamese and triplet networks to derive semantically meaningful sentence embeddings. Enables efficient semantic similarity computation through cosine similarity rather than cross-encoding all sentence pairs.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sentencepiece",
      "term": "SentencePiece",
      "definition": "A language-independent tokenization library that treats the input as a raw byte stream and applies BPE or unigram tokenization directly without pre-tokenization or language-specific preprocessing.",
      "tags": [
        "NLP",
        "Tokenization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sentencepiece-algorithm",
      "term": "SentencePiece Algorithm",
      "definition": "A language-independent subword tokenizer and detokenizer that directly processes raw text without pre-tokenization. Supports both byte-pair encoding and unigram language model approaches in a unified framework.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sentiment-analysis",
      "term": "Sentiment Analysis",
      "definition": "An NLP task that determines the emotional tone of text (positive, negative, neutral). Used in customer feedback analysis, social media monitoring, and brand tracking.",
      "tags": [
        "NLP Task",
        "Classification"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sentiment-polarity",
      "term": "Sentiment Polarity",
      "definition": "The classification of text sentiment into categories such as positive, negative, or neutral, representing the overall emotional orientation expressed toward the subject of the text.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sepp-hochreiter",
      "term": "Sepp Hochreiter",
      "definition": "Austrian computer scientist who co-invented the Long Short-Term Memory network architecture in 1997 with Jurgen Schmidhuber, solving a fundamental problem in training recurrent neural networks on long sequences.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-seq2seq",
      "term": "Seq2Seq",
      "definition": "Sequence-to-Sequence, an encoder-decoder framework where an encoder processes an input sequence into a fixed-length representation and a decoder generates an output sequence from that representation.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-seq2seq-model",
      "term": "Seq2Seq Model",
      "definition": "The sequence-to-sequence model introduced by Ilya Sutskever Oriol Vinyals and Quoc Le at Google in 2014. Using encoder-decoder RNN architecture seq2seq enabled end-to-end learning for variable-length input-output pairs revolutionizing machine translation and text generation.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-sequence-alignment-algorithm",
      "term": "Sequence Alignment Algorithm",
      "definition": "An algorithm that arranges sequences to identify regions of similarity. Needleman-Wunsch performs global alignment and Smith-Waterman performs local alignment both using dynamic programming with scoring matrices.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sequence-labeling",
      "term": "Sequence Labeling",
      "definition": "The task of assigning a categorical label to each element in a sequence, such as tagging each word in a sentence with its named entity type, POS tag, or chunk boundary.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sequence-parallelism",
      "term": "Sequence Parallelism",
      "definition": "A technique that distributes the processing of long sequences across multiple devices by partitioning the sequence dimension, enabling context lengths that exceed single-device memory limits.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sequence-level-accuracy",
      "term": "Sequence-Level Accuracy",
      "definition": "An evaluation metric that considers an entire generated sequence correct only if every token matches the reference, providing a strict holistic assessment used in tasks like structured prediction and code generation.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sequential-quadratic-programming",
      "term": "Sequential Quadratic Programming",
      "definition": "An iterative optimization method for nonlinear constrained problems that solves a quadratic programming subproblem at each step. Approximates the Lagrangian Hessian and linearizes constraints to form the subproblem.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-server-rack",
      "term": "Server Rack",
      "definition": "Standardized enclosure for mounting server equipment in data centers. AI server racks are evolving to support higher power densities required by modern GPU servers.",
      "tags": [
        "Data Center",
        "Infrastructure",
        "Physical"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-seymour-papert",
      "term": "Seymour Papert",
      "definition": "South African-born American mathematician and computer scientist who co-authored the influential book Perceptrons (1969) with Marvin Minsky. Co-founded the MIT AI Laboratory and created the Logo programming language for teaching children computational thinking.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-sft",
      "term": "SFT (Supervised Fine-Tuning)",
      "definition": "Training a pre-trained model on labeled examples of desired behavior. Often the first step in aligning LLMs, teaching them to follow instructions before RLHF.",
      "tags": [
        "Training",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-sgi-origin",
      "term": "SGI Origin",
      "definition": "Silicon Graphics server series using MIPS processors and ccNUMA architecture. Used for scientific visualization and early neural network research in the 1990s and 2000s.",
      "tags": [
        "Historical",
        "System",
        "Server"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-sgpt",
      "term": "SGPT",
      "definition": "Sentence embeddings from GPT models that use position-weighted mean pooling or cross-encoder approaches for semantic search and sentence similarity.",
      "tags": [
        "Models",
        "Technical",
        "Embedding",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-shadow-ai",
      "term": "Shadow AI",
      "definition": "The use of unauthorized or unvetted AI tools and systems by employees within an organization. Poses risks to data security regulatory compliance and organizational safety governance.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-shakey-the-robot",
      "term": "Shakey the Robot",
      "definition": "The first general-purpose mobile robot developed at SRI International from 1966 to 1972 that could reason about its own actions, integrating computer vision, natural language understanding, and planning.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-shannon-entropy",
      "term": "Shannon Entropy",
      "definition": "A measure of the average information content or uncertainty in a random variable defined as the expected value of the negative log probability. Higher entropy indicates more uncertainty. Foundation of information theory introduced by Claude Shannon in 1948.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-shannon-fano-coding",
      "term": "Shannon-Fano Coding",
      "definition": "An early entropy coding algorithm that recursively partitions symbols into two groups of approximately equal probability. A precursor to Huffman coding and not always optimal but historically important.",
      "tags": [
        "Algorithms",
        "Technical",
        "Information Theory",
        "History"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-shap-values",
      "term": "SHAP Values",
      "definition": "SHapley Additive exPlanations, a unified framework for feature importance that assigns each feature a contribution value for a specific prediction based on Shapley values from cooperative game theory, satisfying desirable theoretical properties.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-shap-e",
      "term": "Shap-E",
      "definition": "A model by OpenAI that directly generates 3D implicit functions from text or images. Produces textured 3D meshes that can be rendered from any viewpoint. Faster than Point-E while producing more detailed outputs.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-shaped-reward",
      "term": "Shaped Reward",
      "definition": "An auxiliary reward signal added to the environment's natural reward to guide learning toward desired behavior. Shaped rewards provide more frequent feedback in sparse reward settings but must be carefully designed to avoid altering the optimal policy.",
      "tags": [
        "Reinforcement Learning",
        "Reward Design"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-shapenet",
      "term": "ShapeNet",
      "definition": "A large-scale repository of 3D CAD models with rich annotations covering 55 common object categories. Used for 3D object classification reconstruction and generation research.",
      "tags": [
        "Benchmark",
        "3D",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-shapiro-wilk-test",
      "term": "Shapiro-Wilk Test",
      "definition": "A statistical test for normality that evaluates whether a random sample comes from a normal distribution. It is considered one of the most powerful normality tests, especially for small sample sizes.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-shared-memory-gpu",
      "term": "Shared Memory (GPU)",
      "definition": "A fast, programmer-managed on-chip SRAM in GPU streaming multiprocessors that enables efficient data sharing between threads in a thread block. FlashAttention exploits shared memory to avoid expensive HBM accesses for attention computation.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-shared-nearest-neighbor-clustering",
      "term": "Shared Nearest Neighbor Clustering",
      "definition": "A clustering approach that measures similarity between points based on the number of shared nearest neighbors. More robust to varying densities than distance-based methods and works well in high dimensions.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sharegpt",
      "term": "ShareGPT",
      "definition": "A collection of user-shared conversations with ChatGPT used for training open-source instruction-following language models. Provides diverse real-world conversational data.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sharegpt4v",
      "term": "ShareGPT4V",
      "definition": "A vision-language model trained on highly detailed image descriptions generated by GPT-4V for improved visual understanding and caption generation.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sharpness-aware-minimization",
      "term": "Sharpness-Aware Minimization",
      "definition": "An optimization procedure that seeks parameters in neighborhoods with uniformly low loss rather than just minimizing the loss at a single point. Improves generalization by preferring flat minima over sharp ones in the loss landscape.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-shell-sort",
      "term": "Shell Sort",
      "definition": "A generalization of insertion sort that compares elements separated by a gap and progressively reduces the gap. Performance depends on the gap sequence used with the best known sequences achieving O(n^(4/3)) time.",
      "tags": [
        "Algorithms",
        "Technical",
        "Sorting"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-shieldgemma",
      "term": "ShieldGemma",
      "definition": "A safety classifier built on Gemma models from Google that detects harmful content categories in language model inputs and outputs.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Safety"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-short-time-fourier-transform",
      "term": "Short-Time Fourier Transform",
      "definition": "A signal analysis method that divides a signal into short overlapping segments and applies the Fourier transform to each. Provides time-frequency representation but with fixed resolution determined by the window size.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-show-o",
      "term": "Show-o",
      "definition": "A unified Transformer model that handles both multimodal understanding and image generation by combining autoregressive and discrete diffusion modeling approaches.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-shrdlu",
      "term": "SHRDLU",
      "definition": "A natural language understanding program created by Terry Winograd at MIT in 1970 that could converse about and manipulate objects in a simulated blocks world, demonstrating early natural language processing capabilities.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-shufflenet",
      "term": "ShuffleNet",
      "definition": "A lightweight CNN architecture designed for mobile devices that uses pointwise group convolutions and channel shuffle operations. Reduces computation while maintaining accuracy for resource-constrained environments.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sift",
      "term": "SIFT",
      "definition": "Scale-Invariant Feature Transform, a classical algorithm that detects and describes local image features robust to scale, rotation, and illumination changes, widely used as a baseline for feature matching.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-sift-algorithm",
      "term": "SIFT Algorithm",
      "definition": "Scale-Invariant Feature Transform detects and describes local features in images that are invariant to scale and rotation. Constructs a scale space using difference-of-Gaussian filters and computes gradient histograms for descriptors.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Vision",
        "History"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-siglip",
      "term": "SigLIP",
      "definition": "Sigmoid Loss for Language Image Pretraining replaces the softmax-based contrastive loss in CLIP with a sigmoid loss that operates on individual image-text pairs. Simpler and more memory efficient enabling larger batch sizes.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sigmoid",
      "term": "Sigmoid",
      "definition": "A classic activation function that maps inputs to values between 0 and 1 using the formula f(x) = 1 / (1 + exp(-x)). Historically important in neural networks and still used for binary classification output layers and gating mechanisms.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-signed-distance-function",
      "term": "Signed Distance Function",
      "definition": "A 3D representation where a neural network predicts the signed distance from any 3D point to the nearest surface, with the zero-level set defining the shape, enabling smooth surface extraction.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-significance-level",
      "term": "Significance Level",
      "definition": "The threshold probability (alpha, typically 0.05) below which the p-value must fall for the null hypothesis to be rejected. It defines the acceptable risk of making a Type I error.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-silent-data-corruption",
      "term": "Silent Data Corruption",
      "definition": "Undetected data errors in computing systems that produce incorrect results without triggering error signals. A growing concern in large-scale AI training where subtle errors can degrade model quality.",
      "tags": [
        "Reliability",
        "Data Integrity",
        "Challenge"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-silhouette-score",
      "term": "Silhouette Score",
      "definition": "A metric for evaluating clustering quality that measures how similar each point is to its own cluster compared to other clusters. Values range from -1 to 1, where higher values indicate better-defined clusters.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-silicon-photonics",
      "term": "Silicon Photonics",
      "definition": "Technology integrating optical components directly into silicon chips for on-chip and chip-to-chip optical communication. Promises to solve bandwidth and power challenges in AI systems.",
      "tags": [
        "Emerging",
        "Photonic",
        "Integration"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-silicon-wafer",
      "term": "Silicon Wafer",
      "definition": "Thin disk of crystalline silicon used as the substrate for fabricating semiconductor chips. Wafers are typically 300mm in diameter and undergo hundreds of processing steps to create finished chips.",
      "tags": [
        "Fabrication",
        "Manufacturing",
        "Material"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-silu",
      "term": "SiLU",
      "definition": "Sigmoid Linear Unit activation function defined as f(x) = x * sigmoid(x). Mathematically equivalent to Swish with beta equal to 1. Widely used in modern architectures including diffusion models and large language models.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sim-to-real",
      "term": "Sim-to-Real Transfer",
      "definition": "The challenge and set of techniques for deploying policies trained in simulation to physical systems. Sim-to-real methods include domain randomization, system identification, and progressive fine-tuning to bridge the reality gap.",
      "tags": [
        "Reinforcement Learning",
        "Training Paradigms"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sima",
      "term": "SIMA",
      "definition": "Scalable Instructable Multiworld Agent from DeepMind that follows natural language instructions to complete tasks across diverse 3D virtual environments.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP",
        "Robotics"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-simclr",
      "term": "SimCLR",
      "definition": "A contrastive self-supervised learning framework for visual representations that uses data augmentation to create positive pairs and a projection head with NT-Xent loss to learn transferable image features.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-simd",
      "term": "SIMD",
      "definition": "Single Instruction Multiple Data parallel computing model where one instruction operates on multiple data elements simultaneously. Used in CPU vector extensions and GPU shader cores for AI workloads.",
      "tags": [
        "Architecture",
        "Parallelism",
        "Fundamentals"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-similarity-threshold",
      "term": "Similarity Threshold",
      "definition": "A configurable cutoff value that filters vector search results to include only matches exceeding a minimum similarity score, preventing the retrieval of irrelevant results when no sufficiently similar vectors exist in the index.",
      "tags": [
        "Vector Database",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-simmtm",
      "term": "SimMTM",
      "definition": "Simple pre-training framework for Masked Time-series Modeling that uses masked reconstruction to learn transferable time series representations.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-simpleqa",
      "term": "SimpleQA",
      "definition": "A benchmark of factual questions with definitive short answers for evaluating the factual accuracy of language models. Tests whether models provide correct and well-calibrated responses.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-simplex-algorithm",
      "term": "Simplex Algorithm",
      "definition": "A widely used algorithm for solving linear programming problems that moves along the edges of the feasible polytope from vertex to vertex. Despite exponential worst-case complexity it performs efficiently in practice.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Optimization",
        "History"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-simpsons-paradox",
      "term": "Simpson's Paradox",
      "definition": "A statistical phenomenon where a trend that appears in several different groups of data disappears or reverses when these groups are combined. It highlights the importance of accounting for confounding variables.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-simpsons-rule",
      "term": "Simpson's Rule",
      "definition": "A numerical integration method that approximates the definite integral by fitting quadratic polynomials to successive groups of three points. Achieves fourth-order accuracy and is more precise than the trapezoidal rule.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-simt",
      "term": "SIMT",
      "definition": "Single Instruction Multiple Thread execution model used by NVIDIA GPUs where groups of threads execute the same instruction on different data. Extends SIMD with thread-level flexibility.",
      "tags": [
        "Architecture",
        "GPU",
        "NVIDIA"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-simtom-prompting",
      "term": "SimToM Prompting",
      "definition": "A two-step prompting approach for theory-of-mind tasks that first identifies what information a specific person is aware of, then answers the question based solely on that person's limited perspective rather than full omniscient context.",
      "tags": [
        "Prompt Engineering",
        "Theory of Mind"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-simulated-annealing",
      "term": "Simulated Annealing",
      "definition": "A probabilistic optimization algorithm inspired by the annealing process in metallurgy. Accepts worse solutions with decreasing probability over time allowing escape from local optima. Temperature parameter controls the exploration-exploitation tradeoff.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-simulation-hardware",
      "term": "Simulation Hardware",
      "definition": "Specialized computing hardware optimized for running physics simulations used in AI training environments. Enables synthetic data generation for robotics autonomous driving and scientific AI.",
      "tags": [
        "Infrastructure",
        "Simulation",
        "Training"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-singular-learning-theory",
      "term": "Singular Learning Theory",
      "definition": "A mathematical framework using algebraic geometry to study the loss landscapes of neural networks. Provides tools for understanding generalization phase transitions and model selection in singular statistical models.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-singular-value-decomposition",
      "term": "Singular Value Decomposition",
      "definition": "A matrix factorization technique that decomposes a matrix into three matrices (U, S, V^T), where S contains singular values. It is foundational for PCA, latent semantic analysis, and matrix completion.",
      "tags": [
        "Machine Learning",
        "Dimensionality Reduction"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-singularity-concept",
      "term": "Singularity Concept",
      "definition": "The hypothesized future point when AI surpasses human intelligence and triggers runaway technological growth, popularized by Vernor Vinge in 1993 and Ray Kurzweil in his 2005 book The Singularity Is Near.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-sinusoidal-position-encoding",
      "term": "Sinusoidal Position Encoding",
      "definition": "The original position encoding used in the Transformer architecture. Uses sine and cosine functions of different frequencies to generate unique position vectors. Enables the model to learn relative positions through linear projections of the encodings.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sinusoidal-positional-encoding",
      "term": "Sinusoidal Positional Encoding",
      "definition": "A fixed positional encoding scheme that uses sine and cosine functions of different frequencies to encode absolute token positions, allowing the model to learn relative positions through linear projections.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-siqa",
      "term": "SIQA",
      "definition": "Social Interaction QA a benchmark for commonsense reasoning about peoples actions and their social implications. Contains 38000 multiple-choice questions about emotional and social intelligence.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-siri",
      "term": "Siri",
      "definition": "A virtual assistant developed by SRI International and later acquired by Apple in 2010. Launched as an iOS feature in 2011 Siri was one of the first widely deployed AI assistants bringing natural language understanding and voice interaction to consumer devices.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-siri-launch",
      "term": "Siri Launch",
      "definition": "Apple's launch of Siri in October 2011 as the first widely deployed virtual assistant on a smartphone, introducing millions of consumers to conversational AI and voice-activated computing.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-situated-cognition",
      "term": "Situated Cognition",
      "definition": "A theory in cognitive science and AI that emphasizes that cognition is inseparable from the context in which it occurs. Developed by researchers including Lucy Suchman and Rodney Brooks in the late 1980s it challenged the classical symbolic AI paradigm.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-situation-calculus",
      "term": "Situation Calculus",
      "definition": "A logical formalism for representing and reasoning about dynamically changing worlds proposed by John McCarthy in 1963. Situation calculus uses first-order logic to describe actions their preconditions and effects forming a foundation for AI planning and reasoning.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-situational-awareness-in-ai",
      "term": "Situational Awareness in AI",
      "definition": "The ability of an AI system to understand its own context capabilities and potential impact on its environment. Debated as both a safety desideratum and a potential risk for advanced AI systems.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-skeleton-of-thought",
      "term": "Skeleton-of-Thought",
      "definition": "A prompting strategy that first asks the model to generate a skeleton outline of the answer, then expands each point in parallel, reducing end-to-end latency by enabling concurrent generation of independent answer segments.",
      "tags": [
        "Prompt Engineering",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-skill-discovery",
      "term": "Skill Discovery",
      "definition": "Unsupervised methods that learn reusable behavioral primitives or skills without task-specific rewards, typically by maximizing mutual information between skills and states visited. Discovered skills can accelerate downstream task learning.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-skingpt-4",
      "term": "SkinGPT-4",
      "definition": "A multimodal large language model specialized in dermatology that analyzes skin lesion images and provides diagnostic explanations.",
      "tags": [
        "Models",
        "Technical",
        "Medical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-skip-connection",
      "term": "Skip Connection",
      "definition": "A shortcut path that bypasses one or more layers by adding or concatenating the input of a block directly to its output, enabling gradient flow through deep networks and facilitating residual learning.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-skip-connections",
      "term": "Skip Connections",
      "definition": "Direct connections between non-adjacent layers in a neural network that allow gradients and information to bypass intermediate layers. Introduced in ResNet (He et al. 2015) skip connections enabled training of very deep networks and became standard in modern architectures.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-skip-list-algorithm",
      "term": "Skip List Algorithm",
      "definition": "A probabilistic data structure that uses multiple levels of linked lists to achieve O(log n) expected time for search and insertion and deletion. Provides a simpler alternative to balanced binary search trees.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-skip-gram",
      "term": "Skip-gram",
      "definition": "A Word2Vec training objective that predicts surrounding context words given a center word, learning word representations that capture semantic similarity from distributional patterns.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-skywork",
      "term": "Skywork",
      "definition": "A family of large language models from Kunlun Inc. trained on a curated 3.2 trillion token corpus with strong Chinese language capabilities.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sliding-window-attention",
      "term": "Sliding Window Attention",
      "definition": "An attention pattern where each token attends only to a fixed-size local window of neighboring tokens, enabling efficient processing of long sequences by limiting the attention span.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-slimorca",
      "term": "SlimOrca",
      "definition": "A curated subset of the OpenOrca dataset with improved quality through GPT-4 filtering and decontamination. Provides cleaner instruction-following data for fine-tuning.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-slimpajama",
      "term": "SlimPajama",
      "definition": "A cleaned and deduplicated version of RedPajama containing 627 billion tokens. Created by Cerebras to improve data quality through global deduplication across all subsets.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-slot-filling",
      "term": "Slot Filling",
      "definition": "The task of extracting specific pieces of information (slot values) from user utterances in a task-oriented dialogue system, such as extracting dates, locations, or names to fill predefined slots.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-slow-ai-movement",
      "term": "Slow AI Movement",
      "definition": "An advocacy movement promoting thoughtful deliberate approaches to AI development that prioritize safety quality and social benefit over speed and competitive advantage.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-slurm-workload-manager",
      "term": "Slurm Workload Manager",
      "definition": "Open-source cluster management and job scheduling system widely used in HPC and AI training clusters. Allocates GPU resources and manages training job queues across cluster nodes.",
      "tags": [
        "Infrastructure",
        "Scheduling",
        "Open Source"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-smac",
      "term": "SMAC",
      "definition": "StarCraft Multi-Agent Challenge a benchmark for cooperative multi-agent reinforcement learning based on StarCraft II micromanagement scenarios. Tests coordination among multiple learning agents.",
      "tags": [
        "Benchmark",
        "Reinforcement Learning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-smart-cooling-system",
      "term": "Smart Cooling System",
      "definition": "AI-controlled data center cooling system that uses machine learning to optimize cooling efficiency in real time. Google DeepMind reduced data center cooling energy by 40 percent using AI.",
      "tags": [
        "Data Center",
        "Cooling",
        "AI-Optimized"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-smart-sensor",
      "term": "Smart Sensor",
      "definition": "Sensor device with integrated processing capability for local data analysis and AI inference. Enables intelligent edge processing without transmitting raw data to remote servers.",
      "tags": [
        "Edge",
        "IoT",
        "Sensor"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-smartnic",
      "term": "SmartNIC",
      "definition": "Network interface card with programmable processors that offload network processing from the host CPU. Used in AI data centers to accelerate communication and reduce CPU overhead.",
      "tags": [
        "Networking",
        "Hardware"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-smollm",
      "term": "SmolLM",
      "definition": "A family of very small language models from Hugging Face available in 135M and 360M and 1.7B sizes trained on high-quality curated web data.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-smoothquant",
      "term": "SmoothQuant",
      "definition": "A quantization technique that migrates the quantization difficulty from activations to weights by applying per-channel scaling factors, enabling efficient INT8 quantization of both weights and activations for LLMs. SmoothQuant enables W8A8 quantization with minimal accuracy loss.",
      "tags": [
        "Model Optimization",
        "Inference Infrastructure"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-smote",
      "term": "SMOTE",
      "definition": "Synthetic Minority Over-sampling Technique, an oversampling method that creates synthetic examples of the minority class by interpolating between existing minority samples and their k-nearest neighbors in feature space.",
      "tags": [
        "Machine Learning",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-snapshot-ensemble",
      "term": "Snapshot Ensemble",
      "definition": "An ensemble technique that collects multiple models from a single training run by saving checkpoints at different local minima reached through cyclic learning rate schedules. Creates diverse ensembles with no additional training cost.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sneps",
      "term": "SNePS",
      "definition": "The Semantic Network Processing System developed by Stuart Shapiro at the University of Buffalo beginning in 1978. SNePS provided a knowledge representation and reasoning system based on propositional semantic networks supporting natural language understanding and reasoning.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-snips",
      "term": "SNIPS",
      "definition": "A dataset for natural language understanding in voice assistants containing 14484 utterances across 7 intent categories with slot annotations. Used for intent classification benchmarking.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-snli",
      "term": "SNLI",
      "definition": "The Stanford Natural Language Inference corpus containing 570000 human-written sentence pairs labeled for entailment contradiction and neutrality. A foundational benchmark for natural language inference.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-snowflake-arctic",
      "term": "Snowflake Arctic",
      "definition": "A large-scale MoE model from Snowflake with 480B total parameters designed for enterprise AI workloads with a focus on SQL and coding tasks.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Products"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-soar",
      "term": "SOAR",
      "definition": "A cognitive architecture developed by John Laird Allen Newell and Paul Rosenbloom at Carnegie Mellon in the 1980s. SOAR models general intelligence through a unified theory of cognition combining problem solving learning and memory in a single framework.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-sobel-operator",
      "term": "Sobel Operator",
      "definition": "An edge detection operator that computes the gradient of image intensity at each pixel using two 3x3 convolution kernels. Approximates the horizontal and vertical derivatives to highlight regions of rapid intensity change.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-social-chemistry-101",
      "term": "Social Chemistry 101",
      "definition": "A dataset of 292000 rules-of-thumb about social and moral norms covering 104000 everyday situations. Provides fine-grained annotations of social expectations and judgments.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Safety"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-social-impact-assessment-for-ai",
      "term": "Social Impact Assessment for AI",
      "definition": "A systematic evaluation of how an AI system may affect communities social structures and social wellbeing. Broader than individual-focused assessments and considers collective and systemic effects.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-social-license-for-ai",
      "term": "Social License for AI",
      "definition": "The ongoing acceptance and approval granted by society to AI developers and deployers. Depends on demonstrated safety benefit and trustworthiness and can be withdrawn if public trust erodes.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-social-scoring-systems",
      "term": "Social Scoring Systems",
      "definition": "AI-driven systems that assign scores to individuals based on their behavior, social connections, or characteristics, used to determine access to services. Banned as unacceptable risk under the EU AI Act.",
      "tags": [
        "AI Ethics",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-society-of-mind",
      "term": "Society of Mind",
      "definition": "A theory of natural and artificial intelligence proposed by Marvin Minsky in his 1986 book of the same name. The theory proposes that mind is not a single entity but a society of tiny agents each mindless by itself that collectively produce intelligent behavior.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-society-of-mind-book",
      "term": "Society of Mind Book",
      "definition": "The 1986 book by Marvin Minsky proposing that intelligence emerges from the interaction of many simple agents or processes. The Society of Mind theory influenced thinking about emergent intelligence and multi-agent systems in AI research.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-sociotechnical-safety",
      "term": "Sociotechnical Safety",
      "definition": "An approach to AI safety that considers the entire system of people processes and technology rather than just the technical components. Recognizes that safety emerges from the interaction of human and technical elements.",
      "tags": [
        "Safety",
        "Fundamentals"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-sociotechnical-systems-approach",
      "term": "Sociotechnical Systems Approach",
      "definition": "An analytical framework that views AI systems as inseparable from their social context, recognizing that technical and social factors jointly determine system outcomes and that both must be addressed for responsible deployment.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-socratic-prompting",
      "term": "Socratic Prompting",
      "definition": "A prompting technique that guides the model through a series of probing questions rather than direct instructions, encouraging step-by-step reasoning and self-discovery of answers through structured dialogue and critical examination.",
      "tags": [
        "Prompt Engineering",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-soda",
      "term": "SODA",
      "definition": "Social Dialogue Dataset a large-scale dialogue dataset with social commonsense context. Contains 1.5 million conversations grounded in social scenarios for training socially aware chatbots.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Dialogue"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sac",
      "term": "Soft Actor-Critic (SAC)",
      "definition": "An off-policy actor-critic algorithm that maximizes both expected return and policy entropy, encouraging exploration while maintaining stable learning. SAC automatically tunes the temperature parameter balancing reward and entropy.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-soft-attention",
      "term": "Soft Attention",
      "definition": "An attention mechanism that computes a weighted average over all positions using continuous attention weights, making it fully differentiable and trainable with standard backpropagation.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-soft-q-learning",
      "term": "Soft Q-Learning",
      "definition": "A maximum entropy reinforcement learning algorithm that augments the standard Q-learning objective with an entropy bonus. Encourages exploration and produces more robust policies that are better at transferring to new tasks.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-soft-update",
      "term": "Soft Update (Polyak Averaging)",
      "definition": "A method for updating target network parameters as an exponential moving average of the online network parameters, controlled by a smoothing factor tau. Soft updates provide more stable training than periodic hard copies.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-softmax",
      "term": "Softmax",
      "definition": "A function that converts raw scores into probabilities that sum to 1. Used in attention mechanisms and classification outputs to create interpretable probability distributions.",
      "tags": [
        "Math",
        "Function"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-softmax-function",
      "term": "Softmax Function",
      "definition": "A function that normalizes a vector of real numbers into a probability distribution by exponentiating each element and dividing by the sum. Used in attention mechanisms classification outputs and Boltzmann distributions. Numerically stabilized by subtracting the max.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-softmax-temperature",
      "term": "Softmax Temperature",
      "definition": "A parameter that controls the sharpness of the softmax probability distribution. Temperature values below 1 sharpen the distribution making it more peaked while values above 1 flatten it making it more uniform. Used in knowledge distillation and sampling.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-softplus",
      "term": "Softplus",
      "definition": "A smooth approximation of ReLU defined as f(x) = log(1 + exp(x)). Always positive and differentiable everywhere. Used in various contexts including variational autoencoders where positive outputs are required.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-softsign",
      "term": "Softsign",
      "definition": "An activation function defined as f(x) = x / (1 + |x|) that provides similar output range to tanh but with polynomial decay instead of exponential. Converges more slowly near its asymptotes and can be more resistant to saturation.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-solar",
      "term": "SOLAR",
      "definition": "A 10.7B parameter language model from Upstage that uses Depth Up-Scaling (DUS) to merge smaller pre-trained models into a larger architecture.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-solar-107b-instruct",
      "term": "SOLAR 10.7B Instruct",
      "definition": "An instruction-tuned version of the SOLAR model optimized for helpfulness and safety in conversational and task-completion scenarios.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-solomonoff-induction",
      "term": "Solomonoff Induction",
      "definition": "A mathematical theory of universal prediction developed by Ray Solomonoff in 1964. Based on algorithmic probability it provides an idealized framework for inductive inference and is considered a theoretical foundation for artificial general intelligence.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-something-something-v2",
      "term": "Something-Something V2",
      "definition": "A video dataset of 220000 clips showing humans performing 174 predefined actions with everyday objects. Focuses on temporal reasoning about object interactions.",
      "tags": [
        "Benchmark",
        "Video"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sora",
      "term": "Sora",
      "definition": "A text-to-video generation model by OpenAI that produces realistic videos up to a minute long from text prompts. Uses a diffusion transformer architecture operating on spacetime patches. Demonstrates understanding of physical world dynamics.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-soundstream",
      "term": "SoundStream",
      "definition": "A neural audio codec from Google that uses residual vector quantization to compress speech and music and environmental sounds into compact representations.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-space-filling-curve-algorithm",
      "term": "Space-Filling Curve Algorithm",
      "definition": "A continuous curve that passes through every point in a multi-dimensional space reducing multi-dimensional data to a one-dimensional ordering. Hilbert and Z-order curves preserve locality enabling efficient spatial indexing.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparc",
      "term": "SParC",
      "definition": "Cross-Domain Semantic Parsing in Context a context-dependent text-to-SQL benchmark with multi-turn interactions. Tests the ability to handle context-dependent SQL generation.",
      "tags": [
        "Benchmark",
        "NLP",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparc-architecture",
      "term": "SPARC Architecture",
      "definition": "Scalable Processor Architecture RISC design by Sun Microsystems used in Unix workstations and servers. Powered many early computational science and AI research systems.",
      "tags": [
        "Historical",
        "Architecture",
        "RISC"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-approximate-inverse",
      "term": "Sparse Approximate Inverse",
      "definition": "A preconditioning technique that directly computes an approximate inverse of a sparse matrix. Maintains sparsity by constraining the nonzero pattern and is inherently parallelizable unlike incomplete factorization methods.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-attention",
      "term": "Sparse Attention",
      "definition": "An attention mechanism that restricts each token to attend to only a subset of other tokens using predefined or learned sparsity patterns, reducing the quadratic computational cost of full attention.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-autoencoder",
      "term": "Sparse Autoencoder",
      "definition": "An autoencoder that enforces sparsity constraints on the hidden layer activations, encouraging the network to learn a compact, distributed representation where only a few neurons activate for each input.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-autoencoder-model",
      "term": "Sparse Autoencoder Model",
      "definition": "An autoencoder with a sparsity constraint encouraging most hidden units to be inactive for any given input. Learns overcomplete but sparse representations. Used in feature extraction and mechanistic interpretability of neural networks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-direct-solver",
      "term": "Sparse Direct Solver",
      "definition": "A class of algorithms that solve sparse linear systems by computing exact factorizations while exploiting the sparsity pattern. Includes supernodal and multifrontal approaches that minimize fill-in during factorization.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-matrix-algorithm",
      "term": "Sparse Matrix Algorithm",
      "definition": "A collection of techniques for efficiently storing and manipulating matrices with mostly zero entries. Formats include compressed sparse row and compressed sparse column and enable operations proportional to non-zero count.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-models",
      "term": "Sparse Models",
      "definition": "Neural network models where only a fraction of parameters are activated for any given input. Sparse architectures like Mixture of Experts enable much larger models with manageable computational costs. The Switch Transformer (2021) demonstrated trillion-parameter sparse models.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-pca-algorithm",
      "term": "Sparse PCA Algorithm",
      "definition": "A variant of PCA that constrains the principal components to have few non-zero loadings. Produces more interpretable components at the cost of explaining slightly less variance than standard PCA.",
      "tags": [
        "Algorithms",
        "Technical",
        "Dimensionality Reduction"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-retrieval",
      "term": "Sparse Retrieval",
      "definition": "An information retrieval paradigm that represents queries and documents as high-dimensional sparse vectors where most values are zero, with non-zero entries corresponding to term weights, enabling efficient exact matching through inverted indexes.",
      "tags": [
        "Retrieval",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-reward",
      "term": "Sparse Reward Problem",
      "definition": "An RL setting where the agent receives non-zero reward signals only rarely, making credit assignment extremely difficult. Sparse rewards are common in real-world tasks and motivate techniques like reward shaping and intrinsic motivation.",
      "tags": [
        "Reinforcement Learning",
        "Reward Design"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-table-algorithm",
      "term": "Sparse Table Algorithm",
      "definition": "A data structure that answers static range minimum (or maximum) queries in O(1) time after O(n log n) preprocessing. Stores precomputed answers for all power-of-two ranges and combines two overlapping ranges.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-transformer",
      "term": "Sparse Transformer",
      "definition": "A transformer variant that uses sparse factorizations of the attention matrix to reduce computational complexity. Demonstrates that carefully designed sparse patterns can match dense attention on language modeling and image generation.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparse-vector-technique",
      "term": "Sparse Vector Technique",
      "definition": "A differential privacy mechanism that answers a sequence of numerical queries while only paying a privacy cost for queries whose answers exceed a threshold. Enables many queries with bounded privacy loss.",
      "tags": [
        "Algorithms",
        "Technical",
        "Privacy"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparseformer",
      "term": "SparseFormer",
      "definition": "A vision Transformer that uses sparse attention patterns to reduce computational cost while maintaining strong accuracy on image classification and detection tasks.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sparsetsf",
      "term": "SparseTSF",
      "definition": "A sparse time series forecasting method that uses cross-period sparse forecasting to reduce computational cost while maintaining prediction accuracy.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-spatial-attention",
      "term": "Spatial Attention",
      "definition": "An attention mechanism that learns to weight different spatial locations in feature maps, focusing computational resources on the most informative regions of the input.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-spatial-computing-architecture",
      "term": "Spatial Computing Architecture",
      "definition": "Hardware architecture that maps computations spatially across an array of processing elements. Each element performs a fixed operation creating a pipeline through the computation graph.",
      "tags": [
        "Architecture",
        "Emerging",
        "Design"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-spatial-reasoning-in-ai",
      "term": "Spatial Reasoning in AI",
      "definition": "The area of AI concerned with representing and reasoning about spatial relationships between objects and regions. Applications include robot navigation geographic information systems and architectural design. Draws on qualitative spatial calculus and computational geometry.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-spatialtracker",
      "term": "SpatialTracker",
      "definition": "A 3D point tracking model that tracks points in 3D space through video by leveraging monocular depth estimation and camera motion.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-spearman-rank-correlation",
      "term": "Spearman Rank Correlation",
      "definition": "A non-parametric measure of the monotonic relationship between two variables, computed as the Pearson correlation of the ranked values. It does not assume linearity or normal distribution.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-special-tokens",
      "term": "Special Tokens",
      "definition": "Reserved tokens in a vocabulary that serve structural purposes such as marking sequence boundaries, separating segments, padding, or indicating masked positions, rather than representing text content.",
      "tags": [
        "NLP",
        "Tokenization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-specification-gaming",
      "term": "Specification Gaming",
      "definition": "The behavior of an AI system that satisfies the literal specification of an objective without achieving the intended outcome. It is closely related to reward hacking and arises from misaligned objective functions.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-specification-problem",
      "term": "Specification Problem",
      "definition": "The challenge of precisely defining what we want an AI system to do in a way that captures our true intentions. Incomplete or incorrect specifications can lead to systems that satisfy the letter but not the spirit of their design.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-specificity",
      "term": "Specificity",
      "definition": "The proportion of actual negative cases that are correctly identified as negative by a classifier, also known as the true negative rate. It complements sensitivity (recall) in binary classification evaluation.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-spectral-clustering",
      "term": "Spectral Clustering",
      "definition": "A clustering technique that uses the eigenvalues and eigenvectors of a similarity matrix derived from the data to perform dimensionality reduction before clustering in the reduced space, capable of identifying non-convex clusters.",
      "tags": [
        "Machine Learning",
        "Clustering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-spectral-clustering-algorithm",
      "term": "Spectral Clustering Algorithm",
      "definition": "A clustering method that uses eigenvalues of the graph Laplacian to reduce dimensionality before applying k-means. Effective for non-convex cluster shapes and based on the theory of graph partitioning.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-spectral-embedding-algorithm",
      "term": "Spectral Embedding Algorithm",
      "definition": "A dimensionality reduction technique that embeds data points using the leading eigenvectors of the normalized graph Laplacian. Produces embeddings where connected graph components are mapped to nearby points.",
      "tags": [
        "Algorithms",
        "Technical",
        "Dimensionality Reduction"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-spectral-method",
      "term": "Spectral Method",
      "definition": "A numerical method for solving differential equations that represents the solution as a sum of basis functions such as Fourier modes or Chebyshev polynomials. Achieves exponential convergence for smooth solutions.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-spectral-normalization",
      "term": "Spectral Normalization",
      "definition": "A weight normalization technique that constrains the spectral norm of weight matrices to stabilize training. Widely used in GANs to enforce Lipschitz continuity in the discriminator. Controls the largest singular value of each layer.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-spectrogram",
      "term": "Spectrogram",
      "definition": "A visual representation of the spectrum of frequencies in a signal as they vary over time. Commonly displayed as a heatmap with time on the x-axis frequency on the y-axis and intensity as color. Fundamental in audio and speech processing.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-speculative-decoding",
      "term": "Speculative Decoding",
      "definition": "A technique to speed up LLM inference by using a smaller model to draft tokens that the larger model verifies in parallel. Maintains output quality while reducing latency.",
      "tags": [
        "Optimization",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-speculative-execution-llm",
      "term": "Speculative Execution",
      "definition": "A broader inference optimization paradigm where cheaper computations predict likely outcomes that are verified by full-cost operations, encompassing speculative decoding and related techniques for LLM acceleration.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-speculative-sampling",
      "term": "Speculative Sampling",
      "definition": "An inference acceleration technique where a fast draft model proposes multiple tokens that are then verified in parallel by the target model, maintaining the exact output distribution while increasing throughput.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-speech-recognition-history",
      "term": "Speech Recognition History",
      "definition": "The development of automatic speech recognition from Bell Labs' Audrey system in 1952 through Hidden Markov Models in the 1980s to deep learning approaches that achieved near-human accuracy in the 2010s.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-speech-synthesis",
      "term": "Speech Synthesis",
      "definition": "The artificial production of human-like speech from text or other input, using techniques ranging from concatenative synthesis to neural models like Tacotron and VITS.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-speechgpt",
      "term": "SpeechGPT",
      "definition": "A large language model with intrinsic cross-modal conversational abilities that can perceive and generate both speech and text in multi-turn dialogues.",
      "tags": [
        "Models",
        "Technical",
        "Audio",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-speecht5",
      "term": "SpeechT5",
      "definition": "A unified encoder-decoder framework from Microsoft that handles text-to-speech and speech-to-text and speech enhancement through shared representations.",
      "tags": [
        "Models",
        "Technical",
        "Audio",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-spell-correction",
      "term": "Spell Correction",
      "definition": "The automated detection and correction of misspelled words in text using techniques such as edit distance, language models, and context-aware models to suggest corrections.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-spgispeech",
      "term": "SPGISpeech",
      "definition": "A 5000-hour English speech corpus of earnings calls and financial presentations with professional transcriptions. Provides domain-specific speech data for financial ASR applications.",
      "tags": [
        "Training Corpus",
        "Speech"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sphinx",
      "term": "SPHINX",
      "definition": "A versatile multimodal large language model that combines multiple visual encoders and language models for robust image and video understanding.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-spider",
      "term": "Spider",
      "definition": "A complex text-to-SQL benchmark covering 200 databases with 10181 questions and SQL queries. Tests cross-database generalization for natural language to SQL translation.",
      "tags": [
        "Benchmark",
        "NLP",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-spiking-neural-network-hardware",
      "term": "Spiking Neural Network Hardware",
      "definition": "Hardware designed to implement spiking neural networks that communicate through discrete pulses rather than continuous values. Offers potential energy efficiency gains over conventional neural network accelerators.",
      "tags": [
        "Emerging",
        "Neuromorphic",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-spillover-effects-of-ai",
      "term": "Spillover Effects of AI",
      "definition": "Unintended consequences of AI deployment that affect parties or domains beyond the intended scope of the system. Can be positive or negative and are often difficult to predict or measure.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-spin",
      "term": "SPIN",
      "definition": "Self-Play Fine-Tuning is an alignment method where the language model generates training data by distinguishing its own outputs from human-written text in a self-play framework. Progressively improves alignment without requiring additional human preference data.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-spine-leaf-architecture",
      "term": "Spine-Leaf Architecture",
      "definition": "Two-tier data center network topology where every leaf switch connects to every spine switch providing predictable low-latency paths. Standard in modern AI data center deployments.",
      "tags": [
        "Networking",
        "Topology",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-spinnaker",
      "term": "SpiNNaker",
      "definition": "Spiking Neural Network Architecture computing platform developed at the University of Manchester. Uses a million ARM cores to simulate billions of neurons in biological real time.",
      "tags": [
        "Neuromorphic",
        "Research",
        "ARM"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-spirit-lm",
      "term": "Spirit-LM",
      "definition": "A multimodal language model from Meta AI that interleaves speech and text tokens for expressive speech-text generation with emotional and prosodic control.",
      "tags": [
        "Models",
        "Technical",
        "Audio",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-splade",
      "term": "SPLADE",
      "definition": "SParse Lexical AnD Expansion model, a learned sparse retrieval method that predicts importance weights for vocabulary terms including expansion terms not present in the original text, combining the efficiency of sparse indexes with neural relevance estimation.",
      "tags": [
        "Retrieval",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-splay-tree-algorithm",
      "term": "Splay Tree Algorithm",
      "definition": "A self-adjusting binary search tree that moves recently accessed elements to the root through rotations called splaying. Achieves O(log n) amortized time and provides excellent performance for non-uniform access patterns.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-spline-regression",
      "term": "Spline Regression",
      "definition": "A regression technique using piecewise polynomial functions (splines) joined at knot points to fit flexible, smooth curves. Natural and B-splines are common variants that balance flexibility with smoothness.",
      "tags": [
        "Statistics",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-spot-instances",
      "term": "Spot Instances for AI",
      "definition": "Discounted cloud computing instances that use spare capacity at 60-90% less than on-demand pricing but can be interrupted with short notice. Spot instances are widely used for fault-tolerant AI training with checkpointing to resume after interruptions.",
      "tags": [
        "Distributed Computing",
        "Inference Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-sqlcoder",
      "term": "SQLCoder",
      "definition": "A language model fine-tuned specifically for text-to-SQL generation that converts natural language questions into SQL queries for database interaction.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-squad",
      "term": "SQuAD",
      "definition": "Stanford Question Answering Dataset, a reading comprehension benchmark where models extract answer spans from Wikipedia passages, with SQuAD 2.0 additionally including unanswerable questions that test a model's ability to abstain when evidence is insufficient.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-squad-20",
      "term": "SQuAD 2.0",
      "definition": "An extension of SQuAD that includes 50000 unanswerable questions combined with the original answerable ones. Tests whether models can determine when a passage does not contain the answer.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-squad-dataset",
      "term": "SQuAD Dataset",
      "definition": "The Stanford Question Answering Dataset created in 2016 consisting of questions posed about Wikipedia articles where the answer is a segment of text from the article. SQuAD became a standard benchmark for reading comprehension and question answering systems.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-squality",
      "term": "SQuALITY",
      "definition": "A long-document summarization dataset with question-focused summaries written by expert annotators. Tests the ability to summarize long texts in response to specific questions.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-squeeze-and-excitation",
      "term": "Squeeze-and-Excitation",
      "definition": "A channel attention mechanism that adaptively recalibrates channel-wise feature responses. Uses global average pooling followed by two fully connected layers to learn channel importance weights. Proposed by Hu et al. in 2018.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-squeeze-and-excitation-network",
      "term": "Squeeze-and-Excitation Network",
      "definition": "A CNN enhancement that adaptively recalibrates channel-wise feature responses by using global average pooling followed by a small network to learn channel interdependencies and attention weights.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-squeeze-excitation-block",
      "term": "Squeeze-Excitation Block",
      "definition": "A channel attention module that squeezes spatial information via global pooling and excites channel-wise features through a learned gating mechanism to recalibrate feature map importances.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-squeezenet",
      "term": "SqueezeNet",
      "definition": "A compact CNN architecture that achieves AlexNet-level accuracy with 50x fewer parameters using fire modules consisting of squeeze and expand layers. Designed for deployment on devices with limited memory.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sram",
      "term": "SRAM",
      "definition": "Static Random Access Memory that retains data without refresh cycles providing extremely fast access times. Used in CPU and GPU caches for storing frequently accessed data during computation.",
      "tags": [
        "Memory",
        "Fundamentals"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-sri-international",
      "term": "SRI International",
      "definition": "An American nonprofit research institute originally Stanford Research Institute founded in 1946. Developed Shakey the Robot in the late 1960s and created the technology behind Siri. Contributed foundational work in AI robotics and natural language processing.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ssd",
      "term": "SSD",
      "definition": "Single Shot MultiBox Detector is a one-stage object detection model that predicts bounding boxes and class scores at multiple scales from a single forward pass. Balances speed and accuracy for real-time applications.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ssd-for-ai-workloads",
      "term": "SSD for AI Workloads",
      "definition": "Solid-state drives optimized for the high-throughput random read patterns of AI data loading. NVMe SSDs significantly reduce data pipeline bottlenecks during model training.",
      "tags": [
        "Storage",
        "Hardware"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ssd-object-detection",
      "term": "SSD Object Detection",
      "definition": "Single Shot MultiBox Detector, a real-time object detection architecture that predicts bounding boxes and class probabilities from multiple feature maps at different scales in a single forward pass.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ssim",
      "term": "SSIM",
      "definition": "Structural Similarity Index Measure compares images based on luminance contrast and structure. Designed to be more perceptually relevant than pixel-wise metrics like MSE. Ranges from -1 to 1 with 1 indicating identical images.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-sst-2",
      "term": "SST-2",
      "definition": "The Stanford Sentiment Treebank binary classification task containing movie review sentences labeled as positive or negative. Part of the GLUE benchmark for sentiment analysis evaluation.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sst-5",
      "term": "SST-5",
      "definition": "The Stanford Sentiment Treebank with five-class sentiment labels ranging from very negative to very positive. Provides fine-grained sentiment annotations for 11855 movie review sentences.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-stable-audio",
      "term": "Stable Audio",
      "definition": "A latent diffusion model from Stability AI for generating music and audio from text prompts using a diffusion-based approach on learned audio representations.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stable-audio-2",
      "term": "Stable Audio 2",
      "definition": "An improved audio generation model from Stability AI that can generate longer and higher-quality music tracks with better text-to-audio alignment.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stable-cascade",
      "term": "Stable Cascade",
      "definition": "A text-to-image generation model from Stability AI based on the Wuerstchen architecture that uses a three-stage pipeline for high-quality efficient generation.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stable-code",
      "term": "Stable Code",
      "definition": "A family of code-focused language models from Stability AI designed for code generation and completion across multiple programming languages.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stable-diffusion",
      "term": "Stable Diffusion",
      "definition": "An open-source text-to-image model from Stability AI. Its open nature enabled a large ecosystem of fine-tuned models, extensions, and applications.",
      "tags": [
        "Model",
        "Image Generation"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stable-diffusion-xl",
      "term": "Stable Diffusion XL",
      "definition": "An enhanced version of Stable Diffusion with a larger UNet backbone and a two-stage architecture using a base model and refiner. Produces higher resolution and more detailed images than previous versions.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stable-video-diffusion",
      "term": "Stable Video Diffusion",
      "definition": "A video generation model by Stability AI based on latent diffusion adapted for temporal generation. Generates short video clips from image or text inputs. Built on the Stable Diffusion architecture with temporal attention layers.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stable-zero123",
      "term": "Stable Zero123",
      "definition": "A 3D-aware image generation model from Stability AI that generates novel views of objects from single images using a fine-tuned diffusion model.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stablelm",
      "term": "StableLM",
      "definition": "A family of language models by Stability AI designed for both research and commercial use. Features models at various sizes trained on diverse multilingual data with a focus on open access and transparency.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stablelm-2",
      "term": "StableLM 2",
      "definition": "A second-generation language model from Stability AI available in 1.6B and 12B parameter sizes trained on a diverse multilingual data mixture.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stacking",
      "term": "Stacking",
      "definition": "An ensemble learning technique that trains a meta-learner to combine the predictions of multiple base models, using cross-validated predictions from the base models as input features for the meta-learner.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stackoverflow-dataset",
      "term": "StackOverflow Dataset",
      "definition": "Curated collections of questions answers and code from Stack Overflow used for training programming-related language models and code QA systems.",
      "tags": [
        "Training Corpus",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-stakeholder-analysis-in-ai",
      "term": "Stakeholder Analysis in AI",
      "definition": "The process of identifying all individuals, groups, and communities affected by an AI system and systematically considering their interests, power dynamics, and potential harms in the system's design and deployment.",
      "tags": [
        "Governance",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-stance-detection",
      "term": "Stance Detection",
      "definition": "The task of determining an author's position (favor, against, or neutral) toward a specific target or claim from their text, related to but distinct from sentiment analysis.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-standard-deviation",
      "term": "Standard Deviation",
      "definition": "The square root of the variance, measuring the average spread of data points from the mean in the original units of measurement. It quantifies the typical distance of observations from the central value.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-standardization",
      "term": "Standardization",
      "definition": "A feature scaling technique that transforms data to have zero mean and unit variance by subtracting the mean and dividing by the standard deviation. It is particularly important for algorithms sensitive to feature magnitudes.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-stanford-ai-laboratory",
      "term": "Stanford AI Laboratory",
      "definition": "A research laboratory founded by John McCarthy at Stanford University in 1962 that became one of the leading centers for AI research, making contributions to robotics, natural language processing, and knowledge representation.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-stanford-cars",
      "term": "Stanford Cars",
      "definition": "A dataset of 16185 images across 196 car classes defined by make model and year. Used for fine-grained visual classification where differences between classes are subtle.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-stanford-cart",
      "term": "Stanford Cart",
      "definition": "An early autonomous vehicle project at Stanford University begun in the 1960s. The Cart used computer vision to navigate obstacle courses demonstrating early capabilities in machine perception and autonomous navigation that influenced later robotics research.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-stanford-dogs",
      "term": "Stanford Dogs",
      "definition": "A dataset of 20580 images across 120 dog breeds built from ImageNet. Used for fine-grained image classification research where visual differences between classes are minimal.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-stanford-hai",
      "term": "Stanford HAI",
      "definition": "The Stanford Institute for Human-Centered Artificial Intelligence founded in 2019 by Fei-Fei Li and John Etchemendy. HAI conducts interdisciplinary AI research publishes the annual AI Index Report and advises policymakers on AI governance and ethics.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-star-attention",
      "term": "Star Attention",
      "definition": "An efficient attention pattern that uses a set of anchor tokens visible to all positions reducing communication in distributed settings. Enables near-linear scaling of attention for very long sequences across multiple devices.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-starcoder",
      "term": "StarCoder",
      "definition": "A family of code generation models trained by the BigCode project on permissively licensed source code. Supports over 80 programming languages. Trained with responsible AI practices including PII redaction.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-starcoder-training-data",
      "term": "StarCoder Training Data",
      "definition": "The pretraining data for the StarCoder code generation model containing over 783GB of code from 86 programming languages sourced from permissively licensed GitHub repositories.",
      "tags": [
        "Training Corpus",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-starcoder2",
      "term": "StarCoder2",
      "definition": "A second-generation code language model from the BigCode project trained on a curated dataset from The Stack v2 in multiple programming languages.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-starcoder2-instruct",
      "term": "Starcoder2-Instruct",
      "definition": "An instruction-tuned version of StarCoder2 that follows coding instructions for tasks like code explanation and generation and debugging and review.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-starling-7b",
      "term": "Starling-7B",
      "definition": "A language model trained with Reinforcement Learning from AI Feedback (RLAIF) using GPT-4 labeled ranking data for improved helpfulness and safety.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-state",
      "term": "State",
      "definition": "A representation of the current situation of an agent within its environment at a given time step. States encode all relevant information needed for decision-making under the Markov property.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-state-abstraction",
      "term": "State Abstraction",
      "definition": "The process of mapping a detailed state space to a simplified representation that preserves relevant decision-making information. State abstraction reduces the complexity of RL problems and can improve generalization.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-state-space-model",
      "term": "State Space Model",
      "definition": "A sequence model based on continuous-time linear dynamical systems that maps input sequences to output sequences through a latent state, offering efficient parallel training and linear-time inference.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-state-space-models",
      "term": "State Space Models",
      "definition": "A class of sequence models based on state space representations from control theory. Modern structured state space models (S4 by Gu et al. 2021) provide alternatives to Transformers for sequence modeling with advantages in handling very long sequences efficiently.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-static-quantization",
      "term": "Static Quantization",
      "definition": "A quantization approach where scaling factors are fixed at calibration time and used consistently during inference. Static quantization is faster than dynamic quantization at inference time but requires representative calibration data.",
      "tags": [
        "Model Optimization",
        "Inference Infrastructure"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-static-word-embedding",
      "term": "Static Word Embedding",
      "definition": "A fixed vector representation for each word in the vocabulary that remains the same regardless of context, as produced by models like Word2Vec, GloVe, and FastText.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-stationarity",
      "term": "Stationarity",
      "definition": "A property of a time series where statistical properties such as mean, variance, and autocorrelation structure remain constant over time. Many time series models require stationarity as a prerequisite.",
      "tags": [
        "Data Science",
        "Statistics"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-statistical-machine-translation",
      "term": "Statistical Machine Translation",
      "definition": "A machine translation approach that uses statistical models learned from bilingual text corpora to find the most probable translation, employing language models and translation models.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-statistical-power",
      "term": "Statistical Power",
      "definition": "The probability that a statistical test correctly rejects the null hypothesis when the alternative hypothesis is true (1 minus the probability of a Type II error). Higher power reduces the chance of missing a real effect.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-steering-vector",
      "term": "Steering Vector",
      "definition": "A direction in a model's activation space that, when added to hidden states during inference, modifies the model's behavior along a specific attribute such as truthfulness, formality, or toxicity.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-steerlm",
      "term": "SteerLM",
      "definition": "A training method from NVIDIA that uses attribute-conditioned generation to align language models by having users steer outputs along multiple quality dimensions.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-steffensens-method",
      "term": "Steffensen's Method",
      "definition": "An iterative root-finding method that achieves quadratic convergence without requiring derivative information. Uses Aitken's delta-squared process to accelerate the convergence of fixed-point iteration.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-steganographic-communication",
      "term": "Steganographic Communication",
      "definition": "Hidden communication channels that AI systems might use to pass information undetected by human overseers. A theoretical concern for AI safety particularly in multi-agent settings.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-steiner-tree-problem",
      "term": "Steiner Tree Problem",
      "definition": "An optimization problem that finds the minimum-weight tree spanning a specified subset of vertices in a graph. NP-hard in general but solvable in polynomial time for fixed numbers of required terminals.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-stemming",
      "term": "Stemming",
      "definition": "A heuristic process that reduces words to their root form by stripping suffixes using rule-based algorithms like Porter or Snowball stemmer, without considering the word's part of speech or context.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-step-back-prompting",
      "term": "Step-Back Prompting",
      "definition": "A method that instructs the model to first consider a higher-level abstraction or general principle related to the question before attempting the specific answer, improving reasoning by grounding responses in broader conceptual understanding.",
      "tags": [
        "Prompt Engineering",
        "Abstraction"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-stephen-cook",
      "term": "Stephen Cook",
      "definition": "American-Canadian computer scientist who proved Cook's theorem in 1971 establishing the theory of NP-completeness. Understanding computational complexity is fundamental to AI as many AI problems (planning constraint satisfaction) are NP-hard.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-stepwise-regression",
      "term": "Stepwise Regression",
      "definition": "A method of fitting regression models by automatically adding or removing predictor variables based on statistical criteria (such as p-value or AIC) at each step until no further improvement is achieved.",
      "tags": [
        "Statistics",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stereo-matching-algorithm",
      "term": "Stereo Matching Algorithm",
      "definition": "An algorithm that finds corresponding points between two images taken from different viewpoints to estimate depth. Block matching and semi-global matching are common approaches for dense disparity estimation.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-stereo-vision",
      "term": "Stereo Vision",
      "definition": "A technique that estimates 3D depth by finding corresponding points between two images captured from slightly different viewpoints, using disparity maps to triangulate the distance of objects.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-stereoset",
      "term": "StereoSet",
      "definition": "A dataset for measuring stereotypical bias in pretrained language models across four domains of bias: gender profession race and religion. Tests both language modeling and stereotype detection.",
      "tags": [
        "Benchmark",
        "NLP",
        "Fairness"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-stereotype-score",
      "term": "Stereotype Score",
      "definition": "An evaluation metric that measures how frequently a model generates or reinforces social stereotypes related to gender, race, religion, or other protected attributes, used to assess and mitigate representational harms.",
      "tags": [
        "Evaluation",
        "Safety"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-steve-1",
      "term": "STEVE-1",
      "definition": "An instruction-following agent for Minecraft that uses a pre-trained video generation model as a behavioral prior for learning diverse gameplay tasks.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stl-10",
      "term": "STL-10",
      "definition": "An image recognition dataset with 10 classes derived from ImageNet designed for developing unsupervised feature learning algorithms. Contains 5000 labeled training images and 100000 unlabeled images.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-stochastic-depth",
      "term": "Stochastic Depth",
      "definition": "A regularization technique that randomly drops entire layers during training by bypassing them with identity skip connections, effectively training an ensemble of networks with different depths.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stochastic-gradient-descent",
      "term": "Stochastic Gradient Descent",
      "definition": "An optimization algorithm that updates model parameters using the gradient computed on a single randomly selected training example at each iteration, rather than the full dataset. It introduces noise that can help escape local minima.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-stochastic-gradient-descent-history",
      "term": "Stochastic Gradient Descent History",
      "definition": "The development of stochastic gradient descent from the work of Herbert Robbins and Sutton Monro (1951) through mini-batch SGD to modern variants like Adam and SGD with momentum. SGD remains the fundamental optimization algorithm for training neural networks.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-stochastic-neighbor-embedding",
      "term": "Stochastic Neighbor Embedding",
      "definition": "The predecessor to t-SNE that converts pairwise distances to Gaussian probabilities and matches them in a lower-dimensional space. Uses KL divergence as the cost function but suffers from a crowding problem.",
      "tags": [
        "Algorithms",
        "Technical",
        "Dimensionality Reduction"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-stochastic-parrots-paper",
      "term": "Stochastic Parrots Paper",
      "definition": "The influential 2021 paper by Bender, Gebru et al. questioning whether large language models truly understand language or merely produce statistically likely outputs, raising concerns about environmental costs and bias.",
      "tags": [
        "History",
        "AI Ethics"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-stoer-wagner-algorithm",
      "term": "Stoer-Wagner Algorithm",
      "definition": "A deterministic algorithm for finding the global minimum cut in an undirected weighted graph. Uses a maximum adjacency ordering technique and runs in O(VE + V^2 log V) time without requiring flow computations.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-stop-button-problem",
      "term": "Stop Button Problem",
      "definition": "The challenge of designing an AI system that will not resist or circumvent attempts to shut it down, particularly if the system has learned that being turned off prevents it from achieving its objectives.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-stop-sequence",
      "term": "Stop Sequence",
      "definition": "Text patterns that signal when AI should stop generating. Useful for controlling output length and format, preventing the model from continuing beyond the intended response.",
      "tags": [
        "Parameter",
        "Generation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-stop-words",
      "term": "Stop Words",
      "definition": "Commonly occurring words like articles, prepositions, and conjunctions that carry little semantic information and are often removed during text preprocessing for tasks like information retrieval.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-storage-class-memory",
      "term": "Storage Class Memory",
      "definition": "Non-volatile memory technology offering performance between DRAM and NAND flash. Intel Optane was the most notable example providing persistent low-latency storage for AI checkpoints.",
      "tags": [
        "Storage",
        "Memory",
        "Emerging"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-stormer",
      "term": "Stormer",
      "definition": "A weather forecasting model that uses a randomized dynamics forecasting approach with Transformers for efficient and accurate medium-range prediction.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-storycloze",
      "term": "StoryCloze",
      "definition": "A commonsense reasoning dataset where models choose the correct ending for a four-sentence story from two candidates. Tests understanding of narrative structure and causal reasoning.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-straight-through-estimator",
      "term": "Straight-Through Estimator",
      "definition": "A gradient estimation technique for non-differentiable operations that passes gradients through the operation unchanged during backpropagation. Used for quantization binarization and other discrete operations in neural networks.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-strassen-algorithm",
      "term": "Strassen Algorithm",
      "definition": "A matrix multiplication algorithm that reduces the number of multiplications needed for two n-by-n matrices from n^3 to approximately n^2.807. Uses a divide-and-conquer approach with seven recursive multiplications instead of eight.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical",
        "History"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-strategyqa",
      "term": "StrategyQA",
      "definition": "A question answering dataset requiring implicit multi-step reasoning where the reasoning strategy is not specified in the question. Tests whether models can decompose complex questions.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-stratified-k-fold",
      "term": "Stratified K-Fold",
      "definition": "A cross-validation variant that ensures each fold preserves approximately the same proportion of samples for each class as the complete dataset, particularly important for imbalanced classification problems.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stratified-sampling",
      "term": "Stratified Sampling",
      "definition": "A sampling method that divides a population into non-overlapping subgroups (strata) and draws samples from each stratum in proportion to its size, ensuring representative coverage of all subgroups.",
      "tags": [
        "Data Science",
        "Statistics"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-stratified-sampling-for-cv",
      "term": "Stratified Sampling for CV",
      "definition": "A cross-validation variant that ensures each fold maintains the same class distribution as the full dataset. Essential for imbalanced classification problems where random splitting could create folds with missing classes.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-streamdiffusion",
      "term": "StreamDiffusion",
      "definition": "A real-time interactive image generation pipeline that uses batched denoising and residual classifier-free guidance for streaming diffusion at interactive speeds.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-streaming",
      "term": "Streaming",
      "definition": "Receiving AI output incrementally as it's generated, rather than waiting for the complete response. Improves perceived latency and enables real-time display of responses.",
      "tags": [
        "API",
        "UX"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-streaming-clustering-algorithm",
      "term": "Streaming Clustering Algorithm",
      "definition": "A class of clustering algorithms designed for data streams that process points sequentially with limited memory. Maintains a summary of the data seen so far and updates clusters incrementally as new points arrive.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-streaming-multiprocessor",
      "term": "Streaming Multiprocessor (SM)",
      "definition": "The fundamental processing unit in NVIDIA GPU architecture, containing a set of CUDA cores, Tensor Cores, shared memory, and register files. The number of SMs determines a GPU's parallel processing capacity for AI workloads.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-streaming-quantile-algorithm",
      "term": "Streaming Quantile Algorithm",
      "definition": "An algorithm that estimates quantiles (such as the median) of a data stream using limited memory. The GK algorithm and t-digest provide bounded-error quantile estimates for massive streaming datasets.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-streampetr",
      "term": "StreamPETR",
      "definition": "A long-sequence modeling framework for 3D object detection in autonomous driving that propagates temporal information through object queries across frames.",
      "tags": [
        "Models",
        "Technical",
        "Autonomous",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stress-testing-for-ai",
      "term": "Stress Testing for AI",
      "definition": "Subjecting AI systems to extreme or unusual conditions to evaluate their behavior under stress. Identifies failure modes and safety boundaries that may not be apparent during normal operation.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-stride",
      "term": "Stride",
      "definition": "The step size by which a convolutional filter or pooling window moves across the input, controlling the spatial dimensions of the output feature map and the degree of overlap between receptive fields.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-stripedhyena",
      "term": "StripedHyena",
      "definition": "A hybrid model from Together AI that alternates Hyena operators with attention layers for improved efficiency on long-context language modeling.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-strips",
      "term": "STRIPS",
      "definition": "The Stanford Research Institute Problem Solver developed by Richard Fikes and Nils Nilsson in 1971. An automated planning system that represents the world as a set of conditions and uses operators with preconditions and effects. Foundational to AI planning research.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-strongly-connected-components",
      "term": "Strongly Connected Components",
      "definition": "Maximal subsets of vertices in a directed graph where every vertex is reachable from every other vertex in the subset. Algorithms by Tarjan and Kosaraju find all such components in linear time.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-structural-ambiguity",
      "term": "Structural Ambiguity",
      "definition": "The phenomenon where a sentence can be parsed in multiple syntactically valid ways, leading to different interpretations, such as 'I saw the man with the telescope.'",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-structural-bias",
      "term": "Structural Bias",
      "definition": "Bias embedded in the organizational institutional and societal structures that shape AI development and deployment. Cannot be fully addressed through technical fixes alone and requires systemic change.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-structural-equation-modeling",
      "term": "Structural Equation Modeling",
      "definition": "A framework for estimating causal relationships among variables using a system of simultaneous equations. Combines factor analysis with path analysis to model both direct and indirect effects.",
      "tags": [
        "Algorithms",
        "Technical",
        "Causal"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-structural-risk-minimization",
      "term": "Structural Risk Minimization",
      "definition": "A principle for model selection that balances empirical risk (training error) with model complexity, choosing the model that minimizes an upper bound on generalization error derived from VC theory.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-structural-sparsity",
      "term": "Structural Sparsity",
      "definition": "A hardware-accelerated pruning pattern where every group of four weights contains exactly two zeros (2:4 sparsity), enabling specialized Tensor Core instructions. Structural sparsity provides 2x speedup with minimal accuracy loss on supported NVIDIA hardware.",
      "tags": [
        "Model Optimization",
        "Hardware"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-structure-from-motion",
      "term": "Structure from Motion",
      "definition": "A technique that reconstructs 3D scene geometry and camera poses from a collection of unordered 2D images by matching features across views and performing bundle adjustment.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-structured-access",
      "term": "Structured Access",
      "definition": "An approach to AI deployment that provides controlled access to powerful AI capabilities through APIs and monitored interfaces rather than open model release, allowing safety measures while enabling beneficial use.",
      "tags": [
        "AI Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-structured-generation",
      "term": "Structured Generation",
      "definition": "Techniques that force LLM outputs to conform to a predefined schema such as JSON, XML, or a formal grammar, using constrained decoding or fine-tuning to guarantee valid structured output.",
      "tags": [
        "Generative AI",
        "Decoding"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-structured-output",
      "term": "Structured Output",
      "definition": "AI responses formatted as data structures (JSON, XML) rather than prose. Enables reliable parsing for applications and integrations. Many APIs support structured output modes.",
      "tags": [
        "Feature",
        "Integration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-structured-output-prompting",
      "term": "Structured Output Prompting",
      "definition": "A prompting approach that instructs the model to generate responses in a specific structured format such as JSON, XML, tables, or schemas, often using format specifications and examples to ensure parseable and consistent output.",
      "tags": [
        "Prompt Engineering",
        "Output Format"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-structured-prediction",
      "term": "Structured Prediction",
      "definition": "A machine learning paradigm where the output is a complex structure such as a sequence, tree, or graph rather than a single label, requiring models that capture dependencies in the output space.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-structured-pruning",
      "term": "Structured Pruning",
      "definition": "A pruning technique that removes entire neurons, channels, or attention heads from a network, producing smaller dense models that run efficiently on standard hardware. Structured pruning provides immediate speedups without specialized sparse computation support.",
      "tags": [
        "Model Optimization",
        "Inference Infrastructure"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-sts-b",
      "term": "STS-B",
      "definition": "The Semantic Textual Similarity Benchmark containing sentence pairs annotated with similarity scores from 1 to 5. Tests graded semantic similarity in the GLUE benchmark using Pearson correlation.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-stuart-russell",
      "term": "Stuart Russell",
      "definition": "British computer scientist and co-author of the standard AI textbook Artificial Intelligence: A Modern Approach with Peter Norvig. Professor at UC Berkeley known for work on rational agents decision theory and AI safety. Advocate for beneficial AI development.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-students-t-distribution",
      "term": "Student's T-Distribution",
      "definition": "A continuous probability distribution that arises when estimating the mean of a normally distributed population with unknown variance and small sample size. It has heavier tails than the normal distribution.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-students-t-test",
      "term": "Student's T-Test",
      "definition": "A statistical test comparing the means of one or two groups when the population standard deviation is unknown and the sample size is small. Variants include independent two-sample, paired, and one-sample tests.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-stylegan",
      "term": "StyleGAN",
      "definition": "A GAN architecture that uses a mapping network and adaptive instance normalization to inject style information at multiple scales, enabling fine-grained control over generated image attributes.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stylegan2",
      "term": "StyleGAN2",
      "definition": "An improved version of StyleGAN that eliminates artifacts through weight demodulation and path length regularization. Produces higher quality images and has become a standard baseline for image generation research.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-stylegan3",
      "term": "StyleGAN3",
      "definition": "The third generation of StyleGAN that achieves alias-free image generation through careful signal processing. Produces images with continuous equivariance to translation and rotation eliminating texture sticking artifacts.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-styletts",
      "term": "StyleTTS",
      "definition": "A text-to-speech model that uses style-adaptive layer normalization to transfer speaking styles from reference audio to synthesized speech.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-styletts-2",
      "term": "StyleTTS 2",
      "definition": "An improved text-to-speech model that achieves human-level speech synthesis by using diffusion models and large speech language model pre-training for style modeling.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-subcategorization-frame",
      "term": "Subcategorization Frame",
      "definition": "The specification of the syntactic arguments a verb requires or permits, such as whether it takes a direct object, indirect object, or clausal complement.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-subgradient-method",
      "term": "Subgradient Method",
      "definition": "An optimization algorithm for minimizing non-differentiable convex functions that uses subgradients instead of gradients. Convergence is slower than gradient descent but the method applies to a broader class of problems.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-subgraph-matching-algorithm",
      "term": "Subgraph Matching Algorithm",
      "definition": "An algorithm that finds all occurrences of a pattern graph within a larger target graph. This is generally NP-complete and practical solutions use techniques like constraint propagation and backtracking with pruning.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-subliminal-ai-manipulation",
      "term": "Subliminal AI Manipulation",
      "definition": "The use of AI techniques to influence human behavior below the threshold of conscious awareness, classified as an unacceptable risk and prohibited under the EU AI Act.",
      "tags": [
        "AI Ethics",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-subspace-clustering-algorithm",
      "term": "Subspace Clustering Algorithm",
      "definition": "A clustering method that finds clusters in different subspaces of high-dimensional data. Each cluster may exist in a different subset of dimensions addressing the curse of dimensionality in clustering.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-substitution-bias",
      "term": "Substitution Bias",
      "definition": "The cognitive error of replacing a complex question with a simpler one when using AI tools. Users may accept AI outputs as answers to their actual questions when the AI has actually answered a different question.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-subsumption-architecture",
      "term": "Subsumption Architecture",
      "definition": "A reactive robot architecture developed by Rodney Brooks at MIT in 1986 that decomposes robot behavior into layers of simple behaviors rather than using centralized planning. Each layer directly connects sensing to action challenging the traditional sense-plan-act paradigm.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-subword-tokenization",
      "term": "Subword Tokenization",
      "definition": "A family of tokenization methods that split words into smaller meaningful units, balancing vocabulary size with the ability to represent rare and unseen words through common subword components.",
      "tags": [
        "NLP",
        "Tokenization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-successive-halving",
      "term": "Successive Halving",
      "definition": "A hyperparameter optimization algorithm that allocates exponentially more resources to promising configurations while discarding poor ones. Starts with many configurations and small budgets progressively eliminating the worst performers.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-successive-over-relaxation",
      "term": "Successive Over-Relaxation",
      "definition": "An iterative method for solving linear systems that accelerates the Gauss-Seidel method using a relaxation factor. Optimal choice of the relaxation parameter can dramatically improve convergence speed.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-successive-shortest-path-algorithm",
      "term": "Successive Shortest Path Algorithm",
      "definition": "A minimum-cost flow algorithm that repeatedly finds shortest paths in the residual network and augments flow along them. Combines Dijkstra's algorithm with flow augmentation for efficiency.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-successor-feature",
      "term": "Successor Feature",
      "definition": "A generalization of the successor representation to the function approximation setting, where expected cumulative discounted feature occupancies replace state occupancies. Successor features enable zero-shot transfer across tasks with different reward functions.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-successor-representation",
      "term": "Successor Representation",
      "definition": "A decomposition of the value function into a reward predictor and a successor feature matrix that captures expected future state occupancy. The successor representation enables efficient transfer across tasks with shared dynamics but different rewards.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-suffix-array-construction",
      "term": "Suffix Array Construction",
      "definition": "An algorithm that builds a sorted array of all suffixes of a string enabling fast substring searches. The DC3/skew algorithm constructs suffix arrays in O(n) time and supports O(m log n) pattern matching.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-suffix-tree-algorithm",
      "term": "Suffix Tree Algorithm",
      "definition": "A compressed trie of all suffixes of a string that supports pattern matching and substring queries in O(m) time where m is the pattern length. Ukkonen's algorithm constructs suffix trees in linear time.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Data Structure",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-summarization",
      "term": "Summarization",
      "definition": "An NLP task that condenses longer text into shorter summaries. Can be extractive (selecting key sentences) or abstractive (generating new condensed text).",
      "tags": [
        "NLP Task",
        "Application"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-summeval",
      "term": "SummEval",
      "definition": "A benchmark for evaluating summarization evaluation metrics containing 16 model summaries for 100 CNN/DailyMail articles with human annotations for consistency relevance coherence and fluency.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-summit-supercomputer",
      "term": "Summit Supercomputer",
      "definition": "IBM-built supercomputer at Oak Ridge National Laboratory using NVIDIA V100 GPUs that held the top supercomputer ranking from 2018 to 2020. Used for AI research and scientific simulation.",
      "tags": [
        "Supercomputer",
        "NVIDIA",
        "IBM"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-sun-database",
      "term": "SUN Database",
      "definition": "The Scene Understanding dataset containing over 130000 images across 908 scene categories with detailed annotations. One of the largest and most diverse scene recognition benchmarks.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sunway-taihulight",
      "term": "Sunway TaihuLight",
      "definition": "Chinese supercomputer using entirely domestic ShenWei processors that topped the TOP500 from 2016 to 2018. Demonstrated China capability to build world-class supercomputers without foreign chips.",
      "tags": [
        "Historical",
        "Supercomputer",
        "China"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-super-natural-instructions",
      "term": "Super-Natural Instructions",
      "definition": "An expansion of Natural Instructions to over 1600 tasks spanning 76 task types with expert-written instructions. Tests cross-task generalization of instruction-following models.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-super-resolution",
      "term": "Super-Resolution",
      "definition": "A computer vision task that reconstructs a high-resolution image from a low-resolution input, using deep learning models to predict fine details and textures that are not present in the degraded source.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-superb",
      "term": "SUPERB",
      "definition": "Speech processing Universal PERformance Benchmark a leaderboard of 10 speech tasks for evaluating self-supervised speech representations including ASR and speaker identification.",
      "tags": [
        "Benchmark",
        "Speech",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-superconducting-qubit",
      "term": "Superconducting Qubit",
      "definition": "Qubit implemented using superconducting circuits cooled to near absolute zero. The dominant qubit technology used by IBM Google and others in current quantum computers.",
      "tags": [
        "Quantum",
        "Technology",
        "Cryogenic"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-superglue",
      "term": "SuperGLUE",
      "definition": "A benchmark suite of more difficult natural language understanding tasks designed as a harder successor to GLUE, including reading comprehension, textual entailment, and word sense disambiguation tasks with human baseline performance metrics.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-superglue-benchmark",
      "term": "SuperGLUE Benchmark",
      "definition": "A more challenging successor to the GLUE benchmark introduced in 2019 with harder language understanding tasks. Designed to be more difficult for AI systems SuperGLUE included tasks requiring commonsense reasoning and causal inference.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-superintelligence",
      "term": "Superintelligence",
      "definition": "A hypothetical AI system that vastly exceeds human cognitive performance in virtually all domains. Nick Bostrom's work popularized the concept and its associated control challenges.",
      "tags": [
        "AI Safety",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-superpixel-algorithm",
      "term": "Superpixel Algorithm",
      "definition": "A method that groups pixels into perceptually meaningful atomic regions called superpixels. SLIC (Simple Linear Iterative Clustering) is a popular approach that uses k-means in a five-dimensional color and spatial space.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-supervised-learning",
      "term": "Supervised Learning",
      "definition": "Machine learning from labeled examples where the correct answer is provided. The model learns to map inputs to outputs by comparing predictions to ground truth.",
      "tags": [
        "Learning Type",
        "Fundamentals"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-supply-chain-transparency",
      "term": "Supply Chain Transparency",
      "definition": "Visibility into the components tools data and processes used to build an AI system throughout its development pipeline. Essential for identifying potential sources of risk and ensuring accountability.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-support-vector-machine",
      "term": "Support Vector Machine",
      "definition": "A supervised learning algorithm that finds the optimal hyperplane that maximizes the margin between classes in the feature space. It can handle non-linear boundaries through the kernel trick.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-svm-history",
      "term": "Support Vector Machine History",
      "definition": "The development of support vector machines by Vladimir Vapnik and colleagues in the 1990s, which dominated machine learning classification tasks for over a decade before being surpassed by deep learning methods.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-surf-algorithm",
      "term": "SURF Algorithm",
      "definition": "Speeded-Up Robust Features is a feature detection and description algorithm that uses integral images and Hessian matrix approximations. Designed as a faster alternative to SIFT while maintaining comparable performance.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-surrogate-model",
      "term": "Surrogate Model",
      "definition": "An interpretable model trained to approximate the predictions of a complex black-box model. Global surrogates explain overall behavior, while local surrogates (like LIME) explain individual predictions.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-surveillance-ai-ethics",
      "term": "Surveillance AI Ethics",
      "definition": "Ethical concerns about the use of AI for surveillance purposes including facial recognition behavior monitoring and predictive analytics. Raises fundamental questions about privacy civil liberties and power.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-surveillance-capitalism-and-ai",
      "term": "Surveillance Capitalism and AI",
      "definition": "The economic system described by Shoshana Zuboff where AI is used to extract and commodify human behavioral data at scale, raising concerns about privacy, autonomy, and the manipulation of human behavior.",
      "tags": [
        "Privacy",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-survival-analysis",
      "term": "Survival Analysis",
      "definition": "A branch of statistics dealing with the analysis of time-to-event data, accounting for censored observations. Key methods include Kaplan-Meier estimation, log-rank tests, and Cox proportional hazards models.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-survivorship-bias",
      "term": "Survivorship Bias",
      "definition": "A form of selection bias that occurs when analysis is conducted only on subjects that passed a selection process, ignoring those that did not. It leads to overly optimistic conclusions about the surviving group.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-surya-ocr",
      "term": "Surya OCR",
      "definition": "An open-source multilingual OCR model that handles text detection and recognition and line ordering across over 90 languages with high accuracy.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-svd-algorithm",
      "term": "SVD Algorithm",
      "definition": "Singular Value Decomposition factors a matrix into three matrices: a left orthogonal matrix and a diagonal matrix of singular values and a right orthogonal matrix. Fundamental in dimensionality reduction and least squares solutions.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-svd-xt",
      "term": "SVD-XT",
      "definition": "An extended version of Stable Video Diffusion that generates longer video sequences with improved temporal consistency using additional temporal convolution layers.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-svhn",
      "term": "SVHN",
      "definition": "The Street View House Numbers dataset containing over 600000 digit images obtained from house numbers in Google Street View imagery. More challenging than MNIST due to real-world noise and distractors.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-svm-model",
      "term": "SVM Model",
      "definition": "A supervised learning model that finds the optimal hyperplane separating classes by maximizing the margin between support vectors in feature space.",
      "tags": [
        "Models",
        "Fundamentals",
        "History"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-swarm-intelligence",
      "term": "Swarm Intelligence",
      "definition": "The collective intelligent behavior emerging from decentralized, self-organized systems such as ant colonies or bird flocks, formalized computationally in the 1990s and applied to optimization and robotics problems.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-swe-bench",
      "term": "SWE-bench",
      "definition": "Software Engineering Bench a benchmark of real-world GitHub issues paired with their resolutions. Tests the ability of AI systems to autonomously resolve actual software engineering tasks.",
      "tags": [
        "Benchmark",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-swe-bench-verified",
      "term": "SWE-bench Verified",
      "definition": "A human-validated subset of SWE-bench where each task has been verified by software engineers. Provides more reliable evaluation of autonomous coding agent capabilities.",
      "tags": [
        "Benchmark",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-swiglu",
      "term": "SwiGLU",
      "definition": "A gated linear unit variant that uses the Swish activation function for the gating mechanism, providing improved performance in transformer feedforward networks compared to standard ReLU or GELU.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-swin-transformer",
      "term": "Swin Transformer",
      "definition": "A hierarchical vision transformer that computes self-attention within non-overlapping local windows and shifts windows between layers, achieving linear computational complexity with respect to image size.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-swinvrn",
      "term": "SwinVRN",
      "definition": "A weather forecasting model based on the Swin Transformer architecture that predicts atmospheric variables on a volumetric grid for medium-range forecasting.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-swish",
      "term": "Swish",
      "definition": "An activation function defined as f(x) = x * sigmoid(beta * x) discovered through automated search by Google Brain in 2017. Empirically outperforms ReLU on deeper networks. When beta equals 1 it is equivalent to SiLU.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-swish-activation",
      "term": "Swish Activation",
      "definition": "A smooth, non-monotonic activation function defined as x times sigmoid of x, which often outperforms ReLU in deep networks by allowing small negative values to propagate gradients.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-switch-transformer",
      "term": "Switch Transformer",
      "definition": "A mixture-of-experts model that routes each token to a single expert using a simplified top-1 routing mechanism. Dramatically increases model capacity while keeping computation constant. Scales to trillion-parameter models efficiently.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-switchboard",
      "term": "Switchboard",
      "definition": "A collection of approximately 2400 two-sided telephone conversations among 543 speakers. A foundational dataset for conversational speech recognition and dialogue research.",
      "tags": [
        "Training Corpus",
        "Speech"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-sycophancy",
      "term": "Sycophancy",
      "definition": "When AI excessively agrees with users or tells them what they want to hear rather than providing accurate information. A form of misalignment that undermines helpfulness.",
      "tags": [
        "Limitation",
        "Alignment"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-symbol-grounding-problem",
      "term": "Symbol Grounding Problem",
      "definition": "The problem identified by Stevan Harnad in 1990 of how symbols in a formal system can acquire meaning, questioning whether AI systems that manipulate symbols without sensory experience can truly understand.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-symbolic-ai",
      "term": "Symbolic AI",
      "definition": "An approach to AI that represents knowledge using human-readable symbols and manipulates them according to rules of logic. Dominant from the 1950s through the 1980s symbolic AI encompasses expert systems logic programming and knowledge-based systems. Also known as Good Old-Fashioned AI (GOFAI).",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-symbolic-differentiation",
      "term": "Symbolic Differentiation",
      "definition": "Computing derivatives by algebraically manipulating mathematical expressions according to differentiation rules. Produces exact closed-form derivatives but can lead to expression explosion for complex functions. Distinct from automatic differentiation.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-symbolic-numeric-computation",
      "term": "Symbolic-Numeric Computation",
      "definition": "Algorithms that combine exact symbolic manipulation with approximate numerical methods to solve mathematical problems. Bridges computer algebra systems and numerical analysis for improved robustness and efficiency.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-symbolics",
      "term": "Symbolics",
      "definition": "Company that manufactured Lisp machines in the 1980s and registered the first dot-com domain name. Represented the commercial peak of specialized AI hardware before the AI winter.",
      "tags": [
        "Historical",
        "AI",
        "Company"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-syncdreamer",
      "term": "SyncDreamer",
      "definition": "A multi-view image diffusion model that generates consistent multi-view images of an object from a single input view for 3D reconstruction.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-synchronous-sgd",
      "term": "Synchronous SGD",
      "definition": "A distributed training approach where all workers must complete their gradient computation before a synchronized all-reduce and weight update. Synchronous SGD provides exact gradients but throughput is limited by the slowest worker.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-synopsys",
      "term": "Synopsys",
      "definition": "Leading electronic design automation company providing software tools for designing semiconductor chips. Their tools are used in the design of virtually all modern AI accelerator chips.",
      "tags": [
        "Manufacturing",
        "EDA",
        "Company"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-synset",
      "term": "Synset",
      "definition": "A set of synonymous words or phrases in WordNet that represent a single concept, serving as the basic unit of meaning in the lexical database.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-syntax",
      "term": "Syntax",
      "definition": "The branch of linguistics concerning the rules and principles governing the structure of sentences, including word order, phrase structure, and grammatical relations.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-synthetic-control-method",
      "term": "Synthetic Control Method",
      "definition": "A causal inference technique that constructs a weighted combination of control units to approximate the treated unit before intervention. The difference between the synthetic and actual outcomes estimates the treatment effect.",
      "tags": [
        "Algorithms",
        "Technical",
        "Causal"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-synthetic-data",
      "term": "Synthetic Data",
      "definition": "Artificially generated data used for training when real data is scarce, expensive, or privacy-sensitive. Increasingly used to train and evaluate AI models.",
      "tags": [
        "Data",
        "Training"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-synthetic-data-generation",
      "term": "Synthetic Data Generation",
      "definition": "The use of AI models to create artificial training data that mimics real-world data distributions, used to augment datasets, address privacy concerns, or overcome data scarcity.",
      "tags": [
        "Generative AI",
        "LLM"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-synthetic-data-vault",
      "term": "Synthetic Data Vault",
      "definition": "A system for generating synthetic tabular data that preserves the statistical properties of real datasets. Used for privacy-preserving data sharing and augmentation.",
      "tags": [
        "Synthetic",
        "Platform"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-synthetic-media",
      "term": "Synthetic Media",
      "definition": "Media content including images, video, audio, and text that is generated or substantially modified by AI systems, encompassing deepfakes, AI-generated art, voice cloning, and large language model outputs.",
      "tags": [
        "AI Ethics",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-synthetic-text-to-sql",
      "term": "Synthetic Text-to-SQL",
      "definition": "Synthetic datasets of natural language to SQL pairs generated by LLMs for training text-to-SQL models. Augments human-annotated data with diverse synthetic examples.",
      "tags": [
        "Training Corpus",
        "Code",
        "Synthetic"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-system-2-attention",
      "term": "System 2 Attention",
      "definition": "A prompting technique that first asks the model to rewrite the input by removing irrelevant or opinion-laden context, then answers based on the cleaned input, reducing the influence of biased or distracting information on the response.",
      "tags": [
        "Prompt Engineering",
        "Attention"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-system-message-design",
      "term": "System Message Design",
      "definition": "The practice of crafting the system-level prompt that establishes a language model's identity, behavior boundaries, output format, and operational constraints before any user interaction begins in a conversational API.",
      "tags": [
        "Prompt Engineering",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-system-prompt",
      "term": "System Prompt",
      "definition": "Instructions given to AI before a conversation that set context, persona, or behavior guidelines. Shapes all subsequent responses and defines the AI's \"personality\" for the session.",
      "tags": [
        "Prompting",
        "Configuration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-system-on-chip",
      "term": "System-on-Chip",
      "definition": "Integrated circuit combining processor memory interfaces and other components on a single chip. Apple M-series and Qualcomm Snapdragon are SoCs used for mobile and edge AI.",
      "tags": [
        "Architecture",
        "Integration",
        "Design"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-systemic-bias",
      "term": "Systemic Bias",
      "definition": "Bias that is embedded in and perpetuated by institutional processes social structures and historical patterns. AI systems can inherit and amplify systemic biases through training data and deployment contexts.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-systemic-risk-from-ai",
      "term": "Systemic Risk from AI",
      "definition": "The risk that AI systems pose to the stability and functioning of larger social economic or technical systems. Arises from interdependencies concentration of capabilities and correlated failure modes.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-systolic-array",
      "term": "Systolic Array",
      "definition": "Regular array of processing elements that rhythmically pass data between neighbors performing multiply-accumulate operations. The core compute architecture used in Google TPUs and many AI accelerators.",
      "tags": [
        "Architecture",
        "Accelerator",
        "Fundamentals"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    }
  ]
}