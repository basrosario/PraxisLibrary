{
  "letter": "a",
  "count": 315,
  "terms": [
    {
      "id": "term-a-search",
      "term": "A* Search",
      "definition": "A graph search algorithm that finds the shortest path by combining the actual cost from the start node with a heuristic estimate of the remaining cost. Guarantees optimality when the heuristic is admissible. Used in planning and game-playing AI.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-a-star-search-algorithm",
      "term": "A* Search Algorithm",
      "definition": "A graph search algorithm developed by Peter Hart, Nils Nilsson, and Bertram Raphael at SRI International in 1968 that finds the shortest path using heuristics, becoming fundamental to AI planning and pathfinding.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ab-testing",
      "term": "A/B Testing",
      "definition": "A randomized controlled experiment that compares two variants (A and B) to determine which performs better on a specified metric. It is widely used in product development to make data-driven decisions.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-ab-testing-for-llms",
      "term": "A/B Testing for LLMs",
      "definition": "A comparative evaluation methodology where two language model variants or prompt configurations are deployed to different user segments, with statistical analysis of user preference, task completion, and quality metrics determining the superior option.",
      "tags": [
        "Evaluation",
        "Methodology"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-aaai-organization",
      "term": "AAAI (Organization)",
      "definition": "The Association for the Advancement of Artificial Intelligence founded in 1979 (originally the American Association for Artificial Intelligence). A nonprofit scientific society devoted to advancing the understanding of the mechanisms underlying thought and intelligent behavior.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-aaai-conference",
      "term": "AAAI Conference",
      "definition": "The Association for the Advancement of Artificial Intelligence conference held annually since 1980. One of the premier AI conferences covering all areas of artificial intelligence research from robotics to natural language processing.",
      "tags": [
        "History",
        "Conferences"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-aaron",
      "term": "AARON",
      "definition": "An art-generating program created by Harold Cohen beginning in 1973. One of the longest-running AI art projects AARON evolved from producing abstract drawings to creating representational paintings. It raised early questions about computational creativity and authorship.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-abductive-reasoning",
      "term": "Abductive Reasoning",
      "definition": "A form of logical inference that starts with an observation and seeks the simplest or most likely explanation. Used in AI for diagnosis hypothesis generation and plan recognition. Distinguished from deductive and inductive reasoning.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ablation-study",
      "term": "Ablation Study",
      "definition": "A research technique that removes components of a model to understand their contribution. Helps researchers understand which parts of a system are responsible for its capabilities.",
      "tags": [
        "Research",
        "Methodology"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-absolute-position-encoding",
      "term": "Absolute Position Encoding",
      "definition": "A method of injecting position information into transformer inputs by adding a fixed or learned vector to each position. The original transformer used sinusoidal functions while later models like BERT used learned embeddings.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-amr",
      "term": "Abstract Meaning Representation",
      "definition": "A semantic representation that encodes the meaning of a sentence as a rooted directed acyclic graph, abstracting away from syntactic details to capture who did what to whom.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-abstraction-attack",
      "term": "Abstraction Attack",
      "definition": "An adversarial technique that exploits the gap between a model's learned abstractions and real-world inputs by crafting examples that match abstract features while differing perceptually. Related to concept-level adversarial manipulation.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-abstractive-summarization",
      "term": "Abstractive Summarization",
      "definition": "A summarization approach that generates novel sentences capturing the key information from the source text, potentially using words and phrasings not present in the original document.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-academic-prompting",
      "term": "Academic Prompting",
      "definition": "A prompting approach tailored for scholarly tasks that instructs the model to follow academic conventions including formal tone, citation awareness, evidence-based reasoning, and structured argumentation suitable for research contexts.",
      "tags": [
        "Prompt Engineering",
        "Academic"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-access-control-for-ai-systems",
      "term": "Access Control for AI Systems",
      "definition": "Mechanisms and policies that restrict who can deploy query or modify AI systems. Includes authentication authorization and audit logging to prevent unauthorized use of powerful models.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-accountability-gap",
      "term": "Accountability Gap",
      "definition": "The problem that arises when no single party can be held responsible for harm caused by AI systems due to complex supply chains and distributed decision-making across developers deployers and users.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-accountability-in-ai",
      "term": "Accountability in AI",
      "definition": "The principle that identifiable individuals or organizations should be answerable for the outcomes and impacts of AI systems, including mechanisms for redress when AI causes harm.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-accumulated-local-effects",
      "term": "Accumulated Local Effects",
      "definition": "A model-agnostic method for visualizing feature effects that is unbiased in the presence of correlated features, unlike partial dependence plots. It computes effects by accumulating differences in predictions over local intervals.",
      "tags": [
        "Machine Learning",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-accuracy",
      "term": "Accuracy",
      "definition": "A metric measuring how often a model's predictions are correct. Calculated as the ratio of correct predictions to total predictions. While intuitive, it can be misleading for imbalanced datasets.",
      "tags": [
        "Metrics",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-acl-conference",
      "term": "ACL Conference",
      "definition": "The Annual Meeting of the Association for Computational Linguistics first held in 1963. The premier conference for natural language processing research where many foundational papers on language models machine translation and text understanding have been published.",
      "tags": [
        "History",
        "Conferences"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-acm-organization",
      "term": "ACM (Organization)",
      "definition": "The Association for Computing Machinery founded in 1947 as the world's largest educational and scientific computing society. ACM administers the Turing Award often called the Nobel Prize of computing. Many AI researchers have been recognized through ACM awards.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-act-r",
      "term": "ACT-R",
      "definition": "A cognitive architecture developed by John Robert Anderson at Carnegie Mellon University since 1993. ACT-R models human cognition through the interaction of declarative and procedural memory modules. Widely used in cognitive science for modeling human learning and problem solving.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-action",
      "term": "Action",
      "definition": "A decision or move taken by an RL agent that affects the environment and transitions the system to a new state. Actions can be discrete (finite set of choices) or continuous (real-valued vectors).",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-action-masking",
      "term": "Action Masking",
      "definition": "A technique that restricts the set of available actions at each state by zeroing out invalid action probabilities before policy sampling. Action masking enforces domain constraints and prevents the agent from selecting illegal moves.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-action-recognition",
      "term": "Action Recognition",
      "definition": "A video understanding task that identifies and classifies human actions or activities in video sequences, using temporal modeling of motion patterns across frames with architectures like 3D CNNs or video transformers.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-action-repeat",
      "term": "Action Repeat",
      "definition": "A technique where each selected action is executed for multiple consecutive environment steps, reducing the effective decision frequency. Action repeat simplifies the control problem and can improve exploration efficiency.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-action-space",
      "term": "Action Space",
      "definition": "The set of all possible actions available to an RL agent, defined as discrete (finite choices), continuous (real-valued vectors), or multi-discrete. The action space structure fundamentally affects which algorithms are applicable.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-activation-checkpointing",
      "term": "Activation Checkpointing",
      "definition": "A memory optimization technique that trades compute for memory by discarding intermediate activations during the forward pass and recomputing them during backpropagation.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-activation-function",
      "term": "Activation Function",
      "definition": "A mathematical function applied to neurons in neural networks that introduces non-linearity, enabling the network to learn complex patterns. Common examples include ReLU, sigmoid, and tanh.",
      "tags": [
        "Neural Networks",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-activation-patching",
      "term": "Activation Patching",
      "definition": "An interpretability technique that replaces activations at specific positions and layers with activations from a different input to determine causal effects. Identifies which components are responsible for specific model behaviors.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-activation-quantization",
      "term": "Activation Quantization",
      "definition": "The process of quantizing intermediate activations (not just weights) during inference to reduce memory bandwidth requirements and enable INT8 or lower-precision arithmetic. Activation quantization is more challenging than weight quantization due to dynamic ranges.",
      "tags": [
        "Model Optimization",
        "Inference Infrastructure"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-active-inference-safety",
      "term": "Active Inference Safety",
      "definition": "Research into making active inference agents safe by ensuring their generative models and prior preferences are aligned with human values. Draws from the free energy principle in neuroscience.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-active-learning",
      "term": "Active Learning",
      "definition": "A training approach where the model identifies which unlabeled examples would be most valuable to learn from. Reduces labeling costs by focusing human effort where it matters most.",
      "tags": [
        "Training",
        "Technique"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-active-learning-algorithm",
      "term": "Active Learning Algorithm",
      "definition": "A machine learning approach where the model selectively queries an oracle for labels on the most informative unlabeled examples. Reduces labeling costs by identifying which examples would most improve the model if labeled.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-active-prompting",
      "term": "Active Prompting",
      "definition": "A method that identifies the most uncertain or informative questions for chain-of-thought annotation by measuring model disagreement across sampled outputs, then selectively annotates those examples to maximize few-shot demonstration effectiveness.",
      "tags": [
        "Prompt Engineering",
        "Active Learning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-actor-critic",
      "term": "Actor-Critic",
      "definition": "An RL architecture combining a policy network (actor) that selects actions with a value network (critic) that evaluates those actions. The critic's value estimates reduce the variance of policy gradient updates compared to pure policy gradient methods.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-ada-lovelace",
      "term": "Ada Lovelace",
      "definition": "British mathematician (1815-1852) who wrote the first published algorithm intended for a machine, working with Charles Babbage's Analytical Engine, and is widely regarded as the first computer programmer.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-adaboost",
      "term": "AdaBoost",
      "definition": "An ensemble method that trains weak learners sequentially, assigning higher weights to misclassified samples so that subsequent learners focus on the hardest examples. Final predictions are a weighted vote of all learners.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-adadelta",
      "term": "AdaDelta",
      "definition": "An adaptive learning rate optimizer that eliminates the need for a manually set global learning rate. Adapts based on a moving window of gradient updates rather than accumulating all past gradients like AdaGrad. Proposed by Zeiler in 2012.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-adafactor",
      "term": "Adafactor",
      "definition": "A memory-efficient adaptive optimizer that factorizes the second moment accumulator into row and column factors. Reduces optimizer memory usage from O(mn) to O(m+n) for weight matrices. Default optimizer for T5 model training.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-adagrad",
      "term": "AdaGrad",
      "definition": "An optimization algorithm that adapts the learning rate for each parameter individually by dividing by the square root of the sum of all historical squared gradients. It performs well on sparse data but can prematurely reduce learning rates.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-adam",
      "term": "Adam Optimizer",
      "definition": "A popular optimization algorithm combining momentum with adaptive learning rates. The default choice for training many neural networks due to good performance across tasks.",
      "tags": [
        "Training",
        "Algorithm"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-adamw",
      "term": "AdamW",
      "definition": "A variant of the Adam optimizer that decouples weight decay from the gradient update. Proposed by Loshchilov and Hutter in 2019. Shown to provide better generalization than Adam with L2 regularization. The default optimizer for most transformer training.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-adapter-layer",
      "term": "Adapter Layer",
      "definition": "A small trainable module inserted between frozen pretrained layers that learns task-specific transformations with minimal additional parameters, enabling efficient fine-tuning without modifying the base model.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-adapter-layers",
      "term": "Adapter Layers",
      "definition": "Small trainable modules inserted between the layers of a pretrained model for parameter-efficient fine-tuning. Typically consist of a down-projection nonlinearity and up-projection with a residual connection. Only adapter parameters are updated during fine-tuning.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-adaptive-pooling",
      "term": "Adaptive Pooling",
      "definition": "A pooling operation that automatically adjusts its kernel size and stride to produce a specified output size regardless of input dimensions. Commonly used in PyTorch to handle variable-size inputs in classification networks.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-adaptive-stress-testing",
      "term": "Adaptive Stress Testing",
      "definition": "A technique that uses reinforcement learning to find the most likely failure scenarios for autonomous systems. Developed at Stanford to identify edge cases in safety-critical AI applications.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-addictive-design-in-ai",
      "term": "Addictive Design in AI",
      "definition": "The use of AI-driven personalization and engagement optimization techniques that exploit psychological vulnerabilities to maximize user screen time or spending. Raises ethical concerns about autonomy and wellbeing.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-additive-attention",
      "term": "Additive Attention",
      "definition": "An attention mechanism that computes compatibility scores by passing the concatenation of query and key through a feedforward layer, also known as Bahdanau attention from its use in early seq2seq models.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-adjusted-rand-index",
      "term": "Adjusted Rand Index",
      "definition": "A clustering evaluation metric that measures agreement between two clusterings adjusted for chance. Ranges from -1 to 1 with 1 indicating perfect agreement and 0 indicating random clustering. Corrects the Rand Index for expected agreement.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-a2c",
      "term": "Advantage Actor-Critic (A2C)",
      "definition": "A synchronous variant of the actor-critic method that uses the advantage function (difference between action value and state value) to reduce variance in policy gradient updates. A2C collects experiences from multiple parallel environments simultaneously.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-advantage-function",
      "term": "Advantage Function",
      "definition": "The difference A(s,a) = Q(s,a) - V(s) between the action-value and state-value functions, measuring how much better an action is compared to the average action under the current policy. The advantage function reduces variance in policy gradient methods.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-advantage-weighted-regression",
      "term": "Advantage-Weighted Regression (AWR)",
      "definition": "An offline RL algorithm that learns a policy by performing weighted maximum likelihood on a dataset, where the weights are exponentiated advantages. AWR avoids policy gradient variance and off-policy correction issues.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-adversarial-attack",
      "term": "Adversarial Attack",
      "definition": "Deliberate attempts to deceive AI systems by providing specially crafted inputs. These can cause models to make incorrect predictions or generate harmful outputs.",
      "tags": [
        "Security",
        "Safety"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-adversarial-example-cv",
      "term": "Adversarial Example",
      "definition": "An input image with carefully crafted, often imperceptible perturbations that cause a vision model to make incorrect predictions with high confidence, exposing vulnerabilities in neural network classifiers.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-adversarial-machine-learning",
      "term": "Adversarial Machine Learning",
      "definition": "The study of attacks on machine learning systems and defenses against them. Encompasses evasion attacks poisoning attacks model stealing and privacy attacks as well as certified robustness methods.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-adversarial-patch",
      "term": "Adversarial Patch",
      "definition": "A physical-world adversarial attack that uses a printed patch to fool image classifiers or object detectors. Unlike pixel-level perturbations patches are robust to changes in viewing angle and distance.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-adversarial-prompting",
      "term": "Adversarial Prompting",
      "definition": "The deliberate crafting of inputs designed to exploit vulnerabilities in language models, causing them to produce harmful outputs, bypass safety filters, reveal system prompts, or behave contrary to their intended instructions.",
      "tags": [
        "Prompt Engineering",
        "Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-adversarial-robustness",
      "term": "Adversarial Robustness",
      "definition": "The ability of a machine learning model to maintain correct predictions when inputs are deliberately perturbed by an adversary. Measured using attack success rates under various threat models and perturbation budgets.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-adversarial-training",
      "term": "Adversarial Training",
      "definition": "A training procedure that augments the training set with adversarial examples generated during training. The model learns to correctly classify both clean and adversarial inputs improving robustness. Currently the most effective defense against adversarial attacks.",
      "tags": [
        "Algorithms",
        "Safety"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-affinity-propagation",
      "term": "Affinity Propagation",
      "definition": "A clustering algorithm that identifies exemplars among data points by passing messages between pairs. Does not require specifying the number of clusters. Each data point sends messages about how suitable other points are as exemplars.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-age-verification-in-ai",
      "term": "Age Verification in AI",
      "definition": "Technical and policy mechanisms to verify user age before granting access to AI systems that may be inappropriate for minors. Raises tensions between child safety and privacy concerns.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-agent",
      "term": "Agent (AI Agent)",
      "definition": "An AI system that can perceive its environment, make decisions, and take actions to achieve goals. Modern AI agents can use tools, browse the web, execute code, and interact with external systems.",
      "tags": [
        "Architecture",
        "Advanced"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-agent-framework",
      "term": "Agent Framework",
      "definition": "A software architecture that enables LLMs to autonomously plan, reason, and execute multi-step tasks by combining language understanding with tool use, memory, and iterative decision-making.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-agent-safety",
      "term": "Agent Safety",
      "definition": "The study of ensuring autonomous AI agents that take actions in the real world do so safely. Covers problems like safe exploration reward hacking side effects and interruptibility.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-agentic-ai",
      "term": "Agentic AI",
      "definition": "AI systems that can autonomously plan, reason, and take actions to accomplish goals. Includes tool use, multi-step planning, and self-correction capabilities.",
      "tags": [
        "Architecture",
        "Advanced"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-agentic-chunking",
      "term": "Agentic Chunking",
      "definition": "A document splitting strategy that uses a language model agent to make intelligent decisions about chunk boundaries, content grouping, and chunk summaries, producing semantically coherent chunks that a simple rule-based splitter would miss.",
      "tags": [
        "Retrieval",
        "Preprocessing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-agentic-rag",
      "term": "Agentic RAG",
      "definition": "A retrieval-augmented generation approach where an LLM agent dynamically decides what to retrieve, refines queries based on initial results, and iteratively gathers information until it can produce a complete answer.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-aggregate-ethics",
      "term": "Aggregate Ethics",
      "definition": "An approach to AI ethics that considers the cumulative societal impact of many individually harmless AI decisions rather than focusing only on dramatic individual harms. Important for understanding systemic effects.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-aggregation-bias",
      "term": "Aggregation Bias",
      "definition": "Bias arising when a single model is used for groups with different conditional distributions, leading to poor performance for subgroups whose patterns differ from the majority population.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-agi",
      "term": "AGI (Artificial General Intelligence)",
      "definition": "Hypothetical AI that can perform any intellectual task a human can. Unlike today's narrow AI, AGI would generalize across all domains. A long-term goal and safety concern.",
      "tags": [
        "Concept",
        "Future"
      ],
      "domain": "general",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-agi-safety",
      "term": "AGI Safety",
      "definition": "The subfield of AI safety specifically focused on ensuring that artificial general intelligence, systems matching or exceeding human cognitive abilities across all domains, remains beneficial and controllable.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai",
      "term": "AI (Artificial Intelligence)",
      "definition": "Computer systems designed to perform tasks that typically require human intelligence, such as understanding language, recognizing patterns, making decisions, and generating content.",
      "tags": [
        "Fundamentals",
        "Core Concept"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-alignment-problem",
      "term": "AI Alignment Problem",
      "definition": "The challenge of ensuring that AI systems pursue goals and behaviors aligned with human values and intentions. As AI systems become more capable the alignment problem has become one of the most critical open questions in AI safety research.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-alignment-tax",
      "term": "AI Alignment Tax",
      "definition": "The additional cost in performance, compute, or development time required to make an AI system aligned with human values, representing the trade-off between capability and safety.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-and-employment",
      "term": "AI and Employment",
      "definition": "The ongoing debate about how AI and automation will affect jobs and the labor market. Predictions range from mass unemployment to job transformation and augmentation. Historical precedents from previous technological revolutions provide mixed evidence.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-arms-race",
      "term": "AI Arms Race",
      "definition": "The competitive dynamic between nations or companies racing to develop the most advanced AI capabilities, potentially at the expense of safety research, ethical considerations, and international cooperation.",
      "tags": [
        "AI Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-assurance",
      "term": "AI Assurance",
      "definition": "Processes and evidence that demonstrate an AI system meets its specified requirements for safety security and performance. Analogous to software assurance but extended for ML-specific properties like fairness and robustness.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-audit",
      "term": "AI Audit",
      "definition": "A systematic evaluation of an AI system to assess compliance with regulations ethical guidelines and performance standards. May include technical testing documentation review and stakeholder consultation.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-bill-of-rights",
      "term": "AI Bill of Rights",
      "definition": "The Blueprint for an AI Bill of Rights released by the White House OSTP in 2022, outlining five principles for responsible AI: safe systems, algorithmic discrimination protections, data privacy, notice and explanation, and human alternatives.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-boom-2023",
      "term": "AI Boom 2023",
      "definition": "The period of intense investment, development, and public attention in AI following the launch of ChatGPT, characterized by rapid advances in large language models, generative AI, and record venture capital funding.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-bounty-program",
      "term": "AI Bounty Program",
      "definition": "A program that rewards external researchers for identifying vulnerabilities biases or safety issues in AI systems. Modeled on cybersecurity bug bounties and adopted by organizations like OpenAI and Google DeepMind.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-carbon-footprint",
      "term": "AI Carbon Footprint",
      "definition": "The environmental impact of training and running AI models measured in carbon dioxide equivalent emissions. Large language model training can emit hundreds of tons of CO2 raising sustainability concerns.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-certification",
      "term": "AI Certification",
      "definition": "Formal processes by which an independent body assesses and certifies that an AI system meets specified safety performance and ethical standards. Emerging in regulated sectors like healthcare aviation and automotive.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-chip-race",
      "term": "AI Chip Race",
      "definition": "The competition among semiconductor companies to develop specialized chips optimized for AI workloads. Key players include NVIDIA (GPU) Google (TPU) Intel (Gaudi) AMD (Instinct) and startups like Cerebras Graphcore and SambaNova.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-compliance",
      "term": "AI Compliance",
      "definition": "The practice of ensuring AI systems conform to applicable laws regulations industry standards and organizational policies. Includes documentation impact assessments and ongoing monitoring requirements.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-consciousness",
      "term": "AI Consciousness",
      "definition": "The philosophical and scientific question of whether AI systems can have subjective experiences or phenomenal awareness, with implications for moral consideration and the ethical treatment of AI entities.",
      "tags": [
        "AI Ethics",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-containment",
      "term": "AI Containment",
      "definition": "Strategies and technical measures designed to prevent an advanced AI system from exerting unintended influence on the external world, including air-gapping, sandboxing, and limiting communication channels.",
      "tags": [
        "AI Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-content-detection",
      "term": "AI Content Detection",
      "definition": "Tools and techniques for identifying whether text images or other media were generated by AI systems. Uses statistical analysis watermarking and trained classifiers to distinguish human from machine output.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-decolonization",
      "term": "AI Decolonization",
      "definition": "A movement to challenge Western-centric assumptions in AI development and deployment. Advocates for including diverse cultural perspectives addressing power imbalances and preventing technological neo-colonialism.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-democratization-risks",
      "term": "AI Democratization Risks",
      "definition": "The potential dangers of making powerful AI capabilities widely accessible without adequate safety measures. Includes dual-use concerns proliferation risks and the challenge of preventing misuse at scale.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-dependency-risk",
      "term": "AI Dependency Risk",
      "definition": "The risk that over-reliance on AI systems creates fragility in critical infrastructure and decision-making processes. Includes concerns about skill atrophy single points of failure and vendor lock-in.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-detection",
      "term": "AI Detection",
      "definition": "Methods and tools designed to distinguish AI-generated text, images, or media from human-created content, using statistical analysis of token distributions, perplexity patterns, or embedded watermarks.",
      "tags": [
        "Generative AI",
        "LLM"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-digital-divide",
      "term": "AI Digital Divide",
      "definition": "The gap between those who have access to AI technologies and the skills to use them and those who do not, potentially exacerbating existing social and economic inequalities across and within nations.",
      "tags": [
        "AI Ethics",
        "Fairness"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-disclosure-requirements",
      "term": "AI Disclosure Requirements",
      "definition": "Legal or ethical obligations to inform users when they are interacting with an AI system rather than a human. Increasingly mandated by regulations including the EU AI Act and various US state laws.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-due-diligence",
      "term": "AI Due Diligence",
      "definition": "The process of systematically evaluating AI systems for risks before deployment or acquisition. Includes technical audits bias testing legal review and assessment of societal impact.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-ecosystem-risk",
      "term": "AI Ecosystem Risk",
      "definition": "Systemic risks arising from the interconnected nature of AI systems where a failure or vulnerability in one component can cascade through dependent systems and applications.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-effect",
      "term": "AI Effect",
      "definition": "The phenomenon where once a machine can perform a task that was previously considered to require intelligence that task is no longer regarded as requiring true intelligence. This moving goalpost has been observed throughout AI history as achievements are routinely discounted.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-emergency-stop",
      "term": "AI Emergency Stop",
      "definition": "A mechanism to rapidly shut down or constrain an AI system that is operating unsafely. Also known as a kill switch. Designing reliable emergency stops for distributed AI systems remains an open challenge.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-environmental-impact",
      "term": "AI Environmental Impact",
      "definition": "The environmental costs of AI development and deployment, including the substantial energy consumption and carbon emissions from training large models, water usage for data center cooling, and electronic waste.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-ethical-framework",
      "term": "AI Ethical Framework",
      "definition": "A structured set of principles guidelines and procedures for developing and deploying AI systems responsibly. Examples include the IEEE Ethically Aligned Design and the OECD AI Principles.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-ethics",
      "term": "AI Ethics",
      "definition": "The study of moral principles and values that should guide the development and use of AI systems. Covers fairness, transparency, privacy, accountability, and societal impact.",
      "tags": [
        "Ethics",
        "Society"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-ai-ethics-history",
      "term": "AI Ethics History",
      "definition": "The evolution of AI ethics from early philosophical questions (Turing 1950 Weizenbaum 1976) through concerns about bias and fairness (2010s) to modern debates about existential risk alignment and governance of powerful AI systems.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-export-controls",
      "term": "AI Export Controls",
      "definition": "Government regulations restricting the international transfer of AI technology including models training data chips and related expertise. Used as tools of national security and technology competition policy.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-fairness-metrics",
      "term": "AI Fairness Metrics",
      "definition": "Quantitative measures used to assess whether an AI system treats different demographic groups equitably. Common metrics include demographic parity equalized odds and calibration across subgroups.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-forensics",
      "term": "AI Forensics",
      "definition": "The application of investigative techniques to understand AI system behavior after an incident or failure. Includes model inspection log analysis and provenance tracking to determine root causes.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-gap",
      "term": "AI Gap",
      "definition": "The disparity in AI capabilities resources and benefits between wealthy and less wealthy nations or communities. Contributes to widening global inequality and digital divides.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-governance",
      "term": "AI Governance",
      "definition": "The set of policies, regulations, standards, and institutional frameworks that guide the development, deployment, and oversight of artificial intelligence systems at organizational, national, and international levels.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-governance-framework",
      "term": "AI Governance Framework",
      "definition": "A comprehensive structure of policies processes roles and tools for managing the development deployment and monitoring of AI systems within an organization or jurisdiction.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-hallucination-problem",
      "term": "AI Hallucination Problem",
      "definition": "The phenomenon where AI language models generate plausible-sounding but factually incorrect or fabricated information. Recognized as a major challenge for deploying LLMs in production hallucinations have motivated research into grounding retrieval augmentation and uncertainty estimation.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-hype-cycle",
      "term": "AI Hype Cycle",
      "definition": "The pattern of inflated expectations followed by disillusionment and eventual productive adoption that characterizes public perception of AI capabilities. Contributes to misallocation of resources and erosion of public trust.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-impact-assessment",
      "term": "AI Impact Assessment",
      "definition": "A systematic process for evaluating the potential social, ethical, economic, and environmental effects of an AI system before and during deployment, analogous to environmental impact assessments.",
      "tags": [
        "Governance",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-incident-database",
      "term": "AI Incident Database",
      "definition": "A repository cataloging real-world instances where AI systems caused harm or exhibited problematic behavior, maintained by organizations like the Partnership on AI to enable learning from failures.",
      "tags": [
        "AI Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-incident-response",
      "term": "AI Incident Response",
      "definition": "A structured process for detecting investigating and remediating harmful outcomes from AI systems. Modeled on cybersecurity incident response but adapted for ML-specific failure modes like bias drift and hallucination.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-index-report",
      "term": "AI Index Report",
      "definition": "An annual report from Stanford University's Human-Centered AI Institute that tracks measures and visualizes data related to AI progress. The AI Index provides comprehensive benchmarking of AI capabilities investment and policy across the global AI ecosystem.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-insurance",
      "term": "AI Insurance",
      "definition": "Insurance products designed to cover liabilities arising from AI system failures or harms. An emerging market that faces challenges in risk assessment due to the unpredictable nature of AI failures.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-labor-displacement",
      "term": "AI Labor Displacement",
      "definition": "The phenomenon of AI and automation systems replacing human workers in various occupations, raising concerns about unemployment, wage depression, skill obsolescence, and the need for workforce transition programs.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-liability-framework",
      "term": "AI Liability Framework",
      "definition": "Legal frameworks determining who bears responsibility when AI systems cause harm, including debates over strict liability, negligence standards, and the EU's AI Liability Directive proposal.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-literacy",
      "term": "AI Literacy",
      "definition": "The knowledge and skills needed for individuals to understand evaluate and interact effectively with AI systems. Considered essential for informed consent democratic participation and workforce adaptation.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-lobbying",
      "term": "AI Lobbying",
      "definition": "Advocacy activities by AI companies and industry groups to influence government policy and regulation. Raises concerns about regulatory capture and the balance between innovation and public safety.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-manipulation",
      "term": "AI Manipulation",
      "definition": "The use of AI systems to influence human behavior beliefs or decisions through deceptive or coercive means. Includes deepfakes persuasive AI micro-targeting and synthetic media used for propaganda.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-monoculture-risk",
      "term": "AI Monoculture Risk",
      "definition": "The danger that widespread adoption of similar AI models architectures or training data creates systemic vulnerabilities where a single flaw affects many applications simultaneously.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-moratorium",
      "term": "AI Moratorium",
      "definition": "A proposed temporary pause on the development of AI systems above a certain capability threshold, notably advocated in the March 2023 open letter signed by prominent researchers and technologists.",
      "tags": [
        "AI Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-nationalism",
      "term": "AI Nationalism",
      "definition": "Government policies that prioritize domestic AI development as a matter of national competitiveness and security. Can lead to fragmented standards restricted collaboration and an AI arms race between nations.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-ombudsman",
      "term": "AI Ombudsman",
      "definition": "An independent official or office responsible for investigating complaints about AI systems and advocating for affected individuals. Proposed as a governance mechanism to provide recourse for AI-related harms.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-oversight-board",
      "term": "AI Oversight Board",
      "definition": "An organizational body responsible for reviewing and approving high-risk AI deployments. May include technical experts ethicists legal advisors and community representatives to ensure balanced decision-making.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-patent-ethics",
      "term": "AI Patent Ethics",
      "definition": "Ethical considerations around patenting AI inventions including questions of inventorship for AI-generated innovations access to AI technologies and the impact of IP regimes on AI development.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-personhood",
      "term": "AI Personhood",
      "definition": "The legal and philosophical concept of granting AI systems some form of legal personality, enabling them to hold rights, enter contracts, or bear liability, as debated in EU and other jurisdictions.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-pluralism",
      "term": "AI Pluralism",
      "definition": "An approach to AI development that embraces diverse perspectives values and cultural contexts rather than imposing a single worldview. Contrasts with monocultural approaches to AI alignment.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-policy-sandbox",
      "term": "AI Policy Sandbox",
      "definition": "A controlled regulatory environment where new AI applications can be tested under relaxed rules with government oversight. Allows regulators to learn about emerging technologies before establishing permanent rules.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-poverty-trap",
      "term": "AI Poverty Trap",
      "definition": "A scenario where communities lacking AI capabilities fall further behind economically and socially as AI-driven productivity gains accrue primarily to already-advantaged groups and nations.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-procurement-standards",
      "term": "AI Procurement Standards",
      "definition": "Requirements and evaluation criteria that government agencies and organizations use when purchasing or contracting AI systems. Include specifications for fairness transparency security and accountability.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-professional-ethics",
      "term": "AI Professional Ethics",
      "definition": "Ethical obligations and codes of conduct for individuals working in AI development and deployment. Analogous to professional ethics in medicine law and engineering.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-proportionality",
      "term": "AI Proportionality",
      "definition": "The principle that the intrusiveness and risks of an AI system should be proportionate to the benefits it provides and the severity of the problem it addresses. A key principle in the EU AI Act.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-public-engagement",
      "term": "AI Public Engagement",
      "definition": "Processes for involving the general public in decisions about AI development and deployment. Includes citizen assemblies public consultations deliberative forums and participatory design methods.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-quality-assurance",
      "term": "AI Quality Assurance",
      "definition": "Systematic processes to ensure AI systems meet defined standards for accuracy reliability fairness and safety throughout their lifecycle. Extends traditional software QA with ML-specific testing methods.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-race-dynamics",
      "term": "AI Race Dynamics",
      "definition": "The competitive pressures between nations and companies to develop AI capabilities quickly which can lead to cutting corners on safety testing and responsible development practices.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-readiness",
      "term": "AI Readiness",
      "definition": "The skills, knowledge, and mindset needed to use AI tools effectively and responsibly. Includes understanding both capabilities and limitations.",
      "tags": [
        "Fundamentals",
        "Skill"
      ],
      "domain": "general",
      "link": "../tools/index.html",
      "related": []
    },
    {
      "id": "term-ai-readiness-assessment",
      "term": "AI Readiness Assessment",
      "definition": "A structured evaluation of an organization's preparedness to adopt and deploy AI systems responsibly. Covers technical infrastructure data quality skills governance and ethical considerations.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-red-lines",
      "term": "AI Red Lines",
      "definition": "Clearly defined boundaries that AI systems should never cross, such as refusing to assist with creating weapons of mass destruction, generating child sexual abuse material, or undermining democratic processes.",
      "tags": [
        "AI Safety",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-registration",
      "term": "AI Registration",
      "definition": "A proposed requirement that AI systems above a certain capability threshold be registered with a government authority before deployment. Analogous to product registration in pharmaceuticals and aviation.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-regulation-timeline",
      "term": "AI Regulation Timeline",
      "definition": "The chronological progression of AI governance efforts from early ethical guidelines in the 2010s through the EU AI Act, US executive orders, and international summits, representing the maturation of AI policy worldwide.",
      "tags": [
        "History",
        "Regulation"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-regulatory-sandbox",
      "term": "AI Regulatory Sandbox",
      "definition": "A controlled environment established by regulators where AI companies can test innovative products under relaxed regulatory requirements while maintaining safeguards, as provided for in the EU AI Act.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-reliance",
      "term": "AI Reliance",
      "definition": "The degree to which humans depend on AI system outputs for decision-making. Appropriate reliance means using AI recommendations when they improve outcomes and overriding them when they do not.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-rights",
      "term": "AI Rights",
      "definition": "The philosophical and legal question of whether sufficiently advanced AI systems should be granted legal rights or moral standing. Debates draw on animal rights philosophy and corporate personhood precedents.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-risk-assessment",
      "term": "AI Risk Assessment",
      "definition": "A systematic process for identifying evaluating and prioritizing risks associated with an AI system including technical failures ethical harms and societal impacts.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-risk-levels",
      "term": "AI Risk Levels",
      "definition": "A classification scheme, notably used in the EU AI Act, that categorizes AI applications into tiers such as unacceptable risk, high risk, limited risk, and minimal risk, with corresponding regulatory requirements for each tier.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-risk-taxonomy",
      "term": "AI Risk Taxonomy",
      "definition": "A structured classification system for categorizing the types of risks posed by AI systems. Frameworks include NIST AI RMF categories MIT FutureTech risk maps and the EU AI Act risk levels.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-safety",
      "term": "AI Safety",
      "definition": "The field focused on ensuring AI systems behave safely and beneficially. Includes technical research on alignment, governance, and preventing misuse or unintended harms.",
      "tags": [
        "Field",
        "Safety"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-ai-safety-institute",
      "term": "AI Safety Institute",
      "definition": "A government-backed organization, first established by the UK in 2023, dedicated to evaluating and testing frontier AI models for safety risks, with similar institutes subsequently created by the US and other nations.",
      "tags": [
        "Governance",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-safety-research",
      "term": "AI Safety Research",
      "definition": "The field of research dedicated to ensuring that AI systems are safe beneficial and aligned with human values. AI safety encompasses technical alignment research governance frameworks and practical safety engineering for deployed AI systems.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-sandboxing",
      "term": "AI Sandboxing",
      "definition": "The practice of running AI systems in isolated environments with restricted access to networks, resources, and actuators to limit potential harm during testing and evaluation.",
      "tags": [
        "AI Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-security",
      "term": "AI Security",
      "definition": "The practice of protecting AI systems from adversarial attacks data poisoning model theft and other threats. Encompasses both defensive techniques and threat modeling specific to machine learning systems.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-social-contract",
      "term": "AI Social Contract",
      "definition": "The implicit agreement between AI developers deployers users and society about the acceptable uses and limits of AI technology. Draws on social contract theory to frame AI governance obligations.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-spring",
      "term": "AI Spring",
      "definition": "A period of renewed optimism investment and progress in AI research typically referring to the resurgence beginning around 2012 driven by deep learning breakthroughs large datasets and increased computational power from GPUs.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-standards",
      "term": "AI Standards",
      "definition": "Technical specifications and guidelines established by standards bodies for AI system development testing and deployment. Key organizations include ISO IEC IEEE NIST and the OECD.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-supply-chain-security",
      "term": "AI Supply Chain Security",
      "definition": "Measures to ensure the integrity and safety of all components in the AI development pipeline including training data pre-trained models libraries and deployment infrastructure.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-sustainability",
      "term": "AI Sustainability",
      "definition": "The practice of developing and deploying AI systems in ways that are environmentally economically and socially sustainable over the long term. Covers energy efficiency resource use and equitable access.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-talent-pipeline",
      "term": "AI Talent Pipeline",
      "definition": "The system of education training and recruitment that produces qualified AI practitioners. Concentration of AI talent in a few companies and countries raises concerns about equity and safety capacity.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-taxonomy",
      "term": "AI Taxonomy",
      "definition": "A systematic classification of AI systems by capability risk level domain or technology type. Used by regulators to apply differentiated requirements based on the nature and impact of each system.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-testing-standards",
      "term": "AI Testing Standards",
      "definition": "Established methodologies and benchmarks for evaluating AI system performance safety and fairness. Include adversarial testing stress testing bias auditing and performance benchmarking under defined conditions.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-tort-law",
      "term": "AI Tort Law",
      "definition": "The application of tort law principles to AI-related harms. Raises novel questions about duty of care foreseeability causation and liability when autonomous systems cause injury or damage.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-transparency-report",
      "term": "AI Transparency Report",
      "definition": "A public document disclosing information about an organization's AI systems including their capabilities limitations known biases and safety measures. Modeled on corporate social responsibility reporting.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-treaty",
      "term": "AI Treaty",
      "definition": "A proposed international agreement to regulate the development and deployment of AI systems. Discussions draw parallels to nuclear arms control treaties and the Geneva Conventions.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-trust",
      "term": "AI Trust",
      "definition": "The degree to which users and society have confidence that AI systems will behave as expected and in accordance with human values. Built through transparency reliability accountability and demonstrated safety.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-unemployment",
      "term": "AI Unemployment",
      "definition": "The displacement of human workers by AI and automation systems. Economic research suggests AI may transform rather than eliminate most jobs but transition costs and distributional effects raise significant concerns.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-value-lock-in",
      "term": "AI Value Lock-in",
      "definition": "The risk that early AI systems encode specific values or preferences that become difficult to change as systems grow more capable and entrenched. A long-term concern for AI alignment research.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-vulnerability-assessment",
      "term": "AI Vulnerability Assessment",
      "definition": "A systematic evaluation of potential weaknesses in an AI system that could be exploited by adversaries or lead to failure modes. Covers model architecture training data deployment environment and human factors.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-washing",
      "term": "AI Washing",
      "definition": "The practice of companies exaggerating or fabricating the role of AI in their products or services for marketing purposes, misleading consumers and investors about the actual capabilities of their technology.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-water-usage",
      "term": "AI Water Usage",
      "definition": "The water consumption associated with cooling data centers that train and run AI models. Large training runs can consume millions of liters of water raising environmental sustainability concerns.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-weapons-review",
      "term": "AI Weapons Review",
      "definition": "Legal and ethical assessment of autonomous weapon systems under international humanitarian law. Required by Article 36 of Additional Protocol I to the Geneva Conventions for new weapons or means of warfare.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-whistleblowing",
      "term": "AI Whistleblowing",
      "definition": "The act of insiders at AI companies publicly disclosing information about safety concerns, unethical practices, or dangerous capabilities, as seen in open letters and public statements from AI researchers in 2023-2024.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-winter",
      "term": "AI Winter",
      "definition": "Periods of reduced funding and interest in AI research following failed expectations. Notable winters occurred in the 1970s and late 1980s. The current era is considered an AI boom.",
      "tags": [
        "Historical",
        "Industry"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai-workforce-transition",
      "term": "AI Workforce Transition",
      "definition": "Programs and policies to help workers displaced by AI automation acquire new skills and find alternative employment. Includes retraining programs social safety nets and economic diversification strategies.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ai2-allen-institute-for-ai",
      "term": "AI2 (Allen Institute for AI)",
      "definition": "A research institute founded by Paul Allen in 2014 dedicated to AI research for the common good. AI2 has produced influential work including Semantic Scholar the ARC benchmark ELMo and various open-source NLP tools and datasets.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-akaike-information-criterion",
      "term": "Akaike Information Criterion",
      "definition": "A model selection metric that balances goodness of fit with model complexity by adding a penalty proportional to the number of parameters. Lower AIC values indicate a better tradeoff between fit and parsimony.",
      "tags": [
        "Statistics",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-alain-colmerauer",
      "term": "Alain Colmerauer",
      "definition": "French computer scientist who co-created the Prolog programming language in 1972 with Philippe Roussel. Prolog became the primary language for logic programming and was adopted as the core language for the Japanese Fifth Generation Computer Project.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-alan-turing",
      "term": "Alan Turing",
      "definition": "British mathematician and logician (1912-1954) who formalized computation with the Turing machine, broke the Enigma code at Bletchley Park, and proposed the imitation game as a test for machine intelligence.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-alan-turing-institute",
      "term": "Alan Turing Institute",
      "definition": "The United Kingdom's national institute for data science and artificial intelligence founded in 2015. Named after Alan Turing the institute brings together researchers from leading UK universities to advance AI and data science research.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-albert",
      "term": "ALBERT",
      "definition": "A Lite BERT that reduces model size through factorized embedding parameterization and cross-layer parameter sharing while maintaining competitive performance on downstream tasks.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-alec-radford",
      "term": "Alec Radford",
      "definition": "American AI researcher at OpenAI who led the development of GPT (2018) and GPT-2 (2019) demonstrating that unsupervised pre-training of language models on large text corpora produces powerful general-purpose language understanding and generation capabilities.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-alex-krizhevsky",
      "term": "Alex Krizhevsky",
      "definition": "Ukrainian-Canadian computer scientist who designed AlexNet the deep convolutional neural network that won the 2012 ImageNet Large Scale Visual Recognition Challenge by a large margin. This result is widely considered the catalyst for the modern deep learning revolution.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-alexa-launch",
      "term": "Alexa Launch",
      "definition": "Amazon's launch of Alexa and the Echo smart speaker in November 2014, popularizing voice-activated AI assistants in the home and establishing a major platform for ambient computing and smart home control.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-alexnet",
      "term": "AlexNet",
      "definition": "A deep convolutional neural network designed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton that won the 2012 ImageNet competition by a large margin, marking the beginning of the deep learning era in AI.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-algorithm",
      "term": "Algorithm",
      "definition": "A step-by-step procedure or set of rules for solving a problem or accomplishing a task. In AI, algorithms define how models learn from data and make predictions.",
      "tags": [
        "Fundamentals",
        "Computer Science"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-algorithmic-bias",
      "term": "Algorithmic Bias",
      "definition": "Systematic and repeatable errors in computer systems that create unfair outcomes. Algorithmic bias in AI can arise from biased training data biased algorithm design or biased deployment contexts. High-profile examples include facial recognition and criminal justice prediction systems.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-algorithmic-discrimination",
      "term": "Algorithmic Discrimination",
      "definition": "Systematic and unfair differential treatment of individuals or groups by automated decision-making systems, often arising from biased training data, flawed features, or objectives that encode structural inequalities.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-algorithmic-impact-assessment",
      "term": "Algorithmic Impact Assessment",
      "definition": "A formal evaluation process required in some jurisdictions to assess the potential effects of automated decision-making systems on individuals and communities before deployment, particularly for high-stakes applications.",
      "tags": [
        "Governance",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-algorithmic-recourse",
      "term": "Algorithmic Recourse",
      "definition": "The ability of individuals affected by automated decisions to take meaningful actions to change the outcome, such as understanding what inputs to modify to receive a different classification.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-algorithmic-transparency",
      "term": "Algorithmic Transparency",
      "definition": "The degree to which the logic, rules, and data dependencies of an algorithm are made visible and understandable to affected individuals, regulators, and the public.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-alibi",
      "term": "ALiBi",
      "definition": "Attention with Linear Biases, a positional encoding method that adds a linear bias proportional to the distance between key and query positions directly to attention scores, enabling length extrapolation without positional embeddings.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-align",
      "term": "ALIGN",
      "definition": "A Large-scale ImaGe and Noisy-text embedding model trained on over one billion noisy image-text pairs with minimal filtering. Demonstrates that scaling data volume can compensate for noise in the training data.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-alignment",
      "term": "Alignment",
      "definition": "The challenge of ensuring AI systems behave in ways that match human values and intentions. A key concern in AI safety research, involving both technical and philosophical considerations.",
      "tags": [
        "Safety",
        "Research"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-alignment-problem",
      "term": "Alignment Problem",
      "definition": "The fundamental challenge of ensuring that AI systems pursue goals and exhibit behaviors that are consistent with human intentions and values. Central to AI safety research particularly for advanced systems.",
      "tags": [
        "Safety",
        "Fundamentals"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-alignment-research",
      "term": "Alignment Research",
      "definition": "The scientific study of methods to ensure AI systems are aligned with human values and intentions. Includes work on reward modeling interpretability scalable oversight and value learning.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-alignment-tax",
      "term": "Alignment Tax",
      "definition": "The additional cost in performance resources or development time required to make an AI system safe and aligned compared to an unaligned version. High alignment taxes can create incentives to skip safety measures.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-all-gather",
      "term": "All-Gather Operation",
      "definition": "A collective communication pattern where each participant broadcasts its data to all others, so every participant ends up with the complete concatenated dataset. All-gather is used in FSDP to reconstruct full parameters before forward/backward passes.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-all-reduce",
      "term": "All-Reduce Operation",
      "definition": "A collective communication pattern where all participating GPUs contribute data, perform a reduction operation (typically summation), and receive the result. All-reduce is the fundamental communication primitive for synchronizing gradients in data-parallel training.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-allen-institute-for-ai",
      "term": "Allen Institute for AI",
      "definition": "A research institute founded by Paul Allen in 2014 dedicated to conducting high-impact AI research and engineering. Known for projects including Semantic Scholar AI2 Reasoning Challenge and the development of open research tools and datasets.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-allen-newell",
      "term": "Allen Newell",
      "definition": "American computer scientist (1927-1992) who, together with Herbert Simon, developed the Logic Theorist and General Problem Solver, pioneered the physical symbol systems hypothesis, and co-founded the field of AI.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-allocative-harm",
      "term": "Allocative Harm",
      "definition": "Harm that occurs when an AI system unfairly distributes resources, opportunities, or outcomes across different groups, such as denying loans, jobs, or services based on protected characteristics.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-alpac-report",
      "term": "ALPAC Report",
      "definition": "A 1966 report by the Automatic Language Processing Advisory Committee that concluded machine translation was not likely to reach the quality of human translation in the near future. The report led to a significant reduction in US government funding for MT research.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-alpaca",
      "term": "Alpaca",
      "definition": "An early instruction-tuned version of Llama created by Stanford researchers. Demonstrated that instruction-following could be achieved with synthetic data at low cost.",
      "tags": [
        "Model",
        "Historical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-alpacaeval",
      "term": "AlpacaEval",
      "definition": "An automatic evaluation framework that compares model outputs against a reference model using LLM-based pairwise judgments, providing a fast and cost-effective proxy for human evaluation of instruction-following ability with high human agreement rates.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-alpha-beta-pruning",
      "term": "Alpha-Beta Pruning",
      "definition": "An optimization of the minimax algorithm that eliminates branches of the game tree that cannot possibly influence the final decision. Developed independently by several researchers in the 1950s and 1960s it dramatically reduces the number of nodes evaluated in game tree search.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-alphacode",
      "term": "AlphaCode",
      "definition": "A code generation system by DeepMind that solves competitive programming problems at a human-competitive level. Generates millions of candidates then filters and clusters them to find correct solutions.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-alphafold",
      "term": "AlphaFold",
      "definition": "DeepMind's AI system that solved the protein structure prediction problem, winning CASP14 in 2020 and subsequently predicting structures for nearly all known proteins, revolutionizing structural biology.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-alphago",
      "term": "AlphaGo",
      "definition": "A DeepMind system that combined deep neural networks with Monte Carlo tree search to defeat world champion Go players. AlphaGo used supervised learning from human games followed by self-play reinforcement learning to achieve superhuman play.",
      "tags": [
        "Reinforcement Learning",
        "Planning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-alphago-vs-lee-sedol",
      "term": "AlphaGo vs Lee Sedol",
      "definition": "The March 2016 match in which DeepMind's AlphaGo defeated world champion Go player Lee Sedol 4-1, a landmark achievement as Go was long considered too complex for AI due to its vast search space.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-alphazero",
      "term": "AlphaZero",
      "definition": "A generalized version of AlphaGo that learns to play Go, chess, and shogi entirely through self-play without human game data. AlphaZero uses a single neural network for both policy and value prediction combined with MCTS.",
      "tags": [
        "Reinforcement Learning",
        "Planning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-alternative-hypothesis",
      "term": "Alternative Hypothesis",
      "definition": "The hypothesis that contradicts the null hypothesis in statistical testing, typically representing the effect or difference the researcher aims to detect. It can be one-sided or two-sided.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-alvinn",
      "term": "ALVINN",
      "definition": "Autonomous Land Vehicle In a Neural Network developed by Dean Pomerleau at Carnegie Mellon in 1989. One of the earliest demonstrations of using neural networks for autonomous driving ALVINN learned to steer a vehicle by observing human driving behavior.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-am-automated-mathematician",
      "term": "AM (Automated Mathematician)",
      "definition": "An AI program written by Douglas Lenat in 1976 that discovered mathematical concepts by exploring modifications to existing concepts. AM demonstrated automated discovery in mathematics though debates about its reliance on hand-coded heuristics continued for years.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-amazon-bedrock",
      "term": "Amazon Bedrock",
      "definition": "AWS's managed service for accessing foundation models from multiple providers. Offers Claude, Llama, and other models through a unified API with enterprise features.",
      "tags": [
        "Platform",
        "Cloud"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-amd-mi300x",
      "term": "AMD MI300X",
      "definition": "AMD's data center GPU accelerator featuring 192GB HBM3 memory and CDNA 3 architecture, competing with NVIDIA's H100 for AI training and inference. The MI300X offers the largest memory capacity of any GPU accelerator.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-amplification",
      "term": "Amplification",
      "definition": "A scalable oversight technique where human supervisors are augmented by AI assistants to evaluate AI behavior on complex tasks. Proposed by Christiano et al. as a way to maintain human oversight as AI capabilities grow.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-analogical-prompting",
      "term": "Analogical Prompting",
      "definition": "A technique that asks the model to generate relevant analogous problems and their solutions before tackling the target problem, leveraging self-generated exemplars to guide reasoning without requiring manually crafted few-shot examples.",
      "tags": [
        "Prompt Engineering",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-anaphora-resolution",
      "term": "Anaphora Resolution",
      "definition": "The task of determining which previously mentioned entity a pronoun or other referring expression points back to in a text, a subproblem of coreference resolution.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-anchor",
      "term": "Anchor (Prompting)",
      "definition": "A reference point or example in a prompt that guides the AI's response style or format. Anchors help establish expectations for output quality and structure.",
      "tags": [
        "Prompting",
        "Technique"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-anchor-box",
      "term": "Anchor Box",
      "definition": "A predefined set of bounding boxes with various aspect ratios and scales placed at each spatial location in a feature map, serving as reference shapes that object detectors adjust to fit actual objects.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-anchoring-bias-in-ai",
      "term": "Anchoring Bias in AI",
      "definition": "A cognitive bias where initial AI-generated suggestions disproportionately influence subsequent human decisions, causing users to adjust insufficiently from the AI's initial output.",
      "tags": [
        "AI Ethics",
        "Fairness"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-anchoring-effect-in-ai",
      "term": "Anchoring Effect in AI",
      "definition": "A cognitive bias where users over-rely on the first piece of information provided by an AI system. Can lead to poor decision-making when AI outputs are presented as initial recommendations.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-andrej-karpathy",
      "term": "Andrej Karpathy",
      "definition": "Slovak-Canadian AI researcher who led computer vision at Tesla Autopilot and later worked at OpenAI. Known for educational contributions to deep learning through Stanford CS231n course and for developing character-level language models and neural network visualization tools.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-andrew-barto",
      "term": "Andrew Barto",
      "definition": "American computer scientist who co-authored the influential textbook Reinforcement Learning: An Introduction with Richard Sutton. Pioneer of reinforcement learning at the University of Massachusetts Amherst contributing foundational work on actor-critic methods and intrinsic motivation.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-andrew-ng",
      "term": "Andrew Ng",
      "definition": "British-American computer scientist who co-founded Google Brain, led AI at Baidu, founded Coursera and deeplearning.ai, and popularized deep learning education, becoming one of the most influential figures in making AI accessible.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-animatediff",
      "term": "AnimateDiff",
      "definition": "A framework for animating personalized text-to-image models by inserting motion modules into the existing architecture. Enables video generation from any fine-tuned image generation model without video-specific training.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ann-benchmark",
      "term": "ANN Benchmark",
      "definition": "Standardized evaluation suites for comparing approximate nearest neighbor algorithms across metrics like recall, queries per second, and index build time on reference datasets, enabling fair performance comparison between different vector search implementations.",
      "tags": [
        "Vector Database",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-annotation",
      "term": "Annotation",
      "definition": "The process of labeling data to create training datasets for supervised learning. Human annotators add labels, categories, or descriptions to raw data like text, images, or audio.",
      "tags": [
        "Data",
        "Training"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-annotation-labor-ethics",
      "term": "Annotation Labor Ethics",
      "definition": "Ethical concerns about the working conditions, compensation, and psychological impacts experienced by data annotation workers who label training data for AI systems, often exposed to disturbing content.",
      "tags": [
        "AI Ethics",
        "Fairness"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-annoy",
      "term": "Annoy",
      "definition": "Approximate Nearest Neighbors Oh Yeah, an open-source library by Spotify that builds forest-of-trees indexes using random hyperplane splits for fast approximate nearest neighbor search, optimized for memory-mapped read-only access and static datasets.",
      "tags": [
        "Vector Database",
        "Libraries"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-anomaly-detection",
      "term": "Anomaly Detection",
      "definition": "Identifying unusual patterns or outliers in data that don't conform to expected behavior. Used in fraud detection, system monitoring, and quality control.",
      "tags": [
        "ML Task",
        "Application"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-anomaly-detection-for-safety",
      "term": "Anomaly Detection for Safety",
      "definition": "The use of anomaly detection techniques to identify unusual or potentially unsafe AI system behavior in deployment. Serves as an early warning system for distribution shift or adversarial attacks.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-anomaly-detection-images",
      "term": "Anomaly Detection in Images",
      "definition": "The task of identifying unusual patterns, defects, or out-of-distribution samples in images, widely used in industrial quality inspection and medical imaging to detect abnormalities.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-anova",
      "term": "ANOVA",
      "definition": "Analysis of Variance, a statistical method that tests whether the means of three or more groups are significantly different by comparing within-group variance to between-group variance using the F-statistic.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-answer-engineering",
      "term": "Answer Engineering",
      "definition": "Designing prompts to elicit specific response formats or structured outputs. Complements prompt engineering by focusing on how answers should be structured.",
      "tags": [
        "Prompting",
        "Technique"
      ],
      "domain": "general",
      "link": "../learn/crisp.html",
      "related": []
    },
    {
      "id": "term-ant-colony-optimization",
      "term": "Ant Colony Optimization",
      "definition": "A metaheuristic optimization algorithm proposed by Marco Dorigo in 1992, inspired by the foraging behavior of ants using pheromone trails, applied to combinatorial optimization problems like the traveling salesman problem.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-anthropic",
      "term": "Anthropic",
      "definition": "An AI safety company founded in 2021 by former OpenAI researchers. Creator of the Claude family of AI assistants, focused on developing safe and beneficial AI systems.",
      "tags": [
        "Company",
        "LLM Provider"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-anthropic-founding",
      "term": "Anthropic Founding",
      "definition": "The founding of Anthropic in 2021 by former OpenAI researchers Dario and Daniela Amodei, establishing a safety-focused AI company that developed Constitutional AI and the Claude family of AI assistants.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-anthropomorphism-risk",
      "term": "Anthropomorphism Risk",
      "definition": "The danger that designing AI systems with human-like characteristics leads users to attribute human emotions intentions and reliability to systems that lack these qualities.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-anti-discrimination-law-in-ai",
      "term": "Anti-Discrimination Law in AI",
      "definition": "Legal frameworks that prohibit AI systems from discriminating against individuals based on protected characteristics such as race gender age disability or religion.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-api",
      "term": "API (Application Programming Interface)",
      "definition": "A set of protocols that allows different software applications to communicate. AI APIs enable developers to integrate AI capabilities into their applications without building models from scratch.",
      "tags": [
        "Technical",
        "Integration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-apple-neural-engine",
      "term": "Apple Neural Engine",
      "definition": "Apple's dedicated neural network accelerator integrated into Apple Silicon chips (M-series and A-series), delivering up to 38 TOPS for on-device inference. The Neural Engine enables real-time AI features like Face ID, live text, and on-device language models.",
      "tags": [
        "Hardware",
        "Inference Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-appropriate-reliance",
      "term": "Appropriate Reliance",
      "definition": "The calibrated level of trust humans should place in AI systems, avoiding both over-reliance that leads to automation complacency and under-reliance that fails to leverage AI capabilities.",
      "tags": [
        "AI Ethics",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-approximate-nearest-neighbor",
      "term": "Approximate Nearest Neighbor",
      "definition": "A class of search algorithms that find vectors approximately closest to a query vector with high probability rather than guaranteeing exact results, achieving orders-of-magnitude speedups over exact search by accepting a controllable recall trade-off.",
      "tags": [
        "Vector Database",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-arc-benchmark",
      "term": "ARC Benchmark",
      "definition": "The AI2 Reasoning Challenge, a question-answering benchmark consisting of elementary and middle school science exam questions in easy and challenge sets, testing scientific reasoning and world knowledge in language models.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-arcface",
      "term": "ArcFace",
      "definition": "A face recognition loss function that adds an angular margin penalty in the normalized feature space, improving the discriminative power of face embeddings for accurate identity verification.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-architecture-search",
      "term": "Architecture Search (NAS)",
      "definition": "Automated methods for discovering optimal neural network architectures. Can find better designs than human-created networks but requires significant computational resources.",
      "tags": [
        "Research",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-arena-score",
      "term": "Arena Score",
      "definition": "A model ranking metric derived from competitive evaluation platforms where models are compared in blind pairwise matchups with human judges, producing a leaderboard rating that reflects aggregate model quality across diverse tasks.",
      "tags": [
        "Evaluation",
        "Ranking"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-arima",
      "term": "ARIMA",
      "definition": "AutoRegressive Integrated Moving Average, a class of time series models combining autoregression (AR), differencing for stationarity (I), and moving average (MA) components. It is widely used for univariate time series forecasting.",
      "tags": [
        "Machine Learning",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-arithmetic-intensity",
      "term": "Arithmetic Intensity",
      "definition": "The ratio of floating-point operations to bytes of memory accessed in a computation, determining whether performance is limited by compute or memory bandwidth. LLM inference has low arithmetic intensity, making it typically memory-bandwidth-bound.",
      "tags": [
        "Hardware",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-arthur-samuel",
      "term": "Arthur Samuel",
      "definition": "American computer scientist (1901-1990) who created a checkers-playing program at IBM in 1959 that learned through self-play, coining the term machine learning and pioneering the field of game-playing AI.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-artificial-general-intelligence-history",
      "term": "Artificial General Intelligence History",
      "definition": "The pursuit of machines that can understand learn and apply knowledge across any intellectual task that humans can. From the original aspirations of the Dartmouth Conference through decades of research AGI remains an open challenge and active area of development.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-artificial-intelligence-a-modern-approach",
      "term": "Artificial Intelligence: A Modern Approach",
      "definition": "The standard AI textbook by Stuart Russell and Peter Norvig first published in 1995. Used in over 1500 universities in 135 countries the book covers AI comprehensively from search and logic to machine learning and robotics. Now in its fourth edition.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-artificial-life",
      "term": "Artificial Life",
      "definition": "A field of study that examines systems related to natural life their processes and their evolution through the use of simulations and models. Pioneered by Christopher Langton in the late 1980s artificial life explores self-organization emergence and evolutionary dynamics.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-artificial-neuron",
      "term": "Artificial Neuron",
      "definition": "The basic computational unit in neural networks, loosely inspired by biological neurons. Computes a weighted sum of inputs, applies an activation function, and outputs the result.",
      "tags": [
        "Architecture",
        "Fundamentals"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ashish-vaswani",
      "term": "Ashish Vaswani",
      "definition": "Lead author of the 2017 Attention Is All You Need paper that introduced the transformer architecture at Google Brain, fundamentally changing the trajectory of natural language processing and AI research.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-asic-ai",
      "term": "ASIC for AI",
      "definition": "Application-Specific Integrated Circuits designed exclusively for AI computation, offering maximum performance and energy efficiency for fixed workloads. AI ASICs like Google's TPU sacrifice programmability for orders-of-magnitude improvements in performance per watt.",
      "tags": [
        "Hardware",
        "Inference Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-asilomar-ai-principles",
      "term": "Asilomar AI Principles",
      "definition": "A set of 23 principles for beneficial AI research developed at the 2017 Asilomar conference, covering research issues, ethics and values, and longer-term concerns about advanced AI safety.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-aspect-based-sentiment",
      "term": "Aspect-Based Sentiment Analysis",
      "definition": "A fine-grained sentiment analysis task that identifies sentiment toward specific aspects or features of an entity, distinguishing different opinions about different attributes within the same text.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-assistant-message",
      "term": "Assistant Message",
      "definition": "In chat APIs, the AI's response in a conversation. Combined with system and user messages to form the complete conversation context for generating the next response.",
      "tags": [
        "API",
        "Technical"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-assistive-ai-ethics",
      "term": "Assistive AI Ethics",
      "definition": "Ethical considerations specific to AI systems designed to assist people with disabilities. Includes concerns about autonomy dignity dependency and the risk of reducing complex human needs to technical solutions.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-a3c",
      "term": "Asynchronous Advantage Actor-Critic (A3C)",
      "definition": "An actor-critic algorithm that runs multiple agent instances in parallel on separate environment copies, each asynchronously updating shared parameters. A3C stabilizes training through decorrelated parallel experience streams.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-async-generation",
      "term": "Asynchronous Generation",
      "definition": "Running multiple AI inference requests in parallel rather than waiting for each to complete. Improves throughput for applications handling many concurrent users.",
      "tags": [
        "Technical",
        "Production"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-asynchronous-sgd",
      "term": "Asynchronous SGD",
      "definition": "A distributed training approach where workers compute and apply gradients independently without waiting for synchronization, trading gradient staleness for higher throughput. Asynchronous SGD can suffer from convergence issues due to stale updates.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-atrous-convolution",
      "term": "Atrous Convolution",
      "definition": "Also known as dilated convolution, a convolution operation that inserts gaps between filter elements to increase the receptive field without adding parameters or reducing spatial resolution.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-economy-and-ai",
      "term": "Attention Economy and AI",
      "definition": "The intersection of AI-driven content recommendation systems and the competition for human attention. AI amplifies engagement optimization which can conflict with user wellbeing and informed choice.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-head-pruning",
      "term": "Attention Head Pruning",
      "definition": "A model compression technique that removes redundant or less important attention heads from a multi-head attention mechanism, reducing computation with minimal impact on performance.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-is-all-you-need",
      "term": "Attention Is All You Need",
      "definition": "The landmark 2017 paper by Vaswani et al. that introduced the transformer architecture, replacing recurrence with self-attention mechanisms and enabling the massive scaling that underpins modern large language models.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-mask",
      "term": "Attention Mask",
      "definition": "A binary or float tensor applied to attention scores before softmax to prevent the model from attending to certain positions, such as padding tokens or future tokens in causal generation.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-masking",
      "term": "Attention Masking",
      "definition": "A technique that prevents attention from attending to certain positions by setting their attention scores to negative infinity before softmax. Used for causal masking in autoregressive models and padding masking in batched processing.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-mechanism",
      "term": "Attention Mechanism",
      "definition": "A neural network component that allows the model to focus on relevant parts of the input when producing output. Computes weighted sums of values where weights are determined by compatibility between queries and keys. Foundational to transformer architecture.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-mechanism-history",
      "term": "Attention Mechanism History",
      "definition": "The development of attention mechanisms from Bahdanau et al.'s 2014 neural machine translation work through the self-attention innovation in the 2017 transformer paper, which became the foundation of modern large language models.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-pooling",
      "term": "Attention Pooling",
      "definition": "A pooling mechanism that uses learned attention weights to aggregate features, allowing the model to focus on the most informative elements rather than using fixed averaging or max operations.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-score",
      "term": "Attention Score",
      "definition": "The raw compatibility value computed between a query and key vector, typically via scaled dot product, before softmax normalization, indicating how much one token should attend to another.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-sink",
      "term": "Attention Sink",
      "definition": "A phenomenon where initial tokens in a sequence receive disproportionately high attention scores regardless of content, discovered to be important for maintaining generation quality in streaming and infinite-length settings.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-visualization",
      "term": "Attention Visualization",
      "definition": "A model interpretability technique that displays attention weight patterns as heatmaps showing which input tokens the model attends to when making predictions. Useful for understanding transformer behavior though interpretation requires caution.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-based-parsing",
      "term": "Attention-Based Parsing",
      "definition": "A parsing approach that uses attention mechanisms from neural networks to determine syntactic structure, often achieving state-of-the-art results by attending over possible head words or constituents.",
      "tags": [
        "NLP",
        "Parsing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-based-policy",
      "term": "Attention-Based Policy",
      "definition": "An RL policy architecture that uses attention mechanisms to selectively focus on relevant parts of the observation or memory. Attention-based policies excel in environments with variable-size inputs or complex relational structure.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-attention-based-translation",
      "term": "Attention-Based Translation",
      "definition": "A neural machine translation approach where the decoder attends to different parts of the source sentence at each generation step, eliminating the information bottleneck of fixed-length encoding.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-attribution-in-ai",
      "term": "Attribution in AI",
      "definition": "The ability to trace AI system outputs back to their sources including training data model components and design decisions. Important for accountability transparency and intellectual property protection.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-auc",
      "term": "AUC",
      "definition": "Area Under the ROC Curve, a scalar metric summarizing classifier performance across all thresholds. An AUC of 1.0 indicates perfect classification, while 0.5 indicates performance equivalent to random guessing.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-auc-pr",
      "term": "AUC-PR",
      "definition": "Area Under the Precision-Recall Curve measures classifier performance focusing on the positive class. More informative than AUC-ROC for imbalanced datasets. Baseline equals the proportion of positive samples in the dataset.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-auc-roc",
      "term": "AUC-ROC",
      "definition": "Area Under the Receiver Operating Characteristic Curve measures a classifier's ability to distinguish between classes across all threshold values. Ranges from 0 to 1 with 0.5 indicating random performance. Threshold-independent evaluation metric.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-audio-generation",
      "term": "Audio Generation",
      "definition": "AI that creates speech, music, or sound effects from text or other inputs. Includes text-to-speech (TTS), music generation, and sound design applications.",
      "tags": [
        "Application",
        "Generative"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-audiolm",
      "term": "AudioLM",
      "definition": "A language model for audio generation by Google that treats audio as a sequence of discrete tokens. Generates natural-sounding speech and music with long-term coherence by modeling both semantic and acoustic tokens.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-audit-trail-for-ai",
      "term": "Audit Trail for AI",
      "definition": "A chronological record of all decisions actions and changes related to an AI system throughout its lifecycle. Essential for accountability regulatory compliance and incident investigation.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-auditability",
      "term": "Auditability",
      "definition": "The property of an AI system that allows independent third parties to examine its data, algorithms, models, and decision-making processes to assess compliance with standards, fairness criteria, and regulatory requirements.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-augmentation",
      "term": "Augmentation",
      "definition": "Expanding training data by creating modified versions of existing examples. In text: paraphrasing, back-translation. In images: rotation, cropping, color changes.",
      "tags": [
        "Training",
        "Data"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-augmented-dickey-fuller-test",
      "term": "Augmented Dickey-Fuller Test",
      "definition": "A statistical test for determining whether a unit root is present in a time series, which would indicate non-stationarity. A significant test statistic leads to rejection of the null hypothesis of a unit root.",
      "tags": [
        "Data Science",
        "Statistics"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-auto-complete",
      "term": "Auto-Complete",
      "definition": "AI feature that predicts and suggests text as you type. Powers writing assistants, code completion, and search suggestions. Based on language model predictions.",
      "tags": [
        "Application",
        "Feature"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-autoaugment",
      "term": "AutoAugment",
      "definition": "An automated augmentation policy search method that uses reinforcement learning to find optimal combinations and magnitudes of augmentation operations for a given dataset and task.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-autocorrelation",
      "term": "Autocorrelation",
      "definition": "The correlation of a time series with a lagged version of itself. In regression, autocorrelated residuals violate the independence assumption and can lead to inefficient estimates and unreliable hypothesis tests.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-autocorrelation-function",
      "term": "Autocorrelation Function",
      "definition": "A function that measures the correlation between a time series and a lagged version of itself at various time delays. It is used to identify repeating patterns, periodicity, and appropriate model orders.",
      "tags": [
        "Data Science",
        "Statistics"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-autoencoder",
      "term": "Autoencoder",
      "definition": "A neural network that learns to compress data into a smaller representation and then reconstruct it. Used for dimensionality reduction, denoising, and learning efficient data representations.",
      "tags": [
        "Architecture",
        "Unsupervised"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-autoencoder-history",
      "term": "Autoencoder History",
      "definition": "The development of autoencoders from early work on data compression (Hinton and Salakhutdinov 2006) through denoising autoencoders (Vincent et al. 2008) variational autoencoders (Kingma and Welling 2013) to modern representation learning applications.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-autogen",
      "term": "AutoGen",
      "definition": "Microsoft's framework for building multi-agent AI applications. Enables conversations between multiple AI agents that can collaborate, debate, and solve complex problems together.",
      "tags": [
        "Framework",
        "Application"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-automated-theorem-proving",
      "term": "Automated Theorem Proving",
      "definition": "The use of computers to prove mathematical theorems automatically. Beginning with the Logic Theorist in 1956 automated theorem proving has advanced through resolution-based methods (1960s) to modern systems that can discover novel mathematical proofs.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-automatic-chain-of-thought",
      "term": "Automatic Chain-of-Thought",
      "definition": "A method that automatically constructs chain-of-thought demonstrations by clustering questions and selecting representative examples, then using the model to generate reasoning chains, eliminating the need for manual rationale annotation.",
      "tags": [
        "Prompt Engineering",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-automatic-differentiation",
      "term": "Automatic Differentiation",
      "definition": "A family of techniques for efficiently computing derivatives of numerical functions by decomposing them into elementary operations. Includes forward mode and reverse mode. The foundation of gradient computation in all modern deep learning frameworks.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-automatic-prompt-engineer",
      "term": "Automatic Prompt Engineer",
      "definition": "An automated method (APE) that uses language models to generate, score, and select optimal prompt instructions for a given task, effectively searching the space of possible prompts to find high-performing candidates without manual engineering.",
      "tags": [
        "Prompt Engineering",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-asr",
      "term": "Automatic Speech Recognition",
      "definition": "The technology that converts spoken language audio into text, using acoustic models, language models, and decoding algorithms to transcribe speech signals.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-automation-bias",
      "term": "Automation Bias",
      "definition": "The human tendency to over-rely on automated systems and accept their outputs without sufficient critical evaluation, even when contradicted by other evidence. This is a significant concern in human-AI teaming.",
      "tags": [
        "AI Ethics",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-auto-ml",
      "term": "AutoML",
      "definition": "Automated machine learning tools that handle model selection, hyperparameter tuning, and feature engineering. Makes ML accessible to non-experts and speeds up development.",
      "tags": [
        "Tools",
        "Automation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-autonomous-weapons-debate",
      "term": "Autonomous Weapons Debate",
      "definition": "The ongoing international debate about the development and use of lethal autonomous weapons systems (LAWS) that can select and engage targets without human intervention. Discussions involve military ethical legal and technical dimensions of AI in warfare.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-autonomous-weapons-systems",
      "term": "Autonomous Weapons Systems",
      "definition": "Weapons systems that can select and engage targets without direct human intervention, raising profound ethical and legal questions about accountability, proportionality, and the role of human judgment in lethal decisions.",
      "tags": [
        "AI Ethics",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-autoregressive-model",
      "term": "Autoregressive Model",
      "definition": "A time series model that predicts the current value as a linear combination of its own past values plus a noise term. The order p specifies how many lagged values are used as predictors.",
      "tags": [
        "Data Science",
        "Statistics"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-auxiliary-loss",
      "term": "Auxiliary Loss",
      "definition": "Additional loss terms added during training to help learning. Can improve training stability, add regularization, or encourage specific behaviors in the model.",
      "tags": [
        "Training",
        "Advanced"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-auxiliary-task-rl",
      "term": "Auxiliary Task in RL",
      "definition": "An additional prediction or control objective trained alongside the main RL objective to improve representation learning. Auxiliary tasks like pixel prediction, reward prediction, or value replay provide extra gradient signal that enriches learned features.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-average-pooling",
      "term": "Average Pooling",
      "definition": "A technique that reduces data dimensionality by computing the average of regions. Used in CNNs and for creating fixed-size representations from variable-length sequences.",
      "tags": [
        "Architecture",
        "Technique"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-average-precision",
      "term": "Average Precision",
      "definition": "A single-number summary of the precision-recall curve, computed as the weighted mean of precisions at each threshold with the increase in recall as the weight. It is equivalent to the area under the precision-recall curve.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-awq",
      "term": "AWQ",
      "definition": "Activation-aware Weight Quantization, a method that identifies and preserves salient weight channels based on activation magnitudes, enabling efficient low-bit quantization of large language models.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-aws-inferentia",
      "term": "AWS Inferentia",
      "definition": "Amazon's purpose-built inference accelerator chip designed for high-throughput, low-cost ML inference in the cloud. Inferentia provides up to 2x better throughput per watt than comparable GPU instances for transformer model inference.",
      "tags": [
        "Hardware",
        "Inference Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-aws-sagemaker",
      "term": "AWS SageMaker",
      "definition": "Amazon's ML platform for building, training, and deploying models. Provides infrastructure, tools, and pre-built algorithms for the complete ML lifecycle.",
      "tags": [
        "Platform",
        "Cloud"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-aws-trainium",
      "term": "AWS Trainium",
      "definition": "Amazon's custom AI training accelerator chip offering high-performance, cost-effective alternatives to NVIDIA GPUs for deep learning training. Trainium integrates with AWS Neuron SDK and supports distributed training across large clusters.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-azure-openai",
      "term": "Azure OpenAI Service",
      "definition": "Microsoft's enterprise offering of OpenAI models through Azure cloud. Provides GPT-4, ChatGPT, and DALL-E with enterprise security, compliance, and regional availability.",
      "tags": [
        "Platform",
        "Cloud"
      ],
      "domain": "general",
      "link": null,
      "related": []
    }
  ]
}