{
  "letter": "f",
  "count": 198,
  "terms": [
    {
      "id": "term-f-distribution",
      "term": "F-Distribution",
      "definition": "A continuous probability distribution arising as the ratio of two independent chi-square distributions, each divided by their degrees of freedom. It is the basis for the F-test used in ANOVA and regression analysis.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-f1-score",
      "term": "F1 Score",
      "definition": "A metric combining precision and recall into a single score (their harmonic mean). Useful for evaluating classification models, especially with imbalanced datasets.",
      "tags": [
        "Metrics",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fab-fabrication-plant",
      "term": "Fab (Fabrication Plant)",
      "definition": "Semiconductor manufacturing facility containing the equipment and clean rooms needed to produce chips. Building a leading-edge fab costs over 20 billion dollars and takes several years.",
      "tags": [
        "Fabrication",
        "Manufacturing",
        "Facility"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-face-detection",
      "term": "Face Detection",
      "definition": "The task of locating and bounding all human faces in an image regardless of pose, scale, or occlusion, using specialized object detection architectures optimized for the face domain.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-face-recognition",
      "term": "Face Recognition",
      "definition": "A biometric identification task that determines the identity of a person from their facial features, using deep learning models to extract face embeddings and compare them against a database of known identities.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-face-verification",
      "term": "Face Verification",
      "definition": "A one-to-one matching task that determines whether two face images belong to the same person by comparing their face embeddings, typically using a distance threshold for the accept/reject decision.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-facechain",
      "term": "FaceChain",
      "definition": "An open-source tool and model pipeline for generating personalized portrait images with identity preservation using fine-tuning and face-aware generation.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-facial-landmark-detection",
      "term": "Facial Landmark Detection",
      "definition": "The task of predicting the precise locations of key facial points (eyes, nose, mouth corners, jawline) in an image, used for face alignment, expression recognition, and augmented reality applications.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-facial-recognition-ethics",
      "term": "Facial Recognition Ethics",
      "definition": "The ethical debate around AI-powered facial recognition technology, encompassing concerns about surveillance, racial bias in accuracy, consent, civil liberties, and bans enacted by various municipalities.",
      "tags": [
        "AI Ethics",
        "Fairness"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-factor-analysis",
      "term": "Factor Analysis",
      "definition": "A statistical method that models observed variables as linear combinations of latent factors plus noise. Unlike PCA it explicitly models observation noise. Used to identify underlying structure in high-dimensional data and reduce measurement error.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-factor-analysis-algorithm",
      "term": "Factor Analysis Algorithm",
      "definition": "A statistical method that models observed variables as linear combinations of a smaller number of unobserved latent factors plus noise. Unlike PCA it distinguishes between shared variance and unique variance.",
      "tags": [
        "Algorithms",
        "Technical",
        "Dimensionality Reduction"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-factorized-embedding",
      "term": "Factorized Embedding",
      "definition": "A technique that decomposes the embedding matrix into two smaller matrices, separating the vocabulary embedding dimension from the hidden dimension to reduce parameter count.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-factual-consistency",
      "term": "Factual Consistency",
      "definition": "An evaluation metric that measures whether claims in generated text are logically entailed by and consistent with source documents or verifiable facts, often assessed using natural language inference models or fact-checking pipelines.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-factual-grounding",
      "term": "Factual Grounding",
      "definition": "The process of anchoring a language model's responses to verified source documents or knowledge bases, ensuring outputs are supported by retrievable evidence rather than parametric memory alone.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-factuality",
      "term": "Factuality",
      "definition": "The degree to which AI outputs are accurate and true. A major challenge for LLMs, which can generate plausible-sounding but incorrect information (hallucinations).",
      "tags": [
        "Quality",
        "Challenge"
      ],
      "domain": "general",
      "link": "../tools/hallucination.html",
      "related": []
    },
    {
      "id": "term-factuality-evaluation",
      "term": "Factuality Evaluation",
      "definition": "Methods for assessing whether AI-generated text contains accurate and verifiable information. Includes automated fact-checking knowledge-grounded evaluation and citation verification techniques.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-fail-safe-design",
      "term": "Fail-Safe Design",
      "definition": "An engineering approach where AI systems default to a safe state when they encounter errors or unexpected conditions. Ensures that system failures do not lead to dangerous or harmful outcomes.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-failure-mode-analysis",
      "term": "Failure Mode Analysis",
      "definition": "A systematic technique for identifying potential failure modes of an AI system and their effects on system behavior and user safety. Adapted from traditional engineering FMEA for machine learning systems.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-fair-founded",
      "term": "FAIR Founded",
      "definition": "The founding of Facebook AI Research (FAIR) in 2013 led by Yann LeCun. FAIR became one of the leading industrial AI research laboratories contributing significant advances in computer vision natural language processing and open-source AI tools including PyTorch.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-fair-machine-learning",
      "term": "Fair Machine Learning",
      "definition": "The subfield of machine learning focused on developing models and algorithms that produce equitable outcomes across different demographic groups. Encompasses both technical methods and sociotechnical approaches.",
      "tags": [
        "Safety",
        "Fundamentals"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-fairface",
      "term": "FairFace",
      "definition": "A face attribute dataset balanced across 7 racial groups for reducing bias in face analysis. Provides annotations for race gender and age to support fairness-aware computer vision.",
      "tags": [
        "Benchmark",
        "Computer Vision",
        "Fairness"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fairness",
      "term": "Fairness (AI)",
      "definition": "The principle that AI systems should not discriminate or produce biased outcomes across different demographic groups. Multiple mathematical definitions exist, sometimes in tension with each other.",
      "tags": [
        "Ethics",
        "Safety"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-fairness-constraint",
      "term": "Fairness Constraint",
      "definition": "A mathematical condition imposed during model training or post-processing to ensure that predictions satisfy a specified fairness criterion. Examples include parity constraints and calibration requirements.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-fairness-in-machine-learning",
      "term": "Fairness in Machine Learning",
      "definition": "The study of how to ensure machine learning systems treat individuals and groups equitably. Research on ML fairness addresses multiple definitions of fairness (demographic parity equalized odds individual fairness) and techniques for achieving them.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-fairness-through-awareness",
      "term": "Fairness Through Awareness",
      "definition": "A fairness framework proposed by Dwork et al. in 2012 that requires similar individuals to be treated similarly by an algorithm. Uses a task-specific metric to define similarity between individuals.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-fairness-through-unawareness",
      "term": "Fairness Through Unawareness",
      "definition": "A naive fairness approach that simply removes protected attributes from model inputs. Generally insufficient because other features can serve as proxies for protected characteristics.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-faiss",
      "term": "FAISS",
      "definition": "Facebook AI Similarity Search, an open-source library developed by Meta that provides highly optimized implementations of vector similarity search and clustering algorithms, supporting billion-scale datasets with GPU acceleration and multiple index types.",
      "tags": [
        "Vector Database",
        "Libraries"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-faiss-algorithm",
      "term": "FAISS Algorithm",
      "definition": "Facebook AI Similarity Search provides efficient algorithms for searching large collections of dense vectors. Supports exact and approximate nearest-neighbor search using product quantization and inverted file indexes.",
      "tags": [
        "Algorithms",
        "Technical",
        "Searching",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-faithdial",
      "term": "FaithDial",
      "definition": "A benchmark for evaluating faithfulness in knowledge-grounded dialogue. Tests whether dialogue systems generate responses consistent with provided knowledge sources.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation",
        "Dialogue"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-faithful-chain-of-thought",
      "term": "Faithful Chain-of-Thought",
      "definition": "A reasoning framework that decomposes questions into interleaved natural language reasoning and symbolic operations, ensuring that the reasoning chain is faithful to the actual computation by grounding intermediate steps in executable code.",
      "tags": [
        "Prompt Engineering",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-faithfulness",
      "term": "Faithfulness",
      "definition": "An evaluation dimension that measures whether generated text contains only information that is supported by and consistent with the provided source context, with unfaithful content indicating hallucination or fabrication.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-faker",
      "term": "Faker",
      "definition": "A Python library for generating synthetic structured data including names addresses and dates. Used for creating test data and populating databases with realistic fake information.",
      "tags": [
        "Synthetic",
        "Platform"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-falcon",
      "term": "Falcon",
      "definition": "A family of open-source language models developed by the Technology Innovation Institute in Abu Dhabi. Trained on the RefinedWeb dataset. Falcon-180B was one of the largest open models at release.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-falcon-180b",
      "term": "Falcon 180B",
      "definition": "A 180 billion parameter language model from the Technology Innovation Institute that was one of the largest openly available models at its release.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-falcon-2",
      "term": "Falcon 2",
      "definition": "A second-generation open-weight language model from the Technology Innovation Institute with improved training data and multilingual capabilities.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-falconmamba",
      "term": "FalconMamba",
      "definition": "A state space model from TII that applies the Mamba architecture at scale with 7B parameters for efficient language modeling.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-false-discovery-rate",
      "term": "False Discovery Rate",
      "definition": "The expected proportion of false positives among all rejected null hypotheses in multiple testing. The Benjamini-Hochberg procedure controls FDR and is less conservative than the Bonferroni correction.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-false-positive",
      "term": "False Positive / False Negative",
      "definition": "Classification errors: false positives incorrectly predict the positive class; false negatives miss actual positives. The trade-off between them depends on application costs.",
      "tags": [
        "Metrics",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fan",
      "term": "Fan",
      "definition": "Active cooling device that moves air across heat sinks and through computing enclosures. Multiple high-speed fans are used in GPU servers to maintain adequate airflow for AI workloads.",
      "tags": [
        "Cooling",
        "Component",
        "Active"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-fan-out-wafer-level-packaging",
      "term": "Fan-Out Wafer-Level Packaging",
      "definition": "Advanced packaging technique that redistributes chip connections over a larger area than the die itself. Enables thin compact packages for mobile AI processors and edge devices.",
      "tags": [
        "Packaging",
        "Manufacturing",
        "Mobile"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-fashion-mnist",
      "term": "Fashion-MNIST",
      "definition": "A drop-in replacement for MNIST containing 70000 grayscale images of clothing items in 10 categories. Created by Zalando Research to provide a more challenging benchmark than handwritten digits.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fast-fourier-transform",
      "term": "Fast Fourier Transform",
      "definition": "An efficient algorithm for computing the discrete Fourier transform that reduces computational complexity from O(n^2) to O(n log n). Discovered by Cooley and Tukey in 1965. Essential for real-time signal processing and frequency analysis.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fast-multipole-method",
      "term": "Fast Multipole Method",
      "definition": "An algorithm that accelerates the evaluation of long-range forces in N-body problems from O(N^2) to O(N) by grouping distant sources. One of the top ten algorithms of the twentieth century.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical",
        "History"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-faster-rcnn",
      "term": "Faster R-CNN",
      "definition": "A two-stage object detection framework that uses a Region Proposal Network (RPN) to generate candidate bounding boxes, followed by a classification and regression head for final detection.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-fastflow",
      "term": "FastFlow",
      "definition": "A normalizing-flow-based anomaly detection model that estimates the distribution of visual features from a pre-trained network for industrial defect detection.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fastspeech-2",
      "term": "FastSpeech 2",
      "definition": "A non-autoregressive text-to-speech model that directly generates mel-spectrograms in parallel using duration and pitch and energy predictors.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fasttext",
      "term": "FastText",
      "definition": "A word representation model that extends Word2Vec by representing each word as a bag of character n-grams, enabling meaningful embeddings for out-of-vocabulary words and morphologically rich languages.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-fasttext-algorithm",
      "term": "FastText Algorithm",
      "definition": "A word embedding method that represents each word as a bag of character n-grams. Enables computing vector representations for out-of-vocabulary words by summing the vectors of their constituent subword units.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fastvit",
      "term": "FastViT",
      "definition": "A fast vision Transformer that uses structural reparameterization and linear attention for rapid image processing suitable for mobile and embedded applications.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fat-tree-topology",
      "term": "Fat Tree Topology",
      "definition": "Hierarchical network topology using progressively wider bandwidth toward the root of the tree. Common in data center networks providing full bisection bandwidth for AI training clusters.",
      "tags": [
        "Networking",
        "Topology"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-fb15k-237",
      "term": "FB15k-237",
      "definition": "A knowledge graph completion benchmark derived from Freebase containing 14541 entities and 237 relation types. Tests link prediction and knowledge graph embedding methods.",
      "tags": [
        "Benchmark",
        "Knowledge",
        "Graph"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fci-algorithm",
      "term": "FCI Algorithm",
      "definition": "Fast Causal Inference is a causal discovery algorithm that extends the PC algorithm to handle latent confounders and selection bias. Produces a partial ancestral graph that represents a class of causal models.",
      "tags": [
        "Algorithms",
        "Technical",
        "Causal"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fcos",
      "term": "FCOS",
      "definition": "Fully Convolutional One-Stage Object Detection, an anchor-free detector that directly predicts bounding boxes from every foreground pixel using per-pixel regression of distances to box edges.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-feature",
      "term": "Feature",
      "definition": "An individual measurable property or characteristic of data used as input to a model. Good feature engineering can significantly improve model performance.",
      "tags": [
        "Data",
        "ML Fundamentals"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-feature-attribution",
      "term": "Feature Attribution",
      "definition": "An interpretability technique that assigns importance scores to input features indicating their contribution to a model's prediction. Methods include SHAP LIME integrated gradients and attention weights.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-feature-engineering",
      "term": "Feature Engineering",
      "definition": "The process of using domain knowledge to create input features that improve machine learning model performance. Before deep learning feature engineering was the primary way to improve ML systems. The shift to learned features was a defining characteristic of deep learning.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-feature-extraction",
      "term": "Feature Extraction",
      "definition": "The process of constructing new features from raw data through transformations such as PCA, autoencoders, or domain-specific computations, reducing dimensionality while retaining the most informative signal.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-feature-hashing",
      "term": "Feature Hashing",
      "definition": "A dimensionality reduction technique that maps high-dimensional feature vectors to a lower-dimensional space using a hash function, avoiding the need to maintain a dictionary of feature indices.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-feature-importance",
      "term": "Feature Importance",
      "definition": "A measure of how much each input feature contributes to a model's predictions. Common methods include tree-based impurity importance, permutation importance, and SHAP values.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-feature-map",
      "term": "Feature Map",
      "definition": "The output of a convolutional layer representing the activation pattern produced by applying a specific filter to the input, where each channel captures a different learned visual pattern.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-feature-matching",
      "term": "Feature Matching",
      "definition": "The process of finding corresponding points between two images by detecting local features (keypoints) and comparing their descriptors, used in 3D reconstruction, SLAM, and image retrieval.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-feature-pyramid-network",
      "term": "Feature Pyramid Network",
      "definition": "A multi-scale feature extraction architecture that builds a top-down pathway with lateral connections to produce semantically rich features at all scales from a single-scale input.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-feature-scaling",
      "term": "Feature Scaling",
      "definition": "The process of transforming numerical features to a common scale, such as standardization (zero mean, unit variance) or min-max scaling, to prevent features with larger ranges from dominating distance-based or gradient-based algorithms.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-feature-selection",
      "term": "Feature Selection",
      "definition": "The process of identifying and selecting a subset of relevant features for model construction, reducing dimensionality, mitigating overfitting, and improving interpretability without transforming the original features.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-federated-averaging",
      "term": "Federated Averaging",
      "definition": "The foundational algorithm for federated learning that trains models across decentralized devices by averaging locally trained model updates. Each device trains on its local data and only shares model updates preserving data privacy.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-federated-averaging-algorithm-fedavg",
      "term": "Federated Averaging Algorithm (FedAvg)",
      "definition": "A distributed learning algorithm where clients train models locally and a server averages the model parameters. Reduces communication costs by performing multiple local gradient steps between aggregation rounds.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Privacy"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-federated-learning",
      "term": "Federated Learning",
      "definition": "A machine learning approach where models are trained across multiple decentralized devices or servers holding local data samples, without exchanging raw data, thereby preserving privacy while enabling collaborative learning.",
      "tags": [
        "Privacy",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-federated-learning-hardware",
      "term": "Federated Learning Hardware",
      "definition": "Computing devices designed to participate in federated learning where models are trained across distributed devices without centralizing data. Must balance local compute with communication efficiency.",
      "tags": [
        "Edge",
        "Privacy",
        "Distributed"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-federated-learning-privacy",
      "term": "Federated Learning Privacy",
      "definition": "Privacy-preserving properties and risks of federated learning where models are trained across distributed devices without centralizing data. While reducing direct data exposure gradient information can still leak private details.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-fedformer",
      "term": "FEDformer",
      "definition": "Frequency Enhanced Decomposed Transformer uses frequency-domain attention with seasonal-trend decomposition for efficient and accurate long-term time series forecasting.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fedprox-algorithm",
      "term": "FedProx Algorithm",
      "definition": "A federated learning algorithm that adds a proximal term to the local objective to limit how far each client model deviates from the global model. Improves convergence when client data is heterogeneous.",
      "tags": [
        "Algorithms",
        "Technical",
        "Privacy"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-feedback-loop-risk",
      "term": "Feedback Loop Risk",
      "definition": "The danger that AI system outputs influence future training data creating self-reinforcing cycles that amplify errors or biases over time. Common in recommender systems and predictive policing.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-feedforward",
      "term": "Feedforward Neural Network",
      "definition": "A neural network where information flows in one direction from input to output, without cycles. The simplest type of neural network architecture.",
      "tags": [
        "Architecture",
        "Neural Networks"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fei-fei-li",
      "term": "Fei-Fei Li",
      "definition": "Chinese-American computer scientist who led the creation of the ImageNet dataset and competition, which was instrumental in sparking the deep learning revolution. She is a leading advocate for human-centered AI.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-felzenszwalb-segmentation",
      "term": "Felzenszwalb Segmentation",
      "definition": "A graph-based image segmentation algorithm that produces segmentations respecting the internal variation of each component. Runs in nearly linear time and adapts the granularity based on local image structure.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fengwu",
      "term": "FengWu",
      "definition": "A multi-modal weather forecasting foundation model from Shanghai AI Lab that predicts global weather across multiple variables and pressure levels.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fenwick-tree-algorithm",
      "term": "Fenwick Tree Algorithm",
      "definition": "A data structure also known as a binary indexed tree that supports efficient prefix sum queries and point updates in O(log n) time. Uses a compact array representation based on the binary representation of indices.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-ferret",
      "term": "Ferret",
      "definition": "A multimodal large language model from Apple that supports referring and grounding capabilities for precise spatial understanding in images.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ferret-v2",
      "term": "Ferret-v2",
      "definition": "An improved version of Ferret with enhanced resolution handling and better spatial grounding for more accurate region-level image understanding.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-feudal-network",
      "term": "Feudal Network",
      "definition": "A hierarchical RL architecture where a manager module sets abstract goals for a worker module that selects primitive actions. The feudal approach decomposes long-horizon problems into high-level direction setting and low-level motor control.",
      "tags": [
        "Reinforcement Learning",
        "Multi-Agent"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-few-shot",
      "term": "Few-Shot Learning",
      "definition": "A technique where you provide a few examples in your prompt to help AI understand the pattern or format you want. More effective than describing alone for complex outputs.",
      "tags": [
        "Prompting",
        "Technique"
      ],
      "domain": "general",
      "link": "../learn/index.html",
      "related": []
    },
    {
      "id": "term-few-shot-learning-history",
      "term": "Few-Shot Learning History",
      "definition": "The evolution of few-shot learning from early work on one-shot learning (Li Fei-Fei 2003) through meta-learning approaches (MAML 2017) to in-context learning in large language models (GPT-3 2020) where models learn from just a few examples.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-few-shot-object-detection",
      "term": "Few-Shot Object Detection",
      "definition": "Object detection methods that can learn to detect new categories from only a handful of annotated examples, using meta-learning or transfer learning to generalize from limited labeled data.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ffhq",
      "term": "FFHQ",
      "definition": "Flickr-Faces-HQ a dataset of 70000 high-quality face images at 1024x1024 resolution. Created by NVIDIA for training StyleGAN and subsequent face generation architectures.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fgsm",
      "term": "FGSM",
      "definition": "Fast Gradient Sign Method is an adversarial attack that perturbs inputs in the direction of the gradient of the loss with respect to the input. Creates adversarial examples with a single gradient computation. Introduced by Goodfellow et al. in 2015.",
      "tags": [
        "Algorithms",
        "Safety"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fgvc-aircraft",
      "term": "FGVC Aircraft",
      "definition": "A fine-grained visual classification dataset containing 10200 images of aircraft spanning 100 aircraft model variants. Each image is annotated with model variant family and manufacturer.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fiber-optic-cable",
      "term": "Fiber Optic Cable",
      "definition": "Communication cable using glass or plastic fibers to transmit data as light pulses. Standard for long-distance and high-bandwidth connections in AI data center networking.",
      "tags": [
        "Networking",
        "Physical",
        "Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-fibonacci-heap-algorithm",
      "term": "Fibonacci Heap Algorithm",
      "definition": "A heap data structure that achieves O(1) amortized time for most operations including insert and decrease-key. Provides the best theoretical time complexity for Dijkstra's algorithm and Prim's algorithm.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fibonacci-search",
      "term": "Fibonacci Search",
      "definition": "A comparison-based search algorithm that uses Fibonacci numbers to divide the array into unequal parts. Similar to binary search but divides using Fibonacci ratios and avoids division operations using only addition and subtraction.",
      "tags": [
        "Algorithms",
        "Technical",
        "Searching"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fictitious-play",
      "term": "Fictitious Play",
      "definition": "A game-theoretic learning algorithm where each player repeatedly best-responds to the empirical distribution of opponent actions. Converges to Nash equilibrium in certain game classes including zero-sum games.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fid-score",
      "term": "FID Score",
      "definition": "Frechet Inception Distance measures the quality of generated images by comparing the statistics of generated and real image features extracted from an Inception network. Lower FID indicates generated images are more similar to real images in feature space.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fiduciary-duty-for-ai",
      "term": "Fiduciary Duty for AI",
      "definition": "A proposed legal framework that would impose fiduciary obligations on AI developers or deployers requiring them to act in the best interests of the individuals affected by their systems.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-field-programmable-gate-array",
      "term": "Field-Programmable Gate Array",
      "definition": "Integrated circuit that can be configured by the user after manufacturing using programmable logic blocks and interconnects. Used for prototyping AI accelerator designs and specialized inference.",
      "tags": [
        "FPGA",
        "Architecture",
        "Programmable"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-fifth-generation-computer-project",
      "term": "Fifth Generation Computer Project",
      "definition": "A large-scale Japanese government initiative launched in 1982 aiming to create computers with AI capabilities using parallel processing and logic programming (Prolog). The ten-year project ultimately fell short of its ambitious goals contributing to AI skepticism.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-figureqa",
      "term": "FigureQA",
      "definition": "A visual reasoning dataset of questions about synthetically generated figures including bar plots pie charts and line graphs. Tests basic numerical reasoning about visualizations.",
      "tags": [
        "Benchmark",
        "Multimodal",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fill-in-the-middle",
      "term": "Fill-in-the-Middle",
      "definition": "A training objective where the model learns to generate text that fills a gap between a given prefix and suffix, enabling code completion, text infilling, and document editing capabilities.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-filter-bubble",
      "term": "Filter Bubble",
      "definition": "An information ecosystem created by AI recommendation algorithms that limits users exposure to diverse viewpoints by serving content aligned with their existing preferences and beliefs.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-finbert",
      "term": "FinBERT",
      "definition": "A BERT model fine-tuned on financial text for sentiment analysis and other financial NLP tasks. Trained on financial news corporate reports and analyst reports. Outperforms general BERT on financial domain tasks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fine-tuning",
      "term": "Fine-Tuning",
      "definition": "The process of training a pre-existing AI model on additional, specialized data to improve its performance for specific tasks or domains. More efficient than training from scratch.",
      "tags": [
        "Training",
        "Customization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-fineweb",
      "term": "FineWeb",
      "definition": "A large-scale web text dataset derived from Common Crawl with careful quality filtering. Designed for pretraining language models with improved data quality over raw web scrapes.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fineweb-edu",
      "term": "FineWeb-Edu",
      "definition": "A subset of FineWeb filtered for educational content using a classifier trained on high-quality educational text. Produces higher quality pretraining data for knowledge-intensive applications.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-finfet",
      "term": "FinFET",
      "definition": "Three-dimensional transistor design where the channel is wrapped around a thin vertical fin. Standard transistor architecture for process nodes from 22nm to 5nm providing better power control.",
      "tags": [
        "Fabrication",
        "Transistor",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-finite-difference-method",
      "term": "Finite Difference Method",
      "definition": "A numerical method that approximates derivatives by replacing them with difference quotients on a discrete grid. The simplest approach for solving differential equations and forms the basis of many computational methods.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-finite-element-method",
      "term": "Finite Element Method",
      "definition": "A numerical technique for solving partial differential equations by dividing the domain into small elements and approximating the solution with piecewise polynomial functions. Widely used in structural and fluid mechanics.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-finite-state-machine",
      "term": "Finite State Machine",
      "definition": "A mathematical model of computation consisting of a finite number of states transitions between states and actions. Used extensively in computer science for pattern matching parsing and control systems. Early AI systems used FSMs for simple decision-making behaviors.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-finite-volume-method",
      "term": "Finite Volume Method",
      "definition": "A numerical method for evaluating partial differential equations that integrates flux over control volumes. Inherently conservative and widely used in computational fluid dynamics and heat transfer simulations.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-firefly-algorithm",
      "term": "Firefly Algorithm",
      "definition": "A nature-inspired optimization algorithm where artificial fireflies are attracted to brighter (better) solutions. The attraction strength decreases with distance creating a natural exploration-exploitation balance.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-first-ai-winter",
      "term": "First AI Winter",
      "definition": "The period from approximately 1974 to 1980 when AI research funding and interest declined sharply following the Lighthill Report's criticism and the failure of early AI to deliver on ambitious promises.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-fish-speech",
      "term": "Fish Speech",
      "definition": "A text-to-speech model designed for multilingual voice synthesis with voice cloning capabilities using minimal reference audio samples.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fisher-information",
      "term": "Fisher Information",
      "definition": "A measure of the amount of information that an observable random variable carries about an unknown parameter. It quantifies how sensitive the likelihood function is to changes in the parameter value.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fits",
      "term": "FITS",
      "definition": "A lightweight time series analysis model that operates primarily in the frequency domain using simple interpolation for efficient forecasting and reconstruction.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fitted-q-iteration",
      "term": "Fitted Q-Iteration",
      "definition": "A batch RL algorithm that iteratively fits a Q-function approximator to Bellman backup targets computed from a fixed dataset. Fitted Q-iteration generalizes Q-learning to the batch setting using supervised regression.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-fixed-point-iteration",
      "term": "Fixed-Point Iteration",
      "definition": "An iterative method that finds a fixed point of a function by repeatedly applying the function starting from an initial guess. Converges when the function is a contraction mapping in the neighborhood of the fixed point.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fixmatch",
      "term": "FixMatch",
      "definition": "A semi-supervised learning algorithm that combines consistency regularization with pseudo-labeling. Generates pseudo-labels from weakly augmented inputs and trains on strongly augmented versions of those inputs. Achieves strong results with very few labels.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-flamingo",
      "term": "Flamingo",
      "definition": "A visual language model by DeepMind that processes interleaved image and text sequences using cross-attention layers between a frozen vision encoder and frozen language model. Achieves strong few-shot visual understanding.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-flan",
      "term": "FLAN (Fine-tuned Language Net)",
      "definition": "Google's approach to instruction tuning, fine-tuning models on many tasks described with natural language instructions. FLAN models showed strong zero-shot performance.",
      "tags": [
        "Training",
        "Google"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-flan-collection",
      "term": "FLAN Collection",
      "definition": "A collection of datasets used for instruction tuning the FLAN language models. Combines over 1800 tasks with diverse instruction templates to improve zero-shot generalization.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-flan-t5",
      "term": "Flan-T5",
      "definition": "A version of T5 fine-tuned on a large collection of tasks phrased as instructions. Demonstrates that instruction tuning dramatically improves zero-shot and few-shot performance across a wide range of tasks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-flash-attention",
      "term": "Flash Attention",
      "definition": "An optimized attention algorithm that reduces memory usage and improves speed by tiling computations. Enables longer context windows and faster inference for transformers.",
      "tags": [
        "Optimization",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-flash-decoding",
      "term": "Flash Decoding",
      "definition": "An optimized inference algorithm for autoregressive language models that parallelizes the attention computation across the key-value sequence dimension. Improves decoding throughput especially for long sequences and small batch sizes.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-flashattention-2",
      "term": "FlashAttention-2",
      "definition": "An optimized attention implementation that reduces memory I/O by tiling the computation to keep data in fast SRAM, avoiding materialization of the full attention matrix in HBM. FlashAttention-2 achieves 2x speedup over the original FlashAttention through better work partitioning.",
      "tags": [
        "Inference Infrastructure",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-flat-index",
      "term": "Flat Index",
      "definition": "A brute-force vector index that stores all vectors without compression or partitioning and performs exhaustive linear search, guaranteeing exact nearest neighbor results at the cost of O(n) search complexity.",
      "tags": [
        "Vector Database",
        "Index Structure"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-fld",
      "term": "FLD",
      "definition": "Formal Logic Deduction a benchmark testing language models on formal logical reasoning including propositional and predicate logic inference.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fleiss-kappa",
      "term": "Fleiss' Kappa",
      "definition": "A statistical measure that extends Cohen's Kappa to assess inter-rater agreement among three or more annotators making categorical judgments, accounting for chance agreement across the full annotator pool.",
      "tags": [
        "Evaluation",
        "Methodology"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fleurs",
      "term": "FLEURS",
      "definition": "Few-shot Learning Evaluation of Universal Representations of Speech a multilingual speech benchmark covering 102 languages. Used to evaluate speech understanding systems across diverse languages.",
      "tags": [
        "Benchmark",
        "Speech",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fleurys-algorithm",
      "term": "Fleury's Algorithm",
      "definition": "An algorithm for finding Eulerian paths or circuits in a graph that traverses edges one at a time while avoiding bridges unless no other option exists. Simple but runs in O(E^2) time due to bridge checking.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-flickr30k",
      "term": "Flickr30k",
      "definition": "A dataset of 31000 images collected from Flickr with five human-written captions per image. A standard benchmark for image-text retrieval and image captioning evaluation.",
      "tags": [
        "Benchmark",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-flickr30k-entities",
      "term": "Flickr30k Entities",
      "definition": "An extension of Flickr30k with coreference chains linking mentions in captions to bounding boxes in images. Supports phrase grounding and referring expression comprehension.",
      "tags": [
        "Benchmark",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-flipped-interaction",
      "term": "Flipped Interaction",
      "definition": "A method where you ask AI to ask you questions before providing advice. Leads to more personalized and relevant responses for complex situations.",
      "tags": [
        "Framework",
        "Interactive"
      ],
      "domain": "general",
      "link": "../learn/flipped-interaction.html",
      "related": []
    },
    {
      "id": "term-flops",
      "term": "FLOPS",
      "definition": "Floating-Point Operations Per Second, the standard measure of computational throughput for AI hardware. FLOPS is reported at various precisions (FP64, FP32, FP16, INT8), with AI accelerators optimized for lower-precision formats that deliver higher throughput.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-florence",
      "term": "Florence",
      "definition": "A foundation model for computer vision developed by Microsoft that unifies image classification object detection visual question answering and image captioning. Uses a unified architecture with adapters for different downstream tasks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-florence-2",
      "term": "Florence-2",
      "definition": "A unified vision foundation model from Microsoft that uses a sequence-to-sequence architecture to handle diverse vision and vision-language tasks through text prompts.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-flores",
      "term": "FLORES",
      "definition": "A benchmark for machine translation evaluation covering over 200 languages with professional translations. Enables standardized comparison of translation quality across many language pairs.",
      "tags": [
        "Benchmark",
        "NLP",
        "Translation",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-flow-matching",
      "term": "Flow Matching",
      "definition": "A generative modeling framework that learns continuous normalizing flows by regressing velocity fields that transport samples from a noise distribution to the data distribution, offering simpler training than diffusion.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-flower-pollination-algorithm",
      "term": "Flower Pollination Algorithm",
      "definition": "A nature-inspired optimization algorithm based on the pollination process of flowering plants. Combines global pollination via Levy flights with local pollination through random walks between nearby solutions.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-floyd-warshall-algorithm",
      "term": "Floyd-Warshall Algorithm",
      "definition": "An all-pairs shortest path algorithm that finds shortest distances between every pair of vertices in a weighted graph. Uses dynamic programming with three nested loops and runs in O(V^3) time complexity.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fluency-score",
      "term": "Fluency Score",
      "definition": "A metric that evaluates the grammatical correctness, naturalness, and readability of generated text, often assessed through human judgment or proxy models that rate how closely the output resembles natural human-written prose.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-flux",
      "term": "Flux",
      "definition": "A family of image generation models that use a rectified flow transformer architecture (DiT) for diffusion, achieving state-of-the-art image quality with improved text rendering and prompt following.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-flux1",
      "term": "FLUX.1",
      "definition": "A family of text-to-image models from Black Forest Labs using a rectified flow Transformer architecture for high-quality and fast image generation.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-flux1-dev",
      "term": "FLUX.1 Dev",
      "definition": "The development variant of FLUX.1 that provides high-quality image generation with a balance of speed and output detail for open-weight research.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-flux1-schnell",
      "term": "FLUX.1 Schnell",
      "definition": "The fastest variant of FLUX.1 that uses distillation techniques to generate high-quality images in just 1-4 inference steps.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fnet",
      "term": "FNet",
      "definition": "A model that replaces the self-attention layer in transformers with a simple Fourier transform. Achieves 92% of BERT accuracy on GLUE with significantly faster training. Demonstrates that token mixing does not always require attention.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-focal-loss",
      "term": "Focal Loss",
      "definition": "A modified cross-entropy loss that down-weights the contribution of easy examples and focuses training on hard, misclassified examples by adding a modulating factor. It was designed to address class imbalance in object detection.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-focal-loss-function",
      "term": "Focal Loss Function",
      "definition": "A modification of cross-entropy loss that down-weights easy examples and focuses training on hard misclassified examples. Addresses class imbalance by adding a modulating factor. Introduced for dense object detection in RetinaNet.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-focalnet",
      "term": "FocalNet",
      "definition": "A focal modulation network that replaces self-attention with context-dependent modulation for efficient visual modeling without token-to-token interaction.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-folio",
      "term": "FOLIO",
      "definition": "First-Order Logic Inference a benchmark of natural language reasoning problems annotated with first-order logic formulas. Tests the ability to perform logical reasoning in natural language.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fomo",
      "term": "FOMO (AI Context)",
      "definition": "Fear Of Missing Out on AI advancements. The rapid pace of AI development creates pressure to constantly learn new tools and techniques. Balance enthusiasm with focused skill-building.",
      "tags": [
        "Culture",
        "Learning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-food-101",
      "term": "Food-101",
      "definition": "A dataset of 101000 food images across 101 categories with 1000 images per class. Training images contain noise while test images are manually cleaned making it a realistic benchmark.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-ford-fulkerson-algorithm",
      "term": "Ford-Fulkerson Algorithm",
      "definition": "A method for computing maximum flow in a flow network by repeatedly finding augmenting paths from source to sink and increasing flow along those paths. Terminates when no more augmenting paths exist in the residual graph.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Graph",
        "History"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-formal-verification-for-ai",
      "term": "Formal Verification for AI",
      "definition": "The use of mathematical methods to prove that an AI system satisfies specified safety properties. Provides stronger guarantees than empirical testing but faces scalability challenges for large neural networks.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-format-instruction",
      "term": "Format Instructions",
      "definition": "Explicit guidance in prompts about how AI should structure its response. Examples include requesting JSON, markdown tables, bullet points, or specific sections.",
      "tags": [
        "Prompting",
        "Technique"
      ],
      "domain": "general",
      "link": "../learn/crisp.html",
      "related": []
    },
    {
      "id": "term-forward-backward-algorithm",
      "term": "Forward-Backward Algorithm",
      "definition": "An inference algorithm for Hidden Markov Models that computes the posterior probability of each hidden state given the entire observation sequence. Combines forward and backward passes. Used in the Baum-Welch algorithm for HMM parameter estimation.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-foundation-model",
      "term": "Foundation Model",
      "definition": "A large AI model trained on broad data that can be adapted to many downstream tasks. Examples include GPT-4, Claude, and Llama. The base layer for most modern AI applications.",
      "tags": [
        "Model Type",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-foundation-model-risk",
      "term": "Foundation Model Risk",
      "definition": "Risks specific to large foundation models that are adapted for many downstream tasks. A single vulnerability or bias in the foundation model can propagate to all applications built on it.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-foundation-models",
      "term": "Foundation Models",
      "definition": "A term coined by researchers at Stanford in 2021 describing large AI models trained on broad data that can be adapted to a wide range of downstream tasks. Foundation models like GPT-4 BERT and DALL-E represent a paradigm shift toward general-purpose AI systems.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-fourcastnet",
      "term": "FourCastNet",
      "definition": "A Fourier-based neural network for global weather forecasting that uses Adaptive Fourier Neural Operators to predict atmospheric variables at high resolution.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fourier-transform",
      "term": "Fourier Transform",
      "definition": "A mathematical transform that decomposes a function of time or space into its constituent frequencies. Converts signals between time/spatial domain and frequency domain. Fundamental to signal processing spectral analysis and certain neural network architectures.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fox",
      "term": "Fox",
      "definition": "A multi-modal document understanding model optimized for processing complex real-world documents with tables and charts and mixed-format content.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fp16",
      "term": "FP16 (Half Precision)",
      "definition": "A 16-bit floating-point format with 5 exponent bits and 10 mantissa bits, offering half the memory footprint of FP32. FP16 is widely used in mixed precision training but requires loss scaling to handle its limited dynamic range.",
      "tags": [
        "Model Optimization",
        "Hardware"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fp32",
      "term": "FP32 (Single Precision)",
      "definition": "The standard 32-bit floating-point format with 8 exponent bits and 23 mantissa bits, providing high numerical precision for model training. FP32 is the baseline precision but is increasingly replaced by lower-precision formats for efficiency.",
      "tags": [
        "Model Optimization",
        "Hardware"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fp4",
      "term": "FP4 Quantization",
      "definition": "An ultra-low precision 4-bit floating-point format for neural network weights, supported by next-generation AI hardware like NVIDIA Blackwell. FP4 quantization provides 8x compression over FP32 with hardware-accelerated dequantization during computation.",
      "tags": [
        "Model Optimization",
        "Hardware"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fp8",
      "term": "FP8 Precision",
      "definition": "An 8-bit floating-point format introduced for AI training and inference, available in two variants: E4M3 (4 exponent, 3 mantissa bits) for forward passes and E5M2 (5 exponent, 2 mantissa bits) for gradients. FP8 doubles throughput over FP16 on supported hardware like the H100.",
      "tags": [
        "Model Optimization",
        "Hardware"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fpga-ai",
      "term": "FPGA for AI",
      "definition": "Field-Programmable Gate Arrays reconfigured for AI workloads, offering customizable hardware logic that can be tailored to specific neural network architectures. FPGAs provide lower latency than GPUs for certain inference tasks with the flexibility to adapt to evolving model architectures.",
      "tags": [
        "Hardware",
        "Inference Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-frame-problem",
      "term": "Frame Problem",
      "definition": "A fundamental challenge in AI identified by McCarthy and Hayes in 1969 concerning how to represent the effects of actions without explicitly specifying everything that does not change, a key issue in knowledge representation.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-frame-stacking",
      "term": "Frame Stacking",
      "definition": "A technique used in visual RL that concatenates multiple consecutive observation frames as input to the agent, providing temporal context and enabling the perception of motion and velocity from raw pixels.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-framenet",
      "term": "FrameNet",
      "definition": "A lexical database that describes word meanings in terms of semantic frames, specifying the participants, props, and other conceptual roles associated with each frame.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-frames",
      "term": "FRAMES",
      "definition": "Factuality Rating And Measurement for Evaluation of Summarization a benchmark for evaluating factual consistency in text summarization. Tests whether summaries contain hallucinated information.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-frames-minsky",
      "term": "Frames (Minsky)",
      "definition": "A knowledge representation scheme proposed by Marvin Minsky in 1974 where stereotyped situations are represented as data structures with slots for expected information, influencing object-oriented programming and AI knowledge bases.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-frames-theory",
      "term": "Frames Theory",
      "definition": "A knowledge representation approach proposed by Marvin Minsky in 1974 where knowledge is organized into frame structures containing slots for attributes and default values. Frames influenced object-oriented programming and remain relevant in AI knowledge representation.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-frank-rosenblatt",
      "term": "Frank Rosenblatt",
      "definition": "American psychologist (1928-1971) who invented the perceptron in 1957, one of the earliest neural network models capable of learning from data, pioneering the connectionist approach to AI.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-frank-wolfe-algorithm",
      "term": "Frank-Wolfe Algorithm",
      "definition": "A constrained optimization algorithm also known as conditional gradient that replaces the projection step with a linear minimization over the constraint set. Produces sparse solutions and avoids projections which can be expensive for complex constraints.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-freebase",
      "term": "Freebase",
      "definition": "A large collaborative knowledge base containing over 1.9 billion facts about 39 million entities. Acquired by Google in 2010 and used as the basis for the Google Knowledge Graph.",
      "tags": [
        "Knowledge",
        "Graph"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-frequency-penalty",
      "term": "Frequency Penalty",
      "definition": "A parameter that penalizes tokens proportionally to how often they have appeared in the output so far, encouraging lexical diversity in generated text.",
      "tags": [
        "Generative AI",
        "Decoding"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-freshqa",
      "term": "FreshQA",
      "definition": "A dynamic QA benchmark where questions have answers that may change over time. Tests whether language models have up-to-date knowledge and can handle temporal reasoning.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-frontier-ai",
      "term": "Frontier AI",
      "definition": "The most capable AI models at the cutting edge of capability, which may pose novel safety risks not present in less capable systems. The term is used in governance contexts to identify systems requiring heightened oversight.",
      "tags": [
        "AI Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-frontier-model",
      "term": "Frontier Model",
      "definition": "The most capable AI models at any given time, pushing the boundaries of what's possible. Term often used in AI policy discussions about governance of the most powerful systems.",
      "tags": [
        "Policy",
        "Research"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-frontier-model-forum",
      "term": "Frontier Model Forum",
      "definition": "An industry body established in 2023 by major AI companies to promote responsible development and deployment of frontier AI models, focusing on safety research, best practices, and public engagement.",
      "tags": [
        "Governance",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-frontier-safety-framework",
      "term": "Frontier Safety Framework",
      "definition": "A set of policies and practices adopted by leading AI labs to manage the risks associated with the most capable AI models. Includes capability evaluations safety testing and deployment controls.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-frontier-supercomputer",
      "term": "Frontier Supercomputer",
      "definition": "First exascale supercomputer achieving 1.194 exaFLOPS built at Oak Ridge National Laboratory using AMD EPYC CPUs and AMD Instinct MI250X GPUs. Became operational in 2022.",
      "tags": [
        "Supercomputer",
        "AMD",
        "Exascale"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-frontiermath",
      "term": "FrontierMath",
      "definition": "A benchmark of original research-level mathematics problems testing mathematical reasoning beyond standard competitions. Designed to measure frontier AI mathematical capability.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fsd50k",
      "term": "FSD50K",
      "definition": "Freesound Dataset 50K containing 51197 audio clips from Freesound with labels from the AudioSet ontology. Provides a large open dataset for sound event recognition research.",
      "tags": [
        "Benchmark",
        "Audio"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fsdp",
      "term": "FSDP",
      "definition": "Fully Sharded Data Parallel, a PyTorch training strategy that shards model parameters, gradients, and optimizer states across all GPUs, enabling training of models larger than single-GPU memory.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fsdp-fully-sharded-data-parallel",
      "term": "FSDP (Fully Sharded Data Parallel)",
      "definition": "PyTorch native implementation of ZeRO-style parameter sharding for distributed training. Shards model parameters gradients and optimizer states across data parallel workers.",
      "tags": [
        "Distributed Training",
        "PyTorch",
        "Framework"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ft-transformer",
      "term": "FT-Transformer",
      "definition": "Feature Tokenizer plus Transformer applies the transformer architecture to tabular data by converting each feature into an embedding token. Demonstrates that transformers can match or exceed gradient boosting on tabular tasks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fugaku-a64fx-processor",
      "term": "Fugaku A64FX Processor",
      "definition": "Custom ARM-based processor designed by Fujitsu for the Fugaku supercomputer. Notable for integrating HBM2 memory directly into the CPU package without requiring GPUs.",
      "tags": [
        "Processor",
        "ARM",
        "Fujitsu"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-fugaku-supercomputer",
      "term": "Fugaku Supercomputer",
      "definition": "ARM-based supercomputer built by Fujitsu at RIKEN in Japan using custom A64FX processors. Held the TOP500 number one ranking from 2020 to 2022 without using GPUs.",
      "tags": [
        "Supercomputer",
        "ARM",
        "Japan"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-full-text-search",
      "term": "Full-Text Search",
      "definition": "A search technique that examines all words in every stored document to find matches for a query, typically using inverted indexes with tokenization, stemming, and stop word removal to enable fast and flexible text matching.",
      "tags": [
        "Retrieval",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-fully-sharded-data-parallel",
      "term": "Fully Sharded Data Parallel",
      "definition": "A memory-efficient distributed training technique that shards model parameters gradients and optimizer states across data-parallel workers. Each worker only stores a fraction of the model reducing memory requirements while maintaining training throughput.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-function-calling",
      "term": "Function Calling",
      "definition": "An LLM capability that allows models to generate structured output to call external functions or APIs. Enables AI agents to take actions like searching, calculating, or accessing databases.",
      "tags": [
        "Capability",
        "Agents"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-functional-correctness",
      "term": "Functional Correctness",
      "definition": "An evaluation criterion for code generation that assesses whether generated code produces correct outputs for all test inputs, measured through execution-based testing rather than syntactic similarity to reference solutions.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-functional-map-of-the-world",
      "term": "Functional Map of the World",
      "definition": "A satellite imagery dataset containing over 1 million images of 63 categories of functional land use. Tests the ability to classify building and land use from overhead imagery.",
      "tags": [
        "Benchmark",
        "Computer Vision",
        "Remote Sensing"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-fundamental-matrix-estimation",
      "term": "Fundamental Matrix Estimation",
      "definition": "An algorithm that computes the fundamental matrix encoding the epipolar geometry between two uncalibrated views. The eight-point algorithm and its normalized variant are standard approaches for estimation.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fusion-retrieval",
      "term": "Fusion Retrieval",
      "definition": "A retrieval paradigm that combines results from multiple diverse retrieval methods or models through score fusion, rank fusion, or learned combination, leveraging complementary signals to achieve higher recall and precision than any single method.",
      "tags": [
        "Retrieval",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-future-of-life-institute",
      "term": "Future of Life Institute",
      "definition": "A nonprofit organization founded in 2014 focused on existential risks from advanced technology particularly AI. FLI published an open letter in 2023 calling for a pause on training AI systems more powerful than GPT-4 signed by thousands of researchers.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-fuyu",
      "term": "Fuyu",
      "definition": "A multimodal model from Adept AI that directly processes raw image patches without a separate vision encoder for simplified architecture and flexible input handling.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-fuzzy-c-means-algorithm",
      "term": "Fuzzy C-Means Algorithm",
      "definition": "A soft clustering algorithm where each point belongs to every cluster with a degree of membership. Minimizes a weighted sum of squared distances where weights are membership values raised to a fuzziness exponent.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-fuzzy-logic",
      "term": "Fuzzy Logic",
      "definition": "A form of many-valued logic introduced by Lotfi Zadeh in 1965 that handles degrees of truth rather than binary true/false values, enabling AI systems to reason with imprecise, vague, or uncertain information.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-fuzzy-matching",
      "term": "Fuzzy Matching",
      "definition": "Finding approximate rather than exact matches in text. Useful for handling typos, variations, and similar-meaning terms in search and data processing applications.",
      "tags": [
        "NLP",
        "Technique"
      ],
      "domain": "general",
      "link": null,
      "related": []
    }
  ]
}