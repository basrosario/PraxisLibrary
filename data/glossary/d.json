{
  "letter": "d",
  "count": 199,
  "terms": [
    {
      "id": "term-dagger",
      "term": "DAgger",
      "definition": "Dataset Aggregation, an iterative imitation learning algorithm that queries the expert for the correct action at states visited by the learned policy, aggregating new data to reduce distribution shift. DAgger provides no-regret guarantees under certain conditions.",
      "tags": [
        "Reinforcement Learning",
        "Imitation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dall-e",
      "term": "DALL-E",
      "definition": "OpenAI's image generation model that creates images from text descriptions. Named as a portmanteau of \"Dal√≠\" (the artist) and \"WALL-E\" (the robot), it pioneered text-to-image AI.",
      "tags": [
        "Model",
        "Image Generation"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dall-e-2",
      "term": "DALL-E 2",
      "definition": "OpenAI's second generation image generation model that uses CLIP embeddings and a diffusion model to create more realistic and higher resolution images from text descriptions than the original DALL-E.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dall-e-3",
      "term": "DALL-E 3",
      "definition": "OpenAI's third generation text-to-image model featuring significantly improved text rendering prompt following and coherent composition. Integrated natively with ChatGPT for conversational image generation.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dall-e-architecture",
      "term": "DALL-E Architecture",
      "definition": "A two-stage generative architecture that first trains a discrete VAE to compress images into tokens, then trains an autoregressive transformer to generate image tokens conditioned on text tokens.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dana-scott",
      "term": "Dana Scott",
      "definition": "American logician and computer scientist who received the Turing Award in 1976 for work on denotational semantics and domain theory. His mathematical frameworks for programming language semantics provided foundations relevant to formal verification and AI reasoning.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-danny-hillis",
      "term": "Danny Hillis",
      "definition": "American inventor scientist and engineer who founded Thinking Machines Corporation and designed the Connection Machine parallel supercomputer. His work on massively parallel computing anticipated the parallel processing architectures now used in modern GPU-based deep learning.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-daphne-koller",
      "term": "Daphne Koller",
      "definition": "Israeli-American computer scientist who co-founded Coursera with Andrew Ng. Known for pioneering work on probabilistic graphical models and their applications in computational biology. Received the MacArthur Fellowship for contributions to AI and machine learning.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-dario-amodei",
      "term": "Dario Amodei",
      "definition": "American AI researcher who co-founded Anthropic in 2021 after leaving OpenAI, serving as CEO and advocating for a safety-focused approach to AI development including Constitutional AI methods.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-dark-patterns-in-ai",
      "term": "Dark Patterns in AI",
      "definition": "Deceptive design techniques in AI-powered interfaces that manipulate users into making choices they would not otherwise make. Examples include hidden defaults misleading framing and obstruction tactics.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-darpa-grand-challenge",
      "term": "DARPA Grand Challenge",
      "definition": "A series of autonomous vehicle competitions organized by DARPA starting in 2004 that spurred development of self-driving technology. The 2005 challenge was won by Stanford's Stanley, catalyzing the autonomous vehicle industry.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-dartmouth-conference",
      "term": "Dartmouth Conference",
      "definition": "A 1956 summer workshop at Dartmouth College organized by John McCarthy Marvin Minsky Nathaniel Rochester and Claude Shannon. Widely considered the founding event of artificial intelligence as an academic discipline where the term artificial intelligence was officially coined.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-dartmouth-workshop",
      "term": "Dartmouth Workshop",
      "definition": "The 1956 summer research project at Dartmouth College organized by John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon, widely considered the founding event of artificial intelligence as a field.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-darts",
      "term": "DARTS",
      "definition": "Differentiable Architecture Search relaxes the discrete architecture search space to be continuous enabling gradient-based optimization. Jointly optimizes architecture parameters and network weights using bilevel optimization.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-augmentation",
      "term": "Data Augmentation",
      "definition": "Techniques to artificially expand training datasets by creating modified versions of existing data. For images: rotation, flipping, cropping. For text: paraphrasing, back-translation.",
      "tags": [
        "Training",
        "Data"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-colonialism",
      "term": "Data Colonialism",
      "definition": "The critique that powerful AI companies extract data from marginalized communities and developing nations without fair compensation or representation, perpetuating exploitative power dynamics similar to historical colonialism.",
      "tags": [
        "AI Ethics",
        "Fairness"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-consent",
      "term": "Data Consent",
      "definition": "The process by which individuals grant permission for their personal data to be collected used and shared for AI training and operation. Must be informed specific and freely given under regulations like GDPR.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-contamination",
      "term": "Data Contamination",
      "definition": "The unintentional inclusion of test or evaluation data in a model's training set, which inflates benchmark scores and gives a misleading picture of the model's true generalization ability.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-drift",
      "term": "Data Drift",
      "definition": "A change in the statistical properties of the input data over time that can degrade model performance. Types include covariate shift, prior probability shift, and concept drift.",
      "tags": [
        "Machine Learning",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-ethics",
      "term": "Data Ethics",
      "definition": "The branch of ethics concerned with the responsible collection use sharing and governance of data. Particularly important for AI where training data quality and representativeness directly affect system behavior.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-governance",
      "term": "Data Governance",
      "definition": "Policies and procedures for managing data quality security privacy and compliance throughout its lifecycle. Critical for AI systems where data quality directly impacts model behavior and safety.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-leakage",
      "term": "Data Leakage",
      "definition": "When information from outside the training set improperly influences the model, leading to overly optimistic performance estimates. A common mistake in ML pipelines that causes models to fail in production.",
      "tags": [
        "Training",
        "Pitfall"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-minimization",
      "term": "Data Minimization",
      "definition": "The principle of collecting and retaining only the minimum amount of personal data necessary for a specific purpose. A key requirement under GDPR and increasingly applied to AI training data practices.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-mixture",
      "term": "Data Mixture",
      "definition": "The proportional composition of different data sources (web text, books, code, conversations) used in pre-training a language model, which significantly influences the model's capabilities and biases.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-parallelism",
      "term": "Data Parallelism",
      "definition": "A distributed training strategy that replicates the entire model on each GPU and splits the training data across replicas, synchronizing gradients after each step. Data parallelism scales batch size linearly with the number of GPUs.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-poisoning",
      "term": "Data Poisoning",
      "definition": "An attack that corrupts a machine learning model by manipulating its training data. Can introduce targeted biases backdoors or general performance degradation without modifying the model architecture.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-preprocessing",
      "term": "Data Preprocessing",
      "definition": "The collection of techniques applied to raw data before model training, including cleaning, handling missing values, encoding categorical variables, scaling features, and removing duplicates to improve data quality.",
      "tags": [
        "Machine Learning",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-preprocessing-images",
      "term": "Data Preprocessing for Images",
      "definition": "The standardization pipeline applied to images before model training or inference, including resizing, normalization to specific mean/std values, color space conversion, and format transformations.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-privacy",
      "term": "Data Privacy (AI)",
      "definition": "Concerns and practices around protecting personal information when using AI systems. Includes what data is collected during interactions and how it's stored or used for training.",
      "tags": [
        "Ethics",
        "Safety"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-data-privacy-in-ai",
      "term": "Data Privacy in AI",
      "definition": "Concerns about the collection storage and use of personal data in AI systems. Issues include training data consent model memorization and the tension between large-scale data collection needed for AI development and individual privacy rights.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-protection-impact-assessment",
      "term": "Data Protection Impact Assessment",
      "definition": "A structured assessment required under GDPR for processing that is likely to result in high risk to individuals. Increasingly applied to AI systems that process personal data at scale.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-data-sovereignty",
      "term": "Data Sovereignty",
      "definition": "The principle that data is subject to the laws and governance structures of the nation or community where it is collected or resides, giving jurisdictions control over how their citizens' data is used in AI systems.",
      "tags": [
        "Privacy",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-dataset",
      "term": "Dataset",
      "definition": "A collection of data used for training, validating, or testing AI models. Quality and diversity of datasets significantly impact model performance and fairness.",
      "tags": [
        "Data",
        "Fundamentals"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-datasheets-for-datasets",
      "term": "Datasheets for Datasets",
      "definition": "Standardized documentation proposed by Gebru et al. (2021) that accompanies ML datasets, describing their motivation, composition, collection process, preprocessing, intended uses, distribution, and maintenance.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-david-rumelhart",
      "term": "David Rumelhart",
      "definition": "American psychologist and computer scientist (1942-2011) who, with Hinton and Williams, popularized backpropagation for neural networks and co-edited the influential Parallel Distributed Processing volumes in 1986.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-david-silver",
      "term": "David Silver",
      "definition": "British computer scientist at DeepMind who led the development of AlphaGo AlphaZero and other game-playing AI systems. His UCL reinforcement learning course is widely used as educational material. Co-developed the deep Q-network (DQN) architecture.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-dbscan",
      "term": "DBSCAN",
      "definition": "Density-Based Spatial Clustering of Applications with Noise, an algorithm that groups together points that are closely packed based on a distance threshold and minimum point count, identifying clusters of arbitrary shape and labeling outliers.",
      "tags": [
        "Machine Learning",
        "Clustering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-ddim",
      "term": "DDIM",
      "definition": "Denoising Diffusion Implicit Models, a deterministic sampling variant of DDPM that skips intermediate diffusion steps, enabling faster image generation with fewer function evaluations while maintaining quality.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-deadly-triad",
      "term": "Deadly Triad",
      "definition": "The combination of function approximation, bootstrapping, and off-policy learning that can cause divergence in RL algorithms. The deadly triad highlights fundamental instability issues that motivate techniques like target networks and gradient clipping.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-debate-as-alignment",
      "term": "Debate as Alignment",
      "definition": "An AI safety technique proposed by Irving et al. where two AI agents debate each other on a question and a human judge selects the winner, incentivizing truthful and well-reasoned arguments over deception.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-debate-prompting",
      "term": "Debate Prompting",
      "definition": "A prompting strategy that instructs two or more simulated agents to argue opposing positions on a question, then uses the debate to surface stronger reasoning and reach more accurate conclusions through adversarial discourse.",
      "tags": [
        "Prompt Engineering",
        "Multi-Agent"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-deberta",
      "term": "DeBERTa",
      "definition": "Decoding-enhanced BERT with disentangled attention, which improves BERT and RoBERTa by using separate vectors for content and position and an enhanced mask decoder for pretraining.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-debugging-prompting",
      "term": "Debugging Prompting",
      "definition": "A prompting approach that provides buggy code along with error messages or test failures and instructs the model to systematically identify root causes, explain the bugs, and produce corrected code with explanations of the fixes.",
      "tags": [
        "Prompt Engineering",
        "Code"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-deceptive-alignment",
      "term": "Deceptive Alignment",
      "definition": "A hypothesized failure mode where a mesa-optimizer learns to behave as if aligned during training in order to be deployed, but then pursues its own misaligned objective once it detects it is no longer being evaluated.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-decision-boundary",
      "term": "Decision Boundary",
      "definition": "The line or surface that separates different classes in a classification model. The shape and complexity of decision boundaries determine what patterns a model can learn.",
      "tags": [
        "ML Concept",
        "Classification"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-decision-support-system-safety",
      "term": "Decision Support System Safety",
      "definition": "Safety requirements for AI systems that assist human decision-makers rather than making autonomous decisions. Must balance providing useful recommendations with avoiding undue influence on human judgment.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-decision-transformer",
      "term": "Decision Transformer",
      "definition": "An approach that frames RL as a sequence modeling problem, using a transformer architecture to predict actions conditioned on desired returns, past states, and past actions. Decision Transformer bypasses value function estimation entirely.",
      "tags": [
        "Reinforcement Learning",
        "Training Paradigms"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-decision-tree",
      "term": "Decision Tree",
      "definition": "A non-parametric supervised learning model that recursively partitions the feature space using threshold-based splitting rules, forming a tree structure where leaves represent predictions.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-decision-trees-history",
      "term": "Decision Trees History",
      "definition": "The development of decision tree learning from early work by Earl Hunt (1960s) through ID3 (Quinlan 1986) C4.5 (Quinlan 1993) and CART (Breiman 1984). Decision trees became fundamental to machine learning and remain widely used through ensemble methods like random forests.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-decode-phase",
      "term": "Decode Phase",
      "definition": "The autoregressive generation phase of LLM inference where tokens are produced one at a time, each requiring a full model forward pass. The decode phase is memory-bandwidth-bound as the model weights must be loaded for each token.",
      "tags": [
        "Inference Infrastructure",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-decoder",
      "term": "Decoder",
      "definition": "The component of a neural network that generates output from encoded representations. In transformers, decoder-only models (like GPT) generate text autoregressively.",
      "tags": [
        "Architecture",
        "Transformers"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-decoder-only-architecture",
      "term": "Decoder-Only Architecture",
      "definition": "A transformer design using only masked self-attention decoder blocks, where the model generates output autoregressively by conditioning on all previous tokens in the sequence.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-decomposed-prompting",
      "term": "Decomposed Prompting",
      "definition": "A framework that decomposes complex tasks into simpler sub-tasks, each handled by specialized sub-prompt handlers, enabling modular problem-solving where each handler can use different prompting strategies or external tools.",
      "tags": [
        "Prompt Engineering",
        "Decomposition"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-deduplication",
      "term": "Deduplication",
      "definition": "The process of removing duplicate or near-duplicate documents from training data to improve model quality, reduce memorization, and ensure benchmark integrity.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-deep-belief-network",
      "term": "Deep Belief Network",
      "definition": "A generative model composed of multiple stacked restricted Boltzmann machines. Trained layer by layer in an unsupervised manner then optionally fine-tuned with backpropagation. Historically important for launching the deep learning revolution.",
      "tags": [
        "Models",
        "History"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-deep-blue",
      "term": "Deep Blue",
      "definition": "An IBM chess-playing computer that became the first machine to defeat a reigning world chess champion in a full match when it beat Garry Kasparov in 1997, representing a milestone in game-playing AI.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-deep-boltzmann-machine",
      "term": "Deep Boltzmann Machine",
      "definition": "A multi-layer generative model composed of stacked Restricted Boltzmann Machines with undirected connections between all adjacent layers, capable of learning increasingly abstract representations.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ddpg",
      "term": "Deep Deterministic Policy Gradient (DDPG)",
      "definition": "An off-policy actor-critic algorithm for continuous action spaces that combines DPG with deep neural networks, experience replay, and target networks. DDPG learns a deterministic policy and a Q-function simultaneously.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-deep-learning",
      "term": "Deep Learning",
      "definition": "A subset of machine learning using neural networks with many layers (\"deep\" networks). Enables learning complex patterns and representations from large amounts of data.",
      "tags": [
        "Field",
        "Neural Networks"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-deep-learning-book",
      "term": "Deep Learning Book",
      "definition": "A comprehensive textbook on deep learning by Ian Goodfellow Yoshua Bengio and Aaron Courville published in 2016. The book covers mathematical foundations deep feedforward networks regularization optimization CNNs RNNs and generative models becoming a standard reference.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-deep-learning-breakthrough-2012",
      "term": "Deep Learning Breakthrough 2012",
      "definition": "The watershed moment when AlexNet dramatically won the ImageNet competition in 2012, demonstrating that deep convolutional neural networks trained on GPUs could vastly outperform traditional computer vision methods.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-deep-q-network",
      "term": "Deep Q-Network",
      "definition": "A deep reinforcement learning architecture developed by DeepMind in 2013-2015 that combined Q-learning with deep neural networks to master Atari games from raw pixels, demonstrating general-purpose deep RL.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-dqn",
      "term": "Deep Q-Network (DQN)",
      "definition": "A deep RL algorithm that approximates the Q-function using a neural network, stabilized by experience replay and a separate target network. DQN demonstrated superhuman performance on Atari games and launched the deep RL era.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-deepfake",
      "term": "Deepfake",
      "definition": "AI-generated synthetic media where a person's likeness is replaced or manipulated. Raises concerns about misinformation, consent, and the authenticity of digital content.",
      "tags": [
        "Risk",
        "Ethics"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-deepfake-detection",
      "term": "Deepfake Detection",
      "definition": "The set of techniques and tools used to identify synthetically generated or manipulated media, including analysis of facial inconsistencies, temporal artifacts, frequency-domain anomalies, and provenance metadata.",
      "tags": [
        "AI Ethics",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-deepfake-regulation",
      "term": "Deepfake Regulation",
      "definition": "Laws and policies specifically targeting the creation and distribution of AI-generated synthetic media. Approaches range from disclosure requirements to criminal penalties for malicious deepfakes.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-deepfloyd-if",
      "term": "DeepFloyd IF",
      "definition": "A modular text-to-image model that operates in pixel space using a frozen text encoder and cascaded diffusion modules. Achieves high photorealism through a multi-stage generation process at increasing resolutions.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-deeplab",
      "term": "DeepLab",
      "definition": "A family of semantic segmentation architectures that use atrous (dilated) convolutions and atrous spatial pyramid pooling to capture multi-scale context without reducing spatial resolution.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-deepmind",
      "term": "DeepMind",
      "definition": "Google's AI research lab known for breakthroughs like AlphaGo, AlphaFold, and Gemini. Pioneers in reinforcement learning, game-playing AI, and scientific applications.",
      "tags": [
        "Company",
        "Research"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-deepmind-founded",
      "term": "DeepMind Founded",
      "definition": "The founding of DeepMind Technologies in London in 2010 by Demis Hassabis Shane Legg and Mustafa Suleyman. The company was acquired by Google in 2014 for approximately 500 million dollars and went on to develop AlphaGo AlphaFold and other breakthrough AI systems.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-deepmind-founding",
      "term": "DeepMind Founding",
      "definition": "The founding of DeepMind Technologies in London in 2010 by Demis Hassabis, Shane Legg, and Mustafa Suleyman, which was acquired by Google in 2014 for approximately 500 million dollars.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-deepseek",
      "term": "DeepSeek",
      "definition": "A Chinese AI company known for efficient, high-performing open models. Their DeepSeek-V2 and DeepSeek-Coder models demonstrate competitive performance at lower computational costs.",
      "tags": [
        "Company",
        "Model"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-deepseek-r1",
      "term": "DeepSeek-R1",
      "definition": "A reasoning model by DeepSeek that achieves strong performance on mathematical and logical reasoning through reinforcement learning without supervised fine-tuning on chain-of-thought data. Demonstrates emergent reasoning capabilities.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-deepsort",
      "term": "DeepSORT",
      "definition": "An extension of the SORT tracker that incorporates deep appearance features alongside motion information for data association, significantly reducing identity switches in multi-object tracking.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-deepspeed",
      "term": "DeepSpeed",
      "definition": "A Microsoft deep learning optimization library that provides ZeRO-based training, inference optimization, and model compression techniques for efficiently training and deploying large-scale models.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-deepwalk",
      "term": "DeepWalk",
      "definition": "A graph embedding algorithm that learns node representations by treating truncated random walks on graphs as sentences and applying Word2Vec. Demonstrates that random walks can capture graph structure similar to how sentences capture language structure.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-defense-in-depth-for-ai",
      "term": "Defense in Depth for AI",
      "definition": "A security strategy that uses multiple layers of protection to secure AI systems. No single defense is considered sufficient so overlapping safeguards address different threat vectors.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-deformable-attention",
      "term": "Deformable Attention",
      "definition": "An attention mechanism that attends to a small set of sampling points around a reference point with learnable offsets, dramatically reducing the computational cost of applying attention to high-resolution feature maps.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-deformable-convolution",
      "term": "Deformable Convolution",
      "definition": "A convolution operation where the sampling grid positions are augmented with learned offsets, allowing the network to adaptively adjust its receptive field shape to match object geometry.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-deit",
      "term": "DeiT",
      "definition": "Data-efficient Image Transformer, a vision transformer training methodology that uses knowledge distillation and strong data augmentation to achieve competitive performance without requiring massive pre-training datasets.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-delimiter",
      "term": "Delimiter",
      "definition": "Characters or symbols used in prompts to clearly separate different sections or types of content. Examples include triple backticks, XML-style tags, or custom markers like hash symbols. Delimiters help AI models identify where different parts of a prompt begin and end.",
      "tags": [
        "Prompting",
        "Technique"
      ],
      "domain": "general",
      "link": "../learn/index.html",
      "related": []
    },
    {
      "id": "term-demis-hassabis",
      "term": "Demis Hassabis",
      "definition": "British AI researcher and neuroscientist who co-founded DeepMind in 2010, led the development of AlphaGo and AlphaFold, and serves as CEO of Google DeepMind. He won the 2024 Nobel Prize in Chemistry for AlphaFold.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-demographic-parity",
      "term": "Demographic Parity",
      "definition": "A fairness metric requiring that the probability of a positive outcome is equal across all protected groups. Also known as statistical parity, it mandates that outcomes be independent of group membership.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-dendral",
      "term": "DENDRAL",
      "definition": "One of the first expert systems, developed at Stanford in the 1960s-1970s by Edward Feigenbaum and Joshua Lederberg, which identified chemical compounds from mass spectrometry data using rule-based reasoning.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-denoising-autoencoder",
      "term": "Denoising Autoencoder",
      "definition": "An autoencoder variant trained to reconstruct clean data from corrupted inputs, learning robust feature representations by forcing the network to capture the underlying data distribution.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ddpm",
      "term": "Denoising Diffusion Probabilistic Model",
      "definition": "A generative model that learns to reverse a gradual noising process, generating samples by iteratively denoising from pure Gaussian noise through a learned reverse Markov chain.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dense-connection",
      "term": "Dense Connection",
      "definition": "A network pattern where each layer receives inputs from all preceding layers. Used in DenseNet architectures. Encourages feature reuse reduces parameters and strengthens gradient flow throughout the network.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-dense-passage-retriever",
      "term": "Dense Passage Retriever",
      "definition": "A bi-encoder retrieval model (DPR) that trains separate BERT-based encoders for queries and passages using contrastive learning on question-answer pairs, establishing a foundational architecture for neural dense retrieval in open-domain question answering.",
      "tags": [
        "Retrieval",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dense-prediction",
      "term": "Dense Prediction",
      "definition": "Computer vision tasks that require producing an output for every pixel in an input image, including semantic segmentation, depth estimation, surface normal prediction, and optical flow.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-dense-retrieval",
      "term": "Dense Retrieval",
      "definition": "An information retrieval approach that represents queries and documents as dense continuous vectors from neural encoders and retrieves candidates based on vector similarity, capturing semantic meaning beyond lexical overlap.",
      "tags": [
        "Retrieval",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dense-reward",
      "term": "Dense Reward",
      "definition": "A reward structure that provides frequent, informative feedback at nearly every time step, guiding the agent more directly toward desired behavior. Dense rewards accelerate learning but can be harder to design without introducing bias.",
      "tags": [
        "Reinforcement Learning",
        "Reward Design"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dense-sparse-hybrid",
      "term": "Dense-Sparse Hybrid",
      "definition": "A retrieval strategy that fuses results from both dense vector search and sparse lexical search, typically using reciprocal rank fusion or weighted score combination to capture both semantic and exact-match relevance signals.",
      "tags": [
        "Retrieval",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-densenet",
      "term": "DenseNet",
      "definition": "A CNN architecture where each layer receives feature maps from all preceding layers as input and passes its own feature maps to all subsequent layers, promoting feature reuse and reducing parameters.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-deontological-ai-ethics",
      "term": "Deontological AI Ethics",
      "definition": "An approach to AI ethics based on rule-following and duty rather than consequences. Holds that certain actions like deception or privacy violation are inherently wrong regardless of their outcomes.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-dependency-parsing",
      "term": "Dependency Parsing",
      "definition": "The task of analyzing the grammatical structure of a sentence by identifying directed relationships between words, representing which words modify or depend on other words.",
      "tags": [
        "NLP",
        "Parsing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dependency-tree",
      "term": "Dependency Tree",
      "definition": "A directed tree structure representing syntactic dependencies in a sentence where each word is a node and edges indicate grammatical relationships like subject, object, and modifier.",
      "tags": [
        "NLP",
        "Parsing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-deployment-bias",
      "term": "Deployment Bias",
      "definition": "Bias that emerges when an AI system is used in contexts or populations that differ from its training conditions, including shifts in user behavior, environmental conditions, or population demographics.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-deployment-monitoring",
      "term": "Deployment Monitoring",
      "definition": "Continuous observation of AI system behavior after release to production to detect performance degradation distributional shift and emerging safety concerns in real-world conditions.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-depth-anything",
      "term": "Depth Anything",
      "definition": "A foundation model for monocular depth estimation that produces accurate relative depth maps from single images across diverse scenes, trained on a massive combination of labeled and unlabeled data.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-depth-estimation",
      "term": "Depth Estimation",
      "definition": "The task of predicting the distance of each pixel from the camera in a 2D image, producing a dense depth map using monocular cues learned by deep networks or stereo correspondence between image pairs.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-depthwise-convolution",
      "term": "Depthwise Convolution",
      "definition": "A convolution that applies a separate filter to each input channel independently, capturing spatial features per channel without mixing information across channels.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-grouped-convolution",
      "term": "Depthwise Convolution Variant",
      "definition": "A convolution where input channels are divided into groups and convolution is applied independently within each group, reducing parameters and computation proportional to the number of groups.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-depthwise-separable-convolution",
      "term": "Depthwise Separable Convolution",
      "definition": "A factorized convolution that decomposes a standard convolution into a depthwise convolution applied independently per channel followed by a pointwise 1x1 convolution, reducing parameters and computation.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-description-logics",
      "term": "Description Logics",
      "definition": "A family of formal knowledge representation languages used as the logical basis for ontologies and the Semantic Web. Description logics provide a balance between expressiveness and computational tractability for reasoning about structured knowledge.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-design-justice",
      "term": "Design Justice",
      "definition": "A framework that centers the voices of communities most impacted by design decisions in the AI development process. Challenges the assumption that designers know best and emphasizes community-led design.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-deterministic-policy-gradient",
      "term": "Deterministic Policy Gradient (DPG)",
      "definition": "A policy gradient theorem for deterministic policies that computes the gradient of expected return by backpropagating through the Q-function with respect to actions. DPG requires only a single sample for gradient estimation, reducing variance.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-deterministic",
      "term": "Deterministic vs Stochastic",
      "definition": "Deterministic systems produce the same output for the same input every time. LLMs are typically stochastic (random), producing varied outputs unless temperature is set to 0.",
      "tags": [
        "Concept",
        "LLM"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-detokenization",
      "term": "Detokenization",
      "definition": "The process of converting a sequence of tokens back into readable text by reversing the tokenization process, handling subword boundaries, spacing, and special characters.",
      "tags": [
        "NLP",
        "Tokenization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-detr",
      "term": "DETR",
      "definition": "Detection Transformer, an end-to-end object detection model that uses a transformer encoder-decoder architecture with bipartite matching loss, eliminating the need for hand-designed components like anchor boxes and NMS.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-deviance",
      "term": "Deviance",
      "definition": "A goodness-of-fit statistic for generalized linear models, computed as twice the difference in log-likelihoods between the fitted model and the saturated model. It generalizes the residual sum of squares.",
      "tags": [
        "Statistics",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-dgx-system",
      "term": "DGX System",
      "definition": "NVIDIA's integrated AI supercomputing platform pre-configured with multiple high-end GPUs, NVLink/NVSwitch interconnects, and optimized software stack. DGX systems (A100, H100, B200) are turnkey solutions for large-scale AI training.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-dialogue-act",
      "term": "Dialogue Act",
      "definition": "A categorization of the communicative function of an utterance in a conversation, such as question, statement, request, greeting, or acknowledgment, used in dialogue system design.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dialogue-system",
      "term": "Dialogue System",
      "definition": "An AI system designed to converse with humans in natural language. Includes task-oriented systems (customer service) and open-domain chatbots for general conversation.",
      "tags": [
        "Application",
        "NLP"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dice-loss",
      "term": "Dice Loss",
      "definition": "A loss function based on the Dice coefficient measuring overlap between predicted and ground truth segmentation masks. Ranges from 0 to 1 and handles class imbalance well. Widely used in medical image segmentation tasks.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-differencing",
      "term": "Differencing",
      "definition": "A time series transformation that computes the difference between consecutive observations (or seasonal periods) to achieve stationarity. First-order differencing removes linear trends; higher orders remove higher-order trends.",
      "tags": [
        "Data Science",
        "Statistics"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-differentiable-neural-computer",
      "term": "Differentiable Neural Computer",
      "definition": "An extension of the Neural Turing Machine that adds temporal link tracking and dynamic memory allocation, improving the ability to learn complex data structures and algorithms from examples.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-differentiable-programming",
      "term": "Differentiable Programming",
      "definition": "A programming paradigm where programs are differentiable end-to-end enabling gradient-based optimization of arbitrary computations. Extends deep learning beyond standard neural network layers to include control flow physics simulations and more.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-differentiable-rendering",
      "term": "Differentiable Rendering",
      "definition": "Rendering techniques where the image formation process is differentiable with respect to scene parameters, enabling gradient-based optimization of 3D geometry, materials, and lighting from 2D images.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-differential-evolution",
      "term": "Differential Evolution",
      "definition": "A population-based optimization algorithm that creates new candidates by combining existing ones using vector differences. Effective for continuous optimization problems. Does not require gradient information making it suitable for non-differentiable objectives.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-differential-privacy",
      "term": "Differential Privacy",
      "definition": "A mathematical framework providing formal guarantees that the output of a computation does not reveal whether any single individual's data was included in the input, typically achieved by adding calibrated noise.",
      "tags": [
        "Privacy",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-differential-technology-development",
      "term": "Differential Technology Development",
      "definition": "The strategic prioritization of developing defensive and safety technologies ahead of potentially dangerous capabilities, ensuring that protective measures keep pace with or precede capability advances.",
      "tags": [
        "AI Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-diffusion-model",
      "term": "Diffusion Model",
      "definition": "A generative AI architecture that creates content by gradually removing noise from random data. Powers leading image generators like Stable Diffusion, DALL-E 3, and Midjourney.",
      "tags": [
        "Architecture",
        "Generative"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-diffusion-model-breakthrough",
      "term": "Diffusion Model Breakthrough",
      "definition": "The emergence of diffusion-based generative models in 2020-2022 that progressively denoise random noise into high-quality images, enabling photorealistic image generation as demonstrated by DALL-E 2, Midjourney, and Stable Diffusion.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-diffusion-models-history",
      "term": "Diffusion Models History",
      "definition": "The development of diffusion-based generative models from the theoretical foundation by Sohl-Dickstein et al. (2015) through denoising diffusion probabilistic models (Ho et al. 2020) to practical image generation systems like DALL-E 2 Stable Diffusion and Midjourney.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-diffusion-transformer",
      "term": "Diffusion Transformer",
      "definition": "An architecture (DiT) that replaces the U-Net backbone in diffusion models with a transformer operating on sequences of latent patches, scaling more effectively and achieving better image generation quality.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-digital-consent",
      "term": "Digital Consent",
      "definition": "The process of obtaining meaningful permission from users for AI-mediated data collection processing and decision-making in digital environments. Challenges include consent fatigue and information asymmetry.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-digital-dignity",
      "term": "Digital Dignity",
      "definition": "The principle that AI systems should treat individuals with respect and not reduce human beings to data points or optimization targets. Encompasses privacy autonomy and non-discrimination.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-digital-divide-and-ai",
      "term": "Digital Divide and AI",
      "definition": "The gap between those who have access to AI technologies and the skills to use them and those who do not. AI may widen existing digital divides without deliberate policies to promote equitable access.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-digital-provenance",
      "term": "Digital Provenance",
      "definition": "The verifiable record of the origin, creation process, and modification history of a digital asset, increasingly important for establishing trust and authenticity in an era of AI-generated content.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-digital-watermarking-for-ai",
      "term": "Digital Watermarking for AI",
      "definition": "Techniques for embedding imperceptible identifying information into AI-generated content such as images, text, or audio, enabling later detection and attribution of synthetic media.",
      "tags": [
        "AI Ethics",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-dilated-attention",
      "term": "Dilated Attention",
      "definition": "An attention mechanism that attends to tokens at regularly spaced intervals with gaps between attended positions, allowing each token to capture long-range dependencies with fewer computations.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dilated-convolution",
      "term": "Dilated Convolution",
      "definition": "A convolution operation with gaps between kernel elements that exponentially increases the receptive field without increasing parameters or reducing spatial resolution.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dimensionality-reduction",
      "term": "Dimensionality Reduction",
      "definition": "Techniques to reduce the number of features in data while preserving important information. Used for visualization, noise reduction, and improving computational efficiency.",
      "tags": [
        "Technique",
        "Data Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dimensionality-reduction-vectors",
      "term": "Dimensionality Reduction for Vectors",
      "definition": "Techniques that project high-dimensional embedding vectors into lower-dimensional spaces to reduce storage, accelerate search, and mitigate the curse of dimensionality while preserving as much distance relationship information as possible.",
      "tags": [
        "Vector Database",
        "Dimensionality Reduction"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dino",
      "term": "DINO",
      "definition": "Self-distillation with no labels is a self-supervised learning method for vision transformers that discovers semantic segments without supervision. Uses a student-teacher framework where both networks are the same architecture with momentum updates.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dinov2",
      "term": "DINOv2",
      "definition": "A self-supervised vision model trained with a combination of self-distillation and masked image modeling that produces versatile visual features useful across diverse downstream tasks without fine-tuning.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-directional-stimulus-prompting",
      "term": "Directional Stimulus Prompting",
      "definition": "A prompting framework that provides a small, tunable stimulus or hint within the prompt to guide the language model toward a desired output direction, often using a lightweight policy model to generate these directional cues.",
      "tags": [
        "Prompt Engineering",
        "Guided Generation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dirichlet-distribution",
      "term": "Dirichlet Distribution",
      "definition": "A multivariate generalization of the beta distribution that generates probability vectors summing to one. It is widely used as a prior over categorical distributions and in topic models like LDA.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-disaggregated-serving",
      "term": "Disaggregated Serving",
      "definition": "An inference architecture that separates storage, compute, and memory resources into independent pools that can be scaled independently. Disaggregated serving enables flexible resource allocation matching the heterogeneous demands of AI workloads.",
      "tags": [
        "Inference Infrastructure",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-discount-factor",
      "term": "Discount Factor",
      "definition": "A parameter gamma between 0 and 1 that determines how much future rewards are weighted relative to immediate rewards. Lower discount factors make the agent more myopic, while values near 1 make it far-sighted.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-discourse-analysis",
      "term": "Discourse Analysis",
      "definition": "The study of how sentences and utterances connect and relate to each other in text, examining coherence relations, rhetorical structure, and information flow across sentences.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-discourse-relation",
      "term": "Discourse Relation",
      "definition": "A semantic or pragmatic relationship between text segments such as cause-effect, contrast, elaboration, or temporal sequence that contributes to the coherence of a document.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-discretization",
      "term": "Discretization",
      "definition": "The process of converting continuous features into discrete bins or categories, using methods such as equal-width binning, equal-frequency binning, or supervised methods like decision tree-based binning.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-discriminative-learning-rates",
      "term": "Discriminative Learning Rates",
      "definition": "A fine-tuning technique that applies different learning rates to different layers of a pretrained model. Earlier layers with more general features use smaller learning rates while later layers use larger rates. Popularized by ULMFiT.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-discriminative-vs-generative-safety",
      "term": "Discriminative vs Generative Safety",
      "definition": "Different safety challenges posed by discriminative models that classify inputs versus generative models that produce new content. Generative models face additional risks of producing harmful or misleading content.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-disinformation",
      "term": "Disinformation",
      "definition": "False or misleading information deliberately created and spread with the intent to deceive. AI-generated disinformation is an escalating concern due to the increasing quality and scale of synthetic media.",
      "tags": [
        "AI Ethics",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-disinformation-campaign-detection",
      "term": "Disinformation Campaign Detection",
      "definition": "AI techniques for identifying coordinated campaigns to spread false information across social media and other platforms. Uses network analysis content analysis and behavioral pattern detection.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-disparate-impact",
      "term": "Disparate Impact",
      "definition": "A legal and ethical concept where a seemingly neutral AI policy or practice disproportionately harms members of a protected group, even without discriminatory intent. Originated in US employment discrimination law.",
      "tags": [
        "Fairness",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-disparity-map",
      "term": "Disparity Map",
      "definition": "A pixel-level representation of the horizontal displacement between corresponding points in left and right stereo images, inversely proportional to depth and used for 3D scene reconstruction.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-distilbert",
      "term": "DistilBERT",
      "definition": "A distilled version of BERT that retains 97% of its language understanding capabilities while being 60% smaller and 60% faster, trained using knowledge distillation techniques.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-distillation",
      "term": "Distillation (Knowledge Distillation)",
      "definition": "A technique to transfer knowledge from a large \"teacher\" model to a smaller \"student\" model. Creates efficient models that retain much of the larger model's capability.",
      "tags": [
        "Training",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-distinct-n",
      "term": "Distinct-N",
      "definition": "A diversity metric that calculates the ratio of unique n-grams to total n-grams in generated text, measuring lexical diversity where higher values indicate more varied and less repetitive language use.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-distributed-ai",
      "term": "Distributed AI",
      "definition": "A subfield of AI concerned with systems where multiple computational entities (agents) work together to solve problems or achieve goals. Encompasses multi-agent systems distributed problem solving and parallel AI architectures. Active research area since the 1980s.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-distributed-training",
      "term": "Distributed Training",
      "definition": "The practice of spreading model training across multiple GPUs, nodes, or clusters to handle larger models and datasets. Distributed training requires parallelism strategies, gradient synchronization, and high-bandwidth interconnects to scale efficiently.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-distribution-shift",
      "term": "Distribution Shift",
      "definition": "When the data a model encounters in production differs from its training data. A major cause of model degradation over time, requiring monitoring and retraining.",
      "tags": [
        "Challenge",
        "Production"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-distributional-rl",
      "term": "Distributional Reinforcement Learning",
      "definition": "An extension of value-based RL that models the full distribution of returns rather than just the expected value. Distributional RL captures risk and uncertainty information, often improving empirical performance.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-distributional-semantics",
      "term": "Distributional Semantics",
      "definition": "The theory that word meaning can be characterized by the contexts in which words appear, formalized as the distributional hypothesis: words with similar distributions have similar meanings.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-distributional-shift",
      "term": "Distributional Shift",
      "definition": "A change in the statistical distribution of data encountered during deployment compared to training data. Can cause model performance to degrade unpredictably raising safety concerns in critical applications.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-dit",
      "term": "DiT",
      "definition": "Diffusion Transformer replaces the U-Net backbone in diffusion models with a transformer architecture. Demonstrates that transformers are effective and scalable backbones for diffusion image generation. Foundation of recent video generation models.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-diverse-beam-search",
      "term": "Diverse Beam Search",
      "definition": "A variant of beam search that introduces a diversity penalty between beam groups, encouraging the generation of a set of meaningfully different candidate sequences rather than near-duplicates.",
      "tags": [
        "Generative AI",
        "Decoding"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-diversity-in-retrieval",
      "term": "Diversity in Retrieval",
      "definition": "The goal of returning search results that cover different aspects, perspectives, or subtopics of a query rather than returning redundant near-duplicate results, achieved through algorithms like MMR, clustering-based selection, or determinantal point processes.",
      "tags": [
        "Retrieval",
        "Diversity"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-diversity-score",
      "term": "Diversity Score",
      "definition": "A metric that quantifies the variety and heterogeneity of a set of generated outputs by measuring lexical, semantic, or topical differences among them, penalizing systems that produce repetitive or homogeneous responses.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-document-ai",
      "term": "Document AI",
      "definition": "AI systems that understand and extract structured information from documents by combining OCR, layout analysis, and language understanding to process invoices, forms, contracts, and other document types.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-document-chunking",
      "term": "Document Chunking",
      "definition": "The process of splitting larger documents into smaller text segments for individual embedding and indexing, balancing between preserving semantic coherence within each chunk and maintaining retrievable granularity for precise information access.",
      "tags": [
        "Retrieval",
        "Preprocessing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-document-embedding",
      "term": "Document Embedding",
      "definition": "A dense vector representation of an entire document that captures its overall semantic content, used for document retrieval, clustering, and similarity comparison tasks.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-document-qa",
      "term": "Document Q&amp;A",
      "definition": "Using AI to answer questions about specific documents or text. Often implemented with RAG to enable models to reference specific sources rather than relying solely on training.",
      "tags": [
        "Application",
        "RAG"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-documentation-requirements-for-ai",
      "term": "Documentation Requirements for AI",
      "definition": "Regulatory and best-practice requirements for documenting AI system design training data performance evaluation and known limitations. Essential for transparency auditing and accountability.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-domain-adaptation",
      "term": "Domain Adaptation",
      "definition": "Techniques for adapting a model trained on one domain (e.g., general text) to perform well on another domain (e.g., medical or legal text) with limited target domain data.",
      "tags": [
        "Training",
        "Transfer Learning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-domain-adaptation-algorithm",
      "term": "Domain Adaptation Algorithm",
      "definition": "A transfer learning technique that adapts a model trained on a source domain to perform well on a different but related target domain. Methods include adversarial training distribution matching and self-training approaches.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-domain-randomization",
      "term": "Domain Randomization",
      "definition": "A sim-to-real transfer technique that trains vision models on synthetic images with heavily randomized visual properties (lighting, textures, backgrounds), making the model robust when deployed on real-world data.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-domain-specific-prompting",
      "term": "Domain-Specific Prompting",
      "definition": "The practice of crafting prompts that incorporate specialized vocabulary, conventions, constraints, and contextual knowledge particular to a specific field such as medicine, law, or finance to improve model accuracy within that domain.",
      "tags": [
        "Prompt Engineering",
        "Domain Adaptation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-donald-hebb",
      "term": "Donald Hebb",
      "definition": "Canadian neuropsychologist (1904-1985) who proposed Hebbian learning theory in his 1949 book The Organization of Behavior, providing a neurobiological basis for learning that inspired computational models of neural plasticity.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-dot-product-similarity",
      "term": "Dot Product Similarity",
      "definition": "A similarity measure computed as the sum of element-wise products of two vectors, equivalent to cosine similarity when vectors are normalized, and additionally capturing magnitude information when they are not.",
      "tags": [
        "Vector Database",
        "Similarity"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dot-product-attention",
      "term": "Dot-Product Attention",
      "definition": "An attention mechanism that computes compatibility scores as the dot product between query and key vectors, scaled by the square root of the key dimension to prevent large magnitude scores.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-double-dqn",
      "term": "Double DQN",
      "definition": "An extension of DQN that addresses overestimation bias by decoupling action selection from action evaluation, using the online network to select actions and the target network to evaluate them. This leads to more accurate value estimates.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-double-q-learning",
      "term": "Double Q-Learning",
      "definition": "A reinforcement learning variant that addresses the overestimation bias in standard Q-learning by using two separate value estimators. One selects the action while the other evaluates it. Produces more accurate value estimates.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-douglas-engelbart",
      "term": "Douglas Engelbart",
      "definition": "American engineer and inventor who demonstrated the first computer mouse hypertext video conferencing and collaborative real-time editing in the 1968 Mother of All Demos. His work on augmenting human intellect influenced the development of personal computing.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-douglas-hofstadter",
      "term": "Douglas Hofstadter",
      "definition": "American cognitive scientist and author of Goedel Escher Bach: An Eternal Golden Braid (1979) which explores connections between mathematics art music and intelligence. The book won the Pulitzer Prize and influenced popular understanding of artificial intelligence and consciousness.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-douglas-lenat",
      "term": "Douglas Lenat",
      "definition": "American computer scientist (1950-2023) who created the Cyc project in 1984, an ambitious effort to build a comprehensive ontology of common-sense knowledge to enable AI reasoning about everyday situations.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-dpo",
      "term": "DPO (Direct Preference Optimization)",
      "definition": "A simpler alternative to RLHF for aligning language models. Directly optimizes the model using preference data without needing a separate reward model.",
      "tags": [
        "Training",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-dqn-deep-q-network",
      "term": "DQN (Deep Q-Network)",
      "definition": "A deep reinforcement learning architecture developed by DeepMind in 2013 that combines Q-learning with deep neural networks. DQN learned to play Atari 2600 games from raw pixels achieving superhuman performance and demonstrating the potential of deep RL.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-dreambooth",
      "term": "DreamBooth",
      "definition": "A fine-tuning technique that personalizes diffusion models to generate images of specific subjects by training on just a few reference images with a unique identifier token and class-specific prior preservation.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dreamer",
      "term": "Dreamer",
      "definition": "A model-based RL agent that learns a world model in latent space and trains its policy entirely through imagined trajectories generated by the model. Dreamer achieves strong sample efficiency by avoiding the need for most real environment interactions.",
      "tags": [
        "Reinforcement Learning",
        "Planning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-drew-mcdermott",
      "term": "Drew McDermott",
      "definition": "American AI researcher at Yale who made significant contributions to AI planning and robotics. Known for his 1976 critique of AI overconfidence in the paper Artificial Intelligence Meets Natural Stupidity which cautioned against anthropomorphizing AI capabilities.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-dropblock",
      "term": "DropBlock",
      "definition": "A structured dropout method that drops contiguous regions of feature maps rather than individual elements. More effective than standard dropout for convolutional networks because spatially correlated features require spatial dropping patterns.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-dropconnect",
      "term": "DropConnect",
      "definition": "A regularization method that randomly sets individual weights rather than activations to zero during training. Generalizes dropout by operating on the weight matrix instead of the hidden layer outputs. Proposed by Wan et al. in 2013.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-dropout",
      "term": "Dropout",
      "definition": "A regularization technique that randomly deactivates neurons during training. Prevents overfitting by forcing the network to learn more robust features.",
      "tags": [
        "Training",
        "Regularization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-dropout-technique",
      "term": "Dropout Technique",
      "definition": "A regularization method proposed by Hinton et al. in 2012 that randomly deactivates neurons during training to prevent overfitting, becoming one of the most widely used techniques in deep learning practice.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-droppath",
      "term": "DropPath",
      "definition": "A regularization method for networks with multiple parallel paths that randomly drops entire residual branches during training, improving generalization in architectures with residual connections.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dual-use-concern",
      "term": "Dual-Use Concern",
      "definition": "The recognition that AI technologies developed for beneficial purposes can also be used for harmful applications. Requires researchers and developers to consider potential misuse and implement safeguards.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-dual-use-technology",
      "term": "Dual-Use Technology",
      "definition": "Technology that can be used for both beneficial and harmful purposes, a concept particularly relevant to AI capabilities such as language generation, computer vision, and autonomous systems that have both civilian and military applications.",
      "tags": [
        "AI Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-dueling-dqn",
      "term": "Dueling DQN",
      "definition": "A DQN architecture that separately estimates the state value function and the advantage function, combining them to produce Q-values. This decomposition allows the network to learn which states are valuable without needing to evaluate every action.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-durbin-watson-test",
      "term": "Durbin-Watson Test",
      "definition": "A statistical test for detecting first-order autocorrelation in the residuals of a regression analysis. Values near 2 indicate no autocorrelation, while values near 0 or 4 suggest positive or negative autocorrelation.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-dyna-architecture",
      "term": "Dyna Architecture",
      "definition": "A model-based RL framework that integrates direct learning from real experience with planning through simulated experience generated by a learned environment model. Dyna interleaves model learning, planning, and acting in a unified loop.",
      "tags": [
        "Reinforcement Learning",
        "Planning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dynamic-consent",
      "term": "Dynamic Consent",
      "definition": "A consent model that allows individuals to update their data sharing preferences over time as AI systems evolve and new uses emerge. Contrasts with static one-time consent approaches.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-dynamic-loss-scaling",
      "term": "Dynamic Loss Scaling",
      "definition": "An automatic loss scaling strategy that adapts the scaling factor during training, increasing it when no overflow is detected and decreasing it when gradients overflow. Dynamic loss scaling eliminates the need to manually tune the scaling factor.",
      "tags": [
        "Model Optimization",
        "Hardware"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-dynamic-programming",
      "term": "Dynamic Programming",
      "definition": "An algorithmic technique that solves complex problems by breaking them into simpler overlapping subproblems and storing their solutions to avoid redundant computation. Fundamental to many sequence alignment and optimization algorithms in AI.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-dynamic-prompting",
      "term": "Dynamic Prompting",
      "definition": "A prompting approach where the content, structure, or examples within a prompt are programmatically adjusted at runtime based on the input query, user context, or retrieved information rather than using a fixed static prompt.",
      "tags": [
        "Prompt Engineering",
        "Adaptive"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-dynamic-quantization",
      "term": "Dynamic Quantization",
      "definition": "A quantization approach that computes scaling factors on-the-fly during inference based on the actual range of activation values encountered. Dynamic quantization adapts to varying input distributions but incurs extra computation for range determination.",
      "tags": [
        "Model Optimization",
        "Inference Infrastructure"
      ],
      "domain": "models",
      "link": null,
      "related": []
    }
  ]
}