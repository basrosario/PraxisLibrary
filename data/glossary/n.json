{
  "letter": "n",
  "count": 204,
  "terms": [
    {
      "id": "term-n-beats",
      "term": "N-BEATS",
      "definition": "Neural Basis Expansion Analysis for Time Series is a deep learning model for time series forecasting that uses backward and forward residual links.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-n-gram",
      "term": "N-gram",
      "definition": "A contiguous sequence of N items from a text, where items can be characters, words, or tokens, used in language models, text classification, and information retrieval.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-n-gram-language-model",
      "term": "N-gram Language Model",
      "definition": "A statistical language model that predicts the next word based on the preceding n-1 words. Uses maximum likelihood estimation with smoothing techniques like Kneser-Ney to handle unseen n-grams.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-n-hits",
      "term": "N-HiTS",
      "definition": "Neural Hierarchical Interpolation for Time Series extends N-BEATS with multi-rate sampling and hierarchical interpolation for improved long-horizon forecasting.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-n-step-return",
      "term": "N-Step Return",
      "definition": "A return estimate that uses n actual rewards before bootstrapping with a value estimate, interpolating between one-step TD (n=1) and full Monte Carlo (n=infinity). N-step returns offer a bias-variance tradeoff controlled by the step parameter.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nadam",
      "term": "Nadam",
      "definition": "Nesterov-accelerated Adaptive Moment estimation combines the Adam optimizer with Nesterov momentum. Provides faster convergence by incorporating the look-ahead gradient computation from Nesterov accelerated gradient into Adam.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-naive-bayes",
      "term": "Naive Bayes",
      "definition": "A family of probabilistic classifiers based on Bayes' theorem with the strong assumption that features are conditionally independent given the class label. Despite this simplification, it often performs well on text classification tasks.",
      "tags": [
        "Machine Learning",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-naive-bayes-classifier",
      "term": "Naive Bayes Classifier",
      "definition": "A probabilistic classifier based on Bayes' theorem that assumes feature independence and works well for text classification and spam filtering tasks.",
      "tags": [
        "Models",
        "Fundamentals",
        "History",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-naive-bayes-history",
      "term": "Naive Bayes History",
      "definition": "The application of Bayes' theorem with naive independence assumptions to classification tasks. Despite its simplicity naive Bayes became one of the most practical machine learning algorithms especially for text classification and spam filtering from the 1990s onward.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-named-entity-linking",
      "term": "Named Entity Linking",
      "definition": "The task of mapping recognized named entity mentions in text to their corresponding entries in a knowledge base, resolving ambiguity when multiple entities share the same name.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-named-entity-recognition",
      "term": "Named Entity Recognition (NER)",
      "definition": "An NLP task that identifies and classifies named entities (people, organizations, locations, dates) in text. Foundational for information extraction and knowledge graph construction.",
      "tags": [
        "NLP Task",
        "Extraction"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-named-entity-recognition-algorithm",
      "term": "Named Entity Recognition Algorithm",
      "definition": "An algorithm that identifies and classifies named entities (such as people and organizations and locations) in text. Approaches range from conditional random fields to transformer-based sequence labeling models.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-namespace",
      "term": "Namespace",
      "definition": "A logical partitioning mechanism within a vector database index that isolates vectors into separate searchable segments, enabling multi-tenant applications and scoped queries without maintaining separate physical indexes.",
      "tags": [
        "Vector Database",
        "Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-narrativeqa",
      "term": "NarrativeQA",
      "definition": "A question answering dataset requiring understanding of entire books and movie scripts. Questions are written about summaries but must be answered from full-length source documents.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-narrow-ai",
      "term": "Narrow AI (ANI)",
      "definition": "AI systems designed for specific tasks, like playing chess or generating text. All current AI is narrow, as opposed to hypothetical artificial general intelligence (AGI).",
      "tags": [
        "Category",
        "Concept"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-narrow-ai-safety",
      "term": "Narrow AI Safety",
      "definition": "Safety research focused on currently deployed AI systems, addressing issues such as robustness to distribution shift, adversarial inputs, reward misspecification, and safe exploration in constrained environments.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-nasnet",
      "term": "NASNet",
      "definition": "Neural Architecture Search Network designed automatically by a reinforcement learning controller searching over a space of possible architectures. Demonstrated that machine-designed architectures can outperform human-designed ones on ImageNet.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nathaniel-rochester",
      "term": "Nathaniel Rochester",
      "definition": "American computer scientist at IBM who co-organized the 1956 Dartmouth Conference that founded AI as a field. Rochester led the development of the first assembler (for the IBM 701) and worked on early neural network simulations at IBM in the 1950s.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-instructions",
      "term": "Natural Instructions",
      "definition": "A community effort collecting over 1600 diverse NLP tasks with expert-written instructions and examples. Used for training and evaluating instruction-following language models.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-language",
      "term": "Natural Language",
      "definition": "Human language as we naturally speak and write it. AI assistants are designed to understand natural language, so you don't need special syntax or formatting.",
      "tags": [
        "Concept",
        "Interface"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-language-inference",
      "term": "Natural Language Inference",
      "definition": "The task of classifying the logical relationship between a premise and hypothesis text pair into entailment, contradiction, or neutral, testing a model's ability to reason about meaning.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nlp",
      "term": "Natural Language Processing (NLP)",
      "definition": "The field of AI focused on enabling computers to understand, interpret, and generate human language. Encompasses tasks from translation to summarization to dialogue.",
      "tags": [
        "Field",
        "Language"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nlp-history",
      "term": "Natural Language Processing History",
      "definition": "The evolution of NLP from rule-based approaches in the 1960s through statistical methods in the 1990s to neural approaches in the 2010s and the transformer revolution, culminating in modern large language models.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-language-understanding-history",
      "term": "Natural Language Understanding History",
      "definition": "The evolution of machine understanding of human language from early pattern matching (ELIZA 1966) and microworld systems (SHRDLU 1970) through statistical methods (1990s) to deep learning-based approaches (2010s) and large language models.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-policy-gradient",
      "term": "Natural Policy Gradient",
      "definition": "A policy gradient method that preconditions updates with the inverse Fisher information matrix, following the steepest ascent direction in the space of policy distributions rather than parameter space. Natural gradients provide more efficient optimization.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-questions",
      "term": "Natural Questions",
      "definition": "A question answering benchmark by Google consisting of real user queries from Google Search paired with Wikipedia articles, requiring models to identify both short answers and long answer passages to satisfy genuine information needs.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-questions-open",
      "term": "Natural Questions Open",
      "definition": "The open-domain version of Natural Questions where models must answer Google queries without a specified evidence document. Tests open-domain question answering ability.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-naturalspeech",
      "term": "NaturalSpeech",
      "definition": "A text-to-speech system from Microsoft that achieves human-level quality on single-speaker recording studio data through variational autoencoders and flow models.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-naturalspeech-2",
      "term": "NaturalSpeech 2",
      "definition": "A zero-shot speech synthesis model from Microsoft that uses a latent diffusion model with a neural audio codec for diverse and natural-sounding voices.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nccl",
      "term": "NCCL",
      "definition": "NVIDIA Collective Communications Library, a highly optimized library for multi-GPU and multi-node collective communication operations. NCCL automatically selects the best communication algorithms and topologies for the available hardware interconnects.",
      "tags": [
        "Distributed Computing",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ndcg",
      "term": "NDCG",
      "definition": "Normalized Discounted Cumulative Gain, a ranking quality metric that evaluates the usefulness of retrieved items based on their position in the result list, assigning higher weights to relevant items appearing earlier and normalizing against the ideal ranking.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-near-memory-computing",
      "term": "Near-Memory Computing",
      "definition": "Architecture placing compute units physically close to memory to reduce data transfer latency and energy. A promising approach for accelerating memory-bound AI operations.",
      "tags": [
        "Memory",
        "Architecture",
        "Emerging"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-neats-vs-scruffies",
      "term": "Neats vs Scruffies",
      "definition": "A characterization of a philosophical divide in AI research during the 1970s and 1980s. Neats favored formal mathematical approaches and provably correct algorithms while scruffies preferred heuristic approaches and pragmatic solutions that worked in practice even without formal guarantees.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-nectar",
      "term": "Nectar",
      "definition": "A preference ranking dataset created by aggregating multiple existing preference datasets into a unified format. Provides diverse comparison data for RLHF training of language models.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-needle-in-haystack-test",
      "term": "Needle in a Haystack Test",
      "definition": "An evaluation method that measures a language model's ability to retrieve a specific piece of information placed at various positions within a long context, revealing attention degradation patterns.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-negamax-algorithm",
      "term": "Negamax Algorithm",
      "definition": "A simplified variant of the minimax algorithm that exploits the zero-sum property by negating values rather than alternating between maximizing and minimizing. Reduces code complexity while producing identical results.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL",
        "Searching"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-negation-detection",
      "term": "Negation Detection",
      "definition": "The task of identifying negation cues and their scope in text, determining which parts of a sentence are affected by negation words like 'not,' 'never,' or 'without.'",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-negative-externality",
      "term": "Negative Externality",
      "definition": "A cost imposed on third parties who are not involved in an AI transaction or interaction. AI systems can generate negative externalities through environmental impact discrimination and social disruption.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-negative-prompt",
      "term": "Negative Prompt",
      "definition": "Instructions telling AI what to avoid in its output. Common in image generation (\"no blur, no distortion\") and can be used in text to exclude certain topics or styles.",
      "tags": [
        "Prompting",
        "Technique"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-negative-prompting",
      "term": "Negative Prompting",
      "definition": "A technique that explicitly specifies what the model should avoid in its output, including unwanted content, styles, formats, or behaviors, using exclusion instructions to constrain the generation space toward desired outputs.",
      "tags": [
        "Prompt Engineering",
        "Constraints"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-negative-sampling",
      "term": "Negative Sampling",
      "definition": "A training approximation that replaces the full softmax over the vocabulary with a binary classification between true context words and randomly sampled negative examples, making embedding training tractable.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-neighborhood-component-analysis",
      "term": "Neighborhood Component Analysis",
      "definition": "A supervised dimensionality reduction method that learns a linear transformation optimizing leave-one-out classification accuracy on the training set. Directly optimizes a stochastic nearest-neighbor classification objective.",
      "tags": [
        "Algorithms",
        "Technical",
        "Dimensionality Reduction"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-nelder-mead-method",
      "term": "Nelder-Mead Method",
      "definition": "A derivative-free optimization algorithm that uses a simplex of n+1 points in n-dimensional space. The simplex transforms through reflection and expansion and contraction operations to converge toward the optimum.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-nemotron",
      "term": "Nemotron",
      "definition": "A family of language models developed by NVIDIA for enterprise AI applications. Features models optimized for instruction following code generation and synthetic data generation. Trained on NVIDIA's DGX infrastructure.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nemotron-4",
      "term": "Nemotron-4",
      "definition": "A family of large language models from NVIDIA trained for enterprise applications with strong performance on reasoning and coding benchmarks.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nemotron-4-340b",
      "term": "Nemotron-4 340B",
      "definition": "A 340 billion parameter model from NVIDIA designed for synthetic data generation and alignment training of smaller language models.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nequip",
      "term": "NequIP",
      "definition": "Neural Equivariant Interatomic Potentials is an E(3)-equivariant neural network for learning molecular dynamics force fields with high data efficiency.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nerf",
      "term": "NeRF",
      "definition": "Neural Radiance Field, a method that represents 3D scenes as continuous volumetric functions parameterized by neural networks, enabling photorealistic novel view synthesis from sparse input images.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nested-cross-validation",
      "term": "Nested Cross-Validation",
      "definition": "A model evaluation technique using an inner cross-validation loop for hyperparameter tuning and an outer loop for unbiased performance estimation, preventing information leakage from the tuning process.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nested-dissection",
      "term": "Nested Dissection",
      "definition": "A fill-reducing ordering strategy for sparse matrix factorization that recursively bisects the graph of the matrix. Produces orderings that minimize fill-in during Cholesky or LU factorization of sparse symmetric matrices.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-nested-ner",
      "term": "Nested Named Entity Recognition",
      "definition": "A NER variant that handles entities embedded within other entities, such as recognizing both 'Bank of America' as an organization and 'America' as a location within the same span.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nesterov-accelerated-gradient",
      "term": "Nesterov Accelerated Gradient",
      "definition": "A variant of momentum-based optimization that computes the gradient at a lookahead position rather than the current position, providing better convergence properties by correcting the momentum direction before taking a step.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-netflix-prize",
      "term": "Netflix Prize",
      "definition": "A 2006-2009 open competition offering one million dollars for the best collaborative filtering algorithm to predict user movie ratings, which accelerated recommender systems research and popularized machine learning competitions.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-nethack-learning-environment",
      "term": "NetHack Learning Environment",
      "definition": "A reinforcement learning environment based on the classic roguelike game NetHack. Tests long-horizon planning and exploration in procedurally generated dungeons.",
      "tags": [
        "Benchmark",
        "Reinforcement Learning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-network-bandwidth",
      "term": "Network Bandwidth",
      "definition": "The maximum rate of data transfer across a network link measured in bits per second. Higher bandwidth reduces communication bottlenecks in distributed AI training across multiple GPU nodes.",
      "tags": [
        "Networking",
        "Performance"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-network-congestion-control",
      "term": "Network Congestion Control",
      "definition": "Mechanisms for managing data flow to prevent network overload in AI training clusters. Efficient congestion control is critical for maintaining consistent training throughput.",
      "tags": [
        "Networking",
        "Performance",
        "Protocol"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-network-flow-decomposition",
      "term": "Network Flow Decomposition",
      "definition": "An algorithm that decomposes a flow in a network into a set of path flows and cycle flows. Useful for interpreting flow solutions and routing traffic in transportation and communication networks.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-network-interface-card",
      "term": "Network Interface Card",
      "definition": "Hardware device connecting a computer to a network. Modern AI-optimized NICs offload communication protocols to hardware enabling higher throughput for distributed training.",
      "tags": [
        "Networking",
        "Hardware"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-network-latency",
      "term": "Network Latency",
      "definition": "The time delay for data to travel from source to destination across a network. Low latency is critical for synchronous distributed AI training where processors must frequently exchange gradients.",
      "tags": [
        "Networking",
        "Performance"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-network-simplex-algorithm",
      "term": "Network Simplex Algorithm",
      "definition": "A specialized version of the simplex algorithm for solving minimum-cost network flow problems. Exploits the network structure to perform pivots more efficiently than the general simplex method.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-network-topology",
      "term": "Network Topology",
      "definition": "The physical or logical arrangement of nodes and connections in a computing cluster or data center network. Topology choice significantly impacts communication efficiency for distributed AI training.",
      "tags": [
        "Networking",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-architecture-search",
      "term": "Neural Architecture Search",
      "definition": "An automated method for designing neural network architectures by searching over a defined search space. Methods include reinforcement learning evolutionary algorithms and differentiable approaches. Discovered architectures like EfficientNet and NASNet.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-nas-vision",
      "term": "Neural Architecture Search for Vision",
      "definition": "Automated methods for discovering optimal CNN or ViT architectures by searching over design choices (kernel sizes, channel widths, layer connections) using reinforcement learning or evolutionary algorithms.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-architecture-search-hardware",
      "term": "Neural Architecture Search Hardware",
      "definition": "Hardware considerations in designing and executing neural architecture search which requires evaluating thousands of model configurations. Specialized hardware can dramatically accelerate NAS experiments.",
      "tags": [
        "Training",
        "NAS",
        "Optimization"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-hw-aware-nas",
      "term": "Neural Architecture Search Hardware-Aware",
      "definition": "NAS methods that incorporate hardware constraints (latency, memory, power) into the search objective, finding architectures optimized for specific target devices. Hardware-aware NAS produces models that achieve optimal accuracy-efficiency tradeoffs on deployment hardware.",
      "tags": [
        "Model Optimization",
        "Hardware"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-collaborative-filtering",
      "term": "Neural Collaborative Filtering",
      "definition": "A deep learning approach to collaborative filtering that replaces dot products with neural networks for learning user-item interaction functions.",
      "tags": [
        "Models",
        "Technical",
        "Recommendation"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-fictitious-self-play",
      "term": "Neural Fictitious Self-Play",
      "definition": "A deep reinforcement learning algorithm that combines fictitious play with neural network function approximation. Trains an average policy network alongside a best-response network to approximate Nash equilibria.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-machine-translation",
      "term": "Neural Machine Translation",
      "definition": "A machine translation approach using encoder-decoder neural networks that learn to map source language sequences to target language sequences end-to-end from parallel corpora.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-network",
      "term": "Neural Network",
      "definition": "A computing system inspired by biological brains, composed of interconnected nodes (neurons) organized in layers. The foundation of modern deep learning and AI.",
      "tags": [
        "Architecture",
        "Fundamentals"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-network-renaissance",
      "term": "Neural Network Renaissance",
      "definition": "The revival of interest in neural networks in the 2000s and 2010s driven by the work of Geoffrey Hinton and others on deep belief networks followed by breakthroughs in deep learning enabled by large datasets and GPU computing.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-ode",
      "term": "Neural ODE",
      "definition": "A continuous-depth neural network that parameterizes the derivative of hidden states as a neural network and uses ODE solvers for forward and backward passes, enabling adaptive computation and continuous dynamics.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-ordinary-differential-equations",
      "term": "Neural Ordinary Differential Equations",
      "definition": "A class of deep learning models introduced by Chen et al. in 2018 that parameterize the derivative of the hidden state using a neural network. Neural ODEs provide continuous-depth models and won the Best Paper award at NeurIPS 2018.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-npu",
      "term": "Neural Processing Unit (NPU)",
      "definition": "A dedicated hardware accelerator designed specifically for neural network inference, typically integrated into SoCs for on-device AI. NPUs optimize matrix operations and activation functions with minimal power consumption for edge deployment.",
      "tags": [
        "Hardware",
        "Inference Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-style-transfer",
      "term": "Neural Style Transfer",
      "definition": "A technique that applies the artistic style of one image to the content of another by optimizing a generated image to match content features from one source and style features (Gram matrices) from another.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-turing-machine",
      "term": "Neural Turing Machine",
      "definition": "A neural architecture augmented with external memory that the network can read from and write to via differentiable attention mechanisms, enabling learning of algorithmic procedures.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-neuralgcm",
      "term": "NeuralGCM",
      "definition": "A hybrid model combining learned physics with neural networks for climate simulation that maintains physical consistency while improving computational efficiency.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-neurips",
      "term": "NeurIPS",
      "definition": "The Conference on Neural Information Processing Systems originally founded in 1987 as NIPS. One of the most prestigious and influential conferences in machine learning and artificial intelligence. Renamed to NeurIPS in 2018. Held annually with thousands of attendees and paper submissions.",
      "tags": [
        "History",
        "Conferences"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-neuromorphic-computing",
      "term": "Neuromorphic Computing",
      "definition": "Computing approach inspired by biological neural networks using specialized hardware that mimics how brains process information. Promises dramatically lower energy consumption for AI tasks.",
      "tags": [
        "Emerging",
        "Brain-Inspired",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-neuromorphic-computing-ethics",
      "term": "Neuromorphic Computing Ethics",
      "definition": "Ethical considerations around brain-inspired computing architectures that more closely mimic biological neural processing. Raises questions about consciousness moral status and appropriate use.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-nevilles-algorithm",
      "term": "Neville's Algorithm",
      "definition": "An algorithm for polynomial interpolation that constructs the interpolating polynomial incrementally using a tableau of intermediate results. Allows evaluation at a single point without explicitly forming the polynomial.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-newtons-method",
      "term": "Newton's Method",
      "definition": "A second-order optimization algorithm that uses the Hessian matrix to find the minimum of a function. Converges quadratically near the optimum but requires computing and inverting the full Hessian which is expensive for high-dimensional problems.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-newton-cotes-formulas",
      "term": "Newton-Cotes Formulas",
      "definition": "A group of numerical integration formulas that evaluate the integrand at equally spaced points. Includes the trapezoidal rule and Simpson's rule as special cases and uses polynomial interpolation to approximate the integral.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-next-token-prediction",
      "term": "Next Token Prediction",
      "definition": "The core training objective of autoregressive LLMs: predict the next token given all previous tokens. This simple objective, at scale, produces sophisticated language understanding.",
      "tags": [
        "Training",
        "LLM"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-next-gpt-data",
      "term": "NExT-GPT Data",
      "definition": "Training data for the NExT-GPT any-to-any multimodal model covering text image audio and video modalities. Supports cross-modal generation and understanding.",
      "tags": [
        "Training Corpus",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-next-qa",
      "term": "NeXT-QA",
      "definition": "A video question answering benchmark requiring causal and temporal reasoning about video events. Tests understanding of cause-and-effect relationships in video content.",
      "tags": [
        "Benchmark",
        "Video",
        "Multimodal",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-nextvit",
      "term": "NextViT",
      "definition": "A next-generation vision Transformer designed for industrial deployment that balances latency and accuracy through efficient hybrid convolutional-attention blocks.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nexusraven",
      "term": "NexusRaven",
      "definition": "A function-calling specialized language model that excels at converting natural language instructions into structured API calls and tool usage.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nf4",
      "term": "NF4 (Normal Float 4-bit)",
      "definition": "A 4-bit quantization format based on the assumption that neural network weights follow a normal distribution, using quantile quantization for optimal information-theoretic representation. NF4 is used in QLoRA for memory-efficient fine-tuning.",
      "tags": [
        "Model Optimization",
        "Inference Infrastructure"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ngcf",
      "term": "NGCF",
      "definition": "Neural Graph Collaborative Filtering embeds the user-item interaction graph using message passing to capture high-order collaborative signals for recommendations.",
      "tags": [
        "Models",
        "Technical",
        "Recommendation"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-niah",
      "term": "NIAH",
      "definition": "Needle in a Haystack a test that places a specific fact within a long context and asks the model to retrieve it. Measures long-context retrieval ability across different context positions.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-niklaus-wirth",
      "term": "Niklaus Wirth",
      "definition": "Swiss computer scientist who designed several influential programming languages including Pascal (1970) and Modula-2. Winner of the 1984 Turing Award his work on structured programming influenced software engineering practices used in AI system development.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-nils-nilsson",
      "term": "Nils Nilsson",
      "definition": "American computer scientist (1933-2019) who co-invented the A* search algorithm and developed foundational work in robotics and knowledge representation at SRI International, later directing the Stanford AI Lab.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-nist-ai-rmf",
      "term": "NIST AI Risk Management Framework",
      "definition": "A voluntary framework published by the US National Institute of Standards and Technology in 2023 that provides guidance for managing AI risks through governance, mapping, measuring, and managing functions.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-nli-based-evaluation",
      "term": "NLI-Based Evaluation",
      "definition": "An evaluation approach that uses Natural Language Inference models to assess text quality by classifying whether generated claims are entailed by, contradicted by, or neutral with respect to reference text or source documents.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-nllb",
      "term": "NLLB",
      "definition": "No Language Left Behind is a machine translation model from Meta AI supporting direct translation between over 200 languages including many low-resource languages.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Fundamentals"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nllb-dataset",
      "term": "NLLB Dataset",
      "definition": "The No Language Left Behind parallel corpus used by Meta to train translation models covering 200 languages. One of the most comprehensive multilingual translation resources available.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Translation",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-nlvr2",
      "term": "NLVR2",
      "definition": "Natural Language Visual Reasoning a benchmark where models determine whether a statement is true about a pair of images. Tests compositional visual reasoning grounded in natural language.",
      "tags": [
        "Benchmark",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-no-free-lunch-theorem",
      "term": "No Free Lunch Theorem",
      "definition": "A set of theoretical results stating that no single learning algorithm performs best across all possible problems. When averaged over all possible data distributions, all algorithms perform equally.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-no-free-lunch-theorems",
      "term": "No Free Lunch Theorems",
      "definition": "Theorems published by David Wolpert and William Macready in 1997 proving that no optimization algorithm is universally superior across all possible problems. The theorems have important implications for algorithm selection and the design of machine learning systems.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-no-robots",
      "term": "No Robots",
      "definition": "A high-quality dataset of 10000 instructions and demonstrations created entirely by skilled human annotators. Demonstrates the value of human-written data over synthetic generation.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-nobel-prize-for-ai",
      "term": "Nobel Prize for AI",
      "definition": "Recognition of AI contributions through Nobel Prizes including the 2024 Nobel Prize in Physics awarded to John Hopfield and Geoffrey Hinton for foundational discoveries enabling machine learning with artificial neural networks and the 2024 Chemistry Prize for AlphaFold.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-nocaps",
      "term": "Nocaps",
      "definition": "Novel Object Captioning at Scale a benchmark testing image captioning models on images containing objects not seen during training. Evaluates generalization to novel visual concepts.",
      "tags": [
        "Benchmark",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-node2vec",
      "term": "Node2Vec",
      "definition": "A graph embedding algorithm that learns continuous feature representations for nodes by optimizing a neighborhood-preserving objective. Uses biased random walks with parameters controlling the balance between BFS-like and DFS-like exploration.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-noel-sharkey",
      "term": "Noel Sharkey",
      "definition": "British AI and robotics professor at the University of Sheffield known for public engagement with AI ethics particularly regarding autonomous weapons and the use of AI in warfare. Co-founder of the Campaign to Stop Killer Robots.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-noise",
      "term": "Noise (ML)",
      "definition": "Random variation in data or model outputs. In training, noise can cause or hide patterns. In diffusion models, controlled noise addition and removal is how images are generated.",
      "tags": [
        "Concept",
        "Data"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-noise-contrastive-estimation",
      "term": "Noise Contrastive Estimation",
      "definition": "A method for estimating parameters of unnormalized statistical models by training a classifier to distinguish data samples from noise samples. Avoids computing the intractable normalization constant of the model.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-noise-schedule",
      "term": "Noise Schedule",
      "definition": "The predefined or learned sequence of noise levels in diffusion models that determines how quickly noise is added during the forward process and removed during the reverse generation process.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-noisy-networks",
      "term": "Noisy Networks",
      "definition": "A DQN extension that replaces epsilon-greedy exploration with parametric noise added to network weights, allowing the agent to learn the optimal level of exploration. Noisy networks achieve state-dependent exploration that adapts during training.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nomic-embed",
      "term": "Nomic Embed",
      "definition": "An open-source long-context text embedding model that processes up to 8192 tokens. Fully reproducible with open training data code and model weights. Achieves competitive performance with proprietary embedding models.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-non-discrimination-in-ai",
      "term": "Non-Discrimination in AI",
      "definition": "The principle that AI systems should not discriminate against individuals or groups based on protected characteristics. A legal requirement in many jurisdictions and a core principle of responsible AI.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-non-local-neural-network",
      "term": "Non-Local Neural Network",
      "definition": "A neural network module that computes the response at a position as a weighted sum of features at all positions, capturing long-range dependencies in images and video beyond local receptive fields.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-non-maximum-suppression",
      "term": "Non-Maximum Suppression",
      "definition": "A post-processing algorithm in object detection that eliminates redundant overlapping bounding box predictions by keeping only the highest-confidence detection for each object instance.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-non-negative-matrix-factorization",
      "term": "Non-Negative Matrix Factorization",
      "definition": "A matrix decomposition technique that factors a non-negative matrix into two non-negative matrices, producing parts-based representations. It is useful for topic modeling, image analysis, and signal processing.",
      "tags": [
        "Machine Learning",
        "Dimensionality Reduction"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nonmonotonic-reasoning",
      "term": "Nonmonotonic Reasoning",
      "definition": "A form of logical reasoning where the addition of new information can invalidate previously derived conclusions. Developed in the 1980s by researchers including Raymond Reiter and John McCarthy nonmonotonic logics address the need for common-sense reasoning in AI.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-norbert-wiener",
      "term": "Norbert Wiener",
      "definition": "American mathematician (1894-1964) who founded cybernetics in his 1948 book of the same name, establishing the study of feedback, control, and communication in machines and living organisms as a precursor to AI.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-norbert-wiener-cybernetics-book",
      "term": "Norbert Wiener Cybernetics Book",
      "definition": "The 1948 book Cybernetics: Or Control and Communication in the Animal and the Machine by Norbert Wiener. This foundational work established cybernetics as a field and introduced concepts of feedback and information that influenced AI robotics and control theory.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-norm-alignment",
      "term": "Norm Alignment",
      "definition": "Ensuring that AI systems respect and follow the social and cultural norms of the contexts in which they operate. More nuanced than simple rule-following as norms vary across communities and evolve over time.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-normal-distribution",
      "term": "Normal Distribution",
      "definition": "A continuous probability distribution characterized by its bell-shaped curve, symmetric about the mean, fully determined by its mean and standard deviation. Many natural phenomena and statistical methods assume normality.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-normality-test",
      "term": "Normality Test",
      "definition": "A statistical test that evaluates whether a dataset follows a normal distribution. Common methods include the Shapiro-Wilk test, Kolmogorov-Smirnov test, and Anderson-Darling test.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-normalization",
      "term": "Normalization",
      "definition": "Techniques to standardize inputs or layer outputs in neural networks. Layer normalization is critical in transformers for stable training and better generalization.",
      "tags": [
        "Technique",
        "Training"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-normalized-cuts-algorithm",
      "term": "Normalized Cuts Algorithm",
      "definition": "A graph-based image segmentation method that partitions an image by minimizing the normalized cut criterion. Balances the total weight of cut edges against the total connection strength within each segment.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-normalized-mutual-information",
      "term": "Normalized Mutual Information",
      "definition": "A clustering evaluation metric that normalizes mutual information between predicted and ground truth clusterings to account for chance. Ranges from 0 to 1 and is useful for comparing clusterings with different numbers of clusters.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-normalizing-flow",
      "term": "Normalizing Flow",
      "definition": "A generative model that transforms a simple base distribution into a complex target distribution through a sequence of invertible and differentiable transformations with tractable Jacobian determinants.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-normalizing-flows",
      "term": "Normalizing Flows",
      "definition": "A class of generative models that transform a simple base distribution into a complex target distribution through a sequence of invertible and differentiable mappings. Allows exact likelihood computation and efficient sampling.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-notification-requirements-for-ai",
      "term": "Notification Requirements for AI",
      "definition": "Legal obligations to inform individuals when significant decisions affecting them are made using AI systems. Part of broader transparency and due process requirements in AI regulation.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-nougat",
      "term": "Nougat",
      "definition": "Neural Optical Understanding for Academic Documents is a visual Transformer model that converts scanned academic PDFs into structured markdown text.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nous-hermes",
      "term": "Nous Hermes",
      "definition": "A fine-tuned language model from Nous Research optimized for instruction following and helpfulness using synthetic training data.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nous-hermes-2",
      "term": "Nous Hermes 2",
      "definition": "A second-generation instruction-tuned model from Nous Research with improved reasoning and reduced hallucination through advanced training techniques.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-novel-view-synthesis",
      "term": "Novel View Synthesis",
      "definition": "The task of generating photorealistic images of a scene from viewpoints not present in the input photographs, using techniques like NeRF, Gaussian splatting, or light field interpolation.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nq-swap",
      "term": "NQ-Swap",
      "definition": "A modified version of Natural Questions with swapped entities testing whether models rely on parametric memory versus retrieved context for question answering.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-nsql",
      "term": "NSQL",
      "definition": "A family of language models fine-tuned for natural language to SQL translation supporting diverse database schemas and query patterns.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nsynth",
      "term": "NSynth",
      "definition": "A large-scale dataset of 305979 musical notes from 1006 instruments with rich annotations. Used for audio synthesis and musical instrument sound generation research.",
      "tags": [
        "Benchmark",
        "Audio"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-nt-xent-loss",
      "term": "NT-Xent Loss",
      "definition": "Normalized Temperature-scaled Cross-Entropy loss used in SimCLR for self-supervised contrastive learning. Normalizes embeddings and scales by a temperature parameter before computing cross-entropy over positive and negative pairs within a mini-batch.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-ntk-aware-scaling",
      "term": "NTK-Aware Scaling",
      "definition": "A position encoding extension method based on Neural Tangent Kernel theory that modifies the frequency basis of rotary embeddings. Enables context length extension without fine-tuning by adjusting the base frequency of the rotation.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-nucleus-sampling",
      "term": "Nucleus Sampling (Top-p)",
      "definition": "A text generation strategy that samples from the smallest set of tokens whose cumulative probability exceeds p. Balances diversity and quality better than pure random sampling.",
      "tags": [
        "Generation",
        "Parameter"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nudge-theory-and-ai",
      "term": "Nudge Theory and AI",
      "definition": "The application of behavioral nudging through AI-powered interfaces to influence user decisions. Raises ethical questions about manipulation autonomy and the boundary between helpful guidance and undue influence.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-null-hypothesis",
      "term": "Null Hypothesis",
      "definition": "A default assumption in statistical hypothesis testing that there is no effect or no difference between groups. Statistical tests evaluate whether observed data provide sufficient evidence to reject this assumption.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-numerical-differentiation",
      "term": "Numerical Differentiation",
      "definition": "Approximating derivatives using finite differences. Simple to implement but subject to numerical errors from truncation and rounding. Used as a verification tool for gradient implementations but too inaccurate for optimization.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-numerical-stability-analysis",
      "term": "Numerical Stability Analysis",
      "definition": "The study of how errors propagate through numerical algorithms. Forward and backward error analysis techniques identify whether an algorithm amplifies rounding errors and determine conditions for reliable computation.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-nuscenes",
      "term": "nuScenes",
      "definition": "A multimodal autonomous driving dataset with 1000 driving scenes from Boston and Singapore. Provides 3D bounding boxes from lidar and camera with full 360-degree sensor coverage.",
      "tags": [
        "Benchmark",
        "Autonomous Driving"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-a10",
      "term": "NVIDIA A10",
      "definition": "NVIDIA Ampere data center GPU with 9216 CUDA cores and 24GB GDDR6 designed for AI inference and graphics rendering workloads in cloud environments.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-a100",
      "term": "NVIDIA A100",
      "definition": "NVIDIA's third-generation Tensor Core GPU based on the Ampere architecture, featuring 80GB HBM2e memory, support for TF32 and structural sparsity, and multi-instance GPU (MIG) capability. The A100 was the dominant GPU for AI training and inference from 2020-2022.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-a30",
      "term": "NVIDIA A30",
      "definition": "NVIDIA Ampere data center GPU with 3584 CUDA cores and 24GB HBM2 memory. Designed for mainstream AI training and inference with MIG support for multi-tenant deployment.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-a40",
      "term": "NVIDIA A40",
      "definition": "NVIDIA Ampere professional GPU with 10752 CUDA cores and 48GB GDDR6 with ECC. Used for AI inference combined with professional visualization in data center environments.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-ada-lovelace-architecture",
      "term": "NVIDIA Ada Lovelace Architecture",
      "definition": "NVIDIA GPU architecture for the RTX 40 series featuring third-generation ray tracing cores and fourth-generation Tensor Cores. Named after the pioneering mathematician Ada Lovelace.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-ai-dominance",
      "term": "NVIDIA AI Dominance",
      "definition": "NVIDIA's emergence as the dominant provider of AI computing hardware through its GPU technology. From gaming graphics to AI training NVIDIA's CUDA platform A100 and H100 GPUs became the standard infrastructure for training large language models and other AI systems.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-ai-enterprise",
      "term": "NVIDIA AI Enterprise",
      "definition": "NVIDIA software suite for deploying AI applications in production environments. Provides enterprise support optimized containers and management tools for NVIDIA GPU infrastructure.",
      "tags": [
        "Software",
        "NVIDIA",
        "Enterprise"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-ampere-architecture",
      "term": "NVIDIA Ampere Architecture",
      "definition": "NVIDIA GPU architecture powering the A100 and RTX 30 series GPUs. Introduced third-generation Tensor Cores and structural sparsity for doubled throughput on sparse computations.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-b100",
      "term": "NVIDIA B100",
      "definition": "NVIDIA Blackwell generation data center GPU designed for AI training and inference with improved Tensor Core performance and memory bandwidth over previous generations.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-b200",
      "term": "NVIDIA B200",
      "definition": "NVIDIA's Blackwell architecture GPU designed for next-generation AI training and inference, featuring second-generation Transformer Engine with FP4 support and significantly increased memory bandwidth. The B200 targets trillion-parameter model training.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-base-command",
      "term": "NVIDIA Base Command",
      "definition": "NVIDIA platform for managing AI infrastructure including job scheduling resource allocation and cluster monitoring. Provides enterprise management for DGX and HGX-based AI systems.",
      "tags": [
        "Infrastructure",
        "NVIDIA",
        "Management"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-blackwell-architecture",
      "term": "NVIDIA Blackwell Architecture",
      "definition": "NVIDIA GPU architecture generation succeeding Hopper featuring major advances in AI training and inference efficiency. Introduces new Tensor Core designs and enhanced NVLink connectivity.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-bluefield-dpu",
      "term": "NVIDIA BlueField DPU",
      "definition": "NVIDIA Data Processing Unit combining an ARM CPU SmartNIC and programmable acceleration for data center infrastructure offload. Handles networking and security so GPUs focus on AI compute.",
      "tags": [
        "Networking",
        "NVIDIA",
        "Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-connectx",
      "term": "NVIDIA ConnectX",
      "definition": "NVIDIA family of network adapters providing InfiniBand and Ethernet connectivity with hardware offload capabilities. The standard network adapter in high-performance AI training clusters.",
      "tags": [
        "Networking",
        "NVIDIA",
        "Adapter"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-cuda-toolkit",
      "term": "NVIDIA CUDA Toolkit",
      "definition": "Complete development environment for creating GPU-accelerated applications. Includes compilers debugging tools and performance profiling utilities for developing AI software on NVIDIA GPUs.",
      "tags": [
        "Programming",
        "NVIDIA",
        "Development"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-dgx-a100",
      "term": "NVIDIA DGX A100",
      "definition": "NVIDIA AI system with eight A100 GPUs connected via NVSwitch providing 5 petaFLOPS of AI performance. Widely deployed for enterprise and research AI training from 2020.",
      "tags": [
        "System",
        "NVIDIA",
        "Training"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-dgx-gb200",
      "term": "NVIDIA DGX GB200",
      "definition": "NVIDIA AI supercomputer system based on the GB200 Grace Blackwell Superchip. Connects 36 GB200 modules via NVLink providing massive AI training and inference capability.",
      "tags": [
        "System",
        "NVIDIA",
        "Supercomputer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-dgx-h100",
      "term": "NVIDIA DGX H100",
      "definition": "NVIDIA AI system containing eight H100 GPUs connected via NVLink providing 32 petaFLOPS of AI performance. The building block for large-scale AI training infrastructure.",
      "tags": [
        "System",
        "NVIDIA",
        "Training"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-dgx-station",
      "term": "NVIDIA DGX Station",
      "definition": "NVIDIA workstation-class AI system designed for data science teams providing multiple GPUs in a desktop form factor for local AI development and training.",
      "tags": [
        "System",
        "NVIDIA",
        "Workstation"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-dgx-superpod",
      "term": "NVIDIA DGX SuperPOD",
      "definition": "NVIDIA reference architecture for AI supercomputing combining multiple DGX systems with high-bandwidth networking. Provides a scalable blueprint for building AI training infrastructure.",
      "tags": [
        "Data Center",
        "NVIDIA",
        "System"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-fermi-architecture",
      "term": "NVIDIA Fermi Architecture",
      "definition": "NVIDIA GPU architecture from 2010 that was the first to support double-precision floating point efficiently. Enabled the first wave of GPU-accelerated deep learning.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-gb200",
      "term": "NVIDIA GB200",
      "definition": "NVIDIA Blackwell generation GPU combining two B200 GPU dies in a single module for up to 20 petaFLOPS of AI performance. Designed for next-generation AI training supercomputers.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-geforce-rtx-3060",
      "term": "NVIDIA GeForce RTX 3060",
      "definition": "Entry-level Ampere GPU from NVIDIA with 3584 CUDA cores and 12GB GDDR6. Its large memory capacity relative to price made it popular for student and hobbyist AI projects.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Consumer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-geforce-rtx-3070",
      "term": "NVIDIA GeForce RTX 3070",
      "definition": "Mid-range Ampere consumer GPU from NVIDIA with 5888 CUDA cores and 8GB GDDR6. Offered accessible deep learning capability for researchers on a budget.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Consumer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-geforce-rtx-3080",
      "term": "NVIDIA GeForce RTX 3080",
      "definition": "High-performance consumer GPU from NVIDIA Ampere architecture with 8704 CUDA cores and 10GB GDDR6X. Popular among AI hobbyists for its strong performance-to-price ratio.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Consumer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-geforce-rtx-3090",
      "term": "NVIDIA GeForce RTX 3090",
      "definition": "Flagship consumer GPU from the NVIDIA Ampere generation featuring 10496 CUDA cores and 24GB GDDR6X memory. Was the top consumer choice for AI workloads before Ada Lovelace.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Consumer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-geforce-rtx-4080",
      "term": "NVIDIA GeForce RTX 4080",
      "definition": "High-end consumer GPU from NVIDIA Ada Lovelace generation with 9728 CUDA cores and 16GB GDDR6X. Offers strong AI inference performance at a lower price point than the RTX 4090.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Consumer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-geforce-rtx-4090",
      "term": "NVIDIA GeForce RTX 4090",
      "definition": "NVIDIA flagship consumer GPU based on the Ada Lovelace architecture featuring 16384 CUDA cores and 24GB GDDR6X memory. Widely used by researchers and enthusiasts for local AI model training and inference.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Consumer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-gh200-nvl32",
      "term": "NVIDIA GH200 NVL32",
      "definition": "NVIDIA platform connecting 32 Grace Hopper Superchips via NVLink providing 1 exaFLOPS of AI performance with unified memory access across all GPUs for massive model training.",
      "tags": [
        "System",
        "NVIDIA",
        "Platform"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-grace",
      "term": "NVIDIA Grace CPU",
      "definition": "NVIDIA's ARM-based data center CPU designed for AI and HPC workloads, featuring high memory bandwidth via LPDDR5X and direct NVLink connectivity to NVIDIA GPUs. Grace eliminates PCIe bottlenecks in CPU-GPU communication for AI training.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-grace-hopper-superchip",
      "term": "NVIDIA Grace Hopper Superchip",
      "definition": "Combined CPU-GPU module pairing an NVIDIA Grace ARM CPU with an H100 Hopper GPU via NVLink C2C. Provides 900 GB/s coherent bandwidth between CPU and GPU memory.",
      "tags": [
        "System",
        "NVIDIA",
        "Hybrid"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-h100",
      "term": "NVIDIA H100",
      "definition": "NVIDIA's fourth-generation Tensor Core GPU based on the Hopper architecture, featuring the Transformer Engine with FP8 precision, 80GB HBM3 memory, and fourth-generation NVLink. The H100 delivers roughly 3x the AI training performance of the A100.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-h200",
      "term": "NVIDIA H200",
      "definition": "Next-generation NVIDIA data center GPU featuring Hopper architecture with 141GB HBM3e memory providing 4.8TB/s bandwidth. Designed for large language model training and inference.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-hgx",
      "term": "NVIDIA HGX",
      "definition": "NVIDIA multi-GPU baseboard platform designed as the GPU subsystem for OEM server designs. Connects eight GPUs via NVLink and NVSwitch for maximum inter-GPU bandwidth.",
      "tags": [
        "System",
        "NVIDIA",
        "Platform"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-hopper-architecture",
      "term": "NVIDIA Hopper Architecture",
      "definition": "NVIDIA GPU architecture introduced in 2022 powering the H100 and H200 GPUs. Features the Transformer Engine for automatic mixed precision and fourth-generation Tensor Cores.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-isaac",
      "term": "NVIDIA Isaac",
      "definition": "NVIDIA robotics simulation and deployment platform using GPU-accelerated physics simulation. Provides hardware-in-the-loop testing for AI-powered robots and autonomous systems.",
      "tags": [
        "Platform",
        "NVIDIA",
        "Robotics"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-jetson-agx-orin",
      "term": "NVIDIA Jetson AGX Orin",
      "definition": "NVIDIA highest-performance edge AI module with up to 275 TOPS for autonomous machines. Features an Ampere GPU and ARM CPU in a compact power-efficient package.",
      "tags": [
        "Edge",
        "NVIDIA",
        "Platform"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-jetson-nano",
      "term": "NVIDIA Jetson Nano",
      "definition": "Entry-level NVIDIA edge AI platform with a 128-core Maxwell GPU providing 472 GFLOPS. Popular for learning AI development and prototyping edge AI applications.",
      "tags": [
        "Edge",
        "NVIDIA",
        "Platform"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-jetson-orin",
      "term": "NVIDIA Jetson Orin",
      "definition": "NVIDIA most powerful edge AI platform featuring an Ampere GPU with up to 275 TOPS of AI performance. Used in robotics autonomous vehicles and industrial edge AI applications.",
      "tags": [
        "Edge",
        "NVIDIA",
        "Platform"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-jetson-xavier-nx",
      "term": "NVIDIA Jetson Xavier NX",
      "definition": "Mid-range NVIDIA edge AI module providing 21 TOPS in a compact form factor. Bridges the gap between the entry-level Nano and high-end AGX platforms.",
      "tags": [
        "Edge",
        "NVIDIA",
        "Platform"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-kepler-architecture",
      "term": "NVIDIA Kepler Architecture",
      "definition": "NVIDIA GPU architecture from 2012 that introduced dynamic parallelism and Hyper-Q allowing the GPU to generate its own work. Powered the K80 and K40 data center GPUs.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-l4",
      "term": "NVIDIA L4",
      "definition": "Compact low-power NVIDIA Ada Lovelace inference GPU in a single-slot form factor with 7424 CUDA cores and 24GB GDDR6. Designed for efficient AI inference in space-constrained data centers.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center",
        "Inference"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-l40s",
      "term": "NVIDIA L40S",
      "definition": "NVIDIA Ada Lovelace data center GPU designed for AI inference and graphics workloads with 18176 CUDA cores and 48GB GDDR6 with ECC. Supports both AI and visualization tasks.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-maxwell-architecture",
      "term": "NVIDIA Maxwell Architecture",
      "definition": "NVIDIA GPU architecture focused on energy efficiency that delivered twice the performance per watt of its predecessor Kepler. Powered the GeForce GTX 900 series.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-nsight",
      "term": "NVIDIA Nsight",
      "definition": "Suite of development tools from NVIDIA for profiling debugging and optimizing GPU-accelerated applications. Includes Nsight Systems for system-level analysis and Nsight Compute for kernel profiling.",
      "tags": [
        "Programming",
        "NVIDIA",
        "Development"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-omniverse",
      "term": "NVIDIA Omniverse",
      "definition": "NVIDIA platform for building and operating metaverse applications using GPU-accelerated simulation and rendering. Includes digital twin capabilities powered by AI on NVIDIA hardware.",
      "tags": [
        "Platform",
        "NVIDIA",
        "Simulation"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-pascal-architecture",
      "term": "NVIDIA Pascal Architecture",
      "definition": "NVIDIA GPU architecture powering the Tesla P100 and GeForce GTX 10 series. First to use HBM2 memory and introduced NVLink interconnect technology.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-quantum-infiniband",
      "term": "NVIDIA Quantum InfiniBand",
      "definition": "NVIDIA InfiniBand networking platform providing 400 Gb/s per port bandwidth for AI training clusters. Includes In-Network Computing capabilities for accelerating collective operations.",
      "tags": [
        "Networking",
        "NVIDIA",
        "InfiniBand"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-smi",
      "term": "NVIDIA SMI",
      "definition": "NVIDIA System Management Interface command-line tool for monitoring and managing NVIDIA GPU devices. Reports GPU utilization memory usage temperature and power consumption.",
      "tags": [
        "Monitoring",
        "NVIDIA",
        "Tool"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-spectrum-ethernet",
      "term": "NVIDIA Spectrum Ethernet",
      "definition": "NVIDIA Ethernet switching platform optimized for AI workloads. Provides high-bandwidth low-latency Ethernet networking as an alternative to InfiniBand for AI data centers.",
      "tags": [
        "Networking",
        "NVIDIA",
        "Ethernet"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-t4",
      "term": "NVIDIA T4",
      "definition": "NVIDIA Turing architecture inference GPU with 2560 CUDA cores and 16GB GDDR6 memory consuming only 70 watts. Widely deployed in cloud inference and the default GPU on many cloud platforms.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center",
        "Inference"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-tesla-k40",
      "term": "NVIDIA Tesla K40",
      "definition": "NVIDIA Kepler architecture data center GPU with 2880 CUDA cores and 12GB GDDR5. Widely used in scientific computing and early deep learning research in the mid-2010s.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-tesla-k80",
      "term": "NVIDIA Tesla K80",
      "definition": "Dual-GPU accelerator from NVIDIA Kepler architecture containing two GK210 chips with a combined 24GB GDDR5 memory. Was the standard free GPU in early Google Colab notebooks.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-tesla-m40",
      "term": "NVIDIA Tesla M40",
      "definition": "NVIDIA Maxwell architecture data center GPU with 3072 CUDA cores and 12GB GDDR5. Used in data centers for deep learning training before the Volta generation.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-tesla-p100",
      "term": "NVIDIA Tesla P100",
      "definition": "NVIDIA Pascal architecture data center GPU with 3584 CUDA cores and 16GB HBM2 memory. First GPU to use HBM2 and was widely deployed in cloud AI training instances.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-tesla-v100",
      "term": "NVIDIA Tesla V100",
      "definition": "Data center GPU from NVIDIA Volta architecture featuring 5120 CUDA cores and 640 Tensor Cores with 16GB or 32GB HBM2 memory. Was the workhorse of AI training from 2017 to 2020.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-triton-inference-server",
      "term": "NVIDIA Triton Inference Server",
      "definition": "Open-source inference serving software from NVIDIA supporting multiple AI frameworks and hardware backends. Provides dynamic batching model ensemble and GPU utilization optimization.",
      "tags": [
        "Inference",
        "NVIDIA",
        "Serving"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-turing-architecture",
      "term": "NVIDIA Turing Architecture",
      "definition": "NVIDIA GPU architecture that introduced hardware ray tracing and second-generation Tensor Cores in the RTX 20 and T4 product lines.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-volta-architecture",
      "term": "NVIDIA Volta Architecture",
      "definition": "NVIDIA GPU architecture that introduced Tensor Cores for the first time powering the V100 GPU. Marked a fundamental shift toward dedicated AI hardware acceleration in GPUs.",
      "tags": [
        "GPU",
        "NVIDIA",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvlink",
      "term": "NVLink",
      "definition": "NVIDIA's proprietary high-bandwidth, low-latency interconnect for direct GPU-to-GPU communication, bypassing the PCIe bus. NVLink 4.0 (Hopper) provides 900 GB/s total bandwidth per GPU, enabling efficient multi-GPU training and inference.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvlink-c2c",
      "term": "NVLink C2C",
      "definition": "NVIDIA chip-to-chip interconnect technology providing ultra-high-bandwidth coherent connections between GPU and CPU dies. Used in the Grace Hopper Superchip to connect Grace CPU and Hopper GPU.",
      "tags": [
        "Interconnect",
        "NVIDIA"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvme",
      "term": "NVMe",
      "definition": "Non-Volatile Memory Express storage protocol designed for solid-state drives communicating over PCIe. Provides dramatically lower latency than SATA enabling faster data loading for AI training pipelines.",
      "tags": [
        "Storage",
        "Protocol",
        "Standard"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvswitch",
      "term": "NVSwitch",
      "definition": "NVIDIA's fully connected switch fabric that enables all-to-all GPU communication within a node at full NVLink bandwidth. NVSwitch creates a unified memory space across multiple GPUs, critical for large model training requiring high inter-GPU bandwidth.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nyu-depth-v2",
      "term": "NYU Depth V2",
      "definition": "A dataset of 1449 densely labeled RGB-D images of indoor scenes from 464 different scenes. A standard benchmark for monocular depth estimation and indoor scene segmentation.",
      "tags": [
        "Benchmark",
        "Computer Vision",
        "3D"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    }
  ]
}