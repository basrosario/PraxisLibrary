{
  "letter": "n",
  "count": 92,
  "terms": [
    {
      "id": "term-n-gram",
      "term": "N-gram",
      "definition": "A contiguous sequence of N items from a text, where items can be characters, words, or tokens, used in language models, text classification, and information retrieval.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-n-step-return",
      "term": "N-Step Return",
      "definition": "A return estimate that uses n actual rewards before bootstrapping with a value estimate, interpolating between one-step TD (n=1) and full Monte Carlo (n=infinity). N-step returns offer a bias-variance tradeoff controlled by the step parameter.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nadam",
      "term": "Nadam",
      "definition": "Nesterov-accelerated Adaptive Moment estimation combines the Adam optimizer with Nesterov momentum. Provides faster convergence by incorporating the look-ahead gradient computation from Nesterov accelerated gradient into Adam.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-naive-bayes",
      "term": "Naive Bayes",
      "definition": "A family of probabilistic classifiers based on Bayes' theorem with the strong assumption that features are conditionally independent given the class label. Despite this simplification, it often performs well on text classification tasks.",
      "tags": [
        "Machine Learning",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-naive-bayes-history",
      "term": "Naive Bayes History",
      "definition": "The application of Bayes' theorem with naive independence assumptions to classification tasks. Despite its simplicity naive Bayes became one of the most practical machine learning algorithms especially for text classification and spam filtering from the 1990s onward.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-named-entity-linking",
      "term": "Named Entity Linking",
      "definition": "The task of mapping recognized named entity mentions in text to their corresponding entries in a knowledge base, resolving ambiguity when multiple entities share the same name.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-named-entity-recognition",
      "term": "Named Entity Recognition (NER)",
      "definition": "An NLP task that identifies and classifies named entities (people, organizations, locations, dates) in text. Foundational for information extraction and knowledge graph construction.",
      "tags": [
        "NLP Task",
        "Extraction"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-namespace",
      "term": "Namespace",
      "definition": "A logical partitioning mechanism within a vector database index that isolates vectors into separate searchable segments, enabling multi-tenant applications and scoped queries without maintaining separate physical indexes.",
      "tags": [
        "Vector Database",
        "Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-narrow-ai",
      "term": "Narrow AI (ANI)",
      "definition": "AI systems designed for specific tasks, like playing chess or generating text. All current AI is narrow, as opposed to hypothetical artificial general intelligence (AGI).",
      "tags": [
        "Category",
        "Concept"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-narrow-ai-safety",
      "term": "Narrow AI Safety",
      "definition": "Safety research focused on currently deployed AI systems, addressing issues such as robustness to distribution shift, adversarial inputs, reward misspecification, and safe exploration in constrained environments.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-nasnet",
      "term": "NASNet",
      "definition": "Neural Architecture Search Network designed automatically by a reinforcement learning controller searching over a space of possible architectures. Demonstrated that machine-designed architectures can outperform human-designed ones on ImageNet.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nathaniel-rochester",
      "term": "Nathaniel Rochester",
      "definition": "American computer scientist at IBM who co-organized the 1956 Dartmouth Conference that founded AI as a field. Rochester led the development of the first assembler (for the IBM 701) and worked on early neural network simulations at IBM in the 1950s.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-language",
      "term": "Natural Language",
      "definition": "Human language as we naturally speak and write it. AI assistants are designed to understand natural language, so you don't need special syntax or formatting.",
      "tags": [
        "Concept",
        "Interface"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-language-inference",
      "term": "Natural Language Inference",
      "definition": "The task of classifying the logical relationship between a premise and hypothesis text pair into entailment, contradiction, or neutral, testing a model's ability to reason about meaning.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nlp",
      "term": "Natural Language Processing (NLP)",
      "definition": "The field of AI focused on enabling computers to understand, interpret, and generate human language. Encompasses tasks from translation to summarization to dialogue.",
      "tags": [
        "Field",
        "Language"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nlp-history",
      "term": "Natural Language Processing History",
      "definition": "The evolution of NLP from rule-based approaches in the 1960s through statistical methods in the 1990s to neural approaches in the 2010s and the transformer revolution, culminating in modern large language models.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-language-understanding-history",
      "term": "Natural Language Understanding History",
      "definition": "The evolution of machine understanding of human language from early pattern matching (ELIZA 1966) and microworld systems (SHRDLU 1970) through statistical methods (1990s) to deep learning-based approaches (2010s) and large language models.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-policy-gradient",
      "term": "Natural Policy Gradient",
      "definition": "A policy gradient method that preconditions updates with the inverse Fisher information matrix, following the steepest ascent direction in the space of policy distributions rather than parameter space. Natural gradients provide more efficient optimization.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-natural-questions",
      "term": "Natural Questions",
      "definition": "A question answering benchmark by Google consisting of real user queries from Google Search paired with Wikipedia articles, requiring models to identify both short answers and long answer passages to satisfy genuine information needs.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-nccl",
      "term": "NCCL",
      "definition": "NVIDIA Collective Communications Library, a highly optimized library for multi-GPU and multi-node collective communication operations. NCCL automatically selects the best communication algorithms and topologies for the available hardware interconnects.",
      "tags": [
        "Distributed Computing",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ndcg",
      "term": "NDCG",
      "definition": "Normalized Discounted Cumulative Gain, a ranking quality metric that evaluates the usefulness of retrieved items based on their position in the result list, assigning higher weights to relevant items appearing earlier and normalizing against the ideal ranking.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-neats-vs-scruffies",
      "term": "Neats vs Scruffies",
      "definition": "A characterization of a philosophical divide in AI research during the 1970s and 1980s. Neats favored formal mathematical approaches and provably correct algorithms while scruffies preferred heuristic approaches and pragmatic solutions that worked in practice even without formal guarantees.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-needle-in-haystack-test",
      "term": "Needle in a Haystack Test",
      "definition": "An evaluation method that measures a language model's ability to retrieve a specific piece of information placed at various positions within a long context, revealing attention degradation patterns.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-negation-detection",
      "term": "Negation Detection",
      "definition": "The task of identifying negation cues and their scope in text, determining which parts of a sentence are affected by negation words like 'not,' 'never,' or 'without.'",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-negative-externality",
      "term": "Negative Externality",
      "definition": "A cost imposed on third parties who are not involved in an AI transaction or interaction. AI systems can generate negative externalities through environmental impact discrimination and social disruption.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-negative-prompt",
      "term": "Negative Prompt",
      "definition": "Instructions telling AI what to avoid in its output. Common in image generation (\"no blur, no distortion\") and can be used in text to exclude certain topics or styles.",
      "tags": [
        "Prompting",
        "Technique"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-negative-prompting",
      "term": "Negative Prompting",
      "definition": "A technique that explicitly specifies what the model should avoid in its output, including unwanted content, styles, formats, or behaviors, using exclusion instructions to constrain the generation space toward desired outputs.",
      "tags": [
        "Prompt Engineering",
        "Constraints"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-negative-sampling",
      "term": "Negative Sampling",
      "definition": "A training approximation that replaces the full softmax over the vocabulary with a binary classification between true context words and randomly sampled negative examples, making embedding training tractable.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nemotron",
      "term": "Nemotron",
      "definition": "A family of language models developed by NVIDIA for enterprise AI applications. Features models optimized for instruction following code generation and synthetic data generation. Trained on NVIDIA's DGX infrastructure.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nerf",
      "term": "NeRF",
      "definition": "Neural Radiance Field, a method that represents 3D scenes as continuous volumetric functions parameterized by neural networks, enabling photorealistic novel view synthesis from sparse input images.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nested-cross-validation",
      "term": "Nested Cross-Validation",
      "definition": "A model evaluation technique using an inner cross-validation loop for hyperparameter tuning and an outer loop for unbiased performance estimation, preventing information leakage from the tuning process.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nested-ner",
      "term": "Nested Named Entity Recognition",
      "definition": "A NER variant that handles entities embedded within other entities, such as recognizing both 'Bank of America' as an organization and 'America' as a location within the same span.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nesterov-accelerated-gradient",
      "term": "Nesterov Accelerated Gradient",
      "definition": "A variant of momentum-based optimization that computes the gradient at a lookahead position rather than the current position, providing better convergence properties by correcting the momentum direction before taking a step.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-netflix-prize",
      "term": "Netflix Prize",
      "definition": "A 2006-2009 open competition offering one million dollars for the best collaborative filtering algorithm to predict user movie ratings, which accelerated recommender systems research and popularized machine learning competitions.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-architecture-search",
      "term": "Neural Architecture Search",
      "definition": "An automated method for designing neural network architectures by searching over a defined search space. Methods include reinforcement learning evolutionary algorithms and differentiable approaches. Discovered architectures like EfficientNet and NASNet.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-nas-vision",
      "term": "Neural Architecture Search for Vision",
      "definition": "Automated methods for discovering optimal CNN or ViT architectures by searching over design choices (kernel sizes, channel widths, layer connections) using reinforcement learning or evolutionary algorithms.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-hw-aware-nas",
      "term": "Neural Architecture Search Hardware-Aware",
      "definition": "NAS methods that incorporate hardware constraints (latency, memory, power) into the search objective, finding architectures optimized for specific target devices. Hardware-aware NAS produces models that achieve optimal accuracy-efficiency tradeoffs on deployment hardware.",
      "tags": [
        "Model Optimization",
        "Hardware"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-machine-translation",
      "term": "Neural Machine Translation",
      "definition": "A machine translation approach using encoder-decoder neural networks that learn to map source language sequences to target language sequences end-to-end from parallel corpora.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-network",
      "term": "Neural Network",
      "definition": "A computing system inspired by biological brains, composed of interconnected nodes (neurons) organized in layers. The foundation of modern deep learning and AI.",
      "tags": [
        "Architecture",
        "Fundamentals"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-network-renaissance",
      "term": "Neural Network Renaissance",
      "definition": "The revival of interest in neural networks in the 2000s and 2010s driven by the work of Geoffrey Hinton and others on deep belief networks followed by breakthroughs in deep learning enabled by large datasets and GPU computing.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-ode",
      "term": "Neural ODE",
      "definition": "A continuous-depth neural network that parameterizes the derivative of hidden states as a neural network and uses ODE solvers for forward and backward passes, enabling adaptive computation and continuous dynamics.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-ordinary-differential-equations",
      "term": "Neural Ordinary Differential Equations",
      "definition": "A class of deep learning models introduced by Chen et al. in 2018 that parameterize the derivative of the hidden state using a neural network. Neural ODEs provide continuous-depth models and won the Best Paper award at NeurIPS 2018.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-npu",
      "term": "Neural Processing Unit (NPU)",
      "definition": "A dedicated hardware accelerator designed specifically for neural network inference, typically integrated into SoCs for on-device AI. NPUs optimize matrix operations and activation functions with minimal power consumption for edge deployment.",
      "tags": [
        "Hardware",
        "Inference Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-style-transfer",
      "term": "Neural Style Transfer",
      "definition": "A technique that applies the artistic style of one image to the content of another by optimizing a generated image to match content features from one source and style features (Gram matrices) from another.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-neural-turing-machine",
      "term": "Neural Turing Machine",
      "definition": "A neural architecture augmented with external memory that the network can read from and write to via differentiable attention mechanisms, enabling learning of algorithmic procedures.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-neurips",
      "term": "NeurIPS",
      "definition": "The Conference on Neural Information Processing Systems originally founded in 1987 as NIPS. One of the most prestigious and influential conferences in machine learning and artificial intelligence. Renamed to NeurIPS in 2018. Held annually with thousands of attendees and paper submissions.",
      "tags": [
        "History",
        "Conferences"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-neuromorphic-computing-ethics",
      "term": "Neuromorphic Computing Ethics",
      "definition": "Ethical considerations around brain-inspired computing architectures that more closely mimic biological neural processing. Raises questions about consciousness moral status and appropriate use.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-newtons-method",
      "term": "Newton's Method",
      "definition": "A second-order optimization algorithm that uses the Hessian matrix to find the minimum of a function. Converges quadratically near the optimum but requires computing and inverting the full Hessian which is expensive for high-dimensional problems.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-next-token-prediction",
      "term": "Next Token Prediction",
      "definition": "The core training objective of autoregressive LLMs: predict the next token given all previous tokens. This simple objective, at scale, produces sophisticated language understanding.",
      "tags": [
        "Training",
        "LLM"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-nf4",
      "term": "NF4 (Normal Float 4-bit)",
      "definition": "A 4-bit quantization format based on the assumption that neural network weights follow a normal distribution, using quantile quantization for optimal information-theoretic representation. NF4 is used in QLoRA for memory-efficient fine-tuning.",
      "tags": [
        "Model Optimization",
        "Inference Infrastructure"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-niklaus-wirth",
      "term": "Niklaus Wirth",
      "definition": "Swiss computer scientist who designed several influential programming languages including Pascal (1970) and Modula-2. Winner of the 1984 Turing Award his work on structured programming influenced software engineering practices used in AI system development.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-nils-nilsson",
      "term": "Nils Nilsson",
      "definition": "American computer scientist (1933-2019) who co-invented the A* search algorithm and developed foundational work in robotics and knowledge representation at SRI International, later directing the Stanford AI Lab.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-nist-ai-rmf",
      "term": "NIST AI Risk Management Framework",
      "definition": "A voluntary framework published by the US National Institute of Standards and Technology in 2023 that provides guidance for managing AI risks through governance, mapping, measuring, and managing functions.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-nli-based-evaluation",
      "term": "NLI-Based Evaluation",
      "definition": "An evaluation approach that uses Natural Language Inference models to assess text quality by classifying whether generated claims are entailed by, contradicted by, or neutral with respect to reference text or source documents.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-no-free-lunch-theorem",
      "term": "No Free Lunch Theorem",
      "definition": "A set of theoretical results stating that no single learning algorithm performs best across all possible problems. When averaged over all possible data distributions, all algorithms perform equally.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-no-free-lunch-theorems",
      "term": "No Free Lunch Theorems",
      "definition": "Theorems published by David Wolpert and William Macready in 1997 proving that no optimization algorithm is universally superior across all possible problems. The theorems have important implications for algorithm selection and the design of machine learning systems.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-nobel-prize-for-ai",
      "term": "Nobel Prize for AI",
      "definition": "Recognition of AI contributions through Nobel Prizes including the 2024 Nobel Prize in Physics awarded to John Hopfield and Geoffrey Hinton for foundational discoveries enabling machine learning with artificial neural networks and the 2024 Chemistry Prize for AlphaFold.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-node2vec",
      "term": "Node2Vec",
      "definition": "A graph embedding algorithm that learns continuous feature representations for nodes by optimizing a neighborhood-preserving objective. Uses biased random walks with parameters controlling the balance between BFS-like and DFS-like exploration.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-noel-sharkey",
      "term": "Noel Sharkey",
      "definition": "British AI and robotics professor at the University of Sheffield known for public engagement with AI ethics particularly regarding autonomous weapons and the use of AI in warfare. Co-founder of the Campaign to Stop Killer Robots.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-noise",
      "term": "Noise (ML)",
      "definition": "Random variation in data or model outputs. In training, noise can cause or hide patterns. In diffusion models, controlled noise addition and removal is how images are generated.",
      "tags": [
        "Concept",
        "Data"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-noise-schedule",
      "term": "Noise Schedule",
      "definition": "The predefined or learned sequence of noise levels in diffusion models that determines how quickly noise is added during the forward process and removed during the reverse generation process.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-noisy-networks",
      "term": "Noisy Networks",
      "definition": "A DQN extension that replaces epsilon-greedy exploration with parametric noise added to network weights, allowing the agent to learn the optimal level of exploration. Noisy networks achieve state-dependent exploration that adapts during training.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nomic-embed",
      "term": "Nomic Embed",
      "definition": "An open-source long-context text embedding model that processes up to 8192 tokens. Fully reproducible with open training data code and model weights. Achieves competitive performance with proprietary embedding models.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-non-discrimination-in-ai",
      "term": "Non-Discrimination in AI",
      "definition": "The principle that AI systems should not discriminate against individuals or groups based on protected characteristics. A legal requirement in many jurisdictions and a core principle of responsible AI.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-non-local-neural-network",
      "term": "Non-Local Neural Network",
      "definition": "A neural network module that computes the response at a position as a weighted sum of features at all positions, capturing long-range dependencies in images and video beyond local receptive fields.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-non-maximum-suppression",
      "term": "Non-Maximum Suppression",
      "definition": "A post-processing algorithm in object detection that eliminates redundant overlapping bounding box predictions by keeping only the highest-confidence detection for each object instance.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-non-negative-matrix-factorization",
      "term": "Non-Negative Matrix Factorization",
      "definition": "A matrix decomposition technique that factors a non-negative matrix into two non-negative matrices, producing parts-based representations. It is useful for topic modeling, image analysis, and signal processing.",
      "tags": [
        "Machine Learning",
        "Dimensionality Reduction"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nonmonotonic-reasoning",
      "term": "Nonmonotonic Reasoning",
      "definition": "A form of logical reasoning where the addition of new information can invalidate previously derived conclusions. Developed in the 1980s by researchers including Raymond Reiter and John McCarthy nonmonotonic logics address the need for common-sense reasoning in AI.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-norbert-wiener",
      "term": "Norbert Wiener",
      "definition": "American mathematician (1894-1964) who founded cybernetics in his 1948 book of the same name, establishing the study of feedback, control, and communication in machines and living organisms as a precursor to AI.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-norbert-wiener-cybernetics-book",
      "term": "Norbert Wiener Cybernetics Book",
      "definition": "The 1948 book Cybernetics: Or Control and Communication in the Animal and the Machine by Norbert Wiener. This foundational work established cybernetics as a field and introduced concepts of feedback and information that influenced AI robotics and control theory.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-norm-alignment",
      "term": "Norm Alignment",
      "definition": "Ensuring that AI systems respect and follow the social and cultural norms of the contexts in which they operate. More nuanced than simple rule-following as norms vary across communities and evolve over time.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-normal-distribution",
      "term": "Normal Distribution",
      "definition": "A continuous probability distribution characterized by its bell-shaped curve, symmetric about the mean, fully determined by its mean and standard deviation. Many natural phenomena and statistical methods assume normality.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-normality-test",
      "term": "Normality Test",
      "definition": "A statistical test that evaluates whether a dataset follows a normal distribution. Common methods include the Shapiro-Wilk test, Kolmogorov-Smirnov test, and Anderson-Darling test.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-normalization",
      "term": "Normalization",
      "definition": "Techniques to standardize inputs or layer outputs in neural networks. Layer normalization is critical in transformers for stable training and better generalization.",
      "tags": [
        "Technique",
        "Training"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-normalized-mutual-information",
      "term": "Normalized Mutual Information",
      "definition": "A clustering evaluation metric that normalizes mutual information between predicted and ground truth clusterings to account for chance. Ranges from 0 to 1 and is useful for comparing clusterings with different numbers of clusters.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-normalizing-flow",
      "term": "Normalizing Flow",
      "definition": "A generative model that transforms a simple base distribution into a complex target distribution through a sequence of invertible and differentiable transformations with tractable Jacobian determinants.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-normalizing-flows",
      "term": "Normalizing Flows",
      "definition": "A class of generative models that transform a simple base distribution into a complex target distribution through a sequence of invertible and differentiable mappings. Allows exact likelihood computation and efficient sampling.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-notification-requirements-for-ai",
      "term": "Notification Requirements for AI",
      "definition": "Legal obligations to inform individuals when significant decisions affecting them are made using AI systems. Part of broader transparency and due process requirements in AI regulation.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-novel-view-synthesis",
      "term": "Novel View Synthesis",
      "definition": "The task of generating photorealistic images of a scene from viewpoints not present in the input photographs, using techniques like NeRF, Gaussian splatting, or light field interpolation.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nt-xent-loss",
      "term": "NT-Xent Loss",
      "definition": "Normalized Temperature-scaled Cross-Entropy loss used in SimCLR for self-supervised contrastive learning. Normalizes embeddings and scales by a temperature parameter before computing cross-entropy over positive and negative pairs within a mini-batch.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-ntk-aware-scaling",
      "term": "NTK-Aware Scaling",
      "definition": "A position encoding extension method based on Neural Tangent Kernel theory that modifies the frequency basis of rotary embeddings. Enables context length extension without fine-tuning by adjusting the base frequency of the rotation.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-nucleus-sampling",
      "term": "Nucleus Sampling (Top-p)",
      "definition": "A text generation strategy that samples from the smallest set of tokens whose cumulative probability exceeds p. Balances diversity and quality better than pure random sampling.",
      "tags": [
        "Generation",
        "Parameter"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-nudge-theory-and-ai",
      "term": "Nudge Theory and AI",
      "definition": "The application of behavioral nudging through AI-powered interfaces to influence user decisions. Raises ethical questions about manipulation autonomy and the boundary between helpful guidance and undue influence.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-null-hypothesis",
      "term": "Null Hypothesis",
      "definition": "A default assumption in statistical hypothesis testing that there is no effect or no difference between groups. Statistical tests evaluate whether observed data provide sufficient evidence to reject this assumption.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-numerical-differentiation",
      "term": "Numerical Differentiation",
      "definition": "Approximating derivatives using finite differences. Simple to implement but subject to numerical errors from truncation and rounding. Used as a verification tool for gradient implementations but too inaccurate for optimization.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-a100",
      "term": "NVIDIA A100",
      "definition": "NVIDIA's third-generation Tensor Core GPU based on the Ampere architecture, featuring 80GB HBM2e memory, support for TF32 and structural sparsity, and multi-instance GPU (MIG) capability. The A100 was the dominant GPU for AI training and inference from 2020-2022.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-ai-dominance",
      "term": "NVIDIA AI Dominance",
      "definition": "NVIDIA's emergence as the dominant provider of AI computing hardware through its GPU technology. From gaming graphics to AI training NVIDIA's CUDA platform A100 and H100 GPUs became the standard infrastructure for training large language models and other AI systems.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-b200",
      "term": "NVIDIA B200",
      "definition": "NVIDIA's Blackwell architecture GPU designed for next-generation AI training and inference, featuring second-generation Transformer Engine with FP4 support and significantly increased memory bandwidth. The B200 targets trillion-parameter model training.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvidia-grace",
      "term": "NVIDIA Grace CPU",
      "definition": "NVIDIA's ARM-based data center CPU designed for AI and HPC workloads, featuring high memory bandwidth via LPDDR5X and direct NVLink connectivity to NVIDIA GPUs. Grace eliminates PCIe bottlenecks in CPU-GPU communication for AI training.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-h100",
      "term": "NVIDIA H100",
      "definition": "NVIDIA's fourth-generation Tensor Core GPU based on the Hopper architecture, featuring the Transformer Engine with FP8 precision, 80GB HBM3 memory, and fourth-generation NVLink. The H100 delivers roughly 3x the AI training performance of the A100.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvlink",
      "term": "NVLink",
      "definition": "NVIDIA's proprietary high-bandwidth, low-latency interconnect for direct GPU-to-GPU communication, bypassing the PCIe bus. NVLink 4.0 (Hopper) provides 900 GB/s total bandwidth per GPU, enabling efficient multi-GPU training and inference.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-nvswitch",
      "term": "NVSwitch",
      "definition": "NVIDIA's fully connected switch fabric that enables all-to-all GPU communication within a node at full NVLink bandwidth. NVSwitch creates a unified memory space across multiple GPUs, critical for large model training requiring high inter-GPU bandwidth.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    }
  ]
}