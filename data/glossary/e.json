{
  "letter": "e",
  "count": 195,
  "terms": [
    {
      "id": "term-e5",
      "term": "E5",
      "definition": "A family of text embedding models trained with contrastive learning on large-scale text pairs. Achieves strong performance across retrieval clustering and classification tasks. Available in multiple sizes from small to extra-large.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-eagle",
      "term": "Eagle",
      "definition": "A vision-language model that uses a mixture of vision encoders to capture both low-level and high-level visual features for improved multimodal understanding.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-earley-parser",
      "term": "Earley Parser",
      "definition": "A chart parsing algorithm for context-free grammars that can handle all context-free languages including ambiguous grammars. Runs in O(n^3) time in general and O(n^2) for unambiguous grammars and O(n) for most LR(k) grammars.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-early-stopping",
      "term": "Early Stopping",
      "definition": "A regularization technique that stops training when performance on a validation set stops improving. Prevents overfitting and saves computational resources.",
      "tags": [
        "Training",
        "Regularization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-early-stopping-criterion",
      "term": "Early Stopping Criterion",
      "definition": "A regularization technique that monitors validation performance during training and stops when it begins to deteriorate. Prevents overfitting by selecting the model from the epoch with best validation performance. Uses a patience parameter.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-earth-movers-distance",
      "term": "Earth Mover's Distance",
      "definition": "A metric for comparing probability distributions based on the minimum amount of work needed to transform one distribution into the other, where work is the amount of mass moved multiplied by the distance it is moved.",
      "tags": [
        "Statistics",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-earth-simulator",
      "term": "Earth Simulator",
      "definition": "Japanese supercomputer that was the fastest in the world from 2002 to 2004. Built by NEC for climate modeling and earth science research using custom vector processors.",
      "tags": [
        "Historical",
        "Supercomputer",
        "Japan"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ecc-error-correcting-code",
      "term": "ECC (Error Correcting Code)",
      "definition": "Error detection and correction mechanism used in memory and data transmission. ECC in GPU memory is critical for ensuring numerical accuracy during long AI training runs.",
      "tags": [
        "Reliability",
        "Memory",
        "Data Integrity"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ecc-memory",
      "term": "ECC Memory",
      "definition": "Error-Correcting Code memory that detects and corrects single-bit errors and detects multi-bit errors. Required in data center AI systems to ensure computational accuracy during long training runs.",
      "tags": [
        "Memory",
        "Data Center",
        "Reliability"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-eccv",
      "term": "ECCV",
      "definition": "The European Conference on Computer Vision held biennially since 1990. One of the top three computer vision conferences alongside CVPR and ICCV. Known for publishing influential papers on object recognition segmentation and visual understanding.",
      "tags": [
        "History",
        "Conferences"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-echo-state-network",
      "term": "Echo State Network",
      "definition": "A recurrent neural network where the recurrent layer is a large randomly generated reservoir with fixed weights. Only the output weights are trained. Part of the reservoir computing paradigm. Efficient for temporal pattern recognition.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-edge-ai",
      "term": "Edge AI",
      "definition": "Running AI models locally on devices (phones, IoT) rather than in the cloud. Enables faster responses, offline operation, and better privacy but requires efficient models.",
      "tags": [
        "Deployment",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-edge-case-safety",
      "term": "Edge Case Safety",
      "definition": "The challenge of ensuring AI systems behave safely in unusual or extreme situations that were not well represented in training data. Critical for safety-critical applications like autonomous driving.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-edge-computing",
      "term": "Edge Computing",
      "definition": "Computing paradigm that processes data near the source of generation rather than in a centralized data center. Reduces latency and bandwidth needs for AI inference on IoT and mobile devices.",
      "tags": [
        "Edge",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-edge-inference",
      "term": "Edge Inference",
      "definition": "Running AI model inference directly on edge devices (phones, IoT sensors, embedded systems) rather than in the cloud, reducing latency and bandwidth requirements. Edge inference requires highly optimized, compressed models tailored to limited compute and memory.",
      "tags": [
        "Inference Infrastructure",
        "Hardware"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-edge-tpu",
      "term": "Edge TPU",
      "definition": "Google custom ASIC designed for running TensorFlow Lite models at the edge. Provides 4 TOPS of inference performance in a compact low-power package for IoT AI applications.",
      "tags": [
        "Edge",
        "Google",
        "TPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-edit-distance",
      "term": "Edit Distance",
      "definition": "A family of metrics quantifying the minimum number of operations required to transform one string into another, with variants including Levenshtein, Damerau-Levenshtein, and Hamming distance.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-edit-distance-algorithm",
      "term": "Edit Distance Algorithm",
      "definition": "A family of algorithms that compute the minimum number of operations required to transform one sequence into another. Variants include Levenshtein and Damerau-Levenshtein and Hamming distance depending on allowed operations.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-editeval",
      "term": "EditEval",
      "definition": "A benchmark for evaluating code editing capabilities of language models. Tests the ability to modify existing code based on natural language instructions.",
      "tags": [
        "Benchmark",
        "Code",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-edmonds-blossom-algorithm",
      "term": "Edmonds' Blossom Algorithm",
      "definition": "An algorithm for finding maximum weight matching in general (non-bipartite) graphs. Handles odd cycles by contracting blossoms and runs in O(V^3) time for maximum weight perfect matching.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-edmonds-karp-algorithm",
      "term": "Edmonds-Karp Algorithm",
      "definition": "An implementation of the Ford-Fulkerson method that uses breadth-first search to find the shortest augmenting path. Guarantees O(VE^2) time complexity regardless of the capacity values in the network.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-edmund-clarke",
      "term": "Edmund Clarke",
      "definition": "American computer scientist who pioneered model checking a technique for automatically verifying the correctness of finite-state systems. Received the 2007 Turing Award for this work which has applications in verifying AI system safety and correctness.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-edsac",
      "term": "EDSAC",
      "definition": "Electronic Delay Storage Automatic Calculator built at the University of Cambridge in 1949. One of the first practical stored-program computers and ran the first graphical computer game.",
      "tags": [
        "Historical",
        "Computer",
        "Pioneer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-edvac",
      "term": "EDVAC",
      "definition": "The Electronic Discrete Variable Automatic Computer designed in the 1940s was one of the first stored-program computers. John von Neumann's 1945 First Draft of a Report on the EDVAC described the architecture that became the standard for digital computers.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-edward-feigenbaum",
      "term": "Edward Feigenbaum",
      "definition": "American computer scientist known as the father of expert systems, who led the development of DENDRAL and pioneered knowledge engineering at Stanford, demonstrating the commercial viability of AI in the 1970s-1980s.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-edward-shortliffe",
      "term": "Edward Shortliffe",
      "definition": "American biomedical informatician who developed MYCIN one of the most influential early expert systems for medical diagnosis. Shortliffe's work on MYCIN demonstrated the viability of AI in healthcare and introduced certainty factors for handling uncertainty in expert systems.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-effect-size",
      "term": "Effect Size",
      "definition": "A quantitative measure of the magnitude of a phenomenon or the practical significance of a result, independent of sample size. Common measures include Cohen's d, odds ratio, and correlation coefficient.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-effective-batch-size",
      "term": "Effective Batch Size",
      "definition": "Total number of samples processed per optimizer step accounting for data parallelism and gradient accumulation. Equals per-device batch size times number of devices times accumulation steps.",
      "tags": [
        "Training",
        "Parameter",
        "Metric"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-efficiency",
      "term": "Efficiency",
      "definition": "A property of a statistical estimator related to how much information from the data it uses. An efficient estimator achieves the lowest possible variance among all unbiased estimators, reaching the Cramer-Rao bound.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-efficientnet",
      "term": "EfficientNet",
      "definition": "A family of CNN models that use compound scaling to uniformly scale network width, depth, and resolution using a fixed set of scaling coefficients, achieving state-of-the-art accuracy with fewer parameters.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-efficientnetv2",
      "term": "EfficientNetV2",
      "definition": "An improved version of EfficientNet that uses progressive training and fused MBConv blocks for faster training. Achieves better accuracy and training speed than the original EfficientNet family.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-efficientvit",
      "term": "EfficientViT",
      "definition": "An efficient vision Transformer architecture that uses cascaded group attention for high-speed image classification and segmentation on resource-constrained devices.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ego4d",
      "term": "Ego4D",
      "definition": "A massive egocentric video dataset containing 3670 hours of daily life activity from over 900 participants across 74 locations worldwide. Advances first-person visual understanding research.",
      "tags": [
        "Benchmark",
        "Video",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-egoschema",
      "term": "EgoSchema",
      "definition": "A long-form video question answering benchmark derived from Ego4D testing temporal understanding over 3-minute egocentric video clips.",
      "tags": [
        "Benchmark",
        "Video",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-eigendecomposition",
      "term": "Eigendecomposition",
      "definition": "The factorization of a square matrix into eigenvalues and eigenvectors revealing the directions along which the transformation acts by simple scaling. Fundamental to PCA spectral clustering and many numerical methods in machine learning.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-einsum",
      "term": "Einsum",
      "definition": "Einstein Summation notation is a compact way to express multi-dimensional array operations including matrix multiplication outer products contractions and transpositions. Widely used in deep learning frameworks for expressing tensor operations concisely.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-el-capitan-supercomputer",
      "term": "El Capitan Supercomputer",
      "definition": "Exascale supercomputer at Lawrence Livermore National Laboratory using AMD EPYC CPUs and AMD Instinct MI300A APUs. Designed for nuclear security simulations and AI research.",
      "tags": [
        "Supercomputer",
        "AMD",
        "Exascale"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-elastic-fabric-adapter",
      "term": "Elastic Fabric Adapter",
      "definition": "AWS custom network interface providing low-latency high-bandwidth networking for distributed AI training. Enables efficient multi-node GPU communication on AWS cloud instances.",
      "tags": [
        "Networking",
        "AWS",
        "Cloud"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-elastic-net",
      "term": "Elastic Net",
      "definition": "A regularization method that linearly combines L1 and L2 penalty terms, balancing feature selection (sparsity) with weight shrinkage. The mixing ratio controls the relative contribution of each penalty.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-elastic-training",
      "term": "Elastic Training",
      "definition": "A distributed training approach that can dynamically scale the number of workers up or down during a training run without requiring a restart. Elastic training handles node failures and resource availability changes gracefully.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-elastic-weight-consolidation",
      "term": "Elastic Weight Consolidation",
      "definition": "A continual learning technique that slows down learning on weights important for previous tasks. Uses the diagonal of the Fisher information matrix to estimate parameter importance. Allows sequential task learning while mitigating catastrophic forgetting.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-elbow-method",
      "term": "Elbow Method",
      "definition": "A heuristic for selecting the optimal number of clusters by plotting the within-cluster sum of squares against the number of clusters and identifying the point where additional clusters yield diminishing returns, forming an elbow shape.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-electra",
      "term": "ELECTRA",
      "definition": "A pretraining method that trains a discriminator to detect tokens replaced by a small generator network, providing more efficient training than masked language modeling by learning from all input tokens.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-electromagnetic-vulnerability-of-ai",
      "term": "Electromagnetic Vulnerability of AI",
      "definition": "The susceptibility of AI hardware and systems to electromagnetic interference or attack. Relevant for safety-critical deployments where electromagnetic disruption could cause dangerous failures.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-electronic-design-automation",
      "term": "Electronic Design Automation",
      "definition": "Software tools used to design and verify integrated circuits including AI chips. Companies like Synopsys Cadence and Siemens EDA provide the tools chip designers depend on.",
      "tags": [
        "Manufacturing",
        "Software",
        "Design"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-eleutherai",
      "term": "EleutherAI",
      "definition": "A grassroots collective of researchers founded in 2020 dedicated to open-source AI research. EleutherAI developed GPT-Neo GPT-J and GPT-NeoX demonstrating that large language models could be created and shared openly outside major corporate labs.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-eli5",
      "term": "ELI5",
      "definition": "Explain Like Im 5 a long-form question answering dataset from Reddit where answers explain complex topics simply. Tests the ability to generate detailed accessible explanations.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-elias-gamma-coding",
      "term": "Elias Gamma Coding",
      "definition": "A universal code for encoding positive integers where the code length depends only on the magnitude of the integer. Encodes the number of binary digits in unary followed by the binary representation.",
      "tags": [
        "Algorithms",
        "Technical",
        "Information Theory"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-eliciting-latent-knowledge",
      "term": "Eliciting Latent Knowledge",
      "definition": "A research problem in AI alignment focused on extracting truthful information from a model that may have learned to represent the world accurately internally but could report misleadingly.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-eligibility-trace",
      "term": "Eligibility Trace",
      "definition": "A decaying memory of recently visited states used in TD(lambda) and other RL algorithms to distribute credit backward in time. Eligibility traces enable efficient online computation of lambda-weighted multi-step updates.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-eligibility-traces",
      "term": "Eligibility Traces",
      "definition": "A mechanism in reinforcement learning that bridges Monte Carlo and temporal difference methods by maintaining a trace of recently visited states. Assigns credit to past states proportional to their recency and frequency.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-eliza",
      "term": "ELIZA",
      "definition": "A natural language processing program created by Joseph Weizenbaum at MIT in 1966 that simulated a Rogerian psychotherapist, demonstrating the illusion of understanding and becoming one of the first chatbots.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-eliza-effect",
      "term": "Eliza Effect",
      "definition": "The tendency of humans to unconsciously assume that computer behaviors are analogous to human behaviors. Named after the ELIZA chatbot the effect describes how people readily anthropomorphize even simple AI systems attributing understanding and emotions to them.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ellipsis-resolution",
      "term": "Ellipsis Resolution",
      "definition": "The task of identifying and recovering omitted words or phrases in text that are understood from context, such as resolving 'John likes coffee and Mary tea' to include the implied verb.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-ellipsoid-method",
      "term": "Ellipsoid Method",
      "definition": "A polynomial-time algorithm for linear programming that uses a sequence of shrinking ellipsoids to converge on the optimal solution. Theoretically important as the first polynomial-time LP algorithm but rarely used in practice.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization",
        "History"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-elliptic-filter",
      "term": "Elliptic Filter",
      "definition": "A signal processing filter that achieves the steepest roll-off for a given filter order by allowing equiripple behavior in both passband and stopband. Also known as Cauer filters after Wilhelm Cauer.",
      "tags": [
        "Algorithms",
        "Technical",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-elmo",
      "term": "ELMo",
      "definition": "Embeddings from Language Models, a contextualized word representation method that generates word vectors as a function of the entire input sentence using a bidirectional LSTM language model.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-elo-rating-for-models",
      "term": "ELO Rating for Models",
      "definition": "An adaptation of the chess ELO rating system to rank language models through pairwise comparisons, where models gain or lose rating points based on head-to-head evaluation outcomes judged by humans or automated evaluators.",
      "tags": [
        "Evaluation",
        "Ranking"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-elu",
      "term": "ELU",
      "definition": "Exponential Linear Unit activation function that uses an exponential curve for negative inputs. Defined as f(x) = x if x > 0 and f(x) = alpha * (exp(x) - 1) otherwise. Produces negative outputs which helps push mean activations closer to zero and improves learning dynamics.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-embedded-multi-die-interconnect-bridge",
      "term": "Embedded Multi-Die Interconnect Bridge",
      "definition": "Intel advanced packaging technology using a small silicon bridge die to provide high-density connections between chiplets. An alternative to full silicon interposers for multi-die packages.",
      "tags": [
        "Packaging",
        "Intel",
        "Interconnect"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-embedding",
      "term": "Embedding",
      "definition": "A dense vector representation of data (words, sentences, images) in a continuous space. Similar items have similar embeddings, enabling semantic search and comparison.",
      "tags": [
        "Representation",
        "NLP"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-embedding-caching",
      "term": "Embedding Caching",
      "definition": "The practice of storing previously computed embedding vectors for reuse, avoiding redundant embedding model inference for repeated or similar content and reducing latency and computational cost in production retrieval pipelines.",
      "tags": [
        "Vector Database",
        "Performance"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-embedding-dimension",
      "term": "Embedding Dimension",
      "definition": "The number of components in a vector embedding, determining the representational capacity and memory footprint of the embedding space, with typical values ranging from 384 to 4096 dimensions depending on the embedding model.",
      "tags": [
        "Vector Database",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-embedding-drift",
      "term": "Embedding Drift",
      "definition": "The phenomenon where the distribution of vector embeddings changes over time as source data evolves or embedding models are updated, potentially degrading retrieval quality and requiring index refresh or reindexing to maintain accuracy.",
      "tags": [
        "Vector Database",
        "Maintenance"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-embedding-fine-tuning",
      "term": "Embedding Fine-Tuning",
      "definition": "The process of further training a pre-trained embedding model on domain-specific data using contrastive learning or other objectives to produce embeddings better suited for a particular use case, improving retrieval relevance in specialized domains.",
      "tags": [
        "Vector Database",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-embedding-model",
      "term": "Embedding Model",
      "definition": "A model specifically designed to convert text, images, or other data into vector representations. Popular embedding models include OpenAI's text-embedding-ada-002 and open-source alternatives like E5.",
      "tags": [
        "Model Type",
        "Representation"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-embedding-quantization",
      "term": "Embedding Quantization",
      "definition": "The compression of high-dimensional embedding vectors from 32-bit floats to lower precision formats (binary, int8) to reduce storage costs and accelerate similarity search with minimal retrieval quality loss.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-embedding-similarity-search",
      "term": "Embedding Similarity Search",
      "definition": "The process of finding the most semantically similar items to a query by computing distances between their vector embeddings in a shared embedding space, forming the foundation of modern neural information retrieval systems.",
      "tags": [
        "Vector Database",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-embedding-space",
      "term": "Embedding Space",
      "definition": "The continuous high-dimensional vector space in which embeddings reside, where geometric relationships between vectors encode semantic relationships, with similar concepts located nearby and dissimilar ones far apart according to the chosen distance metric.",
      "tags": [
        "Vector Database",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-embodied-ai",
      "term": "Embodied AI",
      "definition": "An approach to AI that emphasizes the role of physical embodiment and sensorimotor interaction with the environment in the development of intelligence. Proponents argue that intelligence cannot be fully understood or replicated without a body situated in the physical world.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-emergent-abilities",
      "term": "Emergent Abilities",
      "definition": "Capabilities that appear in large AI models that weren't present in smaller versions. Examples include complex reasoning, code generation, and following nuanced instructions.",
      "tags": [
        "Phenomenon",
        "Scaling"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-emergent-behavior-risk",
      "term": "Emergent Behavior Risk",
      "definition": "The risk that AI systems exhibit unexpected capabilities or behaviors that were not intended or predicted by their developers. Particularly concerning for large models where emergent properties are difficult to anticipate.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-emergent-capability",
      "term": "Emergent Capability",
      "definition": "An ability that appears in large language models only at sufficient scale and is absent in smaller models, such as multi-step reasoning or code generation, though the sharpness of this emergence is debated.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-emnist",
      "term": "EMNIST",
      "definition": "Extended MNIST dataset that includes handwritten letters in addition to digits providing 814000 character images across multiple splits. Useful for broader handwriting recognition research.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-emnlp",
      "term": "EMNLP",
      "definition": "The Conference on Empirical Methods in Natural Language Processing first held in 1996. A top-tier NLP conference known for emphasis on empirical and data-driven approaches to language processing alongside ACL and NAACL.",
      "tags": [
        "History",
        "Conferences"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-emotion-detection",
      "term": "Emotion Detection",
      "definition": "The task of identifying specific emotions such as joy, anger, sadness, fear, or surprise expressed in text, providing finer-grained analysis than binary sentiment classification.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-emotion-prompting",
      "term": "Emotion Prompting",
      "definition": "A technique that appends emotionally charged phrases to prompts such as urgency cues or importance markers, leveraging the observation that language models can respond to emotional stimuli with improved task performance.",
      "tags": [
        "Prompt Engineering",
        "Behavioral"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-emotion-recognition",
      "term": "Emotion Recognition",
      "definition": "The classification of facial expressions or body language into emotional categories using computer vision models trained on annotated datasets of human affect displays.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-emotion-recognition-ai-ethics",
      "term": "Emotion Recognition AI Ethics",
      "definition": "Ethical concerns about AI systems that claim to detect human emotions from facial expressions, voice, or physiological signals, including scientific validity doubts, cultural bias, and privacy implications.",
      "tags": [
        "AI Ethics",
        "Fairness"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-emotional-ai-ethics",
      "term": "Emotional AI Ethics",
      "definition": "Ethical concerns related to AI systems that detect generate or respond to human emotions. Issues include accuracy across demographics privacy of emotional data and potential for manipulation.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-empatheticdialogues",
      "term": "EmpatheticDialogues",
      "definition": "A dataset of 25000 conversations grounded in emotional situations where one participant responds empathetically to another's described experience. Tests emotional intelligence in dialogue.",
      "tags": [
        "Benchmark",
        "NLP",
        "Dialogue"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-empirical-bayes",
      "term": "Empirical Bayes",
      "definition": "An approach that estimates prior distribution parameters from the data itself, rather than specifying them a priori. It blends Bayesian and frequentist ideas by using the data to inform both the prior and posterior.",
      "tags": [
        "Statistics",
        "Bayesian Methods"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-empirical-distribution-function",
      "term": "Empirical Distribution Function",
      "definition": "A cumulative distribution function constructed from sample data that assigns probability 1/n to each observed value. It converges uniformly to the true CDF as sample size increases (Glivenko-Cantelli theorem).",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-empirical-risk-minimization",
      "term": "Empirical Risk Minimization",
      "definition": "A learning principle that selects the hypothesis minimizing the average loss on the training data. While simple and intuitive, it can lead to overfitting without regularization or capacity constraints.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-empowerment",
      "term": "Empowerment",
      "definition": "An information-theoretic intrinsic motivation measure defined as the channel capacity between an agent's actions and its future states. Empowerment rewards the agent for maintaining maximum influence over its environment, driving exploration toward controllable regions.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-emu-edit",
      "term": "Emu Edit",
      "definition": "A multi-task image editing model from Meta that can follow free-form text instructions for diverse editing operations with precise control.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-emu-video",
      "term": "Emu Video",
      "definition": "A text-to-video generation model from Meta that uses a factored approach generating images first then animating them for efficient video synthesis.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-emu3",
      "term": "Emu3",
      "definition": "A multimodal model from Meta that generates images and text and video through next-token prediction in a discrete token space without diffusion.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-encodec",
      "term": "Encodec",
      "definition": "A neural audio codec by Meta AI that compresses audio at very low bitrates using residual vector quantization. Enables efficient storage and transmission of audio while maintaining high quality. Used in audio language models.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-encoder",
      "term": "Encoder",
      "definition": "A neural network component that transforms input into a compressed representation. In transformers, encoder models (like BERT) process the entire input at once for understanding tasks.",
      "tags": [
        "Architecture",
        "Transformers"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-encoder-decoder-architecture",
      "term": "Encoder-Decoder Architecture",
      "definition": "A neural network design where an encoder processes input into a latent representation and a decoder generates output from that representation, commonly used for translation and summarization.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-encoder-only-architecture",
      "term": "Encoder-Only Architecture",
      "definition": "A transformer design using only bidirectional self-attention encoder blocks, producing contextualized representations of input tokens suited for classification and understanding tasks.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-endpoint",
      "term": "Endpoint",
      "definition": "A specific URL where an API can be accessed. AI services expose endpoints for different functions like chat completions, embeddings, and image generation.",
      "tags": [
        "API",
        "Technical"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-energy-efficiency-in-ai",
      "term": "Energy Efficiency in AI",
      "definition": "The computational output achieved per unit of energy consumed in AI training and inference. Improving energy efficiency is critical as AI model sizes and training costs grow exponentially.",
      "tags": [
        "Efficiency",
        "Sustainability"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-enflame-technology",
      "term": "Enflame Technology",
      "definition": "Chinese AI chip startup designing training and inference accelerators for data center AI workloads. Develops both chips and a software stack to support AI model deployment.",
      "tags": [
        "Accelerator",
        "China",
        "Data Center"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-eniac",
      "term": "ENIAC",
      "definition": "The Electronic Numerical Integrator and Computer, completed in 1945 at the University of Pennsylvania, one of the earliest general-purpose electronic digital computers that demonstrated the feasibility of large-scale electronic computation.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ensemble-learning",
      "term": "Ensemble Learning",
      "definition": "A machine learning paradigm that combines predictions from multiple models to produce a more robust and accurate prediction. Methods include bagging boosting and stacking. Generally outperforms individual models by reducing variance or bias.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-ensemble",
      "term": "Ensemble Methods",
      "definition": "Techniques that combine multiple models to produce better results than any single model. Includes voting, bagging (Random Forest), and boosting (XGBoost). Often used in production for reliability.",
      "tags": [
        "Technique",
        "ML"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-ensemble-methods-history",
      "term": "Ensemble Methods History",
      "definition": "The development of ensemble methods from early voting approaches through bagging (Breiman 1996) boosting (Freund and Schapire 1997) stacking (Wolpert 1992) and random forests (Breiman 2001). Ensembles consistently outperform individual models across diverse tasks.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-enterprise-ai",
      "term": "Enterprise AI",
      "definition": "AI solutions designed for business environments with features like access controls, compliance, data privacy, and integration with existing systems. Different from consumer AI in security and governance requirements.",
      "tags": [
        "Business",
        "Application"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-entity-disambiguation",
      "term": "Entity Disambiguation",
      "definition": "The process of determining which specific real-world entity a textual mention refers to when the same name could refer to multiple entities, using context clues and knowledge bases.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-entityquestions",
      "term": "EntityQuestions",
      "definition": "A benchmark of simple factual questions about entities testing parametric knowledge stored in language models. Evaluates entity knowledge across different popularity levels.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-entropy",
      "term": "Entropy",
      "definition": "A measure from information theory quantifying the uncertainty or disorder in a random variable's distribution. In machine learning, it is used as a splitting criterion and as a component of loss functions like cross-entropy.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-entropy-coding-algorithm",
      "term": "Entropy Coding Algorithm",
      "definition": "A class of lossless compression methods that encode data using the fewest possible bits based on the probability distribution of symbols. Includes Huffman and arithmetic and range coding as specific implementations.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Information Theory"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-entropy-regularization",
      "term": "Entropy Regularization",
      "definition": "A technique that adds the policy entropy to the RL objective function, discouraging the agent from committing to a single action too quickly. Entropy regularization promotes robust exploration and smoother optimization landscapes.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-environment",
      "term": "Environment",
      "definition": "The external system an RL agent interacts with, providing observations and rewards in response to actions. The environment defines the dynamics and rules governing state transitions.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-environmental-justice-in-ai",
      "term": "Environmental Justice in AI",
      "definition": "The principle that the environmental costs of AI development and deployment including energy use and e-waste should not disproportionately burden marginalized communities.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-epic-kitchens",
      "term": "Epic-Kitchens",
      "definition": "A large egocentric video dataset of cooking activities captured in participants kitchens. Contains fine-grained action annotations for action recognition and anticipation research.",
      "tags": [
        "Benchmark",
        "Video"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-epipolar-geometry",
      "term": "Epipolar Geometry",
      "definition": "The geometric relationship between two camera views of the same scene, defined by the fundamental or essential matrix, constraining where a point in one image can appear in the other.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-episode",
      "term": "Episode",
      "definition": "A complete sequence of interaction from an initial state to a terminal state in episodic RL tasks. Episodes provide natural boundaries for computing returns and resetting the environment.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-epistemic-autonomy",
      "term": "Epistemic Autonomy",
      "definition": "The right and capacity of individuals to form their own beliefs and make their own judgments rather than having these determined by AI recommendations and filter bubbles.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-epoch",
      "term": "Epoch",
      "definition": "One complete pass through the entire training dataset. Models typically train for multiple epochs, with each pass allowing weights to be refined based on all available data.",
      "tags": [
        "Training",
        "Technical"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-epsilon-greedy",
      "term": "Epsilon-Greedy Exploration",
      "definition": "An exploration strategy where the agent selects the greedy (best-known) action with probability 1-epsilon and a random action with probability epsilon. The epsilon parameter is typically annealed over training to shift from exploration to exploitation.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-equalized-odds",
      "term": "Equalized Odds",
      "definition": "A fairness criterion requiring that a classifier has equal true positive rates and equal false positive rates across all protected groups, ensuring that prediction accuracy does not vary by group membership.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ernie",
      "term": "ERNIE",
      "definition": "Enhanced Representation through Knowledge Integration is a pre-trained language model from Baidu that incorporates entity and phrase-level knowledge masking.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-error-analysis",
      "term": "Error Analysis",
      "definition": "Systematic examination of model mistakes to understand failure patterns and guide improvements. Essential for iterating on model performance and identifying data or training issues.",
      "tags": [
        "Evaluation",
        "Process"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-esc-50",
      "term": "ESC-50",
      "definition": "Environmental Sound Classification dataset containing 2000 five-second recordings across 50 environmental sound categories. Used for benchmarking environmental sound recognition systems.",
      "tags": [
        "Benchmark",
        "Audio"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-escalation-protocol",
      "term": "Escalation Protocol",
      "definition": "A defined procedure for elevating AI safety concerns from technical teams to management and potentially to external regulators when certain risk thresholds are exceeded.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-esm-1b",
      "term": "ESM-1b",
      "definition": "A protein language model from Meta AI with 650 million parameters that learns protein structure and function information from evolutionary sequence data.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-esm-2",
      "term": "ESM-2",
      "definition": "A protein language model from Meta AI trained on millions of protein sequences that learns evolutionary and structural information for downstream protein analysis tasks.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-esm-if1",
      "term": "ESM-IF1",
      "definition": "An inverse folding model from Meta AI that designs protein sequences for given protein backbone structures using a geometric Transformer architecture.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-esmfold",
      "term": "ESMFold",
      "definition": "A protein structure prediction model from Meta AI that uses a large protein language model (ESM-2) to predict structures in a single forward pass without multiple sequence alignments.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-esperanto-technologies",
      "term": "Esperanto Technologies",
      "definition": "AI chip company designing RISC-V based many-core processors with over 1000 cores per chip for energy-efficient AI inference. Targets cloud and edge deployment scenarios.",
      "tags": [
        "Accelerator",
        "Startup",
        "RISC-V"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-esprit-algorithm",
      "term": "ESPRIT Algorithm",
      "definition": "Estimation of Signal Parameters via Rotational Invariance Techniques exploits the shift structure of sensor arrays to estimate signal directions. Avoids the spectral search of MUSIC and directly computes signal parameters.",
      "tags": [
        "Algorithms",
        "Technical",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-essential-matrix-estimation",
      "term": "Essential Matrix Estimation",
      "definition": "An algorithm that computes the essential matrix relating two calibrated camera views from point correspondences. Encodes the relative rotation and translation between cameras up to a scale factor.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-estimation-of-distribution-algorithm",
      "term": "Estimation of Distribution Algorithm",
      "definition": "An evolutionary algorithm that replaces crossover and mutation with probabilistic modeling of promising solutions. Builds a probability distribution from the best individuals and samples new candidates from it.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-etching",
      "term": "Etching",
      "definition": "Semiconductor manufacturing process that selectively removes material from a wafer surface to create circuit patterns. Includes wet chemical and dry plasma etching techniques.",
      "tags": [
        "Fabrication",
        "Manufacturing",
        "Process"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-roce",
      "term": "Ethernet for AI (RoCE)",
      "definition": "RDMA over Converged Ethernet, a networking protocol that enables remote direct memory access over Ethernet infrastructure. RoCE provides a lower-cost alternative to InfiniBand for AI cluster networking with comparable performance using lossless Ethernet configurations.",
      "tags": [
        "Distributed Computing",
        "Hardware"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ethical-ai-by-design",
      "term": "Ethical AI by Design",
      "definition": "An approach that integrates ethical considerations throughout the AI development lifecycle from initial requirements through design implementation testing and deployment.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ethical-prompting",
      "term": "Ethical Prompting",
      "definition": "The practice of designing prompts that explicitly incorporate ethical guidelines, fairness constraints, and harm-avoidance instructions to steer model outputs toward responsible, unbiased, and socially beneficial responses.",
      "tags": [
        "Prompt Engineering",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ethics",
      "term": "ETHICS",
      "definition": "A benchmark testing language models on basic ethical judgments across five moral domains: justice deontology virtue ethics utilitarianism and commonsense morality.",
      "tags": [
        "Benchmark",
        "NLP",
        "Safety"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-ethics-board",
      "term": "Ethics Board (AI)",
      "definition": "A group that reviews AI development and deployment for ethical concerns. Many major AI companies have ethics boards to evaluate potential harms and establish guidelines.",
      "tags": [
        "Governance",
        "Ethics"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-ethics-of-care-in-ai",
      "term": "Ethics of Care in AI",
      "definition": "An ethical framework that emphasizes relationships responsibility and contextual judgment in AI development. Contrasts with principle-based approaches by focusing on the needs of specific affected individuals and communities.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ethics-washing",
      "term": "Ethics Washing",
      "definition": "The practice of organizations using ethics boards, principles, or frameworks as public relations tools without implementing meaningful changes to their AI development practices or governance structures.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-eu-ai-act",
      "term": "EU AI Act",
      "definition": "The European Union's comprehensive regulatory framework for artificial intelligence, adopted in 2024, which classifies AI systems by risk level and imposes requirements ranging from transparency obligations to outright bans on certain uses.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-eu-chips-act",
      "term": "EU Chips Act",
      "definition": "European Union legislation investing 43 billion euros in semiconductor manufacturing research and design. Part of Europe strategy to secure its chip supply chain including for AI hardware.",
      "tags": [
        "Policy",
        "Legislation",
        "Europe"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-euclidean-distance",
      "term": "Euclidean Distance",
      "definition": "The straight-line distance between two points in Euclidean space, computed as the square root of the sum of squared differences across all dimensions. It is the most common distance metric in machine learning.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-euler-method",
      "term": "Euler Method",
      "definition": "The simplest numerical method for solving ordinary differential equations that uses the tangent line at each step to approximate the solution. First-order accurate but useful for understanding more advanced integration schemes.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-euler-tour-technique",
      "term": "Euler Tour Technique",
      "definition": "A technique that converts a tree into a linear sequence by recording vertices as they are visited during a DFS traversal. Enables subtree queries and lowest common ancestor computations using range query structures.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-eulerian-path-algorithm",
      "term": "Eulerian Path Algorithm",
      "definition": "An algorithm that finds a path visiting every edge in a graph exactly once. Hierholzer's algorithm constructs an Eulerian circuit in linear time by building and merging sub-circuits through repeated traversals.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-eurisko",
      "term": "Eurisko",
      "definition": "An AI program developed by Douglas Lenat in 1981 that could discover new heuristics and concepts. Built as a successor to AM Eurisko famously won the Traveller Trillion Credit Squadron naval wargame championship two consecutive years using discovered fleet designs.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-europarl",
      "term": "Europarl",
      "definition": "A parallel corpus extracted from European Parliament proceedings containing text in 21 European languages. Widely used for training and evaluating statistical and neural machine translation.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Translation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-eurosat",
      "term": "EuroSAT",
      "definition": "A dataset of 27000 labeled satellite images across 10 land use classes derived from Sentinel-2 satellite data. Used for benchmarking remote sensing and land cover classification algorithms.",
      "tags": [
        "Benchmark",
        "Computer Vision",
        "Remote Sensing"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-euv-lithography",
      "term": "EUV Lithography",
      "definition": "Extreme ultraviolet lithography using 13.5nm wavelength light to print the smallest features on advanced semiconductor chips. Required for manufacturing at 7nm and below process nodes.",
      "tags": [
        "Fabrication",
        "Manufacturing",
        "Process"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-eva",
      "term": "EVA",
      "definition": "An Exploring the Limits of Masked Visual Representation Learning model that scales vision Transformers to one billion parameters with masked image modeling.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-eva-02",
      "term": "EVA-02",
      "definition": "A second-generation vision foundation model that uses masked image modeling with CLIP features as reconstruction targets for improved visual representations.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-eva-clip",
      "term": "EVA-CLIP",
      "definition": "A vision-language model that scales CLIP training to 18 billion parameters using the EVA framework for improved zero-shot visual recognition.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-evalplus",
      "term": "EvalPlus",
      "definition": "An enhanced evaluation framework for code generation that augments existing benchmarks with additional test cases. Addresses test case insufficiency in code generation evaluation.",
      "tags": [
        "Benchmark",
        "Code",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-evaluation",
      "term": "Evaluation",
      "definition": "The process of measuring model performance using metrics, benchmarks, and human assessment. Critical for comparing models and ensuring they meet quality standards.",
      "tags": [
        "Process",
        "Quality"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-evaluation-bias",
      "term": "Evaluation Bias",
      "definition": "Bias introduced during model evaluation when benchmark datasets or metrics do not adequately represent the diversity of the deployment population, leading to overly optimistic performance estimates for some groups.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-eval-harness",
      "term": "Evaluation Harness",
      "definition": "A framework for systematically testing AI models across multiple benchmarks and tasks. Popular harnesses include lm-evaluation-harness used for open-source model comparisons.",
      "tags": [
        "Tools",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-evasion-attack",
      "term": "Evasion Attack",
      "definition": "An adversarial attack that modifies inputs at test time to cause misclassification by a deployed model. Unlike poisoning attacks evasion attacks do not require access to the training process.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-event-extraction",
      "term": "Event Extraction",
      "definition": "The task of identifying event triggers and their arguments in text, determining what happened, who was involved, when, where, and other event-specific attributes.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-evidence-lower-bound",
      "term": "Evidence Lower Bound",
      "definition": "A lower bound on the log marginal likelihood (model evidence) that serves as the objective function in variational inference. Maximizing the ELBO is equivalent to minimizing the KL divergence between the variational and true posterior.",
      "tags": [
        "Machine Learning",
        "Bayesian Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-evodiff",
      "term": "EvoDiff",
      "definition": "A diffusion-based generative model for proteins that generates diverse and functional protein sequences through evolutionary-scale denoising diffusion.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-evol-instruct",
      "term": "Evol-Instruct",
      "definition": "A method and dataset that uses LLMs to progressively evolve simple instructions into complex ones. Used to create the WizardLM training data for improved instruction following.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-evolution-strategies-rl",
      "term": "Evolution Strategies for RL",
      "definition": "Black-box optimization methods that estimate policy gradients by perturbing parameters and evaluating returns, without requiring backpropagation through the environment. ES are highly parallelizable and can scale to thousands of workers.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-evolutionary-computation",
      "term": "Evolutionary Computation",
      "definition": "A family of optimization algorithms inspired by biological evolution including genetic algorithms genetic programming evolutionary strategies and differential evolution. Pioneered by researchers including John Holland Lawrence Fogel and Ingo Rechenberg from the 1960s onward.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-exa-scale-computing",
      "term": "EXA-Scale Computing",
      "definition": "Computing capability exceeding one exaFLOPS or a quintillion floating-point operations per second. The Frontier supercomputer achieved this milestone in 2022 enabling unprecedented AI research scale.",
      "tags": [
        "Computing",
        "Milestone",
        "Performance"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-exact-match",
      "term": "Exact Match",
      "definition": "A strict evaluation metric that scores a prediction as correct only if it exactly matches the ground truth answer after normalization, commonly used in question answering and information extraction benchmarks.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-exact-nearest-neighbor",
      "term": "Exact Nearest Neighbor",
      "definition": "A search approach that guarantees finding the true closest vectors to a query by exhaustively computing distances to all vectors in the index, providing perfect recall but with linear time complexity that limits scalability.",
      "tags": [
        "Vector Database",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-exaone",
      "term": "EXAONE",
      "definition": "A bilingual large language model from LG AI Research optimized for Korean and English with strong enterprise and reasoning capabilities.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-exascale-computing",
      "term": "Exascale Computing",
      "definition": "Computing capability at or exceeding one exaFLOPS enabling unprecedented scale of AI training and scientific simulation. Achieved by Frontier in 2022 followed by Aurora and El Capitan.",
      "tags": [
        "Computing",
        "Milestone",
        "Scale"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-executive-order-on-ai",
      "term": "Executive Order on AI",
      "definition": "US Executive Order 14110 on Safe Secure and Trustworthy Development and Use of Artificial Intelligence signed by President Biden on October 30 2023. The order established new standards for AI safety and security and directed federal agencies to address AI risks.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-existential-risk-from-ai",
      "term": "Existential Risk from AI",
      "definition": "The hypothesis that sufficiently advanced AI systems could pose a threat to the continued existence of humanity or permanently curtail its potential, motivating research into alignment and AI safety.",
      "tags": [
        "AI Safety",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-expectation-maximization",
      "term": "Expectation-Maximization",
      "definition": "An iterative algorithm for finding maximum likelihood estimates in models with latent variables. It alternates between computing expected values of the latent variables (E-step) and maximizing the likelihood with respect to model parameters (M-step).",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-expectation-maximization-algorithm",
      "term": "Expectation-Maximization Algorithm",
      "definition": "An iterative statistical method for finding maximum likelihood estimates when data is incomplete or has latent variables. Published by Arthur Dempster Nan Laird and Donald Rubin in 1977 EM became fundamental to clustering topic modeling and mixture model training.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-expected-calibration-error",
      "term": "Expected Calibration Error",
      "definition": "A scalar summary of calibration quality computed by binning predictions by confidence, calculating the absolute difference between accuracy and confidence within each bin, and averaging weighted by bin size.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-expectiminimax-algorithm",
      "term": "Expectiminimax Algorithm",
      "definition": "An extension of minimax for games with chance elements that includes chance nodes representing random events. Computes expected values at chance nodes and optimal moves at player nodes.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-experience-replay",
      "term": "Experience Replay",
      "definition": "A technique where an agent stores past transitions in a replay buffer and samples from it during training, breaking temporal correlations between consecutive samples. Experience replay improves data efficiency and training stability.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-expert-parallelism",
      "term": "Expert Parallelism",
      "definition": "A distributed computing strategy for mixture-of-experts models where different expert subnetworks are placed on different devices, with all-to-all communication routing tokens to their assigned experts.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-expert-prompting",
      "term": "Expert Prompting",
      "definition": "A prompting method that instructs the model to first identify the most qualified expert identity for a given question, adopt that expert's perspective and knowledge base, then provide an authoritative answer informed by that domain expertise.",
      "tags": [
        "Prompt Engineering",
        "Persona"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-expert-systems",
      "term": "Expert Systems",
      "definition": "AI programs popular in the 1970s and 1980s that encoded human expert knowledge as if-then rules to solve domain-specific problems, representing the dominant commercial AI paradigm before the rise of machine learning.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-explainability",
      "term": "Explainability (XAI)",
      "definition": "The ability to understand and explain how AI models make decisions. Important for trust, debugging, regulatory compliance, and identifying potential biases.",
      "tags": [
        "Transparency",
        "Trust"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-explainable-ai",
      "term": "Explainable AI",
      "definition": "A field of research focused on making AI system decisions understandable to humans. Includes techniques like feature attribution attention visualization concept-based explanations and counterfactual reasoning.",
      "tags": [
        "Safety",
        "Fundamentals"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-explainable-ai-history",
      "term": "Explainable AI History",
      "definition": "The evolution of explainable AI from early rule-based systems that were inherently interpretable through the challenge of black-box deep learning to modern XAI techniques like LIME SHAP attention visualization and concept-based explanations.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-exploding-gradient",
      "term": "Exploding Gradient",
      "definition": "A training instability where gradients grow exponentially large during backpropagation through deep networks, causing weight updates to become excessively large and training to diverge.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-exploding-gradient-problem",
      "term": "Exploding Gradient Problem",
      "definition": "A complementary problem to vanishing gradients where gradients grow exponentially during backpropagation causing unstable training. Solutions include gradient clipping proper weight initialization and architectural innovations like LSTM and residual networks.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-exploitation-exploration-tradeoff-safety",
      "term": "Exploitation-Exploration Tradeoff Safety",
      "definition": "Safety implications of the balance between exploiting known-safe actions and exploring new actions in reinforcement learning. Unsafe exploration can lead to catastrophic outcomes in real-world deployments.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-exploration-vs-exploitation",
      "term": "Exploration vs Exploitation",
      "definition": "The fundamental dilemma in RL between exploring unknown actions to discover potentially better strategies and exploiting current knowledge to maximize immediate reward. Balancing this tradeoff is essential for efficient learning.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-exponential-distribution",
      "term": "Exponential Distribution",
      "definition": "A continuous probability distribution modeling the time between events in a Poisson process. It has the memoryless property: the probability of an event in the next interval is independent of elapsed time.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-exponential-family",
      "term": "Exponential Family",
      "definition": "A broad class of probability distributions characterized by a specific mathematical form, including normal, Poisson, binomial, exponential, and gamma distributions. They are foundational to generalized linear models and conjugate Bayesian analysis.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-exponential-histogram-algorithm",
      "term": "Exponential Histogram Algorithm",
      "definition": "A data structure for maintaining approximate counts over sliding windows in data streams. Uses exponentially growing bucket sizes to provide bounded relative error with O(log^2 n) space.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-exponential-mechanism",
      "term": "Exponential Mechanism",
      "definition": "A differential privacy mechanism for selecting an output from a discrete set that favors high-utility options while preserving privacy. Assigns selection probabilities exponentially proportional to a quality score function.",
      "tags": [
        "Algorithms",
        "Technical",
        "Privacy"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-exponential-moving-average-model",
      "term": "Exponential Moving Average Model",
      "definition": "A technique that maintains a running exponential average of model weights during training and uses the averaged model for evaluation. Provides smoother more stable predictions than the final training checkpoint. Standard practice in modern training.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-exponential-search",
      "term": "Exponential Search",
      "definition": "A search algorithm that first finds a range where the target might exist by checking positions at exponentially increasing intervals then performs binary search within that range. Useful for unbounded or infinite lists.",
      "tags": [
        "Algorithms",
        "Technical",
        "Searching"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-exponential-smoothing",
      "term": "Exponential Smoothing",
      "definition": "A family of time series forecasting methods that compute weighted averages of past observations with exponentially decreasing weights. Variants include simple, double (Holt's), and triple (Holt-Winters) exponential smoothing.",
      "tags": [
        "Data Science",
        "Statistics"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-extended-kalman-filter",
      "term": "Extended Kalman Filter",
      "definition": "A nonlinear extension of the Kalman filter that linearizes the system dynamics around the current estimate using first-order Taylor expansion. Widely used in navigation and robotics for state estimation.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-extendible-hashing-algorithm",
      "term": "Extendible Hashing Algorithm",
      "definition": "A dynamic hashing scheme that doubles the directory size when a bucket overflows rather than rehashing all entries. Provides efficient retrieval with at most two disk accesses for any record.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-external-sort",
      "term": "External Sort",
      "definition": "A class of sorting algorithms designed for large datasets that do not fit in main memory. Typically uses a merge-sort approach that reads chunks into memory and sorts them before merging the sorted chunks from disk.",
      "tags": [
        "Algorithms",
        "Technical",
        "Sorting"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-extra-trees",
      "term": "Extra Trees",
      "definition": "Extremely Randomized Trees is an ensemble method similar to random forests but with additional randomization. Splits are chosen completely at random rather than searching for the best split. Faster training with competitive accuracy.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-extraction",
      "term": "Extraction",
      "definition": "Using AI to identify and pull specific information from unstructured text. Applications include named entity extraction, key phrase extraction, and structured data extraction.",
      "tags": [
        "NLP Task",
        "Application"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-extractive-ai",
      "term": "Extractive AI",
      "definition": "AI development practices that extract value from communities through data collection and labor without providing equitable returns. Includes concerns about data exploitation and digital labor in the Global South.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-extractive-question-answering",
      "term": "Extractive Question Answering",
      "definition": "A QA task where the model identifies the answer as a contiguous span of text within a given context passage, predicting the start and end positions of the answer.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-extractive-summarization",
      "term": "Extractive Summarization",
      "definition": "A summarization approach that selects and concatenates the most important sentences or passages from the source document to form a summary without generating new text.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    }
  ]
}