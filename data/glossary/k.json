{
  "letter": "k",
  "count": 43,
  "terms": [
    {
      "id": "term-k-fold",
      "term": "K-Fold Cross-Validation",
      "definition": "A cross-validation technique that divides data into K equal parts, training K times with a different part as the test set each time. Provides robust performance estimates.",
      "tags": [
        "Evaluation",
        "Training"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-k-means",
      "term": "K-Means",
      "definition": "An unsupervised clustering algorithm that partitions n observations into k clusters by iteratively assigning points to the nearest centroid and then updating centroids to be the mean of assigned points until convergence.",
      "tags": [
        "Machine Learning",
        "Clustering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-k-means-clustering",
      "term": "K-Means Clustering",
      "definition": "An unsupervised learning algorithm that partitions data into K clusters by iteratively assigning points to the nearest centroid and updating centroids. Simple and scalable but assumes spherical clusters and requires specifying K in advance.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-k-nearest-neighbors",
      "term": "k-Nearest Neighbors",
      "definition": "A simple non-parametric classification and regression method proposed in early forms by Evelyn Fix and Joseph Hodges in 1951. kNN classifies data points based on the majority class of their k closest neighbors in feature space.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-k-nearest",
      "term": "K-Nearest Neighbors (KNN)",
      "definition": "A simple ML algorithm that classifies data points based on the majority class of their K nearest neighbors. Intuitive but can be slow for large datasets.",
      "tags": [
        "Algorithm",
        "Classification"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-k-nearest-neighbors-search",
      "term": "K-Nearest Neighbors Search",
      "definition": "A vector retrieval operation that returns the K vectors most similar to a query vector according to a specified distance metric, forming the core retrieval primitive for vector databases and embedding-based search systems.",
      "tags": [
        "Vector Database",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-kaggle",
      "term": "Kaggle",
      "definition": "A platform for data science and machine learning competitions founded in 2010 and acquired by Google in 2017. Kaggle hosts competitions provides datasets and offers a collaborative notebook environment that has become central to the ML community.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-kaplan-meier-estimator",
      "term": "Kaplan-Meier Estimator",
      "definition": "A non-parametric statistic used to estimate the survival function from time-to-event data, accounting for right-censored observations. It produces a step function decreasing at each observed event time.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-kasparov-vs-deep-blue",
      "term": "Kasparov vs Deep Blue",
      "definition": "The historic 1997 rematch in which IBM's Deep Blue defeated world chess champion Garry Kasparov 3.5 to 2.5, marking the first time a computer beat a reigning world champion under standard tournament conditions.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-kendall-tau",
      "term": "Kendall Tau",
      "definition": "A non-parametric statistic measuring the ordinal association between two rankings, computed from the number of concordant and discordant pairs. It is more robust to outliers than Spearman's correlation.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-keras",
      "term": "Keras",
      "definition": "A high-level neural network API that makes building deep learning models more accessible. Now integrated into TensorFlow, known for its user-friendly design.",
      "tags": [
        "Framework",
        "Deep Learning"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-keras-release",
      "term": "Keras Release",
      "definition": "The initial release of Keras by Francois Chollet in March 2015 as a high-level neural network API. Keras simplified deep learning by providing an intuitive interface on top of backends like TensorFlow making deep learning accessible to a broader audience of developers.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-kernel",
      "term": "Kernel (ML)",
      "definition": "A function that measures similarity between data points, enabling algorithms like SVMs to work in high-dimensional spaces. Common kernels include linear, polynomial, and RBF.",
      "tags": [
        "Concept",
        "Math"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-kernel-auto-tuning",
      "term": "Kernel Auto-Tuning",
      "definition": "The process of automatically selecting optimal GPU kernel implementations for specific tensor sizes and hardware configurations. Auto-tuning tests multiple implementations at different tile sizes and thread configurations to find the fastest option.",
      "tags": [
        "Inference Infrastructure",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-kernel-density-estimation",
      "term": "Kernel Density Estimation",
      "definition": "A non-parametric method for estimating the probability density function of a random variable by placing a kernel (e.g., Gaussian) at each data point and summing the contributions, controlled by a bandwidth parameter.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-kernel-methods",
      "term": "Kernel Methods",
      "definition": "A class of algorithms for pattern analysis that use kernel functions to operate in high-dimensional feature spaces without explicitly computing the transformation. The kernel trick popularized by Vladimir Vapnik and colleagues enabled SVMs to handle nonlinear classification.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-kernel-trick",
      "term": "Kernel Trick",
      "definition": "A mathematical technique that implicitly maps data into a high-dimensional feature space by computing inner products via a kernel function, without explicitly performing the transformation. It enables linear algorithms to learn non-linear decision boundaries.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-key-value-cache",
      "term": "Key-Value Cache",
      "definition": "An optimization for autoregressive transformer inference that stores previously computed key and value tensors to avoid redundant recomputation when generating each new token.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-keypoint-detection",
      "term": "Keypoint Detection",
      "definition": "The task of identifying specific anatomical or structural points of interest in an image, such as body joints, facial landmarks, or object corners, typically predicting heatmaps for each keypoint location.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-keyword-extraction",
      "term": "Keyword Extraction",
      "definition": "The task of automatically identifying the most important or representative words and phrases in a document, using statistical, graph-based, or neural methods.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-keyword-search",
      "term": "Keyword Search",
      "definition": "A traditional information retrieval method that matches documents based on the presence and frequency of query terms, using algorithms like BM25 or TF-IDF to score relevance without requiring semantic understanding of meaning.",
      "tags": [
        "Retrieval",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-kl-divergence",
      "term": "KL Divergence",
      "definition": "Kullback-Leibler divergence, a non-symmetric measure of how one probability distribution differs from a reference distribution. It quantifies the information lost when approximating the true distribution with the model distribution.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-kling",
      "term": "Kling",
      "definition": "A video generation model developed by Kuaishou Technology that produces high-quality realistic videos from text prompts. Features strong motion modeling and temporal consistency across generated frames.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-know-your-customer-for-ai",
      "term": "Know Your Customer for AI",
      "definition": "Proposed regulatory requirements for AI cloud providers and model distributors to verify the identity and intended use of customers accessing powerful AI capabilities, analogous to financial sector KYC rules.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-knowledge-acquisition-bottleneck",
      "term": "Knowledge Acquisition Bottleneck",
      "definition": "A fundamental challenge in expert systems development referring to the difficulty and expense of extracting knowledge from human experts and encoding it in a form usable by computers. This bottleneck was a major factor in the limitations of expert systems.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-knowledge-cutoff",
      "term": "Knowledge Cutoff",
      "definition": "The date beyond which an AI model has no training data. Events after this date are unknown to the model unless provided through context or retrieval augmentation.",
      "tags": [
        "Limitation",
        "LLM"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-knowledge-distillation",
      "term": "Knowledge Distillation",
      "definition": "A model compression technique where a smaller student model is trained to mimic the outputs of a larger teacher model. The teacher's soft probability distribution provides richer training signal than hard labels enabling the student to learn more effectively.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-knowledge-distillation-efficiency",
      "term": "Knowledge Distillation for Efficiency",
      "definition": "A model compression technique where a smaller student model is trained to mimic the outputs (soft predictions) of a larger teacher model. The student captures the teacher's dark knowledge in probability distributions, achieving better performance than training from scratch.",
      "tags": [
        "Model Optimization",
        "Inference Infrastructure"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-knowledge-distillation-vision",
      "term": "Knowledge Distillation for Vision",
      "definition": "The process of training a compact student vision model to mimic the predictions and feature representations of a larger teacher model, enabling efficient deployment on edge devices.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-knowledge-distillation-loss",
      "term": "Knowledge Distillation Loss",
      "definition": "A training objective where a smaller student model learns to match the soft probability distributions produced by a larger teacher model, transferring knowledge through the teacher's output logits.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-knowledge-engineering",
      "term": "Knowledge Engineering",
      "definition": "The discipline of integrating knowledge into computer systems to solve complex problems normally requiring human expertise. A key practice in the expert systems era of the 1980s knowledge engineering involves eliciting structuring and encoding domain knowledge.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-knowledge-graph",
      "term": "Knowledge Graph",
      "definition": "A structured representation of facts as interconnected entities and relationships. Used to enhance AI systems with factual knowledge and enable reasoning over structured data.",
      "tags": [
        "Data Structure",
        "Knowledge"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-knowledge-representation",
      "term": "Knowledge Representation",
      "definition": "The field within AI concerned with how information about the world can be formally represented in a form that computer systems can use for reasoning, planning, and problem-solving, encompassing logic, frames, semantic nets, and ontologies.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-kolmogorov-complexity",
      "term": "Kolmogorov Complexity",
      "definition": "The length of the shortest computer program that produces a given string as output, representing the intrinsic information content of that string. It is uncomputable but foundational to algorithmic information theory.",
      "tags": [
        "Machine Learning",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-kolmogorov-arnold-network",
      "term": "Kolmogorov-Arnold Network",
      "definition": "A neural network architecture based on the Kolmogorov-Arnold representation theorem that places learnable activation functions on edges rather than nodes. Each weight is replaced by a learnable spline function enabling interpretable models.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-kolmogorov-smirnov-test",
      "term": "Kolmogorov-Smirnov Test",
      "definition": "A non-parametric test that compares a sample distribution with a reference distribution (one-sample) or compares two sample distributions (two-sample) using the maximum absolute difference between cumulative distribution functions.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-kosmos-2",
      "term": "Kosmos-2",
      "definition": "A multimodal large language model by Microsoft that can ground text to the visual world. Combines language understanding with spatial awareness enabling referring expression comprehension and phrase grounding.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-krippendorffs-alpha",
      "term": "Krippendorff's Alpha",
      "definition": "A versatile reliability coefficient that measures agreement among multiple annotators for any number of raters, variable scales, and missing data, applicable to nominal, ordinal, interval, and ratio measurement levels.",
      "tags": [
        "Evaluation",
        "Methodology"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-krl",
      "term": "KRL",
      "definition": "The Knowledge Representation Language developed by Daniel Bobrow and Terry Winograd at Xerox PARC in the mid-1970s. KRL combined aspects of frames semantic networks and procedural representations influencing later knowledge representation systems.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-kto",
      "term": "KTO",
      "definition": "Kahneman-Tversky Optimization, a preference learning method that trains language models using binary feedback (good/bad) rather than pairwise comparisons, inspired by prospect theory from behavioral economics.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-kv-cache",
      "term": "KV Cache (Key-Value Cache)",
      "definition": "An optimization that stores previously computed key and value vectors in transformer models. Speeds up autoregressive generation by avoiding redundant calculations.",
      "tags": [
        "Optimization",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-kv-cache-compression",
      "term": "KV Cache Compression",
      "definition": "Methods for reducing the memory footprint of key-value caches during autoregressive generation, including quantization of cached values, eviction policies, and grouped-query attention.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-kv-cache-optimization",
      "term": "KV Cache Optimization",
      "definition": "Techniques for reducing the memory footprint and access cost of the key-value cache in transformer inference, including quantized KV caches, multi-query attention, grouped-query attention, and cache eviction policies. KV cache often dominates memory usage in long-context LLM serving.",
      "tags": [
        "Inference Infrastructure",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    }
  ]
}