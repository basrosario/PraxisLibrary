{
  "letter": "r",
  "count": 153,
  "terms": [
    {
      "id": "term-r-squared",
      "term": "R-Squared",
      "definition": "A statistical measure indicating the proportion of variance in the dependent variable that is explained by the independent variables in a regression model. Values range from 0 to 1, with higher values indicating better fit.",
      "tags": [
        "Statistics",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-r1-xcon",
      "term": "R1/XCON",
      "definition": "An expert system developed by John McDermott at Carnegie Mellon in 1980 for configuring VAX computer orders at Digital Equipment Corporation, becoming one of the first commercially successful AI systems and saving millions annually.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-race-to-the-bottom-ai-safety",
      "term": "Race to the Bottom in AI Safety",
      "definition": "The concern that competitive pressures among AI developers lead to progressively lower safety standards, as organizations cut corners on alignment research and testing to deploy capabilities faster than rivals.",
      "tags": [
        "AI Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-radam",
      "term": "RAdam",
      "definition": "Rectified Adam addresses the large variance in early training steps of the Adam optimizer by introducing a variance rectification term. Automatically adapts between SGD and Adam behavior providing more stable training without learning rate warmup.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-rademacher-complexity",
      "term": "Rademacher Complexity",
      "definition": "A measure of the richness of a hypothesis class that quantifies how well functions in the class can fit random noise. It provides tighter generalization bounds than VC dimension for many practical settings.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-radial-basis-function-kernel",
      "term": "Radial Basis Function Kernel",
      "definition": "A popular kernel function that measures similarity as an exponentially decaying function of the squared Euclidean distance between points. Its bandwidth parameter gamma controls the reach of each training example's influence.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-raft-optical-flow",
      "term": "RAFT",
      "definition": "Recurrent All-Pairs Field Transforms, a deep learning architecture for optical flow estimation that uses 4D correlation volumes and recurrent GRU-based updates to iteratively refine flow predictions.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-rag",
      "term": "RAG (Retrieval-Augmented Generation)",
      "definition": "A technique that combines AI generation with information retrieval from external sources. The model retrieves relevant documents and uses them to generate accurate, grounded responses.",
      "tags": [
        "Architecture",
        "Accuracy"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ragas",
      "term": "RAGAS",
      "definition": "Retrieval Augmented Generation Assessment, an evaluation framework that provides reference-free metrics for RAG pipelines including faithfulness, answer relevancy, and context precision, enabling automated quality assessment without ground-truth answers.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-rainbow-dqn",
      "term": "Rainbow DQN",
      "definition": "An integrated DQN agent that combines six extensions: double Q-learning, prioritized replay, dueling architecture, multi-step returns, distributional RL, and noisy networks. Rainbow demonstrated that these improvements are largely complementary.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-raj-reddy",
      "term": "Raj Reddy",
      "definition": "Indian-American computer scientist who received the Turing Award in 1994 for pioneering work in speech recognition and AI. Co-founded the Robotics Institute at Carnegie Mellon and advanced large-vocabulary continuous speech recognition systems.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-randaugment",
      "term": "RandAugment",
      "definition": "A simplified automated augmentation strategy that randomly applies a fixed number of augmentation operations from a predefined set with a shared magnitude, requiring only two hyperparameters.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-random-erasing",
      "term": "Random Erasing",
      "definition": "A data augmentation technique that randomly selects rectangular regions in training images and replaces their pixels with random values or mean values, acting as a regularizer similar to dropout.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-random-forest",
      "term": "Random Forest",
      "definition": "An ensemble of decision trees that vote on predictions. Robust, interpretable, and works well on tabular data. Still widely used despite the deep learning era.",
      "tags": [
        "Algorithm",
        "ML"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-random-forest-history",
      "term": "Random Forest History",
      "definition": "The development of random forest ensemble methods by Leo Breiman in 2001 combining bagging with random feature selection. Random forests proved remarkably effective across diverse prediction tasks and became one of the most widely used machine learning algorithms.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-random-projection",
      "term": "Random Projection",
      "definition": "A dimensionality reduction technique based on the Johnson-Lindenstrauss lemma that projects high-dimensional vectors onto a lower-dimensional space using random matrices while approximately preserving pairwise distances, used to accelerate vector search.",
      "tags": [
        "Vector Database",
        "Dimensionality Reduction"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-random-search",
      "term": "Random Search",
      "definition": "A hyperparameter tuning strategy that samples parameter combinations randomly from specified distributions, often finding good configurations more efficiently than grid search when only a few hyperparameters matter.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-random-search-for-hyperparameters",
      "term": "Random Search for Hyperparameters",
      "definition": "A hyperparameter optimization method that samples configurations randomly from specified distributions. Shown by Bergstra and Bengio in 2012 to be more efficient than grid search because it explores more values of important parameters.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-random-walk",
      "term": "Random Walk",
      "definition": "A stochastic process consisting of successive random steps on a graph or in a space. Used in graph algorithms like DeepWalk and Node2Vec for learning node embeddings and in PageRank for measuring node importance.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-rate-limit",
      "term": "Rate Limit",
      "definition": "Restrictions on API usage, typically measured in requests per minute or tokens per minute. Prevents abuse and ensures fair resource distribution among users.",
      "tags": [
        "API",
        "Technical"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-ray-kurzweil",
      "term": "Ray Kurzweil",
      "definition": "American inventor, author, and futurist who popularized the concept of the technological singularity, predicted accelerating returns in technology, and joined Google in 2012 to work on natural language understanding.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-rdma",
      "term": "RDMA",
      "definition": "Remote Direct Memory Access, a networking technology that enables direct data transfer between GPU memory on different nodes without CPU involvement. RDMA via InfiniBand or RoCE is essential for high-performance distributed AI training with minimal communication overhead.",
      "tags": [
        "Distributed Computing",
        "Hardware"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-re-identification",
      "term": "Re-Identification",
      "definition": "The task of matching the same person or vehicle across different camera views or time periods by learning discriminative appearance embeddings that are robust to viewpoint and lighting changes.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-re-ranking",
      "term": "Re-Ranking",
      "definition": "A second-stage retrieval process that applies a more computationally expensive model to re-score and reorder an initial set of retrieved candidates, improving precision by applying deeper cross-attention between query and document representations.",
      "tags": [
        "Retrieval",
        "Ranking"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-react",
      "term": "ReAct (Reasoning + Acting)",
      "definition": "A prompting framework combining Reasoning and Acting. AI thinks through problems step-by-step, showing its reasoning process transparently while taking actions.",
      "tags": [
        "Framework",
        "Reasoning"
      ],
      "domain": "general",
      "link": "../learn/react.html",
      "related": []
    },
    {
      "id": "term-react-pattern",
      "term": "ReAct Pattern",
      "definition": "A prompting paradigm that interleaves reasoning traces and action steps, allowing a language model to dynamically plan, execute tool calls, observe results, and refine its approach iteratively.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-reasoning",
      "term": "Reasoning (AI)",
      "definition": "AI's ability to draw logical conclusions, follow multi-step chains, and solve complex problems. A key capability that distinguishes modern LLMs from simpler systems.",
      "tags": [
        "Capability",
        "Prompting"
      ],
      "domain": "general",
      "link": "../learn/react.html",
      "related": []
    },
    {
      "id": "term-recall",
      "term": "Recall",
      "definition": "A metric measuring the proportion of actual positives correctly identified. Important in search and information retrieval where missing relevant results is costly.",
      "tags": [
        "Metrics",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-recall-at-k",
      "term": "Recall at K",
      "definition": "A retrieval metric that measures the proportion of all relevant documents in the corpus that appear within the top K retrieved results, indicating how comprehensively the system captures relevant information at a given cutoff.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-recall-at-k-retrieval",
      "term": "Recall at K for Retrieval",
      "definition": "A retrieval-specific metric measuring the proportion of all relevant documents that appear within the top K results returned by a vector search or hybrid search system, critical for assessing RAG pipeline retrieval completeness.",
      "tags": [
        "Retrieval",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-receiver-operating-characteristic",
      "term": "Receiver Operating Characteristic",
      "definition": "A graphical analysis technique that plots classifier performance across all possible decision thresholds, showing the tradeoff between true positive rate and false positive rate at each threshold setting.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-receptive-field",
      "term": "Receptive Field",
      "definition": "The region of the original input image that influences a particular neuron's activation in a deeper layer, growing larger with each successive convolutional and pooling layer in the network.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-reciprocal-rank-fusion",
      "term": "Reciprocal Rank Fusion",
      "definition": "A rank aggregation method that combines result lists from multiple retrieval systems by assigning each document a score based on the reciprocal of its rank in each list, providing a simple yet effective way to fuse hybrid search results.",
      "tags": [
        "Retrieval",
        "Ranking"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reconstruction-loss",
      "term": "Reconstruction Loss",
      "definition": "A loss function that measures how well a model can reconstruct its input from a compressed or encoded representation. Used in autoencoders and variational autoencoders. Can be implemented as MSE for continuous data or cross-entropy for discrete data.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-rectified-flow",
      "term": "Rectified Flow",
      "definition": "A generative modeling approach that learns straight-line paths between noise and data distributions, enabling faster sampling than curved diffusion trajectories while maintaining sample quality.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-recurrent-policy",
      "term": "Recurrent Policy",
      "definition": "An RL policy that uses recurrent neural network components (LSTM, GRU) to maintain internal memory across time steps. Recurrent policies enable agents to handle partial observability by aggregating information over observation histories.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-recursive-character-splitting",
      "term": "Recursive Character Splitting",
      "definition": "A document chunking strategy that attempts to split text using a hierarchy of separators from paragraph breaks down to individual characters, preferring natural boundaries while ensuring each chunk remains within the target size.",
      "tags": [
        "Retrieval",
        "Preprocessing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-recursive-feature-elimination",
      "term": "Recursive Feature Elimination",
      "definition": "A feature selection method that repeatedly trains a model, ranks features by importance, and removes the least important features, iterating until the desired number of features remains.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-recursive-prompting",
      "term": "Recursive Prompting",
      "definition": "A prompting pattern where the output of one prompt call is used to construct the next prompt in a recursive loop, enabling the model to handle arbitrarily complex tasks by repeatedly refining or extending its work until a termination condition is met.",
      "tags": [
        "Prompt Engineering",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-red-team",
      "term": "Red Team",
      "definition": "A group that tests AI systems by attempting to find vulnerabilities, bypass safety measures, or elicit harmful outputs. Essential for identifying and fixing safety issues before deployment.",
      "tags": [
        "Safety",
        "Testing"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-red-teaming-in-ai",
      "term": "Red Teaming in AI",
      "definition": "The practice of systematically testing AI systems by attempting to elicit harmful undesired or unsafe outputs. Red teaming has become a standard practice in AI safety with organizations like Anthropic and OpenAI conducting extensive red team evaluations before model releases.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-redpajama",
      "term": "RedPajama",
      "definition": "An open-source effort to reproduce the LLaMA training dataset and model. Provides a fully open training pipeline including the 1.2 trillion token dataset and model checkpoints at various sizes.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-reduce-on-plateau",
      "term": "Reduce on Plateau",
      "definition": "A learning rate scheduling strategy that reduces the learning rate by a factor when a monitored metric stops improving for a specified number of epochs. Commonly used as a simple adaptive schedule in practice.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-reduce-scatter",
      "term": "Reduce-Scatter Operation",
      "definition": "A collective communication pattern that reduces data across all participants and distributes different chunks of the result to each participant. Reduce-scatter is used in ZeRO and FSDP for gradient aggregation and sharding.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-reflexion-pattern",
      "term": "Reflexion Pattern",
      "definition": "An agent architecture where the LLM reflects on previous failed attempts by storing verbal feedback in an episodic memory, using these reflections to improve performance on subsequent tries.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-reformer",
      "term": "Reformer",
      "definition": "A transformer variant that uses locality-sensitive hashing to reduce attention complexity from O(n^2) to O(n log n) and reversible residual layers to reduce memory usage. Designed for processing very long sequences efficiently.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-refusal",
      "term": "Refusal",
      "definition": "When AI declines to answer a request due to safety guidelines. Well-calibrated refusals protect against harm while overly cautious refusals reduce helpfulness.",
      "tags": [
        "Safety",
        "Behavior"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-region-proposal-network",
      "term": "Region Proposal Network",
      "definition": "A fully convolutional network that slides over feature maps to generate object proposals (candidate bounding boxes) with objectness scores, serving as the first stage of two-stage detectors like Faster R-CNN.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-regnet",
      "term": "RegNet",
      "definition": "A family of network architectures derived from a structured design space that constrains network parameters to follow simple linear rules. Provides a systematic way to design efficient networks across different compute budgets.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-regression",
      "term": "Regression",
      "definition": "A machine learning task that predicts continuous values (like prices or temperatures) rather than categories. Common algorithms include linear regression and neural network regressors.",
      "tags": [
        "ML Task",
        "Prediction"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-regret",
      "term": "Regret",
      "definition": "In online learning and bandit problems, the cumulative difference between the reward obtained by an algorithm and the reward that would have been obtained by always choosing the optimal action in hindsight.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-regret-bound",
      "term": "Regret Bound",
      "definition": "A theoretical guarantee on the cumulative difference between the reward obtained by an RL algorithm and the reward of the optimal policy over T steps. Regret bounds characterize the efficiency of exploration algorithms.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-regularization",
      "term": "Regularization",
      "definition": "Techniques to prevent overfitting by adding constraints during training. Includes dropout, weight decay, and early stopping. Improves generalization to new data.",
      "tags": [
        "Training",
        "Technique"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reinforce-algorithm",
      "term": "REINFORCE Algorithm",
      "definition": "A foundational Monte Carlo policy gradient algorithm that updates policy parameters proportionally to the return multiplied by the gradient of log-probability of the action taken. It is simple but suffers from high variance.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-reinforcement-learning",
      "term": "Reinforcement Learning (RL)",
      "definition": "A learning paradigm where agents learn by receiving rewards or penalties for actions. Used in RLHF to align LLMs with human preferences.",
      "tags": [
        "Learning Type",
        "Training"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reinforcement-learning-history",
      "term": "Reinforcement Learning History",
      "definition": "The development of reinforcement learning from early work by Arthur Samuel on checkers in 1959 through temporal difference learning by Sutton in 1988 to deep RL breakthroughs with DQN and AlphaGo.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-rejection-sampling",
      "term": "Rejection Sampling",
      "definition": "A basic Monte Carlo method for generating samples from a target distribution by sampling from a proposal distribution and accepting or rejecting samples based on a comparison with the target density scaled by a bound.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-rejection-sampling-for-alignment",
      "term": "Rejection Sampling for Alignment",
      "definition": "A training data curation technique that generates multiple responses per prompt and keeps only those above a reward threshold for fine-tuning. Creates high-quality training data from the model's own best outputs.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-relabeling",
      "term": "Relabeling",
      "definition": "A data augmentation technique in RL that modifies components of stored transitions (such as goals, rewards, or actions) to generate additional training signal from existing data. Relabeling is central to HER and goal-conditioned RL.",
      "tags": [
        "Reinforcement Learning",
        "Training Paradigms"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-relation-extraction",
      "term": "Relation Extraction",
      "definition": "The task of identifying and classifying semantic relationships between entities mentioned in text, such as extracting that a person works for a specific organization.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-relative-position-encoding",
      "term": "Relative Position Encoding",
      "definition": "A position encoding scheme that represents the distance between tokens rather than their absolute positions. Allows the model to generalize to different sequence lengths. Variants include Shaw et al. and the T5 relative position bias.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-relative-positional-encoding",
      "term": "Relative Positional Encoding",
      "definition": "A positional encoding scheme that encodes the relative distance between tokens rather than absolute positions, enabling better generalization to sequence lengths not seen during training.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-relevance-score",
      "term": "Relevance Score",
      "definition": "A metric that measures how well a generated response addresses the input query or matches the intended topic, evaluating content appropriateness and topical alignment between the question and answer.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-relu",
      "term": "ReLU (Rectified Linear Unit)",
      "definition": "A simple activation function that outputs zero for negative inputs and the input itself for positives. Widely used due to efficiency and effectiveness despite simplicity.",
      "tags": [
        "Architecture",
        "Function"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-reparameterization-trick",
      "term": "Reparameterization Trick",
      "definition": "A technique that enables gradient-based optimization through stochastic sampling by expressing random variables as deterministic functions of parameters and independent noise. Essential for training variational autoencoders with backpropagation.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-repetition-penalty",
      "term": "Repetition Penalty",
      "definition": "A decoding parameter that reduces the probability of tokens that have already appeared in the generated text, preventing the model from producing repetitive phrases or loops.",
      "tags": [
        "Generative AI",
        "Decoding"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-repetition-rate",
      "term": "Repetition Rate",
      "definition": "A metric that quantifies the frequency of repeated phrases, sentences, or patterns within generated text, used to detect and penalize degenerate model behavior such as looping or excessive redundancy.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-rephrase-and-respond",
      "term": "Rephrase and Respond",
      "definition": "A prompting method that asks the model to first rephrase the input question in its own words before answering it, improving comprehension and reducing misinterpretation by ensuring the model accurately understands the query intent.",
      "tags": [
        "Prompt Engineering",
        "Clarification"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-replay-buffer",
      "term": "Replay Buffer",
      "definition": "A data structure (typically a fixed-size circular buffer) that stores past experience tuples for sampling during off-policy training. Replay buffers break temporal correlations and enable multiple learning updates from each experience.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-replication-vector-databases",
      "term": "Replication in Vector Databases",
      "definition": "The maintenance of multiple copies of a vector index across different nodes to provide fault tolerance and increased read throughput, ensuring that vector search remains available even when individual nodes fail.",
      "tags": [
        "Vector Database",
        "Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-representation-engineering",
      "term": "Representation Engineering",
      "definition": "A technique for understanding and controlling LLM behavior by identifying and manipulating specific directions in the model's activation space that correspond to concepts like honesty, safety, or sentiment.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-representation-learning",
      "term": "Representation Learning",
      "definition": "Learning useful features automatically from data rather than engineering them manually. A key strength of deep learning that enables transfer learning.",
      "tags": [
        "Concept",
        "Deep Learning"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-representation-learning-rl",
      "term": "Representation Learning in RL",
      "definition": "Methods for learning compact, informative state representations from high-dimensional observations (like images) to improve RL efficiency. Techniques include contrastive learning, reconstruction-based methods, and bisimulation metrics.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-representational-harm",
      "term": "Representational Harm",
      "definition": "Harm that occurs when an AI system reinforces stereotypes, demeans, or erases particular social groups through its outputs, even if no direct resource allocation decision is affected.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-request-scheduling",
      "term": "Request Scheduling",
      "definition": "The algorithm that determines the order and priority of processing incoming inference requests on limited GPU resources. Scheduling strategies optimize for fairness, latency SLAs, throughput, or cost across heterogeneous request workloads.",
      "tags": [
        "Inference Infrastructure",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-reranking",
      "term": "Reranking",
      "definition": "A two-stage retrieval approach where an initial fast retriever fetches candidate documents, and a more powerful cross-encoder model rescores and reorders them for relevance before passing them to the LLM.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-residual-analysis",
      "term": "Residual Analysis",
      "definition": "The examination of residuals (differences between observed and predicted values) to assess model fit, check assumptions such as normality and homoscedasticity, and identify influential observations or patterns.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-residual-connection",
      "term": "Residual Connection",
      "definition": "An additive skip connection where the input to a layer block is added element-wise to the block's output, allowing the network to learn residual mappings rather than direct mappings.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-residual-learning",
      "term": "Residual Learning",
      "definition": "The principle of learning additive residual functions with reference to the layer inputs rather than learning unreferenced functions, making it easier to optimize very deep networks.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-resnet",
      "term": "ResNet",
      "definition": "Residual Network, a deep convolutional neural network architecture that introduces skip connections to enable training of very deep networks by mitigating the vanishing gradient problem.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-resnet-101",
      "term": "ResNet-101",
      "definition": "A 101-layer variant of the Residual Network achieving higher accuracy than ResNet-50 at the cost of additional computation. Commonly used as a backbone in object detection and segmentation models.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-resnet-152",
      "term": "ResNet-152",
      "definition": "The deepest standard variant of the Residual Network with 152 layers. Demonstrates that deeper networks with skip connections continue to improve accuracy. Used in high-accuracy applications where computational cost is less constrained.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-resnet-50",
      "term": "ResNet-50",
      "definition": "A 50-layer variant of the Residual Network architecture widely used as a baseline for image classification and feature extraction. Contains bottleneck blocks with 1x1 3x3 and 1x1 convolutions. Approximately 25.6 million parameters.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-resnext",
      "term": "ResNeXt",
      "definition": "An extension of ResNet that introduces cardinality as an additional dimension through grouped convolutions. Proposed by Xie et al. in 2017. Achieves better accuracy than ResNet with similar computational complexity by using split-transform-merge blocks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-resolution-theorem-proving",
      "term": "Resolution Theorem Proving",
      "definition": "An inference rule that produces a new clause implied by two clauses containing complementary literals. Introduced by John Alan Robinson in 1965 resolution became the foundation for automated theorem proving and logic programming including Prolog.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-responsible-ai",
      "term": "Responsible AI",
      "definition": "An approach to developing and deploying AI systems that emphasizes ethical considerations, fairness, transparency, accountability, and societal benefit throughout the entire AI lifecycle.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-responsible-disclosure-for-ai",
      "term": "Responsible Disclosure for AI",
      "definition": "The practice of privately reporting discovered vulnerabilities or dangerous capabilities in AI systems to the developer before public disclosure, allowing time for mitigation while ensuring transparency.",
      "tags": [
        "AI Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-restricted-boltzmann-machine",
      "term": "Restricted Boltzmann Machine",
      "definition": "A generative stochastic neural network with a bipartite structure of visible and hidden units with no intra-layer connections, trained using contrastive divergence to learn probability distributions over inputs.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-rete-algorithm",
      "term": "Rete Algorithm",
      "definition": "An efficient pattern matching algorithm developed by Charles Forgy in 1979 for production rule systems. The Rete algorithm dramatically improved the performance of rule-based expert systems by avoiding redundant pattern matching across rules.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-retinanet",
      "term": "RetinaNet",
      "definition": "A single-stage object detection model that combines a Feature Pyramid Network backbone with focal loss, achieving accuracy comparable to two-stage detectors while maintaining the speed advantage of single-stage methods.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-retnet",
      "term": "RetNet",
      "definition": "Retentive Network, an architecture that supports parallel training, recurrent inference, and chunk-wise recurrent computation through a retention mechanism that replaces standard attention.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-retrieval",
      "term": "Retrieval",
      "definition": "Finding relevant information from a database or corpus. In RAG, retrieval brings external knowledge into the generation process for more accurate responses.",
      "tags": [
        "Process",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-retrieval-evaluation",
      "term": "Retrieval Evaluation",
      "definition": "The systematic assessment of retrieval system quality using metrics such as recall, precision, NDCG, and MRR applied to ranked result lists, often conducted against labeled relevance judgments or ground-truth answer sets.",
      "tags": [
        "Retrieval",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-retrieval-head",
      "term": "Retrieval Head",
      "definition": "Specific attention heads within a transformer that specialize in copying or retrieving information from the context, playing a crucial role in in-context learning and factual recall.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-retrieval-augmented-fine-tuning",
      "term": "Retrieval-Augmented Fine-Tuning",
      "definition": "A training approach that fine-tunes a language model with retrieval-augmented examples, teaching the model to effectively incorporate retrieved context into its responses.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-retrieval-augmented-generation",
      "term": "Retrieval-Augmented Generation",
      "definition": "A technique that enhances language model outputs by retrieving relevant documents from an external knowledge base and conditioning generation on the retrieved context. Reduces hallucination and enables knowledge updates without retraining.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": "learn/rag.html",
      "related": []
    },
    {
      "id": "term-retrieval-augmented-generation-history",
      "term": "Retrieval-Augmented Generation History",
      "definition": "The development of RAG from the original paper by Lewis et al. at Facebook AI in 2020 to widespread adoption in enterprise AI. RAG combines retrieval from external knowledge bases with language model generation reducing hallucinations and enabling knowledge updates.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-retrieval-augmented-lm",
      "term": "Retrieval-Augmented Language Model",
      "definition": "A language model architecture that incorporates a retrieval component to fetch relevant documents from an external corpus during generation, grounding responses in retrieved evidence.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-retrieval-augmented-prompting",
      "term": "Retrieval-Augmented Prompting",
      "definition": "A technique that dynamically retrieves relevant documents, examples, or knowledge from an external corpus and incorporates them into the prompt context before generation, improving factual accuracy and domain coverage beyond what is stored in model parameters.",
      "tags": [
        "Prompt Engineering",
        "Retrieval"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-return",
      "term": "Return",
      "definition": "The cumulative discounted sum of future rewards from a given time step, representing the total long-term value an agent receives. The return is the primary quantity that RL algorithms aim to maximize.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reward",
      "term": "Reward",
      "definition": "A scalar signal received by an agent from the environment after taking an action, indicating how good or bad the outcome was. Rewards drive learning by defining the optimization objective.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reward-clipping",
      "term": "Reward Clipping",
      "definition": "A preprocessing technique that bounds reward values to a fixed range (commonly [-1, 1]) to stabilize training across diverse environments. Reward clipping was used in the original DQN but can discard useful reward magnitude information.",
      "tags": [
        "Reinforcement Learning",
        "Reward Design"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reward-decomposition",
      "term": "Reward Decomposition",
      "definition": "Techniques that break a complex reward signal into simpler components that are easier to learn from, enabling more interpretable and efficient training. Decomposed rewards can align with sub-objectives or different aspects of desired behavior.",
      "tags": [
        "Reinforcement Learning",
        "Reward Design"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reward-engineering",
      "term": "Reward Engineering",
      "definition": "The process of designing reward functions that accurately capture desired agent behavior, balancing specificity with generality. Poor reward engineering can lead to reward hacking where agents exploit loopholes in the reward specification.",
      "tags": [
        "Reinforcement Learning",
        "Reward Design"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reward-hacking",
      "term": "Reward Hacking",
      "definition": "A failure mode in reinforcement learning from human feedback where the policy model exploits weaknesses in the reward model to achieve high reward scores without genuinely improving output quality.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-reward-machine",
      "term": "Reward Machine",
      "definition": "A finite-state automaton that specifies reward functions based on high-level events or propositional symbols, enabling structured reward specification for complex tasks. Reward machines decompose non-Markovian rewards into manageable components.",
      "tags": [
        "Reinforcement Learning",
        "Reward Design"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reward-model",
      "term": "Reward Model",
      "definition": "A model trained to score AI outputs based on human preferences. Used in RLHF to guide language models toward more helpful and safe behaviors.",
      "tags": [
        "Training",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-reward-normalization",
      "term": "Reward Normalization",
      "definition": "The practice of scaling reward signals to have consistent magnitude across different environments or during training, typically using running statistics. Reward normalization stabilizes value function learning and improves hyperparameter transfer.",
      "tags": [
        "Reinforcement Learning",
        "Reward Design"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reward-shaping",
      "term": "Reward Shaping",
      "definition": "The practice of adding auxiliary reward signals to guide learning, making sparse reward problems more tractable. Potential-based reward shaping preserves the optimal policy while accelerating convergence.",
      "tags": [
        "Reinforcement Learning",
        "Reward Design"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reward-free-exploration",
      "term": "Reward-Free Exploration",
      "definition": "An RL paradigm where the agent first explores the environment without any reward signal to build a comprehensive understanding, then uses this knowledge to quickly solve downstream tasks. Reward-free exploration decouples exploration from task specification.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-reward-weighted-regression",
      "term": "Reward-Weighted Regression",
      "definition": "A policy search method that computes policy updates by performing weighted maximum likelihood estimation on sampled trajectories, with weights proportional to exponentiated returns. It avoids explicit gradient computation.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-rst",
      "term": "Rhetorical Structure Theory",
      "definition": "A theory of text organization that describes how clauses and larger text spans are connected through rhetorical relations like elaboration, contrast, and cause, forming a hierarchical discourse tree.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-richard-karp",
      "term": "Richard Karp",
      "definition": "American computer scientist who identified 21 NP-complete problems in his 1972 paper demonstrating the breadth of computationally intractable problems. His work showed that many optimization problems encountered in AI are fundamentally hard.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-richard-sutton",
      "term": "Richard Sutton",
      "definition": "Canadian computer scientist who co-authored the seminal textbook on reinforcement learning with Andrew Barto, developed temporal difference learning, and wrote the influential Bitter Lesson essay on AI research methodology.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ridge-regression",
      "term": "Ridge Regression",
      "definition": "A linear regression variant that adds an L2 penalty term to the ordinary least squares objective, shrinking coefficients toward zero to reduce overfitting, especially when predictors are correlated.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-right-to-explanation",
      "term": "Right to Explanation",
      "definition": "The legal or ethical principle that individuals subjected to automated decision-making are entitled to a meaningful explanation of the logic involved, as partially codified in the GDPR's Article 22.",
      "tags": [
        "Governance",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-ring-all-reduce",
      "term": "Ring All-Reduce",
      "definition": "An efficient implementation of all-reduce where GPUs are arranged in a ring topology and data is sent in chunks through two passes (scatter-reduce and all-gather). Ring all-reduce provides bandwidth-optimal communication scaling.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ring-attention",
      "term": "Ring Attention",
      "definition": "A distributed attention computation method that splits long sequences across devices in a ring topology, overlapping communication with computation to process sequences of near-unlimited length.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-risk-sensitive-rl",
      "term": "Risk-Sensitive RL",
      "definition": "RL methods that optimize risk-aware objectives such as conditional value-at-risk (CVaR) or variance-penalized returns rather than expected return alone. Risk-sensitive approaches are critical for safety-critical applications.",
      "tags": [
        "Reinforcement Learning",
        "Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-rlhf",
      "term": "RLHF (Reinforcement Learning from Human Feedback)",
      "definition": "A training technique that uses human preferences to guide model behavior. Human raters compare outputs, and these preferences train a reward model that shapes the LLM.",
      "tags": [
        "Training",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-rlhf-algorithm",
      "term": "RLHF Algorithm",
      "definition": "Reinforcement Learning from Human Feedback trains language models using human preference data. Involves supervised fine-tuning reward model training and policy optimization using PPO or similar algorithms. Core technique behind ChatGPT alignment.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Safety"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-rms-normalization",
      "term": "RMS Normalization",
      "definition": "Root Mean Square Layer Normalization, a simplified variant of layer normalization that only rescales by the root mean square of activations without recentering, reducing computational cost while maintaining performance.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-rmsnorm",
      "term": "RMSNorm",
      "definition": "Root Mean Square Layer Normalization, a simplified normalization technique that normalizes activations using only the RMS statistic without mean centering, reducing computation while maintaining model quality.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-rmsprop",
      "term": "RMSProp",
      "definition": "An adaptive learning rate optimization algorithm that divides the learning rate by a running average of the magnitudes of recent gradients for each parameter. It addresses the diminishing learning rate problem of AdaGrad.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-rnn",
      "term": "RNN (Recurrent Neural Network)",
      "definition": "A neural network architecture that processes sequences by maintaining hidden state across steps. Predecessors to transformers, still used in some sequence applications.",
      "tags": [
        "Architecture",
        "Historical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-robert-floyd",
      "term": "Robert Floyd",
      "definition": "American computer scientist who received the Turing Award in 1978 for contributions to programming languages including operator precedence parsing and the Floyd-Warshall shortest path algorithm. His work on program verification influenced formal methods in AI.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-robert-kowalski",
      "term": "Robert Kowalski",
      "definition": "British-American logician and computer scientist who developed the procedural interpretation of Horn clauses providing the theoretical foundation for logic programming and the Prolog language. His work established the equation Algorithm = Logic + Control.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-roberta",
      "term": "RoBERTa",
      "definition": "A robustly optimized BERT pretraining approach that improves upon BERT by training longer with more data, removing next sentence prediction, and using dynamic masking patterns.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-robot-rights",
      "term": "Robot Rights",
      "definition": "The concept that sufficiently advanced robots or AI systems might deserve legal protections or moral consideration analogous to those granted to humans or animals, a topic of active philosophical and legal debate.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-robotics-history",
      "term": "Robotics History",
      "definition": "The history of robotics from early automata and Unimate (1961) through mobile robots (Shakey 1966) to modern robotic systems including autonomous vehicles surgical robots and humanoid robots. Robotics has been closely intertwined with AI development.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-robust-regression",
      "term": "Robust Regression",
      "definition": "A class of regression methods designed to be resistant to outliers and violations of model assumptions. Techniques include M-estimation, least trimmed squares, and RANSAC.",
      "tags": [
        "Statistics",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-robust-rl",
      "term": "Robust RL",
      "definition": "RL algorithms designed to find policies that perform well under worst-case environment perturbations or model uncertainty. Robust RL optimizes against an adversarial set of possible environments or transition dynamics.",
      "tags": [
        "Reinforcement Learning",
        "Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-robust-scaler",
      "term": "Robust Scaler",
      "definition": "A feature scaling method that uses the median and interquartile range instead of the mean and standard deviation, making it more resistant to outliers than standard scaling.",
      "tags": [
        "Machine Learning",
        "Feature Engineering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-roc-curve",
      "term": "ROC Curve",
      "definition": "Receiver Operating Characteristic curve, a plot of the true positive rate against the false positive rate at various classification thresholds. It visualizes the tradeoff between sensitivity and specificity.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-rodney-brooks",
      "term": "Rodney Brooks",
      "definition": "Australian roboticist who directed the MIT AI Laboratory from 1997 to 2007. Pioneer of behavior-based robotics and the subsumption architecture. Co-founder of iRobot (Roomba) and Rethink Robotics. Challenged traditional AI with the principle of intelligence without representation.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-roger-schank",
      "term": "Roger Schank",
      "definition": "American AI researcher (1946-2023) who developed conceptual dependency theory and script theory for natural language understanding, advancing the role of knowledge structures in AI comprehension of stories and situations.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-roi-align",
      "term": "ROI Align",
      "definition": "An improved version of ROI Pooling that uses bilinear interpolation instead of quantized grid snapping, eliminating misalignment artifacts and producing more accurate feature extraction for instance segmentation.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-roi-pooling",
      "term": "ROI Pooling",
      "definition": "Region of Interest Pooling, an operation that extracts fixed-size feature representations from arbitrary-sized region proposals, enabling the classification head of object detectors to process variable-sized regions uniformly.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-role-assignment",
      "term": "Role Assignment",
      "definition": "The prompt technique of explicitly designating a specific role, profession, or character for the model to adopt, shaping its response style, vocabulary, expertise level, and perspective to match the assigned identity.",
      "tags": [
        "Prompt Engineering",
        "Persona"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-role-prompting",
      "term": "Role Prompting",
      "definition": "Assigning AI a specific persona, expertise, or perspective to shape its responses. For example, \"Act as a senior developer\" or \"You are a patient teacher.\"",
      "tags": [
        "Prompting",
        "Technique"
      ],
      "domain": "general",
      "link": "../learn/crisp.html",
      "related": []
    },
    {
      "id": "term-roofline-model",
      "term": "Roofline Model",
      "definition": "A performance analysis framework that plots achievable performance as a function of operational intensity (FLOPS per byte of memory traffic). The roofline model identifies whether a workload is compute-bound or memory-bound, guiding optimization strategy.",
      "tags": [
        "Hardware",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-root-mean-squared-error",
      "term": "Root Mean Squared Error",
      "definition": "The square root of the mean squared error, expressed in the same units as the target variable. It provides an interpretable measure of the typical magnitude of prediction errors.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-rope",
      "term": "RoPE (Rotary Position Embedding)",
      "definition": "A positional encoding technique that encodes position through rotation in complex space. Enables better length generalization than absolute position encodings.",
      "tags": [
        "Architecture",
        "Transformers"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ross-quillian",
      "term": "Ross Quillian",
      "definition": "American computer scientist who introduced semantic networks in his 1968 doctoral thesis as a model of human associative memory, establishing a foundational approach to knowledge representation in AI.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-rotary-position-embedding",
      "term": "Rotary Position Embedding",
      "definition": "A method that encodes position information by rotating query and key vectors in pairs of dimensions according to their position, naturally encoding relative positions through the inner product.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-rouge",
      "term": "ROUGE",
      "definition": "Recall-Oriented Understudy for Gisting Evaluation, a set of metrics for evaluating summarization quality by measuring n-gram overlap between generated summaries and reference summaries.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-rouge-score",
      "term": "ROUGE Score",
      "definition": "Recall-Oriented Understudy for Gisting Evaluation, a family of metrics that measures text summarization quality by computing n-gram overlap, longest common subsequences, or skip-bigram co-occurrence between generated and reference summaries.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-rouge-1",
      "term": "ROUGE-1",
      "definition": "A ROUGE variant that measures unigram (single word) overlap between a generated text and reference text, providing a basic assessment of content coverage at the individual word level.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-rouge-2",
      "term": "ROUGE-2",
      "definition": "A ROUGE variant that measures bigram (two consecutive word) overlap between generated and reference texts, capturing phrase-level similarity and providing a stronger indicator of fluency and content preservation than ROUGE-1.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-rouge-l",
      "term": "ROUGE-L",
      "definition": "A ROUGE variant based on the longest common subsequence (LCS) between generated and reference texts, capturing sentence-level structural similarity without requiring consecutive word matches, making it sensitive to word ordering.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-rt-2",
      "term": "RT-2",
      "definition": "Robotic Transformer 2 is a vision-language-action model that directly outputs robot actions from camera images and language instructions. Demonstrates that web-scale vision-language pretraining transfers to robotic control tasks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-rt-detr",
      "term": "RT-DETR",
      "definition": "Real-Time Detection Transformer, a hybrid detection architecture that combines a CNN backbone with a transformer decoder, achieving the accuracy of DETR-based models with real-time inference speed.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-rwkv",
      "term": "RWKV",
      "definition": "A linear attention-based architecture that combines the parallelizable training of transformers with the efficient inference of RNNs, using a novel time-mixing and channel-mixing approach.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    }
  ]
}