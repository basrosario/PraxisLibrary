{
  "letter": "b",
  "count": 222,
  "terms": [
    {
      "id": "term-b-tree-algorithm",
      "term": "B-Tree Algorithm",
      "definition": "A self-balancing tree data structure that maintains sorted data and allows searches and insertions and deletions in logarithmic time. Designed for storage systems that read and write large blocks of data.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-babilong",
      "term": "Babilong",
      "definition": "A benchmark for evaluating long-context reasoning by extending bAbI tasks to very long contexts. Tests whether models can reason over relevant information buried in long sequences.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-back-translation",
      "term": "Back-Translation",
      "definition": "A data augmentation technique for machine translation that translates monolingual target-language text back to the source language using a reverse model, creating synthetic parallel training data.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-backdoor-attack",
      "term": "Backdoor Attack",
      "definition": "A type of poisoning attack where an adversary introduces a hidden trigger into a model during training that causes targeted misclassification when the trigger is present in test inputs.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-background-removal",
      "term": "Background Removal",
      "definition": "The process of automatically separating foreground subjects from their background in images using deep learning segmentation and matting models, widely used in photography and e-commerce.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-backpropagation",
      "term": "Backpropagation",
      "definition": "The fundamental algorithm for training neural networks. It calculates how much each weight contributed to the error and adjusts weights accordingly, propagating the error signal backward through the network.",
      "tags": [
        "Training",
        "Neural Networks"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-backpropagation-discovery",
      "term": "Backpropagation Discovery",
      "definition": "The development of the backpropagation algorithm for training multi-layer neural networks. While the mathematical foundations existed earlier the 1986 paper by Rumelhart Hinton and Williams demonstrated its practical effectiveness and revived interest in neural networks.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-backpropagation-history",
      "term": "Backpropagation History",
      "definition": "The development of the backpropagation algorithm for training neural networks, independently discovered multiple times but popularized by Rumelhart, Hinton, and Williams in their influential 1986 Nature paper.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-backpropagation-through-time",
      "term": "Backpropagation Through Time",
      "definition": "An extension of backpropagation for training recurrent neural networks that unrolls the network through time steps and applies the chain rule. Computational cost is proportional to sequence length. Can suffer from vanishing or exploding gradients for long sequences.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-backside-power-delivery",
      "term": "Backside Power Delivery",
      "definition": "Chip design innovation routing power connections through the back of the silicon die rather than the front. Frees up routing resources on the front for signal interconnects improving density.",
      "tags": [
        "Architecture",
        "Design",
        "Innovation"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-backward-euler-method",
      "term": "Backward Euler Method",
      "definition": "An implicit numerical method for solving ordinary differential equations that evaluates the derivative at the next time step. Unconditionally stable for stiff problems but requires solving a nonlinear equation at each step.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bactrian-x",
      "term": "Bactrian-X",
      "definition": "A multilingual instruction-following dataset covering 52 languages created by translating Alpaca instructions. Tests whether translated instructions produce effective multilingual models.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bag-of-visual-words",
      "term": "Bag of Visual Words",
      "definition": "A computer vision technique that represents images as histograms of local feature descriptors quantized to a visual vocabulary. Learned by clustering feature descriptors and used for image classification and retrieval.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bag-of-words",
      "term": "Bag of Words",
      "definition": "A simple text representation that counts word occurrences, ignoring order and grammar. Despite its simplicity, still useful for some classification tasks and as a baseline.",
      "tags": [
        "NLP",
        "Representation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-bagging",
      "term": "Bagging (Bootstrap Aggregating)",
      "definition": "Training multiple models on random subsets of data and averaging their predictions. Reduces variance and overfitting. The basis for Random Forest algorithms.",
      "tags": [
        "Technique",
        "Ensemble"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-baichuan",
      "term": "Baichuan",
      "definition": "A series of Chinese bilingual LLMs known for strong performance in Chinese language tasks. Part of the growing ecosystem of non-Western foundation models.",
      "tags": [
        "Model",
        "Chinese AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-baichuan2",
      "term": "Baichuan2",
      "definition": "A second-generation large language model from Baichuan Inc. with improved training methodology and strong Chinese and English bilingual performance.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bairstows-method",
      "term": "Bairstow's Method",
      "definition": "An iterative root-finding algorithm that simultaneously extracts quadratic factors from a polynomial with real coefficients. Avoids complex arithmetic by finding pairs of real or complex conjugate roots together.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-balanced-iterative-reducing-and-clustering",
      "term": "Balanced Iterative Reducing and Clustering",
      "definition": "An incremental hierarchical clustering algorithm designed for very large datasets that summarizes data using a compact tree structure. Processes data in a single pass through memory making it scalable to millions of records.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-ball-tree-algorithm",
      "term": "Ball Tree Algorithm",
      "definition": "A spatial data structure that partitions points into nested hyperspheres for efficient nearest-neighbor searches. Outperforms k-d trees in high dimensions because it does not suffer from the curse of dimensionality as severely.",
      "tags": [
        "Algorithms",
        "Technical",
        "Searching",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bamboogle",
      "term": "Bamboogle",
      "definition": "A dataset of multi-hop questions specifically designed to be answerable by combining multiple Google searches. Tests the ability to integrate information from multiple sources.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bandit-algorithm",
      "term": "Bandit Algorithm",
      "definition": "An algorithm for the multi-armed bandit problem that balances exploration (trying new actions) with exploitation (choosing the best-known action) to maximize cumulative reward over time.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bandwidth",
      "term": "Bandwidth (AI Context)",
      "definition": "The rate at which data can be transferred, crucial for AI infrastructure. Memory bandwidth often limits GPU performance; network bandwidth affects distributed training.",
      "tags": [
        "Infrastructure",
        "Performance"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-bandwidth-selection",
      "term": "Bandwidth Selection",
      "definition": "The process of choosing the bandwidth parameter in kernel density estimation, which controls the smoothness of the estimated density. Methods include cross-validation, Silverman's rule of thumb, and plug-in estimators.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-barbara-liskov",
      "term": "Barbara Liskov",
      "definition": "American computer scientist who received the 2008 Turing Award for contributions to programming language design including data abstraction and the Liskov substitution principle. Her work on CLU and Argus influenced software engineering practices used in AI systems.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bard",
      "term": "Bard",
      "definition": "Google's conversational AI product, later renamed to Gemini. Competed with ChatGPT using Google's LLM technology and integration with Google services.",
      "tags": [
        "Product",
        "Historical"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bark",
      "term": "Bark",
      "definition": "An open-source text-to-audio model by Suno AI that generates realistic speech in multiple languages including nonverbal sounds like laughter and music. Uses a GPT-style architecture for audio token generation.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bark-scale-algorithm",
      "term": "Bark Scale Algorithm",
      "definition": "A psychoacoustic scale that maps frequencies to critical bands of human hearing. Used in audio processing to model the frequency resolution of the human auditory system and weight spectral features.",
      "tags": [
        "Algorithms",
        "Technical",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-barnes-hut-algorithm",
      "term": "Barnes-Hut Algorithm",
      "definition": "An approximation algorithm for N-body simulations that uses a tree structure to group distant particles. Reduces computational complexity from O(N^2) to O(N log N) by treating clusters of particles as single entities.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-barrier-method",
      "term": "Barrier Method",
      "definition": "An interior point approach that adds a logarithmic barrier function to the objective to enforce inequality constraints. The barrier parameter is decreased over iterations allowing solutions to approach the constraint boundary.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bart",
      "term": "BART",
      "definition": "Bidirectional and Auto-Regressive Transformers combines a bidirectional encoder with an autoregressive decoder. Pretrained by corrupting text with arbitrary noise and learning to reconstruct the original. Effective for generation summarization and translation.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-base-model",
      "term": "Base Model",
      "definition": "A pre-trained model before fine-tuning for specific tasks. Base models are good at text completion but need instruction tuning to become helpful assistants.",
      "tags": [
        "Model Type",
        "Training"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-baseboard-management-controller",
      "term": "Baseboard Management Controller",
      "definition": "Embedded processor on server motherboards providing remote monitoring and management capabilities. Enables administrators to manage AI servers remotely including power cycling and health monitoring.",
      "tags": [
        "Infrastructure",
        "Management",
        "Server"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-based",
      "term": "Based",
      "definition": "A linear attention model architecture that combines short sliding window attention with linear attention for efficient sequence modeling.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-baseline",
      "term": "Baseline",
      "definition": "A simple model or approach used as a reference point for comparison. New methods should outperform baselines to demonstrate value. Common baselines include random guessing or simple rules.",
      "tags": [
        "Evaluation",
        "Research"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bat-algorithm",
      "term": "Bat Algorithm",
      "definition": "A swarm intelligence algorithm inspired by the echolocation behavior of bats. Varies the frequency and loudness and pulse emission rate of virtual bats to balance exploration and exploitation during optimization.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-batch",
      "term": "Batch",
      "definition": "A subset of training data processed together in one iteration. Batch processing improves training efficiency and stability compared to processing one example at a time.",
      "tags": [
        "Training",
        "Technical"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-batch-indexing",
      "term": "Batch Indexing",
      "definition": "The process of building or rebuilding a vector index from a complete dataset in a single operation, producing an optimally structured index that typically offers better search performance than incrementally built alternatives.",
      "tags": [
        "Vector Database",
        "Maintenance"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-batch-normalization",
      "term": "Batch Normalization",
      "definition": "A technique that normalizes the inputs to each layer by subtracting the batch mean and dividing by the batch standard deviation, then applying learned scale and shift parameters. It stabilizes and accelerates training.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-batch-processing-in-ai",
      "term": "Batch Processing in AI",
      "definition": "The practice of processing data in groups rather than individually during neural network training. Stochastic gradient descent with mini-batches became standard practice balancing computational efficiency with gradient estimate quality. The batch size is a key training hyperparameter.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-batch-rl",
      "term": "Batch Reinforcement Learning",
      "definition": "An approach to RL where the agent learns from a fixed batch of pre-collected transitions without online interaction. Batch RL methods like fitted Q-iteration address the challenges of learning from static datasets.",
      "tags": [
        "Reinforcement Learning",
        "Training Paradigms"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-batch-renormalization",
      "term": "Batch Renormalization",
      "definition": "An extension of batch normalization that introduces correction terms to reduce dependence on mini-batch statistics. Proposed by Ioffe in 2017 to address batch normalization failures with small batch sizes or non-i.i.d. mini-batches.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-batch-scheduling",
      "term": "Batch Scheduling for Inference",
      "definition": "The strategy of grouping multiple inference requests together for simultaneous processing on a GPU, improving hardware utilization and throughput. Batch scheduling involves tradeoffs between latency (waiting to fill batches) and throughput (processing more requests per second).",
      "tags": [
        "Inference Infrastructure",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-batch-size",
      "term": "Batch Size",
      "definition": "The number of training examples processed together before updating model weights. Larger batches provide more stable gradients but require more memory; smaller batches train faster but with more noise.",
      "tags": [
        "Hyperparameter",
        "Training"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-batched-inference",
      "term": "Batched Inference",
      "definition": "The practice of processing multiple inference requests simultaneously through a model to maximize GPU utilization and throughput, amortizing the cost of loading model weights across many inputs.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bayes-error-rate",
      "term": "Bayes Error Rate",
      "definition": "The lowest achievable error rate for any classifier on a given classification problem, determined by the irreducible noise in the data. It represents the theoretical performance limit set by the overlap between class distributions.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bayes-theorem",
      "term": "Bayes' Theorem",
      "definition": "A fundamental rule of probability that relates the conditional probability of a hypothesis given evidence to the prior probability of the hypothesis, the likelihood of the evidence, and the marginal probability of the evidence.",
      "tags": [
        "Statistics",
        "Bayesian Methods"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bayesian-inference",
      "term": "Bayesian Inference",
      "definition": "A statistical framework that updates probability estimates for hypotheses as additional evidence is acquired, using Bayes' theorem to compute posterior distributions from prior distributions and observed data.",
      "tags": [
        "Statistics",
        "Bayesian Methods"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bayesian-information-criterion",
      "term": "Bayesian Information Criterion",
      "definition": "A model selection criterion similar to AIC but with a larger penalty for the number of parameters that depends on sample size. It tends to favor simpler models than AIC, especially with large datasets.",
      "tags": [
        "Statistics",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bayesian",
      "term": "Bayesian Methods",
      "definition": "Statistical approaches that incorporate prior knowledge and update beliefs based on evidence. Used for uncertainty quantification, hyperparameter optimization, and probabilistic modeling.",
      "tags": [
        "Statistics",
        "Theory"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bayesian-model-averaging",
      "term": "Bayesian Model Averaging",
      "definition": "A technique that accounts for model uncertainty by averaging predictions across multiple models weighted by their posterior probabilities, rather than selecting a single best model.",
      "tags": [
        "Statistics",
        "Bayesian Methods"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bayesian-network",
      "term": "Bayesian Network",
      "definition": "A directed acyclic graph that represents a set of random variables and their conditional dependencies. Each node has a conditional probability table specifying the probability of the node given its parents.",
      "tags": [
        "Machine Learning",
        "Bayesian Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-bayesian-network-history",
      "term": "Bayesian Network History",
      "definition": "The development of Bayesian networks by Judea Pearl and others in the 1980s, providing a graphical framework for representing and reasoning under uncertainty that became central to AI and machine learning.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bayesian-networks",
      "term": "Bayesian Networks",
      "definition": "Probabilistic graphical models that represent a set of variables and their conditional dependencies via directed acyclic graphs. Pioneered by Judea Pearl in the 1980s Bayesian networks enable reasoning under uncertainty and have applications in diagnosis prediction and decision making.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bayesian-optimization",
      "term": "Bayesian Optimization",
      "definition": "A sequential strategy for optimizing expensive black-box functions that builds a probabilistic surrogate model (typically a Gaussian process) and uses an acquisition function to determine the most promising points to evaluate next.",
      "tags": [
        "Machine Learning",
        "Bayesian Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-bbq",
      "term": "BBQ",
      "definition": "Bias Benchmark for QA a dataset of 58000 question-answer pairs testing social biases in language models across 11 categories. Evaluates whether models exhibit biased behavior in ambiguous contexts.",
      "tags": [
        "Benchmark",
        "NLP",
        "Fairness"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bdd100k",
      "term": "BDD100K",
      "definition": "The Berkeley Deep Drive dataset containing 100000 driving videos with diverse annotations including image-level tagging object detection lane marking and semantic segmentation.",
      "tags": [
        "Benchmark",
        "Autonomous Driving"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-beam-search",
      "term": "Beam Search",
      "definition": "A search algorithm used in text generation that maintains multiple candidate sequences at each step, selecting the most promising ones. Balances quality and computational cost compared to exhaustive search.",
      "tags": [
        "Generation",
        "Algorithm"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-beam-search-decoding",
      "term": "Beam Search Decoding",
      "definition": "A search algorithm for sequence generation that maintains the top-K partial sequences at each step. Explores multiple hypotheses simultaneously and selects the highest-scoring complete sequence. Widely used in machine translation and speech recognition.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-beam-search-with-length-penalty",
      "term": "Beam Search with Length Penalty",
      "definition": "An extension of beam search decoding that normalizes sequence scores by length to prevent the algorithm from favoring shorter sequences. Commonly used in machine translation and text generation systems.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-beats",
      "term": "BEATs",
      "definition": "Bidirectional Encoder representation from Audio Transformers is an audio pre-training framework using iterative audio tokenization for general audio understanding.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-beavertails",
      "term": "BeaverTails",
      "definition": "A dataset of harmful LLM outputs categorized across 14 harm categories with safety labels. Used for training content safety classifiers and harmlessness reward models.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Safety"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bee-algorithm",
      "term": "Bee Algorithm",
      "definition": "A swarm intelligence metaheuristic inspired by the foraging behavior of honeybees. Scout bees explore random solutions while recruited bees exploit neighborhoods of the best solutions found so far.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-begin",
      "term": "BEGIN",
      "definition": "Benchmark for Evaluation of Grounded Interaction in Natural Language a dataset for evaluating grounded dialogue systems on faithfulness to source knowledge.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation",
        "Dialogue"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-behavior-cloning",
      "term": "Behavior Cloning",
      "definition": "Learning to imitate expert behavior from demonstrations. The model learns to map observations to actions by copying what experts do in similar situations.",
      "tags": [
        "Training",
        "Imitation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-behavior-based-robotics",
      "term": "Behavior-Based Robotics",
      "definition": "An approach to robotics that generates complex behavior from the interaction of simple reactive behaviors rather than centralized planning. Pioneered by Rodney Brooks in the late 1980s this approach challenged traditional AI and proved effective for real-world robot control.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-behavioral-cloning-safety",
      "term": "Behavioral Cloning Safety",
      "definition": "Safety concerns arising from training AI agents to imitate human behavior. Includes distribution shift compounding errors and the risk of learning unsafe human behaviors along with desired ones.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-beijing-ai-principles",
      "term": "Beijing AI Principles",
      "definition": "A set of AI governance principles released in 2019 by the Beijing Academy of AI, emphasizing harmony, fairness, safety, shared benefits, and responsible development in the Chinese AI governance context.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-beir",
      "term": "BEIR",
      "definition": "Benchmarking Information Retrieval a heterogeneous benchmark of 18 retrieval datasets for zero-shot evaluation. Tests generalization of retrieval models across diverse domains.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-beit",
      "term": "BEiT",
      "definition": "Bidirectional Encoder representation from Image Transformers applies masked image modeling as a pretraining task for vision transformers. Tokenizes image patches into visual tokens and predicts masked tokens similar to BERT in NLP.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-belebele",
      "term": "Belebele",
      "definition": "A reading comprehension benchmark covering 122 language variants with parallel passages and questions. One of the most linguistically diverse NLP evaluation benchmarks available.",
      "tags": [
        "Benchmark",
        "NLP",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-belief-propagation-algorithm",
      "term": "Belief Propagation Algorithm",
      "definition": "A message-passing algorithm for performing inference in graphical models. Each node sends messages to its neighbors summarizing the evidence from the rest of the graph and marginal beliefs are computed from incoming messages.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bell-labs-ai-research",
      "term": "Bell Labs AI Research",
      "definition": "AI and machine learning research conducted at Bell Laboratories (AT&T) where foundational work was done on information theory speech recognition and neural networks. Yann LeCun developed early convolutional neural networks at Bell Labs in the late 1980s and 1990s.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bellman-equation",
      "term": "Bellman Equation",
      "definition": "A recursive equation relating the value of a state to the immediate reward plus the discounted value of successor states. The Bellman equation provides the foundation for dynamic programming and most value-based RL algorithms.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-bellman-ford-algorithm",
      "term": "Bellman-Ford Algorithm",
      "definition": "A shortest-path algorithm that computes shortest paths from a single source vertex to all other vertices in a weighted graph. Unlike Dijkstra's it can handle graphs with negative edge weights and detects negative-weight cycles.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-benchmark",
      "term": "Benchmark",
      "definition": "A standardized test or dataset used to evaluate and compare AI model performance. Common LLM benchmarks include MMLU, HellaSwag, and HumanEval for measuring different capabilities.",
      "tags": [
        "Evaluation",
        "Research"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-benchmark-gaming",
      "term": "Benchmark Gaming",
      "definition": "The practice of optimizing a model specifically to achieve high scores on popular benchmarks without corresponding improvements in real-world capabilities, often through data contamination or overfitting.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-benders-decomposition",
      "term": "Benders Decomposition",
      "definition": "A decomposition technique for solving large-scale optimization problems with complicating variables. Splits the problem into a master problem and subproblems and iteratively adds optimality and feasibility cuts.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-benefit-sharing-in-ai",
      "term": "Benefit Sharing in AI",
      "definition": "The principle that the economic and social benefits generated by AI should be distributed broadly across society rather than concentrated among a small number of developers, companies, or nations.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-benefit-risk-analysis-for-ai",
      "term": "Benefit-Risk Analysis for AI",
      "definition": "A systematic comparison of the potential benefits and risks of an AI system to determine whether deployment is justified. Required by many regulatory frameworks for high-risk AI applications.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-berkeley-ai-research-lab",
      "term": "Berkeley AI Research Lab",
      "definition": "The Berkeley Artificial Intelligence Research Laboratory (BAIR) at UC Berkeley conducting research across computer vision NLP robotics and machine learning. BAIR has produced influential work on reinforcement learning robotic manipulation and open-source AI tools.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bernoulli-distribution",
      "term": "Bernoulli Distribution",
      "definition": "The simplest discrete probability distribution, modeling a single trial with two outcomes (success with probability p, failure with probability 1-p). It is the building block of the binomial distribution.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bert",
      "term": "BERT (Bidirectional Encoder Representations from Transformers)",
      "definition": "A influential language model from Google (2018) that processes text bidirectionally, understanding context from both left and right. Revolutionized NLP and inspired many subsequent models.",
      "tags": [
        "Model",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bert-release",
      "term": "BERT Release",
      "definition": "Google's Bidirectional Encoder Representations from Transformers model, released in October 2018, which achieved state-of-the-art results across numerous NLP tasks through bidirectional pre-training and established a new paradigm for language understanding.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bert4rec",
      "term": "BERT4Rec",
      "definition": "A sequential recommendation model that applies bidirectional self-attention (BERT-style) with masked item prediction to capture user behavior patterns.",
      "tags": [
        "Models",
        "Technical",
        "Recommendation"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bertscore",
      "term": "BERTScore",
      "definition": "An evaluation metric that computes the similarity between generated and reference texts using contextual BERT embeddings with greedy token matching, capturing semantic equivalence beyond exact surface-form overlap.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-best-first-search",
      "term": "Best-First Search",
      "definition": "A graph search strategy that selects the most promising node for expansion based on an evaluation function. Greedy best-first search uses only the heuristic estimate while A* adds the path cost.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph",
        "Searching"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-best-of-n-sampling",
      "term": "Best-of-N Sampling",
      "definition": "An inference strategy that generates N candidate completions and returns the one scoring highest on a reward model, trading increased compute for better output quality without model modification.",
      "tags": [
        "Generative AI",
        "Decoding"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-beta-distribution",
      "term": "Beta Distribution",
      "definition": "A continuous probability distribution defined on the interval [0, 1], parametrized by two shape parameters. It is commonly used as a prior distribution for probabilities in Bayesian inference.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-beta-vae",
      "term": "Beta-VAE",
      "definition": "A modification of the variational autoencoder that introduces a hyperparameter beta to weight the KL divergence term, promoting disentangled latent representations when beta is greater than one.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bev-perception",
      "term": "BEV Perception",
      "definition": "Bird's Eye View perception, a paradigm in autonomous driving that transforms multi-camera or LiDAR data into a unified top-down representation for joint 3D detection, segmentation, and prediction.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-bevdet",
      "term": "BEVDet",
      "definition": "A Bird Eye View detection framework for autonomous driving that transforms perspective-view features into BEV space for accurate 3D object detection.",
      "tags": [
        "Models",
        "Technical",
        "Autonomous",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bevformer",
      "term": "BEVFormer",
      "definition": "A spatiotemporal Transformer for autonomous driving that generates Bird Eye View representations from multi-camera inputs using deformable attention.",
      "tags": [
        "Models",
        "Technical",
        "Autonomous",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bf16",
      "term": "BF16 (Brain Floating Point)",
      "definition": "A 16-bit floating-point format with 8 exponent bits (same as FP32) and 7 mantissa bits, developed by Google Brain. BF16 maintains FP32's dynamic range while halving memory, eliminating the need for loss scaling required by FP16.",
      "tags": [
        "Model Optimization",
        "Hardware"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bfloat16",
      "term": "bfloat16",
      "definition": "A 16-bit floating-point format optimized for neural network training. Sacrifices precision for range compared to float16, offering better training stability.",
      "tags": [
        "Technical",
        "Precision"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-bge",
      "term": "BGE",
      "definition": "BAAI General Embedding is a family of embedding models that achieve strong performance on text retrieval tasks. Trained by Beijing Academy of Artificial Intelligence with support for multiple languages and both short and long texts.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bi-encoder",
      "term": "Bi-Encoder",
      "definition": "A neural retrieval architecture that independently encodes queries and documents into fixed-size vectors using separate or shared encoders, enabling pre-computation of document embeddings and fast similarity search through vector comparison.",
      "tags": [
        "Retrieval",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-estimation-bias",
      "term": "Bias",
      "definition": "In statistical estimation, the difference between the expected value of an estimator and the true value of the parameter being estimated. An unbiased estimator has zero bias.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bias-amplification",
      "term": "Bias Amplification",
      "definition": "The phenomenon where machine learning models amplify biases present in training data producing outputs that are more biased than the data itself. Can create feedback loops that worsen inequality over time.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-bias-bounty",
      "term": "Bias Bounty",
      "definition": "A program that rewards individuals for identifying and reporting biases in AI systems. Similar to bug bounties in cybersecurity and aimed at crowdsourcing the discovery of unfair model behaviors.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-bias-in-ai",
      "term": "Bias in AI",
      "definition": "Systematic errors in AI system outputs that arise from prejudiced assumptions in training data algorithm design or deployment context. Can lead to unfair discriminatory or inaccurate outcomes for affected groups.",
      "tags": [
        "Safety",
        "Fundamentals"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-bias-mitigation",
      "term": "Bias Mitigation",
      "definition": "Techniques and practices for reducing unfair bias in AI systems. Includes pre-processing methods like resampling in-processing methods like adversarial debiasing and post-processing methods like threshold adjustment.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-bias-score",
      "term": "Bias Score",
      "definition": "A metric that measures the degree of systematic prejudice or unfair treatment in model outputs across demographic groups, assessed through differential response analysis, stereotype association tests, or fairness benchmarks.",
      "tags": [
        "Evaluation",
        "Safety"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bias-testing",
      "term": "Bias Testing",
      "definition": "The systematic evaluation of AI systems for unfair biases across demographic groups and use cases. Includes statistical parity testing disparate impact analysis and intersectional bias assessment.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-bias-variance-decomposition",
      "term": "Bias-Variance Decomposition",
      "definition": "A mathematical decomposition of expected prediction error into three components: irreducible noise, squared bias (systematic error), and variance (sensitivity to training data), providing insight into sources of model error.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bias-variance-tradeoff",
      "term": "Bias-Variance Tradeoff",
      "definition": "The fundamental tension in supervised learning between a model's ability to minimize bias (error from overly simplistic assumptions) and variance (error from sensitivity to small fluctuations in the training set). Reducing one typically increases the other.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bicgstab-algorithm",
      "term": "BiCGSTAB Algorithm",
      "definition": "Biconjugate Gradient Stabilized method is an iterative solver for non-symmetric linear systems. Combines the biconjugate gradient method with stabilization techniques to avoid irregular convergence behavior.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-biden-executive-order-on-ai",
      "term": "Biden Executive Order on AI",
      "definition": "Executive Order 14110, issued by President Biden in October 2023, establishing requirements for AI safety and security including red-teaming standards, reporting of large training runs, and federal agency AI governance.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-bidirectional",
      "term": "Bidirectional",
      "definition": "Processing sequences in both directions (left-to-right and right-to-left). BERT processes bidirectionally for understanding; GPT processes unidirectionally for generation.",
      "tags": [
        "Architecture",
        "Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bidirectional-attention",
      "term": "Bidirectional Attention",
      "definition": "An attention pattern that allows each token to attend to all other tokens in both directions. Used in encoder models like BERT for building contextual representations. Contrasts with causal attention used in decoder models.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bidirectional-rnn",
      "term": "Bidirectional RNN",
      "definition": "A recurrent architecture that processes input sequences in both forward and backward directions simultaneously, combining both context directions to produce richer representations at each time step.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bidirectional-search",
      "term": "Bidirectional Search",
      "definition": "A graph search algorithm that simultaneously runs two searches from the start and goal nodes until they meet. Can reduce the search space exponentially compared to unidirectional search in certain graph structures.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph",
        "Searching"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-big-bench",
      "term": "BIG-bench",
      "definition": "The Beyond the Imitation Game Benchmark a collaborative benchmark of over 200 tasks contributed by 450 researchers. Tests language model capabilities including reasoning knowledge and social understanding.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-big-bench-hard",
      "term": "BIG-bench Hard",
      "definition": "A subset of 23 particularly challenging BIG-bench tasks where prior language model evaluations fell below average human performance. Used to test frontier model reasoning abilities.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bigbench",
      "term": "BigBench",
      "definition": "Beyond the Imitation Game Benchmark, a large collaborative benchmark containing over 200 diverse tasks contributed by researchers, designed to probe language model capabilities including reasoning, translation, and social understanding that go beyond standard benchmarks.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bigbird",
      "term": "BigBird",
      "definition": "A sparse attention transformer that combines random attention, window attention, and global attention patterns to achieve linear complexity while provably maintaining the expressive power of full attention.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bigcodebench",
      "term": "BigCodeBench",
      "definition": "A comprehensive benchmark for evaluating code generation models on practical programming tasks. Tests functional correctness across diverse real-world programming scenarios.",
      "tags": [
        "Benchmark",
        "Code",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bigearthnet",
      "term": "BigEarthNet",
      "definition": "A large-scale Sentinel-2 satellite image benchmark containing 590326 image patches with multiple land cover labels. One of the largest remote sensing classification datasets.",
      "tags": [
        "Benchmark",
        "Computer Vision",
        "Remote Sensing"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-biggan",
      "term": "BigGAN",
      "definition": "A large-scale GAN that generates high-fidelity images by scaling up batch size model size and applying class-conditional generation with truncation. Demonstrated that GANs benefit significantly from scale.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bigram",
      "term": "Bigram / N-gram",
      "definition": "Sequences of N consecutive tokens used in language modeling. Bigrams are pairs; trigrams are triples. N-gram models were dominant before neural approaches but remain useful baselines.",
      "tags": [
        "NLP",
        "Historical"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bigvgan",
      "term": "BigVGAN",
      "definition": "A large-scale universal neural vocoder that uses anti-aliased multi-periodicity composition for generating high-fidelity audio across diverse signal types.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bilateral-filter-algorithm",
      "term": "Bilateral Filter Algorithm",
      "definition": "An edge-preserving smoothing filter that averages nearby pixels weighted by both spatial distance and intensity difference. Preserves edges while removing noise by only averaging pixels with similar intensities.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-binary-classification",
      "term": "Binary Classification",
      "definition": "A classification task with exactly two possible outcomes (yes/no, spam/not spam). The simplest classification problem, often a building block for more complex tasks.",
      "tags": [
        "ML Task",
        "Classification"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-binary-cross-entropy",
      "term": "Binary Cross-Entropy",
      "definition": "A loss function for binary classification that measures the divergence between predicted probabilities and binary labels. Defined as -[y*log(p) + (1-y)*log(1-p)]. Equivalent to the negative log-likelihood of a Bernoulli distribution.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-binary-quantization",
      "term": "Binary Quantization",
      "definition": "An aggressive vector compression technique that reduces each vector dimension to a single bit based on its sign, enabling 32x compression from float32 and extremely fast Hamming distance comparisons at the cost of reduced recall accuracy.",
      "tags": [
        "Vector Database",
        "Quantization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-binary-search",
      "term": "Binary Search",
      "definition": "A search algorithm that finds the position of a target value within a sorted array by repeatedly dividing the search interval in half. Achieves O(log n) time complexity and requires the input to be sorted.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Searching"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bing-chat",
      "term": "Bing Chat / Copilot",
      "definition": "Microsoft's AI-powered search assistant, integrating GPT-4 with web search. Can answer questions with citations, create content, and access current information.",
      "tags": [
        "Product",
        "Microsoft"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-binning",
      "term": "Binning",
      "definition": "Process of sorting manufactured chips into quality grades based on their tested performance characteristics. Higher-quality bins become premium products while lower bins may be sold at reduced specifications.",
      "tags": [
        "Manufacturing",
        "Process",
        "Quality"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-binomial-distribution",
      "term": "Binomial Distribution",
      "definition": "A discrete probability distribution modeling the number of successes in a fixed number of independent Bernoulli trials, each with the same probability of success. It is parametrized by n (trials) and p (success probability).",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-binomial-heap-algorithm",
      "term": "Binomial Heap Algorithm",
      "definition": "A heap data structure consisting of a collection of binomial trees that supports efficient merging of two heaps. All operations run in O(log n) worst-case time and merge takes O(log n) time.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bio-tagging",
      "term": "BIO Tagging",
      "definition": "An alternative name for IOB tagging format using Begin, Inside, Outside labels for sequence labeling tasks, where B marks the start of an entity and I continues it.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-bioasq",
      "term": "BioASQ",
      "definition": "A biomedical semantic indexing and question answering challenge providing datasets for biomedical information retrieval and QA. Includes yes/no factoid list and summary questions.",
      "tags": [
        "Benchmark",
        "NLP",
        "Medical"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-biobert",
      "term": "BioBERT",
      "definition": "A biomedical language representation model pre-trained on large-scale biomedical corpora including PubMed abstracts and PMC full-text articles.",
      "tags": [
        "Models",
        "Technical",
        "Medical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bioes-tagging",
      "term": "BIOES Tagging",
      "definition": "An extended sequence labeling scheme that adds End and Single tags to the BIO format, providing more precise boundary information for named entities and improving recognition accuracy.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-biogpt",
      "term": "BioGPT",
      "definition": "A domain-specific generative language model pretrained on large-scale biomedical literature. Achieves strong performance on biomedical text generation question answering and relation extraction tasks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-biogpt-large",
      "term": "BioGPT-Large",
      "definition": "An expanded version of BioGPT with more parameters and training data for improved biomedical text generation and knowledge extraction.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Medical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-biomedclip",
      "term": "BiomedCLIP",
      "definition": "A multimodal model trained on biomedical image-text pairs from scientific literature for biomedical visual question answering and image retrieval.",
      "tags": [
        "Models",
        "Technical",
        "Medical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-biometric-ai-regulation",
      "term": "Biometric AI Regulation",
      "definition": "Legal restrictions on AI systems that process biometric data such as facial features, fingerprints, or gait patterns, including bans on real-time biometric surveillance in public spaces under the EU AI Act.",
      "tags": [
        "Privacy",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-biomistral",
      "term": "BioMistral",
      "definition": "A biomedical language model built on Mistral 7B through continued pre-training on PubMed Central articles for medical text understanding and generation.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Medical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-biosam",
      "term": "BioSAM",
      "definition": "A biomedical adaptation of the Segment Anything Model designed for cell and tissue segmentation in microscopy and histopathology images.",
      "tags": [
        "Models",
        "Technical",
        "Medical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-birch",
      "term": "BIRCH",
      "definition": "Balanced Iterative Reducing and Clustering using Hierarchies is a clustering algorithm designed for large datasets. Builds a compact summary called a CF-tree in a single pass through the data then applies standard clustering to the summary.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bird",
      "term": "BIRD",
      "definition": "A large text-to-SQL benchmark featuring real-world databases with dirty data and external knowledge requirements. More challenging than Spider with practical database scenarios.",
      "tags": [
        "Benchmark",
        "NLP",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-biren-technology",
      "term": "Biren Technology",
      "definition": "Chinese AI chip company developing high-performance GPU alternatives for the Chinese market. Their BR100 chip targets data center AI training and inference workloads.",
      "tags": [
        "Accelerator",
        "GPU",
        "China"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-bisection-method",
      "term": "Bisection Method",
      "definition": "A root-finding algorithm that repeatedly bisects an interval and selects the subinterval where the function changes sign. Guaranteed to converge for continuous functions but convergence is slower than Newton's method.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bisimulation-metric",
      "term": "Bisimulation Metric",
      "definition": "A distance metric on states that groups together states with similar reward and transition dynamics, providing a principled basis for state abstraction in RL. Deep bisimulation methods learn representations that preserve behaviorally relevant information.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-bit-precision",
      "term": "Bit Precision",
      "definition": "The number of bits used to represent model weights and activations. Lower precision (8-bit, 4-bit) reduces memory and increases speed but may affect accuracy.",
      "tags": [
        "Technical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bitonic-sort",
      "term": "Bitonic Sort",
      "definition": "A parallel sorting algorithm that first creates a bitonic sequence and then repeatedly merges bitonic sequences to produce a sorted output. Well-suited for parallel and hardware implementations due to its fixed comparison network.",
      "tags": [
        "Algorithms",
        "Technical",
        "Sorting"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bitter-lesson",
      "term": "Bitter Lesson",
      "definition": "An influential 2019 essay by Rich Sutton arguing that the history of AI shows general methods leveraging computation (search and learning) ultimately outperform approaches that encode human domain knowledge.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-black-box",
      "term": "Black Box",
      "definition": "A system whose internal workings are not visible or understandable to users. Many AI models are considered black boxes because their decision-making processes are difficult to interpret.",
      "tags": [
        "Interpretability",
        "Concept"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-black-box-problem",
      "term": "Black Box Problem",
      "definition": "The challenge that many AI systems, particularly deep neural networks, operate in ways that are opaque to human understanding, making it difficult to explain, audit, or trust their decisions.",
      "tags": [
        "AI Ethics",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-blackboard-system",
      "term": "Blackboard System",
      "definition": "An AI architecture where multiple knowledge sources cooperate to solve a problem by reading from and writing to a shared data structure called the blackboard. Developed in the 1970s for speech understanding the architecture influenced multi-agent systems.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-blended-skill-talk",
      "term": "Blended Skill Talk",
      "definition": "A dialogue dataset requiring models to blend multiple conversational skills including knowledge personality and empathy in a single conversation.",
      "tags": [
        "Benchmark",
        "NLP",
        "Dialogue"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bletchley-declaration-on-ai",
      "term": "Bletchley Declaration on AI",
      "definition": "A declaration signed by 28 countries at the November 2023 AI Safety Summit at Bletchley Park, acknowledging the potential for serious harm from frontier AI and committing to international cooperation on safety.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-bletchley-park-ai-safety-summit",
      "term": "Bletchley Park AI Safety Summit",
      "definition": "The first major international AI Safety Summit held at Bletchley Park, UK, in November 2023, bringing together governments and AI companies to discuss frontier AI risks and establish international cooperation frameworks.",
      "tags": [
        "History",
        "Governance"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bletchley-park-codebreaking",
      "term": "Bletchley Park Codebreaking",
      "definition": "The World War II British codebreaking operation where Alan Turing and colleagues developed the Bombe and Colossus machines to decrypt Axis communications, advancing computational methods that influenced early AI development.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bleu-reference-data",
      "term": "BLEU Reference Data",
      "definition": "Standard reference translation datasets used for computing BLEU scores in machine translation evaluation. Provides human translations as gold standards for automatic metrics.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation",
        "Translation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bleu-score",
      "term": "BLEU Score",
      "definition": "Bilingual Evaluation Understudy is a metric for evaluating machine translation quality by comparing n-gram overlap between candidate and reference translations. Introduced by Papineni et al. in 2002. Ranges from 0 to 1 with higher scores indicating better quality.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bleurt",
      "term": "BLEURT",
      "definition": "A learned evaluation metric that fine-tunes BERT on synthetic and human-rated data to predict text quality scores, providing robust assessments that correlate with human judgments even for paraphrases and semantically equivalent but lexically different outputs.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-block-matrix-algorithm",
      "term": "Block Matrix Algorithm",
      "definition": "A technique that partitions matrices into submatrices and performs operations on the blocks. Improves cache utilization and enables parallel computation for large-scale linear algebra problems.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bloom",
      "term": "BLOOM",
      "definition": "A large multilingual open-source language model created by BigScience, trained on 46 languages. Demonstrated the viability of collaborative, open AI development.",
      "tags": [
        "Model",
        "Open Source"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bloom-filter-algorithm",
      "term": "Bloom Filter Algorithm",
      "definition": "A space-efficient probabilistic data structure that tests whether an element is a member of a set. May produce false positives but never false negatives and uses multiple hash functions on a bit array.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bloom-176b",
      "term": "BLOOM-176B",
      "definition": "The largest variant of the BLOOM multilingual model with 176 billion parameters trained collaboratively by over 1000 researchers across 46 languages.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "History"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bloomberggpt",
      "term": "BloombergGPT",
      "definition": "A 50 billion parameter language model by Bloomberg trained on a mix of financial data and general text. Designed for financial NLP tasks while maintaining strong general language understanding capabilities.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-blue-team-ai",
      "term": "Blue Team (AI)",
      "definition": "A team responsible for defending AI systems against adversarial attacks and identifying vulnerabilities. Works in opposition to red teams to improve system security and robustness.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-bluelm",
      "term": "BlueLM",
      "definition": "A large language model from vivo with 7B and 13B parameters that supports both English and Chinese with 128K context window extensions.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bm25",
      "term": "BM25",
      "definition": "Best Matching 25, a probabilistic information retrieval ranking function that extends TF-IDF with document length normalization and term frequency saturation for more effective document scoring.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-bm25-algorithm",
      "term": "BM25 Algorithm",
      "definition": "A probabilistic information retrieval ranking function that scores documents based on query term frequency and document length. Extends TF-IDF with saturation of term frequency and document length normalization parameters.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bm25-in-rag",
      "term": "BM25 in RAG",
      "definition": "The application of the Best Matching 25 probabilistic ranking function within retrieval-augmented generation pipelines, providing strong lexical baseline retrieval that complements dense embedding search for finding documents with exact term matches.",
      "tags": [
        "Retrieval",
        "Search"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-bold",
      "term": "BOLD",
      "definition": "Bias in Open-ended Language Generation Dataset a benchmark of 23679 prompts for evaluating social biases across 5 domains in open-ended text generation by language models.",
      "tags": [
        "Benchmark",
        "NLP",
        "Fairness"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-boltzmann-exploration",
      "term": "Boltzmann Exploration",
      "definition": "An exploration strategy that selects actions with probability proportional to exponentiated Q-values divided by a temperature parameter. Higher temperatures increase randomness while lower temperatures converge toward greedy selection.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-boltzmann-machine",
      "term": "Boltzmann Machine",
      "definition": "A stochastic neural network model invented by Geoffrey Hinton and Terry Sejnowski in 1985 that uses simulated annealing to learn internal representations, representing an important step toward deep learning architectures.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bonferroni-correction",
      "term": "Bonferroni Correction",
      "definition": "A multiple comparison adjustment that divides the significance level by the number of tests performed, controlling the family-wise error rate. It is conservative but simple to apply.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bookcorpus",
      "term": "BookCorpus",
      "definition": "A dataset of 11000 free books from unpublished authors used to train the original BERT model alongside Wikipedia. Provides narrative text that complements encyclopedic knowledge.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-booksum",
      "term": "BookSum",
      "definition": "A dataset for long-form narrative summarization of full-length books and their chapter-level and book-level summaries. Tests the ability to comprehend and summarize very long documents.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-boolean-retrieval",
      "term": "Boolean Retrieval",
      "definition": "Search using AND, OR, NOT operators to combine terms. Simple but limited compared to semantic search. Still used in specialized databases and advanced search interfaces.",
      "tags": [
        "Search",
        "Traditional"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-boolq",
      "term": "BoolQ",
      "definition": "A question answering dataset of 15942 yes/no questions naturally generated from Google search queries. Tests the ability to perform boolean reasoning about short Wikipedia passages.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-boolq-contrast-set",
      "term": "BoolQ Contrast Set",
      "definition": "A modified version of BoolQ with expert-crafted perturbations that change the correct answer. Tests model robustness to small but meaningful input changes.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-boosting",
      "term": "Boosting",
      "definition": "An ensemble technique that trains models sequentially, with each new model focusing on examples the previous ones got wrong. Powers XGBoost and LightGBM, popular for tabular data.",
      "tags": [
        "Technique",
        "ML"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-boosting-history",
      "term": "Boosting History",
      "definition": "The development of boosting algorithms from the theoretical work of Michael Kearns and Leslie Valiant (1988) through AdaBoost (Freund and Schapire 1995) to gradient boosting (Friedman 2001). Boosting transformed weak learners into strong learners through sequential error correction.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-bootstrap",
      "term": "Bootstrap",
      "definition": "A resampling technique that estimates the sampling distribution of a statistic by repeatedly drawing samples with replacement from the observed data. It provides standard errors, confidence intervals, and bias estimates.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bootstrap-aggregating",
      "term": "Bootstrap Aggregating",
      "definition": "An ensemble method (also called bagging) that trains multiple models on different bootstrap samples of the training data and combines their predictions by averaging (regression) or voting (classification) to reduce variance.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-boruvkas-algorithm",
      "term": "Boruvka's Algorithm",
      "definition": "One of the earliest known algorithms for finding a minimum spanning tree. Works by simultaneously finding the cheapest edge for each component and merging components in parallel rounds until only one tree remains.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph",
        "History"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-boston-housing",
      "term": "Boston Housing",
      "definition": "A classic regression dataset containing housing prices in Boston suburbs with 13 features. Widely used for teaching regression analysis though criticized for racial bias issues.",
      "tags": [
        "Benchmark",
        "Tabular"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bottleneck",
      "term": "Bottleneck",
      "definition": "A narrow layer in a neural network that forces compression of information. Used in autoencoders and some architectures to learn efficient representations.",
      "tags": [
        "Architecture",
        "Design"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bottleneck-layer",
      "term": "Bottleneck Layer",
      "definition": "A narrow hidden layer that compresses representations to a lower dimension before expanding them, used in autoencoders and residual blocks to reduce computation and encourage abstraction.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-boundary-element-method",
      "term": "Boundary Element Method",
      "definition": "A numerical technique that solves boundary integral equations rather than volume equations reducing the problem dimension by one. Particularly efficient for problems with infinite or semi-infinite domains.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-boundary-testing",
      "term": "Boundary Testing",
      "definition": "The practice of probing AI systems at the edges of their intended operating conditions to identify failure modes and safety limitations. Essential for understanding system behavior under stress.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-box-cox-transformation",
      "term": "Box-Cox Transformation",
      "definition": "A family of power transformations parametrized by lambda that aims to stabilize variance and make data more normally distributed. Special cases include the logarithmic transformation (lambda=0) and no transformation (lambda=1).",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-boyer-moore-algorithm",
      "term": "Boyer-Moore Algorithm",
      "definition": "A string-searching algorithm that preprocesses the pattern to skip sections of text that cannot contain a match. Uses bad character and good suffix heuristics to achieve sublinear average-case time.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "NLP",
        "Searching"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bpe",
      "term": "BPE (Byte Pair Encoding)",
      "definition": "A tokenization algorithm that breaks text into subword units. Starts with individual characters and iteratively merges frequent pairs, balancing vocabulary size with the ability to handle rare words.",
      "tags": [
        "Tokenization",
        "NLP"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-bpr",
      "term": "BPR",
      "definition": "Bayesian Personalized Ranking is a pairwise learning framework for implicit feedback recommendation that optimizes the ranking of observed over unobserved items.",
      "tags": [
        "Models",
        "Technical",
        "Recommendation"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-brain-computer",
      "term": "Brain-Computer Interface (BCI)",
      "definition": "Technology connecting brain signals directly to computers. AI helps interpret neural signals for prosthetics, communication devices, and research applications.",
      "tags": [
        "Application",
        "Neuroscience"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-brainscales",
      "term": "BrainScaleS",
      "definition": "European neuromorphic computing platform that implements neural networks in analog hardware running 10000 times faster than biological real time. Part of the Human Brain Project.",
      "tags": [
        "Neuromorphic",
        "Research",
        "Europe"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-branch-and-bound",
      "term": "Branch and Bound",
      "definition": "An algorithmic paradigm for solving combinatorial optimization problems that systematically enumerates candidates while pruning large portions of the search space using bounds on the optimal solution. Used in integer programming and scheduling.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-branch-prediction",
      "term": "Branch Prediction",
      "definition": "Processor mechanism that guesses the outcome of conditional branches before they are resolved. Accurate prediction prevents pipeline stalls and maintains high instruction throughput.",
      "tags": [
        "Architecture",
        "Processor",
        "Optimization"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-breadth-first-search",
      "term": "Breadth-First Search",
      "definition": "A graph traversal algorithm that explores all neighbors at the current depth before moving to the next level. Uses a queue data structure and finds the shortest path in unweighted graphs.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Graph",
        "Searching"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-breast-cancer-wisconsin",
      "term": "Breast Cancer Wisconsin",
      "definition": "A dataset of 569 fine needle aspirate cell measurements for classifying breast tumors as malignant or benign. Widely used for binary classification benchmarking.",
      "tags": [
        "Benchmark",
        "Tabular",
        "Medical"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-brents-method",
      "term": "Brent's Method",
      "definition": "A root-finding algorithm that combines the bisection method with the secant method and inverse quadratic interpolation. Guarantees convergence while achieving superlinear speed and is widely used in numerical software libraries.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bridge-detection-algorithm",
      "term": "Bridge Detection Algorithm",
      "definition": "An algorithm that finds edges in an undirected graph whose removal disconnects the graph. Uses a modified depth-first search tracking discovery times and low-link values to identify bridge edges in linear time.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-brier-score",
      "term": "Brier Score",
      "definition": "A scoring metric that measures the accuracy of probabilistic predictions by computing the mean squared difference between predicted probabilities and actual binary outcomes. Lower values indicate better calibrated predictions.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bron-kerbosch-algorithm",
      "term": "Bron-Kerbosch Algorithm",
      "definition": "A backtracking algorithm for finding all maximal cliques in an undirected graph. Uses pivot selection to prune the search space and is the most widely used algorithm for clique enumeration.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-browse-mode",
      "term": "Browse Mode",
      "definition": "AI capability to access and retrieve current web information during conversations. Addresses knowledge cutoff limitations by fetching real-time data.",
      "tags": [
        "Feature",
        "Capability"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-broydens-method",
      "term": "Broyden's Method",
      "definition": "A quasi-Newton method for solving systems of nonlinear equations that approximates the Jacobian using rank-one updates. Avoids the cost of recomputing the full Jacobian at each iteration while maintaining superlinear convergence.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bruce-buchanan",
      "term": "Bruce Buchanan",
      "definition": "American computer scientist who co-developed DENDRAL the first expert system with Edward Feigenbaum and Joshua Lederberg at Stanford. Buchanan's work on knowledge-based systems helped establish expert systems as a practical AI technology.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-brushnet",
      "term": "BrushNet",
      "definition": "A dual-branch diffusion model for image inpainting that separately processes masked image features and noisy latent features for high-quality completion.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bubble-sort",
      "term": "Bubble Sort",
      "definition": "A simple comparison-based sorting algorithm that repeatedly swaps adjacent elements if they are in the wrong order. Has O(n^2) time complexity and is primarily used for educational purposes due to its poor performance.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Sorting"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bucket-sort",
      "term": "Bucket Sort",
      "definition": "A distribution sort that divides elements into a fixed number of buckets and then sorts each bucket individually. Achieves O(n) average time when input is uniformly distributed across the range of bucket boundaries.",
      "tags": [
        "Algorithms",
        "Technical",
        "Sorting"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-buffer",
      "term": "Buffer (Memory)",
      "definition": "Temporary storage for data being processed. In AI agents, conversation buffers store recent exchanges. In training, data buffers optimize GPU utilization.",
      "tags": [
        "Technical",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-bugsinpy",
      "term": "BugsInPy",
      "definition": "A database of real bugs from Python programs with test cases for each bug. Used for benchmarking automated debugging and program repair approaches in Python.",
      "tags": [
        "Benchmark",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-bundle-adjustment",
      "term": "Bundle Adjustment",
      "definition": "An optimization procedure that jointly refines 3D point positions and camera parameters by minimizing the reprojection error across all views, forming the core refinement step in 3D reconstruction pipelines.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-bundle-method",
      "term": "Bundle Method",
      "definition": "An optimization technique for non-smooth convex minimization that accumulates subgradient information in a bundle. Constructs a piecewise-linear model of the objective function and solves a quadratic subproblem at each step.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-burgs-method",
      "term": "Burg's Method",
      "definition": "A parametric spectral estimation technique that fits an autoregressive model to data by minimizing forward and backward prediction errors. Produces high-resolution spectral estimates from short data records.",
      "tags": [
        "Algorithms",
        "Technical",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-burn-in-testing",
      "term": "Burn-In Testing",
      "definition": "Stress testing of semiconductor chips at elevated temperatures and voltages to identify early failures. Ensures reliability of AI chips that will operate continuously in data centers.",
      "tags": [
        "Manufacturing",
        "Testing",
        "Reliability"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-burrows-wheeler-transform",
      "term": "Burrows-Wheeler Transform",
      "definition": "A reversible text transformation that rearranges characters to group similar characters together. Widely used in data compression (bzip2) and bioinformatics (sequence alignment) as a preprocessing step.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP",
        "Information Theory"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-burst",
      "term": "Burst (API)",
      "definition": "Short periods of high API usage that may exceed normal rate limits. Many providers allow bursting with gradual throttling rather than hard cutoffs.",
      "tags": [
        "API",
        "Usage"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-burstiness",
      "term": "Burstiness",
      "definition": "A statistical property measuring the variability of sentence length and structure in text, often used in AI-generated text detection where machine-generated content tends to show lower burstiness (more uniform patterns) than human writing.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-butterworth-filter",
      "term": "Butterworth Filter",
      "definition": "An analog or digital filter designed to have a maximally flat frequency response in the passband. Named after Stephen Butterworth and characterized by smooth roll-off without ripples in either band.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-byte-fallback",
      "term": "Byte Fallback",
      "definition": "A tokenization strategy that encodes unknown characters as individual bytes when they cannot be represented by the learned vocabulary, ensuring all possible inputs can be tokenized.",
      "tags": [
        "NLP",
        "Tokenization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-byte-pair-encoding",
      "term": "Byte Pair Encoding",
      "definition": "A subword tokenization algorithm that iteratively merges the most frequent pair of consecutive bytes or characters. Originally a data compression technique adapted for NLP by Sennrich et al. in 2016. Used in GPT models for vocabulary construction.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-bpe-tokenizer",
      "term": "Byte Pair Encoding Tokenizer",
      "definition": "A subword tokenization algorithm that iteratively merges the most frequent pair of adjacent bytes or characters in the training corpus to build a vocabulary of variable-length subword units.",
      "tags": [
        "NLP",
        "Tokenization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-byte-level-bpe-algorithm",
      "term": "Byte-Level BPE Algorithm",
      "definition": "A variant of byte pair encoding that operates on raw bytes rather than Unicode characters. Enables tokenization of any text in any language without requiring language-specific preprocessing or vocabulary.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-byte-level-tokenization",
      "term": "Byte-Level Tokenization",
      "definition": "A tokenization approach that operates on raw bytes rather than characters, ensuring complete coverage of any text input without unknown tokens, used in models like GPT-2 with byte-level BPE.",
      "tags": [
        "NLP",
        "Tokenization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    }
  ]
}