{
  "letter": "c",
  "count": 526,
  "terms": [
    {
      "id": "term-c-eval",
      "term": "C-Eval",
      "definition": "A comprehensive Chinese evaluation benchmark spanning 52 subjects across four difficulty levels. Tests Chinese language model capabilities on domain-specific knowledge and reasoning.",
      "tags": [
        "Benchmark",
        "NLP",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-c2pa",
      "term": "C2PA",
      "definition": "The Coalition for Content Provenance and Authenticity, a joint development foundation creating technical standards for certifying the source and history of media content through cryptographic provenance metadata.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-c4",
      "term": "C4",
      "definition": "The Colossal Clean Crawled Corpus a 750GB cleaned version of Common Crawl created by Google for training the T5 model. Applies deduplication and quality filtering to raw web text.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cadence-design-systems",
      "term": "Cadence Design Systems",
      "definition": "Major electronic design automation company providing chip design and verification tools. Their software is essential for designing the complex circuits in modern AI processors.",
      "tags": [
        "Manufacturing",
        "EDA",
        "Company"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-caffe-framework",
      "term": "Caffe Framework",
      "definition": "A deep learning framework developed by Yangqing Jia at UC Berkeley in 2013. Caffe (Convolutional Architecture for Fast Feature Embedding) was widely used for computer vision research and contributed to the rapid adoption of CNNs in the early deep learning era.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-caformer",
      "term": "CAFormer",
      "definition": "A MetaFormer variant that combines convolutional token mixers in early stages with attention token mixers in later stages for strong image classification.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-calibration",
      "term": "Calibration",
      "definition": "The degree to which a model's predicted probabilities match the true frequencies of outcomes. A well-calibrated model predicting 80% probability should be correct approximately 80% of the time for such predictions.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-calibration-data",
      "term": "Calibration Data for Quantization",
      "definition": "A representative subset of input data used to determine optimal quantization parameters such as scaling factors and zero points. Calibration data quality directly affects the accuracy of post-training quantized models.",
      "tags": [
        "Model Optimization",
        "Inference Infrastructure"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-calibration-error",
      "term": "Calibration Error",
      "definition": "A metric that measures the discrepancy between a model's predicted confidence and its actual accuracy, where a well-calibrated model's stated probability of being correct closely matches its empirical accuracy at each confidence level.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-calibration-fairness",
      "term": "Calibration Fairness",
      "definition": "A fairness metric requiring that among individuals assigned a given predicted probability, the actual proportion of positive outcomes is the same across all protected groups, ensuring that confidence scores are equally meaningful.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-california-housing",
      "term": "California Housing",
      "definition": "A dataset of housing prices in California districts used for regression benchmarking. Contains median house values and socioeconomic features from the 1990 census.",
      "tags": [
        "Benchmark",
        "Tabular"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-callback",
      "term": "Callback",
      "definition": "A function called at specific points during training or inference. Used for logging, checkpointing, early stopping, and custom behaviors in ML pipelines.",
      "tags": [
        "Technical",
        "Training"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-caltech-101",
      "term": "Caltech-101",
      "definition": "A dataset of images from 101 object categories plus a background category with 40 to 800 images per class. Created at Caltech and widely used for object recognition benchmarking in the 2000s.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-caltech-256",
      "term": "Caltech-256",
      "definition": "An extension of Caltech-101 containing 30607 images across 256 object categories plus a clutter class. Provides a more challenging and diverse object recognition benchmark.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cambrian-1",
      "term": "Cambrian-1",
      "definition": "A family of multimodal language models that systematically study visual representation learning and achieves strong performance through dynamic visual token routing.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cambricon-technologies",
      "term": "Cambricon Technologies",
      "definition": "Chinese AI chip company that developed some of the earliest commercial neural network processors. Their MLU chips are deployed across Chinese cloud and edge AI applications.",
      "tags": [
        "Accelerator",
        "China"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-camera-calibration",
      "term": "Camera Calibration",
      "definition": "The process of estimating the intrinsic parameters (focal length, principal point, distortion) and extrinsic parameters (position, orientation) of a camera, essential for accurate 3D reconstruction and measurement.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-canaicode",
      "term": "CanAICode",
      "definition": "A benchmark for evaluating the coding abilities of language models across multiple programming languages and problem types. Provides standardized code generation evaluation.",
      "tags": [
        "Benchmark",
        "Code",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-canary",
      "term": "Canary",
      "definition": "A multilingual speech recognition model from NVIDIA NeMo that handles automatic speech recognition and translation across multiple languages simultaneously.",
      "tags": [
        "Models",
        "Technical",
        "Audio",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-canny-edge-detection",
      "term": "Canny Edge Detection",
      "definition": "A multi-stage edge detection algorithm that applies Gaussian smoothing and gradient computation and non-maximum suppression and hysteresis thresholding to produce thin accurate edges in images.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-canonical-correlation-analysis",
      "term": "Canonical Correlation Analysis",
      "definition": "A multivariate statistical method that finds linear combinations of variables from two datasets that are maximally correlated. Used for multi-view learning and cross-modal retrieval of related information.",
      "tags": [
        "Algorithms",
        "Technical",
        "Dimensionality Reduction"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-canopy-clustering-algorithm",
      "term": "Canopy Clustering Algorithm",
      "definition": "A fast pre-clustering algorithm that creates overlapping canopies using two distance thresholds. Typically used as a preprocessing step to speed up more expensive clustering algorithms like k-means.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-capability",
      "term": "Capability (AI)",
      "definition": "A specific skill or function an AI system can perform. Capabilities range from basic (text generation) to advanced (multi-step reasoning, tool use). Understanding capabilities helps set realistic expectations.",
      "tags": [
        "Concept",
        "Assessment"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-capability-control",
      "term": "Capability Control",
      "definition": "Safety measures that limit what an AI system can do by restricting its access to resources, communication channels, or actuators, as opposed to motivational control which shapes what the system wants to do.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-capability-elicitation",
      "term": "Capability Elicitation",
      "definition": "Techniques for systematically discovering what an AI system can do including capabilities that may not be apparent from standard benchmarks. Important for understanding potential risks of advanced systems.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-capsule-network",
      "term": "Capsule Network",
      "definition": "A neural network architecture that uses groups of neurons (capsules) to encode both the presence and instantiation parameters of features, using dynamic routing to model part-whole relationships.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-capsule-networks",
      "term": "Capsule Networks",
      "definition": "A neural network architecture proposed by Geoffrey Hinton and colleagues (Sabour et al. 2017) that uses groups of neurons (capsules) to represent spatial hierarchies and part-whole relationships. Capsule networks aimed to address limitations of CNNs in understanding spatial relationships.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-captioning",
      "term": "Captioning",
      "definition": "Generating text descriptions of images or videos. A multimodal task requiring visual understanding and language generation. Used for accessibility and content organization.",
      "tags": [
        "Task",
        "Multimodal"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-capybara",
      "term": "Capybara",
      "definition": "A multi-turn conversational dataset designed for training helpful and detailed AI assistants. Covers diverse topics with extended conversation chains.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-carbon-footprint-of-ai-training",
      "term": "Carbon Footprint of AI Training",
      "definition": "The greenhouse gas emissions generated by the energy consumed during AI model training. Training a single large language model can produce emissions equivalent to several transcontinental flights.",
      "tags": [
        "Sustainability",
        "Training"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-carbon-nanotube-transistor",
      "term": "Carbon Nanotube Transistor",
      "definition": "Transistor using carbon nanotubes as the channel material instead of silicon. Promises better performance and lower power than silicon transistors at extremely small dimensions.",
      "tags": [
        "Emerging",
        "Materials",
        "Transistor"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-carla",
      "term": "CARLA",
      "definition": "An open-source simulator for autonomous driving research providing urban driving environments with dynamic weather and traffic. Used for training and evaluating self-driving policies.",
      "tags": [
        "Benchmark",
        "Reinforcement Learning",
        "Autonomous Driving"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-carnegie-mellon-ai",
      "term": "Carnegie Mellon AI",
      "definition": "AI research programs at Carnegie Mellon University including the work of Herbert Simon Allen Newell and Raj Reddy. Home to the Robotics Institute and the Machine Learning Department one of the first dedicated ML departments at any university.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cartesian-tree-algorithm",
      "term": "Cartesian Tree Algorithm",
      "definition": "A binary tree derived from a sequence of numbers where the root is the minimum element and left and right subtrees are Cartesian trees of the subsequences before and after the root. Used in range minimum queries.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-case-based-reasoning",
      "term": "Case-Based Reasoning",
      "definition": "An AI methodology that solves new problems by adapting solutions from similar past cases. Developed by Roger Schank and others in the 1980s CBR systems maintain a case library and use similarity metrics to retrieve and adapt relevant prior experiences.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-casual-conversations",
      "term": "Casual Conversations",
      "definition": "A Meta dataset of 45186 videos of paid participants with self-provided age gender and skin tone labels. Designed for evaluating fairness and bias in face and speech analysis.",
      "tags": [
        "Benchmark",
        "Fairness",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cataphora",
      "term": "Cataphora",
      "definition": "A linguistic phenomenon where a referring expression precedes the entity it refers to in the text, as in 'Before he arrived, John called ahead,' posing challenges for reference resolution.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-catastrophic-forgetting",
      "term": "Catastrophic Forgetting",
      "definition": "The tendency of neural networks to forget previously learned information when trained on new data. A significant challenge in continual learning and fine-tuning scenarios.",
      "tags": [
        "Training",
        "Challenge"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-catastrophic-forgetting-ethics",
      "term": "Catastrophic Forgetting Ethics",
      "definition": "Ethical implications of the tendency of neural networks to forget previously learned safety constraints when trained on new data, potentially undermining alignment measures during continued training.",
      "tags": [
        "AI Safety",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-catastrophic-forgetting-rl",
      "term": "Catastrophic Forgetting in RL",
      "definition": "The tendency of neural network-based RL agents to lose previously learned skills when adapting to new tasks or environments. Continual RL methods use regularization, replay, or modular architectures to mitigate forgetting.",
      "tags": [
        "Reinforcement Learning",
        "Training Paradigms"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-catastrophic-interference",
      "term": "Catastrophic Interference",
      "definition": "A phenomenon in neural networks where learning new information causes the model to forget previously learned information. Poses safety risks when models deployed in production lose critical capabilities.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-catastrophic-risk-from-ai",
      "term": "Catastrophic Risk from AI",
      "definition": "The risk that AI systems could cause large-scale irreversible harm falling short of existential risk, such as widespread economic collapse, loss of critical infrastructure, or major environmental damage.",
      "tags": [
        "AI Safety",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-catboost",
      "term": "CatBoost",
      "definition": "A gradient boosting library that natively handles categorical features using ordered target statistics and employs ordered boosting to reduce prediction shift, yielding strong performance with minimal hyperparameter tuning.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-catboost-model",
      "term": "CatBoost Model",
      "definition": "A gradient boosting library from Yandex that handles categorical features natively and uses ordered boosting to reduce prediction shift.",
      "tags": [
        "Models",
        "Fundamentals"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-categorical-dqn-algorithm",
      "term": "Categorical DQN Algorithm",
      "definition": "A distributional reinforcement learning algorithm that models the full distribution of returns rather than just the expected value. Uses a categorical representation with a fixed set of atoms to approximate the return distribution.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-causal-convolution",
      "term": "Causal Convolution",
      "definition": "A convolution that only uses current and past inputs ensuring the output at time t depends only on inputs at times t and earlier. Essential for autoregressive sequence modeling in architectures like WaveNet and temporal convolutional networks.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-causal-fairness",
      "term": "Causal Fairness",
      "definition": "An approach to algorithmic fairness that uses causal reasoning to determine whether an AI system's decisions are influenced by protected attributes through illegitimate causal pathways.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-causal-forest-algorithm",
      "term": "Causal Forest Algorithm",
      "definition": "An ensemble method for estimating heterogeneous treatment effects that adapts random forests to causal inference. Splits on variables that maximize treatment effect heterogeneity rather than prediction accuracy.",
      "tags": [
        "Algorithms",
        "Technical",
        "Causal"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-causal-language-model",
      "term": "Causal Language Model",
      "definition": "A model that predicts the next token based only on previous tokens (left-to-right). GPT and most text generation models are causal. Contrast with bidirectional models like BERT.",
      "tags": [
        "Architecture",
        "LLM"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-causal-language-modeling",
      "term": "Causal Language Modeling",
      "definition": "A training objective where the model predicts each token based only on the preceding tokens in the sequence, enforcing a left-to-right autoregressive generation order.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-causal-mask",
      "term": "Causal Mask",
      "definition": "A triangular attention mask that prevents each position from attending to subsequent positions, enforcing the autoregressive property required for left-to-right language generation.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-causal-masking",
      "term": "Causal Masking",
      "definition": "A specific attention mask pattern that prevents each position from attending to future positions ensuring autoregressive behavior. Implemented as a lower triangular mask matrix. Essential for language model training and generation.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-causalbench",
      "term": "CausalBench",
      "definition": "A benchmark for evaluating causal reasoning capabilities of language models. Tests the ability to identify causes effects and causal mechanisms in text.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cb",
      "term": "CB",
      "definition": "CommitmentBank a corpus of naturally occurring discourses with embedded clauses annotated for speaker commitment. Part of the SuperGLUE benchmark testing fine-grained textual entailment.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cbam",
      "term": "CBAM",
      "definition": "Convolutional Block Attention Module, a lightweight attention module that sequentially applies channel and spatial attention to feature maps, enhancing representational power with minimal overhead.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cbow",
      "term": "CBOW",
      "definition": "Continuous Bag of Words, a Word2Vec training objective that predicts a center word from the average of its surrounding context word vectors, typically faster to train than Skip-gram.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-cc-news",
      "term": "CC-News",
      "definition": "A dataset of 63 million English news articles collected from Common Crawl between 2016 and 2019. Used as a pretraining component for RoBERTa and other language models.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cc-stories",
      "term": "CC-Stories",
      "definition": "A subset of Common Crawl filtered to contain narrative and story-like text. Used as part of the GPT-2 training methodology to include fiction and narrative reasoning data.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cc100",
      "term": "CC100",
      "definition": "A monolingual dataset extracted from Common Crawl snapshots covering 100 languages. Created for pretraining multilingual models and language-specific language models.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-ccaligned",
      "term": "CCAligned",
      "definition": "A parallel corpus of 68 language pairs extracted from Common Crawl using document alignment. Provides web-mined translation data for training multilingual NLP models.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Translation",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cdc-6600",
      "term": "CDC 6600",
      "definition": "Control Data Corporation supercomputer designed by Seymour Cray in 1964. Generally considered the first successful supercomputer and the fastest computer in the world from 1964 to 1969.",
      "tags": [
        "Historical",
        "Supercomputer",
        "Pioneer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ceiling-effect",
      "term": "Ceiling Effect",
      "definition": "When a benchmark becomes too easy to distinguish between models, all scoring near the maximum. Prompts creation of harder benchmarks to continue measuring progress.",
      "tags": [
        "Evaluation",
        "Benchmark"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-celeba",
      "term": "CelebA",
      "definition": "A large-scale face attributes dataset with over 200000 celebrity images each annotated with 40 binary attributes and 5 landmark locations. Widely used for face generation and attribute prediction.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-celeba-hq",
      "term": "CelebA-HQ",
      "definition": "A high-quality version of CelebA containing 30000 face images at 1024x1024 resolution. Created for training high-resolution generative models particularly progressive GANs.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cellular-automata",
      "term": "Cellular Automata",
      "definition": "Discrete models of computation consisting of a grid of cells each in a finite number of states that evolve over time according to simple rules. John von Neumann and Stanislaw Ulam developed the concept in the 1940s. Conway's Game of Life (1970) became the most famous example.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-censoring",
      "term": "Censoring",
      "definition": "A condition in survival analysis where the exact time of an event is not observed for some subjects, typically because the study ended or the subject was lost to follow-up. Right censoring is the most common form.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-center-for-ai-safety",
      "term": "Center for AI Safety",
      "definition": "A nonprofit research and field-building organization founded in 2022 focused on reducing societal-scale risks from AI. CAIS published the Statement on AI Risk signed by leading AI researchers and policymakers warning about existential risks from advanced AI.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-centernet",
      "term": "CenterNet",
      "definition": "An anchor-free object detection approach that represents objects as center points with associated size and offset predictions, simplifying the detection pipeline by eliminating anchor box design and NMS post-processing.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-centerpoint",
      "term": "CenterPoint",
      "definition": "A center-based 3D object detection and tracking model for autonomous driving that detects objects as center points in bird-eye-view representations.",
      "tags": [
        "Models",
        "Technical",
        "Autonomous",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-central-limit-theorem",
      "term": "Central Limit Theorem",
      "definition": "A fundamental theorem stating that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the population's original distribution, provided the variance is finite.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-ctde",
      "term": "Centralized Training Decentralized Execution (CTDE)",
      "definition": "A multi-agent RL paradigm where agents have access to global information during training but must act independently based only on local observations at test time. CTDE bridges the gap between joint and independent learning.",
      "tags": [
        "Reinforcement Learning",
        "Multi-Agent"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-centroid-decomposition",
      "term": "Centroid Decomposition",
      "definition": "A tree decomposition technique that recursively splits a tree at its centroid to create a balanced decomposition tree. Enables efficient divide-and-conquer algorithms for tree path queries with O(n log n) preprocessing.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-centroid-based-clustering-vectors",
      "term": "Centroid-Based Clustering for Vectors",
      "definition": "The use of clustering algorithms like k-means to partition a vector collection into groups represented by centroid vectors, forming the basis of IVF indexes where query vectors are first compared to centroids to identify relevant partitions.",
      "tags": [
        "Vector Database",
        "Index Structure"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-cerebras",
      "term": "Cerebras",
      "definition": "A semiconductor company that produces wafer-scale AI processors (WSE series) with millions of cores and terabytes of on-chip SRAM. Cerebras systems eliminate memory bandwidth bottlenecks by keeping entire large models in on-chip memory.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cerebras-cs-2",
      "term": "Cerebras CS-2",
      "definition": "AI training system built around the Cerebras WSE-2 chip providing simplified cluster-free training for large AI models. Eliminates the need for model parallelism across multiple GPUs.",
      "tags": [
        "Accelerator",
        "System"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cerebras-systems",
      "term": "Cerebras Systems",
      "definition": "An AI hardware company founded in 2016 that developed the Wafer Scale Engine the largest chip ever built. The CS-2 system uses an entire silicon wafer as a single chip providing massive parallelism for training large neural networks.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cerebras-wse-2",
      "term": "Cerebras WSE-2",
      "definition": "Cerebras Wafer Scale Engine 2 containing 2.6 trillion transistors and 850000 AI-optimized cores on a single wafer-scale chip. The largest chip ever built designed for AI training.",
      "tags": [
        "Accelerator",
        "Wafer-Scale"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cerebras-gpt",
      "term": "Cerebras-GPT",
      "definition": "A family of language models trained by Cerebras Systems following Chinchilla-optimal scaling laws. Released with training recipes and full reproducibility details. Models range from 111M to 13B parameters.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-certified-robustness",
      "term": "Certified Robustness",
      "definition": "A formal guarantee that a model's predictions will not change under input perturbations within a specified bound. Provides provable rather than empirical assurance of adversarial robustness.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-cflow-ad",
      "term": "CFlow-AD",
      "definition": "Conditional normalizing Flow for Anomaly Detection uses position-conditioned normalizing flows on multi-scale features for pixel-level anomaly localization.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cgcnn",
      "term": "CGCNN",
      "definition": "Crystal Graph Convolutional Neural Network predicts material properties directly from crystal structures using a graph representation of atomic bonds.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-chain-of-density",
      "term": "Chain of Density",
      "definition": "A prompting technique that iteratively increases the information density of a summary by asking the model to rewrite it with additional entities while maintaining the same length, producing progressively more concise and entity-rich summaries.",
      "tags": [
        "Prompt Engineering",
        "Summarization"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-chain-of-responsibility-in-ai",
      "term": "Chain of Responsibility in AI",
      "definition": "The linked sequence of actors including developers deployers and users who share accountability for AI system outcomes. Legal frameworks are evolving to allocate responsibility across this chain.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-chain-of-code",
      "term": "Chain-of-Code",
      "definition": "A reasoning framework that augments chain-of-thought with executable code generation, allowing the model to write and simulate code execution for reasoning steps that benefit from computation while using natural language for semantic reasoning.",
      "tags": [
        "Prompt Engineering",
        "Code-Augmented"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-chain-of-knowledge",
      "term": "Chain-of-Knowledge",
      "definition": "A prompting framework that progressively builds and refines a knowledge chain by eliciting relevant facts, verifying their consistency, and reasoning over the accumulated knowledge to produce answers grounded in verified information.",
      "tags": [
        "Prompt Engineering",
        "Knowledge Augmentation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-chain-of-table",
      "term": "Chain-of-Table",
      "definition": "A reasoning framework for tabular data that iteratively transforms tables through operations like filtering, sorting, and aggregation as intermediate reasoning steps, with each step producing a new table state that informs the next operation.",
      "tags": [
        "Prompt Engineering",
        "Tabular Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-chain-of-thought",
      "term": "Chain-of-Thought (CoT)",
      "definition": "A prompting technique that encourages AI to show its reasoning process step-by-step, leading to more accurate and transparent responses for complex problems.",
      "tags": [
        "Prompting",
        "Reasoning"
      ],
      "domain": "general",
      "link": "../learn/index.html",
      "related": []
    },
    {
      "id": "term-chain-of-thought-discovery",
      "term": "Chain-of-Thought Discovery",
      "definition": "The discovery that prompting large language models to think step by step dramatically improves their reasoning performance. Introduced by Jason Wei et al. at Google Brain in 2022 chain-of-thought prompting became one of the most influential prompt engineering techniques.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-chain-of-thought-prompting",
      "term": "Chain-of-Thought Prompting",
      "definition": "A prompting technique that elicits step-by-step reasoning from language models by including intermediate reasoning steps in the prompt. Dramatically improves performance on arithmetic commonsense and symbolic reasoning tasks.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Prompting"
      ],
      "domain": "algorithms",
      "link": "learn/chain-of-thought.html",
      "related": []
    },
    {
      "id": "term-cot-self-consistency",
      "term": "Chain-of-Thought with Self-Consistency",
      "definition": "The combined technique of generating multiple chain-of-thought reasoning paths for a single problem using sampling and selecting the most frequently occurring final answer through majority voting to improve reasoning reliability.",
      "tags": [
        "Prompt Engineering",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-chameleon",
      "term": "Chameleon",
      "definition": "A mixed-modal foundation model from Meta that natively processes and generates interleaved text and image sequences using discrete tokenization for all modalities.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-channel-attention",
      "term": "Channel Attention",
      "definition": "An attention mechanism that learns to weight the importance of different feature channels in a CNN, selectively emphasizing informative channels while suppressing less useful ones.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-channel-capacity-algorithm",
      "term": "Channel Capacity Algorithm",
      "definition": "An algorithm that computes the maximum rate of reliable communication over a noisy channel. The Blahut-Arimoto algorithm iteratively optimizes the input distribution to maximize mutual information.",
      "tags": [
        "Algorithms",
        "Technical",
        "Information Theory"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-character-error-rate",
      "term": "Character Error Rate",
      "definition": "A fine-grained evaluation metric that computes the edit distance between predicted and reference texts at the character level, useful for evaluating OCR systems and speech recognition where partial word matches carry meaningful signal.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-character-n-gram",
      "term": "Character N-gram",
      "definition": "A contiguous sequence of N characters extracted from a word or text, used as features for text classification, language identification, and spelling correction tasks.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-character-level",
      "term": "Character-Level Model",
      "definition": "Models that process text character by character rather than using tokens. More flexible with novel words but typically slower and requiring more parameters for the same capability.",
      "tags": [
        "Architecture",
        "Alternative"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-charades",
      "term": "Charades",
      "definition": "A dataset of 10000 videos of daily indoor activities with temporal annotations for 157 action classes. Collected by workers acting out scripts in their own homes.",
      "tags": [
        "Benchmark",
        "Video"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-charles-babbage",
      "term": "Charles Babbage",
      "definition": "English mathematician and inventor (1791-1871) who conceived the Difference Engine and the Analytical Engine, mechanical general-purpose computers that anticipated key concepts in modern computing and AI.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-chartllama",
      "term": "ChartLlama",
      "definition": "A multimodal large language model fine-tuned for chart understanding that can describe and analyze and reason about diverse chart types.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-chartqa",
      "term": "ChartQA",
      "definition": "A benchmark for question answering about charts and data visualizations. Tests the ability to extract trends comparisons and specific values from chart images.",
      "tags": [
        "Benchmark",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-chat-completion",
      "term": "Chat Completion",
      "definition": "An API endpoint type where the model generates responses in a conversational format. Takes a list of messages (system, user, assistant) and returns the next assistant message.",
      "tags": [
        "API",
        "Technical"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-chat-template",
      "term": "Chat Template",
      "definition": "A structured formatting convention that defines how system messages, user inputs, and assistant responses are tokenized and delimited for multi-turn conversation models.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-chatbot-arena",
      "term": "Chatbot Arena",
      "definition": "An open platform for evaluating LLMs through crowdsourced pairwise comparisons. Produces Elo ratings for language models based on thousands of human preference judgments.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-chatbot-arena-conversations",
      "term": "Chatbot Arena Conversations",
      "definition": "A dataset of conversations from LMSYS Chatbot Arena where users compare responses from different LLMs. Provides human preference data through pairwise model comparisons.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-chatglm",
      "term": "ChatGLM",
      "definition": "A family of bilingual language models based on the General Language Model architecture. Developed by Tsinghua University and Zhipu AI. Features efficient inference and strong performance on Chinese language tasks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-chatglm3",
      "term": "ChatGLM3",
      "definition": "The third generation of the ChatGLM conversational model with improved function calling and code interpretation and long-context handling capabilities.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-chatgpt",
      "term": "ChatGPT",
      "definition": "OpenAI's conversational AI product launched in November 2022. Built on GPT models fine-tuned for dialogue, it popularized conversational AI and sparked widespread public interest in LLMs.",
      "tags": [
        "Product",
        "OpenAI"
      ],
      "domain": "general",
      "link": "chatgpt-guide.html",
      "related": []
    },
    {
      "id": "term-chatgpt-launch",
      "term": "ChatGPT Launch",
      "definition": "OpenAI's release of ChatGPT on November 30, 2022, a conversational AI interface built on GPT-3.5 that reached 100 million users in two months, triggering widespread public engagement with AI and an industry-wide AI race.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-chebyshev-filter",
      "term": "Chebyshev Filter",
      "definition": "A type of analog or digital filter that achieves a steeper roll-off than Butterworth filters at the cost of ripple in the passband (Type I) or stopband (Type II). Named after Pafnuty Chebyshev.",
      "tags": [
        "Algorithms",
        "Technical",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-chebyshev-iteration",
      "term": "Chebyshev Iteration",
      "definition": "An iterative method for solving linear systems that uses Chebyshev polynomials to minimize the error over a known eigenvalue range. Converges faster than simple iteration when spectral bounds are available.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-checklist",
      "term": "CheckList",
      "definition": "A task-agnostic methodology for behavioral testing of NLP models using linguistic capabilities. Provides templates for testing robustness fairness and specific linguistic phenomena.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-checkpoint",
      "term": "Checkpoint",
      "definition": "A saved snapshot of model weights during training. Enables resuming training after interruption, comparing different training stages, and selecting the best performing version.",
      "tags": [
        "Training",
        "Technical"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-checkpoint-and-restart",
      "term": "Checkpoint and Restart",
      "definition": "Technique of periodically saving training state to storage so training can resume from the latest checkpoint after interruptions. Essential for long-running AI training jobs on large clusters.",
      "tags": [
        "Training",
        "Reliability",
        "Technique"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-checkpointing-training",
      "term": "Checkpointing for Training",
      "definition": "The practice of periodically saving model weights, optimizer state, and training metadata to persistent storage during training. Checkpointing enables recovery from hardware failures, job preemptions, and experiment reproduction.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-chem-bench",
      "term": "CHEM-Bench",
      "definition": "A chemistry reasoning benchmark covering diverse chemistry subdisciplines. Tests the ability of AI systems to solve chemical problems and understand molecular properties.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning",
        "Scientific"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-chemical-mechanical-planarization",
      "term": "Chemical Mechanical Planarization",
      "definition": "Process of polishing semiconductor wafers to achieve an extremely flat surface between manufacturing layers. Essential for maintaining focus accuracy in subsequent lithography steps.",
      "tags": [
        "Fabrication",
        "Manufacturing",
        "Process"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-chemllm",
      "term": "ChemLLM",
      "definition": "A large language model specialized for chemistry that handles molecular property prediction and reaction planning and chemical literature understanding.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cheriton-tarjan-algorithm",
      "term": "Cheriton-Tarjan Algorithm",
      "definition": "A minimum spanning tree algorithm that achieves O(E log log V) time for dense graphs. Uses a priority queue based on soft heaps and improves upon the basic greedy approaches for certain graph classes.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-chestx-ray14",
      "term": "ChestX-ray14",
      "definition": "A dataset of 112000 frontal-view chest X-ray images from over 30000 patients annotated with 14 disease labels. One of the first large-scale chest X-ray datasets for deep learning.",
      "tags": [
        "Benchmark",
        "Medical",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-chexnet",
      "term": "CheXNet",
      "definition": "A deep learning model for detecting pneumonia from chest X-rays that uses a 121-layer DenseNet and achieves radiologist-level performance.",
      "tags": [
        "Models",
        "Technical",
        "Medical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-chexpert",
      "term": "CheXpert",
      "definition": "A large chest X-ray dataset from Stanford containing 224000 images with automated labels for 14 radiological observations. Includes an uncertainty-aware labeling approach.",
      "tags": [
        "Benchmark",
        "Medical",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-chgnet",
      "term": "CHGNet",
      "definition": "Crystal Hamiltonian Graph Neural Network is a universal machine learning interatomic potential that incorporates magnetic moments for accurate materials simulation.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-chi-square-distribution",
      "term": "Chi-Square Distribution",
      "definition": "The distribution of the sum of squares of k independent standard normal random variables. It is used in chi-square tests, confidence interval estimation for variance, and goodness-of-fit tests.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-chi-square-test",
      "term": "Chi-Square Test",
      "definition": "A statistical test that evaluates whether observed frequencies differ significantly from expected frequencies under a null hypothesis. It is used for testing independence between categorical variables and goodness of fit.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-child-safety-in-ai",
      "term": "Child Safety in AI",
      "definition": "Protections and design considerations to prevent AI systems from harming minors. Includes age-appropriate content filtering data privacy for children and preventing exploitation or manipulation.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-chilling-effect-of-ai",
      "term": "Chilling Effect of AI",
      "definition": "The phenomenon where awareness of AI surveillance or monitoring causes people to self-censor their speech behavior or activities. Raises concerns about freedom of expression and democratic participation.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-chinchilla",
      "term": "Chinchilla",
      "definition": "A DeepMind model and scaling study showing optimal training requires more data than previously thought. Influenced subsequent model development toward larger datasets.",
      "tags": [
        "Research",
        "Scaling"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-chinchilla-optimal",
      "term": "Chinchilla Optimal",
      "definition": "A training regime derived from DeepMind's Chinchilla scaling laws, suggesting that for a given compute budget, model size and training data should be scaled proportionally for optimal performance.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-chinchilla-paper",
      "term": "Chinchilla Paper",
      "definition": "The 2022 DeepMind paper by Hoffmann et al. demonstrating that many large language models were undertrained relative to their size, establishing new scaling laws suggesting that training data and model size should be scaled equally.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-chinchilla-scaling-laws",
      "term": "Chinchilla Scaling Laws",
      "definition": "Findings published by DeepMind in 2022 (Hoffmann et al.) showing that many large language models were significantly undertrained. The Chinchilla paper demonstrated that for compute-optimal training the number of training tokens should scale proportionally with model parameters.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-chinese-postman-problem",
      "term": "Chinese Postman Problem",
      "definition": "An optimization problem that seeks the shortest closed walk visiting every edge of a graph at least once. Solved in polynomial time for undirected graphs by finding a minimum-weight perfect matching on odd-degree vertices.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-chinese-room-argument",
      "term": "Chinese Room Argument",
      "definition": "A thought experiment by John Searle in 1980 arguing that a computer executing a program cannot have genuine understanding or consciousness, even if it perfectly simulates intelligent conversation, challenging strong AI claims.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-chinook",
      "term": "Chinook",
      "definition": "A computer checkers program developed by Jonathan Schaeffer at the University of Alberta that won the World Checkers Championship in 1994. In 2007 the team proved that perfect play by both sides leads to a draw making checkers the most complex game solved to date.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-chip-packaging",
      "term": "Chip Packaging",
      "definition": "Process of enclosing a semiconductor die in a protective case with electrical connections to the outside world. Advanced packaging enables multi-die designs critical for modern AI chips.",
      "tags": [
        "Fabrication",
        "Packaging"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-chip-on-chip",
      "term": "Chip-on-Chip",
      "definition": "Packaging technique stacking one chip directly on top of another for short high-bandwidth connections. Used in advanced processor packages to integrate logic and memory dies.",
      "tags": [
        "Packaging",
        "Architecture",
        "Advanced"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-chiplet-architecture",
      "term": "Chiplet Architecture",
      "definition": "A processor design approach using multiple small silicon dies (chiplets) connected via high-speed interconnects on a single package. Chiplet designs improve manufacturing yield and enable mixing different process nodes for different functional units.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-chiplet-design",
      "term": "Chiplet Design",
      "definition": "Approach of building processors from multiple smaller dies rather than one large monolithic die. Improves manufacturing yield and allows mixing components made on different process nodes.",
      "tags": [
        "Architecture",
        "Manufacturing",
        "Design"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-chiplet-interconnect-standard",
      "term": "Chiplet Interconnect Standard",
      "definition": "Industry standards like UCIe (Universal Chiplet Interconnect Express) for connecting chiplets from different vendors in a single package. Enables a modular approach to AI chip design.",
      "tags": [
        "Standard",
        "Packaging",
        "Interconnect"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-chips-act",
      "term": "CHIPS Act",
      "definition": "United States legislation providing 52 billion dollars in subsidies for domestic semiconductor manufacturing. Aims to reduce dependence on overseas chip production particularly for AI and defense chips.",
      "tags": [
        "Policy",
        "Legislation",
        "Manufacturing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-chirp-z-transform",
      "term": "Chirp Z-Transform",
      "definition": "A generalization of the DFT that evaluates the Z-transform along spiral contours in the complex plane. Enables frequency analysis with arbitrary frequency resolution and range using FFT-based convolution.",
      "tags": [
        "Algorithms",
        "Technical",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cholesky-decomposition",
      "term": "Cholesky Decomposition",
      "definition": "A matrix factorization that decomposes a symmetric positive-definite matrix into the product of a lower triangular matrix and its transpose. Roughly twice as efficient as LU decomposition for applicable matrices.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-christofides-algorithm",
      "term": "Christofides Algorithm",
      "definition": "An approximation algorithm for the metric traveling salesman problem that guarantees a solution within 3/2 of the optimal tour length. Combines minimum spanning tree construction with minimum-weight perfect matching on odd-degree vertices.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-christopher-watkins",
      "term": "Christopher Watkins",
      "definition": "British computer scientist who introduced Q-learning in his 1989 PhD thesis at Cambridge University. Q-learning is a model-free reinforcement learning algorithm that learns the value of actions in states without requiring a model of the environment.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-chroma",
      "term": "Chroma",
      "definition": "A generative model for designing protein structures and sequences that uses diffusion processes conditioned on desired structural and functional constraints.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-chromadb",
      "term": "ChromaDB",
      "definition": "An open-source embedding database designed for AI applications that provides a simple API for storing, querying, and filtering embeddings with associated metadata, popular for prototyping and lightweight RAG implementations.",
      "tags": [
        "Vector Database",
        "Open Source"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-chronos",
      "term": "Chronos",
      "definition": "A family of pre-trained time series forecasting models from Amazon that tokenize time series values into discrete bins and use language model architectures.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-chunk-overlap",
      "term": "Chunk Overlap",
      "definition": "The number of tokens or characters shared between consecutive chunks during document splitting, ensuring that information spanning chunk boundaries is not lost and maintaining contextual continuity across adjacent segments.",
      "tags": [
        "Retrieval",
        "Preprocessing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-chunk-size",
      "term": "Chunk Size",
      "definition": "The target length of individual text segments produced during document chunking, typically measured in tokens or characters, where smaller chunks enable more precise retrieval while larger chunks preserve more context and coherence.",
      "tags": [
        "Retrieval",
        "Preprocessing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-chunked-prefill",
      "term": "Chunked Prefill",
      "definition": "An inference optimization that breaks the prompt processing phase into smaller chunks to be interleaved with decoding steps. Reduces time-to-first-token latency for long prompts and enables better GPU utilization in serving systems.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-chunking",
      "term": "Chunking",
      "definition": "Splitting long documents into smaller pieces for processing. Essential for RAG and embedding systems where input length exceeds model limits or affects retrieval quality.",
      "tags": [
        "Technique",
        "Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-church-turing-thesis",
      "term": "Church-Turing Thesis",
      "definition": "The hypothesis independently proposed by Alonzo Church and Alan Turing in 1936 that any function computable by an effective procedure can be computed by a Turing machine. The thesis defines the fundamental limits of what is mechanically computable.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cider",
      "term": "CIDEr",
      "definition": "Consensus-based Image Description Evaluation, a metric that measures image captioning quality using TF-IDF weighted n-gram similarity between generated and reference captions, emphasizing informative words that distinguish specific images from the corpus.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cider-score-algorithm",
      "term": "CIDEr Score Algorithm",
      "definition": "Consensus-based Image Description Evaluation measures the similarity of a generated caption to reference captions using TF-IDF weighted n-gram matching. Designed specifically for evaluating image captioning systems.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cifar-organization",
      "term": "CIFAR (Organization)",
      "definition": "The Canadian Institute for Advanced Research a nonprofit research organization that has been instrumental in supporting AI research. CIFAR's Learning in Machines and Brains program provided crucial funding to deep learning researchers during periods when the field was unfashionable.",
      "tags": [
        "History",
        "Organizations"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cifar-10",
      "term": "CIFAR-10",
      "definition": "A dataset of 60000 32x32 color images in 10 classes collected by Alex Krizhevsky and Geoffrey Hinton in 2009. Along with CIFAR-100 it became a standard benchmark for evaluating image classification algorithms in machine learning research.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cifar-100",
      "term": "CIFAR-100",
      "definition": "An extension of CIFAR-10 containing 60000 32x32 color images in 100 fine-grained classes grouped into 20 superclasses. More challenging than CIFAR-10 due to fewer examples per class.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cisc-architecture",
      "term": "CISC Architecture",
      "definition": "Complex Instruction Set Computer design philosophy using variable-length instructions with rich addressing modes. x86 is the dominant CISC architecture in desktop and server computing.",
      "tags": [
        "Architecture",
        "Fundamentals",
        "Design"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-citation-generation",
      "term": "Citation Generation",
      "definition": "The capability of a language model to produce inline references to source documents that support its claims, enabling users to verify the accuracy of generated content.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-citeseer",
      "term": "Citeseer",
      "definition": "A citation network dataset of 3312 scientific papers across 6 classes. Alongside Cora one of the classic small-scale benchmarks for graph-based semi-supervised learning.",
      "tags": [
        "Benchmark",
        "Graph"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cityscapes",
      "term": "Cityscapes",
      "definition": "A dataset of 5000 finely annotated and 20000 coarsely annotated street scene images from 50 cities. Standard benchmark for urban scene understanding and autonomous driving perception.",
      "tags": [
        "Benchmark",
        "Computer Vision",
        "Autonomous Driving"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-civil-comments",
      "term": "Civil Comments",
      "definition": "A dataset of over 2 million public comments annotated for toxicity and identity-based harassment. Used for training content moderation systems and evaluating toxicity detection.",
      "tags": [
        "Benchmark",
        "NLP",
        "Safety"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-civil-society-and-ai",
      "term": "Civil Society and AI",
      "definition": "The role of non-governmental organizations advocacy groups and community organizations in shaping AI policy and holding developers accountable. Provides an important counterbalance to industry and government interests.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-cky-algorithm",
      "term": "CKY Algorithm",
      "definition": "Cocke-Kasami-Younger algorithm, a dynamic programming parser for context-free grammars that builds parse trees bottom-up in O(n^3) time by filling a chart of possible constituents.",
      "tags": [
        "NLP",
        "Parsing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-cladder",
      "term": "CLadder",
      "definition": "A causal reasoning benchmark testing language models on causal inference questions. Evaluates understanding of causation through questions requiring counterfactual and interventional reasoning.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-clap",
      "term": "CLAP",
      "definition": "Contrastive Language-Audio Pretraining aligns audio and text in a shared embedding space for zero-shot audio classification and retrieval tasks.",
      "tags": [
        "Models",
        "Technical",
        "Audio",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-clarans-algorithm",
      "term": "CLARANS Algorithm",
      "definition": "Clustering Large Applications based on Randomized Search is a k-medoids variant designed for large datasets. Uses random sampling of neighbor solutions to efficiently search the space of possible medoid configurations.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-clarity",
      "term": "Clarity (Prompting)",
      "definition": "Using clear, unambiguous language in prompts to reduce misinterpretation. Specific instructions and explicit requirements improve response quality.",
      "tags": [
        "Prompting",
        "Best Practice"
      ],
      "domain": "general",
      "link": "../learn/prompt-basics.html",
      "related": []
    },
    {
      "id": "term-class-activation-map",
      "term": "Class Activation Map",
      "definition": "A visualization technique that highlights the image regions most important for a CNN's classification decision, computed by weighting feature map activations by the classification layer's weights.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-class-imbalance",
      "term": "Class Imbalance",
      "definition": "When training data has unequal representation across categories. Can cause models to favor majority classes. Addressed through sampling, weighting, or specialized techniques.",
      "tags": [
        "Data",
        "Challenge"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-class-weight",
      "term": "Class Weight",
      "definition": "A technique for handling class imbalance by assigning higher weight to the minority class in the loss function, effectively making misclassification of underrepresented classes more costly during training.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-classeval",
      "term": "ClassEval",
      "definition": "A benchmark for evaluating class-level code generation requiring models to generate complete Python classes with multiple methods and complex interdependencies.",
      "tags": [
        "Benchmark",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-classification",
      "term": "Classification",
      "definition": "A machine learning task that assigns input data to predefined categories. Examples include spam detection (spam/not spam), sentiment analysis (positive/negative/neutral), and image recognition.",
      "tags": [
        "ML Task",
        "Supervised"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-classifier-free-guidance",
      "term": "Classifier-Free Guidance",
      "definition": "A technique for conditional diffusion models that interpolates between conditional and unconditional score estimates during sampling, controlling the trade-off between sample quality and diversity without a separate classifier.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-claude",
      "term": "Claude",
      "definition": "An AI assistant created by Anthropic, designed to be helpful, harmless, and honest. Known for nuanced reasoning, long context handling, and strong performance on complex tasks.",
      "tags": [
        "Product",
        "Anthropic"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-claude-ai",
      "term": "Claude (AI)",
      "definition": "A family of AI assistants developed by Anthropic beginning with Claude 1.0 in March 2023. Built using Constitutional AI methods and Reinforcement Learning from Human Feedback. Known for being helpful harmless and honest with strong reasoning capabilities.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-claude-35-haiku",
      "term": "Claude 3.5 Haiku",
      "definition": "A fast and compact model from Anthropic that balances speed with intelligence for high-throughput tasks requiring quick responses.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Products"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-claude-35-sonnet",
      "term": "Claude 3.5 Sonnet",
      "definition": "An updated version of Anthropic Claude Sonnet model with improved coding and reasoning capabilities and a larger 200K context window.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Products"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-claude-haiku",
      "term": "Claude Haiku",
      "definition": "The fastest and most compact model in the Claude family optimized for quick responses and high throughput. Suitable for tasks requiring speed such as customer interactions and content moderation.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-claude-instant",
      "term": "Claude Instant / Haiku",
      "definition": "Anthropic's faster, more cost-effective models for simpler tasks. Trade some capability for speed and lower cost, suitable for classification, extraction, and basic chat.",
      "tags": [
        "Model",
        "Anthropic"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-claude-launch",
      "term": "Claude Launch",
      "definition": "Anthropic's release of Claude, a family of AI assistants trained using Constitutional AI methods, first made available in March 2023, emphasizing safety, helpfulness, and harmlessness in conversational AI.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-claude-opus",
      "term": "Claude Opus",
      "definition": "Anthropic's most capable model, designed for complex reasoning, creative tasks, and nuanced understanding. Higher cost but best performance on difficult tasks.",
      "tags": [
        "Model",
        "Anthropic"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-claude-shannon",
      "term": "Claude Shannon",
      "definition": "American mathematician (1916-2001) known as the father of information theory, whose 1948 paper established the mathematical foundations for digital communication and contributed foundational ideas to early AI research.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-claude-sonnet",
      "term": "Claude Sonnet",
      "definition": "A balanced model in the Claude family offering strong performance with good efficiency. Suitable for a wide range of tasks including coding analysis and content generation.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-clean-room",
      "term": "Clean Room",
      "definition": "Ultra-low particle environment where semiconductor manufacturing takes place. Modern fabs maintain Class 1 or better cleanliness with fewer than one particle per cubic foot of air.",
      "tags": [
        "Fabrication",
        "Manufacturing",
        "Facility"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cleaned-alpaca",
      "term": "Cleaned Alpaca",
      "definition": "A cleaned version of the Stanford Alpaca dataset with improved data quality by fixing hallucinations empty outputs and other issues in the original synthetic training data.",
      "tags": [
        "Training Corpus",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-clever-hans-effect",
      "term": "Clever Hans Effect",
      "definition": "Named after a horse that appeared to perform arithmetic but was actually reading its trainer's body language. In AI it refers to models that appear to perform well on a task but are actually using spurious correlations or shortcuts rather than genuine understanding.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-clevr",
      "term": "CLEVR",
      "definition": "Compositional Language and Elementary Visual Reasoning a synthetic visual QA dataset testing compositional reasoning about 3D rendered objects. Isolates visual reasoning from recognition.",
      "tags": [
        "Benchmark",
        "Multimodal",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cliff-shaw",
      "term": "Cliff Shaw",
      "definition": "American programmer at RAND Corporation who along with Allen Newell and Herbert Simon developed the Logic Theorist (1956) and General Problem Solver. Shaw created the Information Processing Language (IPL) one of the earliest list-processing computer languages.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-climax",
      "term": "ClimaX",
      "definition": "A foundation model for weather and climate science that uses Transformers pre-trained on climate data for various atmospheric prediction tasks.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-clinicalbert",
      "term": "ClinicalBERT",
      "definition": "A BERT model fine-tuned on clinical notes from electronic health records to capture medical language patterns for clinical NLP applications.",
      "tags": [
        "Models",
        "Technical",
        "Medical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-clip",
      "term": "CLIP",
      "definition": "Contrastive Language-Image Pre-training, a model that learns visual concepts from natural language supervision by training image and text encoders jointly to match images with their text descriptions.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-clipped-surrogate-objective",
      "term": "Clipped Surrogate Objective",
      "definition": "The core optimization objective in PPO that clips the probability ratio between new and old policies, preventing excessively large updates. This simple mechanism provides trust-region-like stability without the computational cost of TRPO.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-clips",
      "term": "CLIPS",
      "definition": "The C Language Integrated Production System developed by NASA's Johnson Space Center in 1985. An expert system shell designed for building rule-based and object-based expert systems. CLIPS became widely used in government industry and academia for knowledge-based applications.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-clock-cycle",
      "term": "Clock Cycle",
      "definition": "Single tick of a processor clock representing the smallest unit of time for digital operations. Processor speed measured in clock cycles per second (hertz) determines raw computation rate.",
      "tags": [
        "Architecture",
        "Fundamentals",
        "Metric"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cloud-computing-ai",
      "term": "Cloud Computing for AI",
      "definition": "The use of cloud infrastructure services (AWS, GCP, Azure) for AI model training and inference, providing on-demand access to GPU clusters without capital expenditure. Cloud AI services range from raw GPU instances to fully managed training and serving platforms.",
      "tags": [
        "Distributed Computing",
        "Inference Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cloud-gpu-instance",
      "term": "Cloud GPU Instance",
      "definition": "Virtual machine in a cloud data center with attached GPU accelerators for AI workloads. Major providers offer instances with NVIDIA A100 H100 and other GPUs on demand.",
      "tags": [
        "Cloud",
        "GPU",
        "Service"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cloze",
      "term": "Cloze Task",
      "definition": "A task where models predict missing words in text. A classic NLP benchmark and training objective. BERT's masked language modeling is a form of cloze task.",
      "tags": [
        "Task",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-clustering",
      "term": "Clustering",
      "definition": "An unsupervised learning technique that groups similar data points together without predefined labels. Used for customer segmentation, document organization, and pattern discovery.",
      "tags": [
        "ML Task",
        "Unsupervised"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-clutrr",
      "term": "CLUTRR",
      "definition": "Compositional Language Understanding and Textual Reasoning a benchmark testing systematic generalization in kinship reasoning. Tests the ability to infer family relationships from stories.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cma-es",
      "term": "CMA-ES",
      "definition": "Covariance Matrix Adaptation Evolution Strategy is a derivative-free optimization algorithm that adapts its search distribution by updating the covariance matrix of a multivariate normal. Considered state-of-the-art for continuous black-box optimization.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cmmlu",
      "term": "CMMLU",
      "definition": "Chinese Massive Multitask Language Understanding a comprehensive benchmark testing knowledge and reasoning across 67 Chinese-specific subjects covering STEM humanities and social sciences.",
      "tags": [
        "Benchmark",
        "NLP",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cmos",
      "term": "CMOS",
      "definition": "Complementary Metal-Oxide-Semiconductor technology using paired NMOS and PMOS transistors for logic circuits. The dominant manufacturing technology for virtually all modern digital chips including AI processors.",
      "tags": [
        "Fabrication",
        "Technology",
        "Fundamentals"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cmu-ai-research",
      "term": "CMU AI Research",
      "definition": "Carnegie Mellon University's AI research programs, including the work of Allen Newell and Herbert Simon, the development of expert systems, and pioneering contributions to robotics, speech recognition, and autonomous vehicles.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cnn",
      "term": "CNN (Convolutional Neural Network)",
      "definition": "A neural network architecture designed for processing grid-like data such as images. Uses convolutional layers to automatically learn spatial hierarchies of features.",
      "tags": [
        "Architecture",
        "Computer Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cnndailymail",
      "term": "CNN/DailyMail",
      "definition": "A dataset of over 300000 news articles from CNN and the Daily Mail paired with multi-sentence summaries. One of the most widely used benchmarks for abstractive text summarization.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-co-detr",
      "term": "Co-DETR",
      "definition": "Collaborative DETR is a detection Transformer that uses collaborative hybrid assignments from multiple parallel heads to improve training efficiency and accuracy.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-co-occurrence-matrix",
      "term": "Co-occurrence Matrix",
      "definition": "A matrix recording how often pairs of words appear together within a defined context window across a corpus, used as the basis for distributional word representations like GloVe.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-co-packaged-optics",
      "term": "Co-Packaged Optics",
      "definition": "Technology integrating optical transceivers directly into switch packages rather than using separate pluggable modules. Reduces power consumption and increases bandwidth density for AI networking.",
      "tags": [
        "Networking",
        "Photonic",
        "Packaging"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-co-training",
      "term": "Co-Training",
      "definition": "A semi-supervised learning method that trains two classifiers on different views or feature sets of the data. Each classifier labels unlabeled examples for the other creating a mutual teaching loop. Requires conditionally independent feature views.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-coarse-grained-reconfigurable-architecture",
      "term": "Coarse-Grained Reconfigurable Architecture",
      "definition": "Programmable hardware architecture operating on word-level data paths rather than individual bits like FPGAs. Offers better energy efficiency for AI inference than general-purpose processors.",
      "tags": [
        "Architecture",
        "Reconfigurable",
        "Emerging"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-coaxial-cable",
      "term": "Coaxial Cable",
      "definition": "Electrical cable with concentric conductors historically used for data networking. Has been largely replaced by fiber optics in modern data centers but remains relevant in some legacy installations.",
      "tags": [
        "Networking",
        "Historical",
        "Physical"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-coca",
      "term": "CoCa",
      "definition": "Contrastive Captioners is a model from Google that combines contrastive learning with image captioning in a unified encoder-decoder framework for visual understanding.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cocktail-shaker-sort",
      "term": "Cocktail Shaker Sort",
      "definition": "A bidirectional variant of bubble sort that traverses the list alternately from left to right and right to left. Slightly more efficient than standard bubble sort for certain types of partially sorted data.",
      "tags": [
        "Algorithms",
        "Technical",
        "Sorting"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-coco",
      "term": "COCO",
      "definition": "The Common Objects in Context dataset containing over 330000 images with object detection segmentation and captioning annotations for 80 object categories. A primary benchmark for computer vision tasks.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-coco-captions",
      "term": "COCO Captions",
      "definition": "A subset of the COCO dataset with five human-written captions per image totaling over 1.5 million captions. Widely used for training and evaluating image captioning models.",
      "tags": [
        "Benchmark",
        "Computer Vision",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-coco-dataset",
      "term": "COCO Dataset",
      "definition": "Common Objects in Context, a large-scale benchmark dataset containing images with annotations for object detection, instance segmentation, keypoint detection, and image captioning across 80 object categories.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-coco-panoptic",
      "term": "COCO Panoptic",
      "definition": "An extension of COCO that unifies instance and semantic segmentation into panoptic segmentation where every pixel receives both a semantic label and an instance identity.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-code-alpaca",
      "term": "Code Alpaca",
      "definition": "A dataset of 20000 code instruction-following examples generated using the Self-Instruct framework. Used for fine-tuning language models on coding tasks.",
      "tags": [
        "Training Corpus",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-code-as-policies",
      "term": "Code as Policies",
      "definition": "A framework that uses large language models to generate robot policy code from natural language instructions enabling flexible and interpretable robotic behaviors.",
      "tags": [
        "Models",
        "Technical",
        "Robotics"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-code-generation",
      "term": "Code Generation",
      "definition": "The ability of AI models to write programming code from natural language descriptions. Powers tools like GitHub Copilot, Cursor, and code-focused features in general LLMs.",
      "tags": [
        "Application",
        "Development"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-code-generation-prompting",
      "term": "Code Generation Prompting",
      "definition": "Specialized prompting techniques for producing high-quality code, incorporating language specification, function signatures, docstrings, test cases, and algorithmic constraints to guide models toward correct and efficient implementations.",
      "tags": [
        "Prompt Engineering",
        "Code"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-code-interpreter",
      "term": "Code Interpreter",
      "definition": "AI capability to write and execute code, enabling data analysis, visualization, and computation. ChatGPT's code interpreter runs Python in a sandbox environment.",
      "tags": [
        "Feature",
        "Tool Use"
      ],
      "domain": "general",
      "link": "chatgpt-guide.html",
      "related": []
    },
    {
      "id": "term-code-llama",
      "term": "Code Llama",
      "definition": "A specialized version of LLaMA fine-tuned for code generation and understanding. Available in base Python and instruction-tuned variants. Supports infilling and long-context code understanding up to 100K tokens.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-code-llm",
      "term": "Code LLM",
      "definition": "Language models specialized for programming tasks. Examples include Codex, StarCoder, and Code Llama. Often trained on large code corpora from GitHub and similar sources.",
      "tags": [
        "Model Type",
        "Specialized"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-code-switching",
      "term": "Code-Switching",
      "definition": "The phenomenon of alternating between two or more languages within a single conversation or utterance, posing challenges for NLP systems designed for monolingual text processing.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-codebleu",
      "term": "CodeBLEU",
      "definition": "A code evaluation metric that extends BLEU with code-specific components including abstract syntax tree matching, data-flow analysis, and weighted n-gram matching, capturing both syntactic correctness and semantic similarity of generated code.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-codecontests",
      "term": "CodeContests",
      "definition": "A competitive programming dataset from Google DeepMind containing problems from Codeforces and other platforms. Used to train AlphaCode with problems solutions and test cases.",
      "tags": [
        "Benchmark",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-codeforces-dataset",
      "term": "Codeforces Dataset",
      "definition": "A collection of competitive programming problems from the Codeforces platform with solutions and test cases. Used for evaluating advanced algorithmic problem solving in AI.",
      "tags": [
        "Benchmark",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-codegemma",
      "term": "CodeGemma",
      "definition": "A collection of code-specialized models from Google built on the Gemma architecture for code generation and infilling and instruction following.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-codegen",
      "term": "CodeGen",
      "definition": "A family of large language models for program synthesis that convert natural language descriptions into executable code. Trained with multi-turn program synthesis enabling iterative code generation through conversation.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-codeparrot",
      "term": "CodeParrot",
      "definition": "An open-source dataset of Python code from GitHub used to train the CodeParrot code generation model. Contains approximately 180GB of deduplicated Python source code.",
      "tags": [
        "Training Corpus",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-codeqwen",
      "term": "CodeQwen",
      "definition": "A code-specialized model from the Qwen family trained on diverse programming language data for code generation and understanding and debugging.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-codesearchnet",
      "term": "CodeSearchNet",
      "definition": "A dataset and benchmark for code search and code summarization spanning six programming languages. Contains 2 million code-comment pairs for training code understanding models.",
      "tags": [
        "Benchmark",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-codeshell",
      "term": "CodeShell",
      "definition": "A 7 billion parameter code foundation model trained on 500 billion tokens of code and text data for diverse programming language generation.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-codestral",
      "term": "Codestral",
      "definition": "A code-focused large language model from Mistral AI trained on diverse programming languages for code generation and completion and explanation tasks.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-codex",
      "term": "Codex",
      "definition": "An OpenAI model fine-tuned from GPT-3 on publicly available code from GitHub. Powers GitHub Copilot for code completion and generation. Proficient in Python and supports dozens of programming languages.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-codexglue",
      "term": "CodeXGLUE",
      "definition": "A benchmark for code intelligence covering 10 code-related tasks including code completion translation and summarization. Tests broad code understanding and generation capabilities.",
      "tags": [
        "Benchmark",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cogagent",
      "term": "CogAgent",
      "definition": "A visual language model from Tsinghua that specializes in GUI understanding and navigation with the ability to interact with graphical user interfaces.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cognitive-liberty",
      "term": "Cognitive Liberty",
      "definition": "The right of individuals to maintain sovereignty over their own thought processes and mental states free from manipulation by AI or neurotechnology. An emerging concept in digital rights and neuroethics.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-cognitive-load",
      "term": "Cognitive Load (Prompting)",
      "definition": "The mental effort required to process complex prompts. Simpler, well-organized prompts often yield better results by reducing the model's processing burden.",
      "tags": [
        "Prompting",
        "Best Practice"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-cogvideo",
      "term": "CogVideo",
      "definition": "A large-scale pre-trained text-to-video generation model from Tsinghua University that inherits knowledge from CogView for video creation.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cogvideox",
      "term": "CogVideoX",
      "definition": "An extended version of CogVideo with improved temporal coherence and video quality for generating longer and more detailed video sequences from text.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cogvlm",
      "term": "CogVLM",
      "definition": "A visual language model that integrates vision features deep into the language model through a visual expert module in every attention and FFN layer. Achieves strong visual understanding without sacrificing language model capability.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cohens-kappa",
      "term": "Cohen's Kappa",
      "definition": "A statistic measuring inter-rater agreement for categorical items that accounts for agreement occurring by chance. Values range from -1 to 1, with 1 indicating perfect agreement beyond chance.",
      "tags": [
        "Statistics",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cohere",
      "term": "Cohere",
      "definition": "An enterprise AI company providing LLMs for text generation, embeddings, and search. Known for Command models and focus on enterprise use cases with strong RAG capabilities.",
      "tags": [
        "Company",
        "LLM Provider"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cohere-aya-expanse",
      "term": "Cohere Aya Expanse",
      "definition": "An extended multilingual model from Cohere For AI building on the Aya project with expanded language coverage and improved cross-lingual performance.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cohere-command",
      "term": "Cohere Command",
      "definition": "A family of generative language models by Cohere designed for enterprise applications. Optimized for instruction following text generation and tool use. Available in multiple sizes for different deployment needs.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cohere-embed",
      "term": "Cohere Embed",
      "definition": "A family of embedding models by Cohere designed for search and retrieval applications. Supports over 100 languages with state-of-the-art performance on multilingual benchmarks. Offers compression for efficient storage.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cohere-embed-v3",
      "term": "Cohere Embed v3",
      "definition": "The third generation of Cohere embedding model featuring improved multilingual support and compression-aware training for efficient vector search.",
      "tags": [
        "Models",
        "Technical",
        "Embedding",
        "NLP",
        "Products"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-coherence-modeling",
      "term": "Coherence Modeling",
      "definition": "The computational assessment of how well sentences in a text flow together logically and topically, evaluating whether a text reads naturally and maintains consistent themes and references.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-coherence-score",
      "term": "Coherence Score",
      "definition": "An evaluation metric that assesses the logical consistency and semantic flow of generated text, measuring whether ideas connect naturally, maintain topical consistency, and form a well-structured narrative.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-coinflip",
      "term": "CoinFlip",
      "definition": "A simple benchmark testing language models on symbolic reasoning by tracking coin flip state changes. Tests the ability to maintain and update state through sequential operations.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cointegration",
      "term": "Cointegration",
      "definition": "A statistical property of two or more non-stationary time series that share a common stochastic trend, meaning a linear combination of them is stationary. It implies a long-run equilibrium relationship.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cola",
      "term": "CoLA",
      "definition": "The Corpus of Linguistic Acceptability containing 10657 English sentences annotated for grammatical acceptability by expert linguists. Tests linguistic competence within the GLUE benchmark.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-colbert",
      "term": "ColBERT",
      "definition": "A late-interaction retrieval model that independently encodes queries and documents into per-token embeddings, then scores relevance through efficient MaxSim operations between the two sets of embeddings.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cold-start",
      "term": "Cold Start Problem",
      "definition": "Difficulty making predictions for new users or items with no historical data. Common in recommendation systems. Addressed with hybrid approaches combining collaborative and content-based methods.",
      "tags": [
        "Challenge",
        "Recommendations"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-collaborative-filtering",
      "term": "Collaborative Filtering",
      "definition": "Recommendation technique based on user behavior patterns. \"Users who liked X also liked Y.\" Forms the basis of many recommendation systems at Netflix, Amazon, etc.",
      "tags": [
        "Technique",
        "Recommendations"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-collaborative-filtering-model",
      "term": "Collaborative Filtering Model",
      "definition": "A recommendation approach that predicts user preferences by finding patterns in the collective behavior of many users and items.",
      "tags": [
        "Models",
        "Fundamentals",
        "Recommendation"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-collection",
      "term": "Collection",
      "definition": "A named grouping of vectors and their associated metadata within a vector database, analogous to a table in relational databases, serving as the primary organizational unit for storing and querying related embeddings.",
      "tags": [
        "Vector Database",
        "Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-collective-action-in-ai-safety",
      "term": "Collective Action in AI Safety",
      "definition": "The challenge of coordinating multiple AI developers and nations to invest in safety measures when competitive pressures incentivize racing ahead. A classic collective action problem in AI governance.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-collective-communication",
      "term": "Collective Communication",
      "definition": "Coordinated data exchange patterns among multiple processes or GPUs, including all-reduce, all-gather, reduce-scatter, and broadcast. Efficient collective communication is fundamental to scaling distributed AI training.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-collocation",
      "term": "Collocation",
      "definition": "A sequence of words that co-occur more frequently than expected by chance, forming conventional expressions such as 'strong coffee' or 'make a decision' that are identified through statistical measures.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-colocation-data-center",
      "term": "Colocation Data Center",
      "definition": "Third-party facility where organizations rent space power and cooling for their own computing equipment. Used by AI companies that need physical control over their training hardware.",
      "tags": [
        "Data Center",
        "Infrastructure",
        "Service"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-colossus-computer",
      "term": "Colossus Computer",
      "definition": "The world's first programmable electronic digital computer, built at Bletchley Park in 1943-1944 to break German Lorenz cipher messages, representing a crucial step toward the general-purpose computers needed for AI.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-column-generation",
      "term": "Column Generation",
      "definition": "An optimization technique for solving large linear programs with many variables by starting with a restricted set of columns and iteratively adding profitable columns. Used in vehicle routing and crew scheduling.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-comb-sort",
      "term": "Comb Sort",
      "definition": "An improvement over bubble sort that uses a shrinking gap to compare and swap elements. The gap starts large and shrinks by a factor of approximately 1.3 each pass until it reaches one.",
      "tags": [
        "Algorithms",
        "Technical",
        "Sorting"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-combinatorial-explosion",
      "term": "Combinatorial Explosion",
      "definition": "The rapid growth of possible states or paths in a problem space as the number of variables increases. A fundamental challenge in AI search and planning combinatorial explosion limits brute-force approaches and motivated the development of heuristic search methods.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-comet-reference-data",
      "term": "COMET Reference Data",
      "definition": "Evaluation data for the COMET machine translation metric which uses neural models to predict translation quality scores that correlate with human judgments.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation",
        "Translation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-command-model",
      "term": "Command Model",
      "definition": "Cohere's instruction-tuned LLMs optimized for following commands and business applications. Includes Command R for RAG and enterprise use cases.",
      "tags": [
        "Model",
        "Cohere"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-command-r",
      "term": "Command R",
      "definition": "A family of language models by Cohere optimized for retrieval-augmented generation and tool use. Designed for enterprise applications with strong grounding in retrieved documents and citation generation capabilities.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-commitbench",
      "term": "CommitBench",
      "definition": "A benchmark of code changes from real git commits testing the ability to generate meaningful code modifications. Tests understanding of incremental software development.",
      "tags": [
        "Benchmark",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-commitpack",
      "term": "CommitPack",
      "definition": "A dataset of 4 terabytes of Git commits across 350 programming languages. Provides code change data for training models on code editing and commit message generation.",
      "tags": [
        "Training Corpus",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-common-crawl",
      "term": "Common Crawl",
      "definition": "A massive open repository of web data used to train many LLMs. Contains petabytes of text crawled from the internet, requiring careful filtering for quality and safety.",
      "tags": [
        "Data",
        "Training"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-common-voice",
      "term": "Common Voice",
      "definition": "A Mozilla project collecting a massively multilingual open-source dataset of human speech. Contains validated recordings in over 100 languages contributed by volunteers worldwide.",
      "tags": [
        "Training Corpus",
        "Speech",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-commonsense-reasoning",
      "term": "Commonsense Reasoning",
      "definition": "AI's ability to understand everyday knowledge humans take for granted. That water is wet, objects fall down, people need sleep. A challenging area where LLMs have improved dramatically.",
      "tags": [
        "Capability",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-commonsenseqa",
      "term": "CommonsenseQA",
      "definition": "A question answering dataset requiring diverse types of commonsense knowledge. Contains 12247 questions generated from ConceptNet knowledge graph edges testing broad world knowledge.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-commonsenseqa-20",
      "term": "CommonsenseQA 2.0",
      "definition": "A successor to CommonsenseQA with harder commonsense reasoning questions generated through a gamified approach. Uses yes/no format with validated human agreement scores.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-communication-marl",
      "term": "Communication in Multi-Agent RL",
      "definition": "Protocols and mechanisms that allow agents in a multi-agent system to share information through learned communication channels. Emergent communication can develop structured language-like properties through reinforcement learning.",
      "tags": [
        "Reinforcement Learning",
        "Multi-Agent"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-communication-overlap",
      "term": "Communication Overlap",
      "definition": "A distributed training optimization that overlaps gradient communication with backward pass computation, hiding communication latency behind useful work. Bucketed all-reduce and asynchronous communication enable effective overlap.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-communication-bound",
      "term": "Communication-Bound",
      "definition": "Condition where distributed training speed is limited by network bandwidth between nodes. Becomes the dominant bottleneck when scaling AI training to very large GPU clusters.",
      "tags": [
        "Performance",
        "Analysis",
        "Distributed"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-companion-matrix-method",
      "term": "Companion Matrix Method",
      "definition": "A technique for finding polynomial roots by computing the eigenvalues of the companion matrix. Converts the root-finding problem into a well-studied eigenvalue problem solvable by standard linear algebra methods.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-competitive-rl",
      "term": "Competitive Reinforcement Learning",
      "definition": "A multi-agent RL setting where agents have opposing objectives, such as zero-sum games. Competitive RL involves finding Nash equilibria and developing strategies robust to adversarial opponents.",
      "tags": [
        "Reinforcement Learning",
        "Multi-Agent"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-compile-time-graph-optimization",
      "term": "Compile-Time Graph Optimization",
      "definition": "Static optimization of computation graphs before execution, including constant folding, dead code elimination, and operator fusion. Ahead-of-time compilation produces more efficient execution plans than dynamic interpretation.",
      "tags": [
        "Inference Infrastructure",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-completion",
      "term": "Completion",
      "definition": "Text generated by an AI to continue a given prompt. The basic operation of language models: given input text, predict what comes next.",
      "tags": [
        "Task",
        "Fundamentals"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-complexity-based-prompting",
      "term": "Complexity-Based Prompting",
      "definition": "A self-consistency variant that selects the final answer from reasoning chains with the highest complexity, measured by the number of reasoning steps, based on the observation that more detailed reasoning chains tend to produce more accurate answers.",
      "tags": [
        "Prompt Engineering",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-compliance-by-design",
      "term": "Compliance-by-Design",
      "definition": "An approach to AI development that embeds regulatory compliance requirements into the system design and development process from the outset rather than adding compliance measures retroactively.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-composable-infrastructure",
      "term": "Composable Infrastructure",
      "definition": "Data center architecture where compute storage and networking resources can be dynamically assembled and reassembled into different configurations. Enables flexible allocation for varying AI workloads.",
      "tags": [
        "Infrastructure",
        "Architecture",
        "Flexible"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-compositional-robustness",
      "term": "Compositional Robustness",
      "definition": "The ability of an AI system to maintain safe behavior when its components are combined in new ways or deployed in contexts different from those anticipated during development.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-compositionality",
      "term": "Compositionality",
      "definition": "The principle that the meaning of a complex expression is determined by the meanings of its parts and the rules used to combine them, a foundational concept in formal semantics.",
      "tags": [
        "NLP",
        "Linguistics"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-compressed-trie-algorithm",
      "term": "Compressed Trie Algorithm",
      "definition": "A space-optimized trie that merges chains of single-child nodes into single edges labeled with strings. Also known as a Patricia tree or radix tree and reduces memory usage compared to standard tries.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-compression",
      "term": "Compression (Model)",
      "definition": "Reducing model size while maintaining performance. Techniques include quantization, pruning, and distillation. Enables deployment on edge devices and reduces costs.",
      "tags": [
        "Optimization",
        "Deployment"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-compute",
      "term": "Compute",
      "definition": "Computational resources required for training and running AI models. Measured in FLOPs, GPU-hours, or dollars. A primary constraint and cost driver in AI development.",
      "tags": [
        "Infrastructure",
        "Resources"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-compute-express-link",
      "term": "Compute Express Link",
      "definition": "Cache-coherent interconnect standard built on PCIe physical layer that enables shared memory between CPUs GPUs and accelerators. Allows memory pooling across devices in AI systems.",
      "tags": [
        "Interconnect",
        "Memory",
        "Standard"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-compute-governance",
      "term": "Compute Governance",
      "definition": "Policy approaches that use computational resources as a lever for AI governance, including monitoring large training runs, export controls on AI chips, and reporting requirements for compute-intensive AI development.",
      "tags": [
        "Governance",
        "AI Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-compute-bound",
      "term": "Compute-Bound Workload",
      "definition": "A processing task where performance is limited by the rate of arithmetic computation rather than memory bandwidth or I/O. Training large models with large batch sizes is typically compute-bound, benefiting from more FLOPS capacity.",
      "tags": [
        "Hardware",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-compute-optimal-training",
      "term": "Compute-Optimal Training",
      "definition": "An approach to model training that seeks the best allocation of a fixed compute budget between model parameters and training tokens, based on empirical scaling law research.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-computer-vision",
      "term": "Computer Vision",
      "definition": "The field of AI that enables machines to interpret and understand visual information from images and videos. Applications include object detection, facial recognition, and medical imaging.",
      "tags": [
        "Field",
        "Images"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-computer-vision-history",
      "term": "Computer Vision History",
      "definition": "The evolution of computer vision from early edge detection and pattern recognition in the 1960s through feature-based methods like SIFT and HOG to the deep learning revolution triggered by AlexNet in 2012.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-computing-machinery-and-intelligence",
      "term": "Computing Machinery and Intelligence",
      "definition": "A seminal 1950 paper by Alan Turing published in the journal Mind that proposed the imitation game (later known as the Turing Test) as a way to evaluate machine intelligence. The paper addressed objections to the possibility of machine thinking.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-concept-drift",
      "term": "Concept Drift",
      "definition": "When the relationship between input and output changes over time, causing model performance to degrade. Requires monitoring and retraining to maintain accuracy.",
      "tags": [
        "Challenge",
        "Production"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-conceptnet",
      "term": "ConceptNet",
      "definition": "A multilingual knowledge graph connecting everyday concepts with labeled relationships. Contains over 21 million edges representing commonsense knowledge in multiple languages.",
      "tags": [
        "Knowledge",
        "Graph",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-conceptual-12m",
      "term": "Conceptual 12M",
      "definition": "An expanded version of Conceptual Captions with 12 million image-caption pairs. Relaxes quality filters to provide more training data for vision-language pretraining at scale.",
      "tags": [
        "Training Corpus",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-conceptual-captions",
      "term": "Conceptual Captions",
      "definition": "A dataset of approximately 3.3 million image-caption pairs automatically harvested from the web. Used for pretraining vision-language models with weakly supervised image descriptions.",
      "tags": [
        "Training Corpus",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-conceptual-dependency-theory",
      "term": "Conceptual Dependency Theory",
      "definition": "A theory of natural language understanding developed by Roger Schank in the 1970s that represents the meaning of sentences using a small set of primitive actions and conceptual categories independent of the specific language used.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-condition-number-analysis",
      "term": "Condition Number Analysis",
      "definition": "A numerical analysis technique that measures how sensitive the solution of a problem is to perturbations in the input data. A large condition number indicates ill-conditioning and potential numerical instability.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-conditional-gan",
      "term": "Conditional GAN",
      "definition": "A GAN variant where both generator and discriminator receive additional conditioning information such as class labels or text, enabling controlled generation of specific categories or attributes.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-conditional-generation",
      "term": "Conditional Generation",
      "definition": "Generating content based on specific conditions or inputs. Image generation conditioned on text, or text generation conditioned on a topic or style.",
      "tags": [
        "Technique",
        "Generation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-crf",
      "term": "Conditional Random Field",
      "definition": "A discriminative probabilistic model for sequence labeling that models the conditional probability of label sequences given observations, capturing dependencies between adjacent labels.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-confabulation",
      "term": "Confabulation",
      "definition": "Another term for hallucinationwhen AI generates plausible but false information. The model \"fills in gaps\" with invented content that sounds convincing.",
      "tags": [
        "Risk",
        "Limitation"
      ],
      "domain": "safety",
      "link": "../tools/hallucination.html",
      "related": []
    },
    {
      "id": "term-confidence-interval",
      "term": "Confidence Interval",
      "definition": "A range of values constructed from sample data that, if the sampling procedure were repeated many times, would contain the true population parameter a specified percentage (e.g., 95%) of the time.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-confidence-score",
      "term": "Confidence Score",
      "definition": "A numerical value indicating how certain a model is about its prediction or output. Higher scores suggest the model is more sure, though confidence doesn't always correlate with accuracy.",
      "tags": [
        "Metrics",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-confidence-threshold-cv",
      "term": "Confidence Threshold",
      "definition": "The minimum prediction score required to accept a detection as valid, balancing between missing true detections (high threshold) and including false positives (low threshold).",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-confirmation-bias-in-ai",
      "term": "Confirmation Bias in AI",
      "definition": "The tendency for AI developers or users to favor data, model outputs, or evaluation criteria that confirm pre-existing beliefs, leading to biased system design and selective interpretation of results.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-conformer",
      "term": "Conformer",
      "definition": "A speech processing architecture that combines convolution and transformer modules in each block, capturing both local and global dependencies for improved automatic speech recognition.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-conformity-assessment-for-ai",
      "term": "Conformity Assessment for AI",
      "definition": "The formal evaluation process required under the EU AI Act to verify that high-risk AI systems meet regulatory requirements before being placed on the market, including both self-assessment and third-party audit pathways.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-confounding-variable",
      "term": "Confounding Variable",
      "definition": "A variable that influences both the independent and dependent variables, creating a spurious association between them. Failure to control for confounders can lead to incorrect causal conclusions.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-confusion-matrix",
      "term": "Confusion Matrix",
      "definition": "A table showing correct and incorrect predictions for each class. Reveals where a classification model makes mistakes, enabling targeted improvements.",
      "tags": [
        "Evaluation",
        "Visualization"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-conjugate-direction-method",
      "term": "Conjugate Direction Method",
      "definition": "A family of iterative optimization methods that generate search directions conjugate with respect to a positive-definite matrix. Guarantees convergence in at most n steps for n-dimensional quadratic functions.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-conjugate-gradient-method",
      "term": "Conjugate Gradient Method",
      "definition": "An iterative optimization algorithm for solving systems of linear equations with symmetric positive-definite matrices. Also adapted for nonlinear optimization. Converges in at most n steps for an n-dimensional problem.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-conjugate-prior",
      "term": "Conjugate Prior",
      "definition": "A prior distribution that, when combined with a particular likelihood function via Bayes' theorem, yields a posterior distribution in the same family as the prior. It simplifies Bayesian computations to closed-form updates.",
      "tags": [
        "Statistics",
        "Bayesian Methods"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-conll-shared-tasks",
      "term": "CoNLL Shared Tasks",
      "definition": "A series of influential NLP shared task datasets covering named entity recognition chunking semantic role labeling and coreference resolution. Standard benchmarks for sequence labeling.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-connected-components-labeling",
      "term": "Connected Components Labeling",
      "definition": "An algorithm that assigns a unique label to each connected region of pixels in a binary image. Two-pass algorithms use equivalence tables while union-find based methods achieve near-linear time complexity.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-connection-machine",
      "term": "Connection Machine",
      "definition": "A series of massively parallel supercomputers designed by Danny Hillis at Thinking Machines Corporation in the 1980s. The Connection Machine CM-1 (1985) had up to 65536 processors and was designed for AI applications including neural networks and parallel computation.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-connectionism",
      "term": "Connectionism",
      "definition": "A theoretical framework in cognitive science and AI that models mental phenomena using interconnected networks of simple units. The connectionist approach contrasts with symbolic AI by emphasizing distributed representations and learning from data rather than explicit rules.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-connectionism-vs-symbolism",
      "term": "Connectionism vs Symbolism",
      "definition": "The historical debate in AI between connectionist approaches using neural networks that learn distributed representations and symbolic approaches using explicit rules and logic for knowledge representation and reasoning.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-connectionist-revival",
      "term": "Connectionist Revival",
      "definition": "The resurgence of interest in neural networks in the 1980s driven by the parallel distributed processing (PDP) research group including Rumelhart McClelland and Hinton. Their two-volume work Parallel Distributed Processing (1986) provided theoretical foundations for modern connectionism.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-consensus-clustering",
      "term": "Consensus Clustering",
      "definition": "An ensemble method that combines multiple clustering results to produce a single robust partition. Runs the base clustering algorithm many times with different parameters or subsamples and aggregates the results.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-consent-in-ai",
      "term": "Consent in AI",
      "definition": "The principle that individuals should give informed voluntary consent before their data is used to train AI systems or before AI systems make decisions affecting them.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-consent-laundering",
      "term": "Consent Laundering",
      "definition": "The practice of obtaining user consent for data collection through opaque terms of service and then repurposing that data for AI training in ways that users neither anticipated nor meaningfully agreed to.",
      "tags": [
        "Privacy",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-consequential-decision-making",
      "term": "Consequential Decision-Making",
      "definition": "AI applications that make or significantly influence decisions with material effects on people's lives such as hiring lending healthcare and criminal justice.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-conservative-q-learning",
      "term": "Conservative Q-Learning (CQL)",
      "definition": "An offline RL algorithm that adds a regularizer to penalize Q-values for out-of-distribution actions, producing conservative value estimates that avoid overestimation of unseen state-action pairs. CQL provides lower-bound guarantees on policy performance.",
      "tags": [
        "Reinforcement Learning",
        "Value Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-consistency",
      "term": "Consistency",
      "definition": "A property of a statistical estimator indicating that it converges in probability to the true parameter value as the sample size approaches infinity. Consistent estimators become arbitrarily accurate with enough data.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-consistency-model",
      "term": "Consistency Model",
      "definition": "A generative model that learns to map any point along a diffusion trajectory directly to the trajectory's starting point, enabling one-step or few-step generation without iterative denoising.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-consistency-regularization",
      "term": "Consistency Regularization",
      "definition": "A semi-supervised learning principle that enforces the model to produce similar predictions for perturbed versions of the same input. Encourages smooth decision boundaries. Used in methods like Mean Teacher and FixMatch.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-consistency-based-self-evaluation",
      "term": "Consistency-Based Self-Evaluation",
      "definition": "An evaluation method where a language model assesses the quality of its own outputs by generating multiple responses and measuring agreement across them, using high consistency as a proxy for confidence and correctness.",
      "tags": [
        "Evaluation",
        "LLM-Based"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-consistent-hashing-algorithm",
      "term": "Consistent Hashing Algorithm",
      "definition": "A distributed hashing scheme that minimizes key redistribution when nodes are added or removed. Maps both keys and nodes to a ring and assigns each key to the nearest node in clockwise direction.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-constant-q-transform",
      "term": "Constant-Q Transform",
      "definition": "A time-frequency transform where the frequency bins have a constant ratio of center frequency to bandwidth. Provides logarithmic frequency resolution matching musical perception and is used in music analysis.",
      "tags": [
        "Algorithms",
        "Technical",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-constituency-parsing",
      "term": "Constituency Parsing",
      "definition": "The task of analyzing sentence structure by breaking it into hierarchical nested constituents (phrases) according to a grammar, producing a tree showing how words group into larger syntactic units.",
      "tags": [
        "NLP",
        "Parsing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-constituency-parsing-algorithm",
      "term": "Constituency Parsing Algorithm",
      "definition": "An algorithm that decomposes sentences into nested constituent phrases according to a formal grammar. Chart-based methods like CYK and probabilistic context-free grammars are standard approaches.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-constitutional-ai",
      "term": "Constitutional AI",
      "definition": "Anthropic's approach to AI alignment where models are trained to follow a set of principles (\"constitution\") that guide their behavior. Reduces reliance on human feedback for safety training.",
      "tags": [
        "Safety",
        "Anthropic"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-constitutional-ai-model",
      "term": "Constitutional AI Model",
      "definition": "An AI system trained using constitutional AI methods where the model self-critiques and revises its outputs against a set of principles. Reduces the need for human feedback by using AI-generated feedback guided by explicit rules.",
      "tags": [
        "Models",
        "Safety"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-constitutional-ai-training",
      "term": "Constitutional AI Training",
      "definition": "A training methodology where the model critiques and revises its own outputs according to a set of written principles, reducing reliance on human feedback for alignment.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-constitutional-prompting",
      "term": "Constitutional Prompting",
      "definition": "A prompting approach that provides the model with an explicit set of principles, rules, or constitutional guidelines that it must follow when generating responses, enabling value-aligned outputs through declarative constraint specification.",
      "tags": [
        "Prompt Engineering",
        "Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-constrained-beam-search",
      "term": "Constrained Beam Search",
      "definition": "A beam search variant that enforces lexical or structural constraints during decoding, ensuring that certain tokens or phrases must appear in the generated output.",
      "tags": [
        "Generative AI",
        "Decoding"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-constrained-clustering-algorithm",
      "term": "Constrained Clustering Algorithm",
      "definition": "A semi-supervised clustering approach that incorporates must-link and cannot-link constraints between pairs of points. Uses domain knowledge to guide the clustering toward more meaningful groupings.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-constrained-rl",
      "term": "Constrained Reinforcement Learning",
      "definition": "An RL formulation where the agent maximizes expected return while satisfying one or more constraint functions on expected costs. Constrained MDPs are solved using Lagrangian methods or primal-dual optimization.",
      "tags": [
        "Reinforcement Learning",
        "Safety"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-constraint",
      "term": "Constraint (Prompting)",
      "definition": "Limitations or requirements specified in a prompt. \"Respond in 50 words or less\" or \"Use only formal language.\" Constraints shape and focus AI output.",
      "tags": [
        "Prompting",
        "Technique"
      ],
      "domain": "general",
      "link": "../learn/crisp.html",
      "related": []
    },
    {
      "id": "term-constraint-prompting",
      "term": "Constraint Prompting",
      "definition": "A technique that specifies explicit constraints within the prompt such as length limits, format requirements, vocabulary restrictions, or content boundaries that the model must satisfy in its generated output.",
      "tags": [
        "Prompt Engineering",
        "Constraints"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-constraint-satisfaction",
      "term": "Constraint Satisfaction",
      "definition": "A paradigm for solving problems by finding values for variables that satisfy a set of constraints. Constraint satisfaction problems (CSPs) are fundamental to AI planning scheduling and configuration. Techniques include backtracking constraint propagation and arc consistency.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-containerized-gpu-workloads",
      "term": "Containerized GPU Workloads",
      "definition": "Running AI applications in containers with direct GPU access using runtimes like NVIDIA Container Toolkit. Standard deployment method for AI inference and training in production.",
      "tags": [
        "Virtualization",
        "Container",
        "Deployment"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-content-authenticity-initiative",
      "term": "Content Authenticity Initiative",
      "definition": "An industry coalition led by Adobe that develops open standards for attributing and verifying the provenance of digital content, helping distinguish authentic media from AI-generated or manipulated material.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-content-filtering",
      "term": "Content Filtering",
      "definition": "Systems that detect and block harmful content in AI inputs or outputs. Part of safety infrastructure, filtering violence, explicit content, and other policy violations.",
      "tags": [
        "Safety",
        "Moderation"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-content-moderation",
      "term": "Content Moderation",
      "definition": "The process of monitoring and filtering user-generated content on digital platforms to enforce community standards, increasingly assisted by AI classifiers for detecting hate speech, violence, and other policy violations.",
      "tags": [
        "AI Ethics",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-content-based-filtering",
      "term": "Content-Based Filtering",
      "definition": "A recommendation approach that suggests items similar to those a user has previously liked based on item feature representations.",
      "tags": [
        "Models",
        "Fundamentals",
        "Recommendation"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-contestability",
      "term": "Contestability",
      "definition": "The ability of individuals to challenge and seek review of decisions made by or with the assistance of AI systems. A key principle in ensuring accountability and due process in automated decision-making.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-context",
      "term": "Context",
      "definition": "Background information provided to AI that helps it understand your situation and needs. Essential for getting relevant, accurate responses.",
      "tags": [
        "Prompting",
        "Core Concept"
      ],
      "domain": "general",
      "link": "../learn/crisp.html",
      "related": []
    },
    {
      "id": "term-context-distillation",
      "term": "Context Distillation",
      "definition": "A training technique that transfers the behavior elicited by a specific prompt or context into the model's weights, eliminating the need to include that context at inference time.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-context-length",
      "term": "Context Length",
      "definition": "The maximum amount of text a model can process at once, measured in tokens. Ranges from 4K to 200K+ depending on the model. Longer contexts enable more complex tasks.",
      "tags": [
        "Specification",
        "Limitation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-context-parallelism",
      "term": "Context Parallelism",
      "definition": "A specialized parallelism approach that distributes attention computation across GPUs along the sequence length dimension for very long context windows. Context parallelism enables processing of sequences that exceed the memory capacity of a single device.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-context-window",
      "term": "Context Window",
      "definition": "The amount of text (measured in tokens) that an AI can process at once. Modern models range from 4K to 200K+ tokens, determining how much conversation history and reference material the AI can consider.",
      "tags": [
        "Limitation",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-context-window-management",
      "term": "Context Window Management",
      "definition": "Techniques for efficiently utilizing and extending the finite context window of language models, including sliding windows, summarization of earlier context, and hierarchical memory systems.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-context-free-grammar",
      "term": "Context-Free Grammar",
      "definition": "A formal grammar where production rules map single non-terminal symbols to sequences of terminals and non-terminals, widely used in NLP for defining syntactic structure of sentences.",
      "tags": [
        "NLP",
        "Parsing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-contextual-bandit",
      "term": "Contextual Bandit",
      "definition": "An extension of the multi-armed bandit where the agent observes a context (feature vector) before choosing an action, allowing the policy to adapt its decisions to the current situation. Used extensively in recommendation systems and online advertising.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-contextual-calibration",
      "term": "Contextual Calibration",
      "definition": "A technique that adjusts a language model's output probabilities by estimating and correcting for biases introduced by the prompt context, typically by measuring the model's prior distribution on content-free inputs and applying an affine transformation.",
      "tags": [
        "Prompt Engineering",
        "Calibration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-contextual-compression",
      "term": "Contextual Compression",
      "definition": "A retrieval post-processing technique that compresses or extracts only the most relevant portions from retrieved documents based on the query context, reducing noise and token usage by filtering out irrelevant content before passing to the LLM.",
      "tags": [
        "Retrieval",
        "Post-Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-contextual-embedding",
      "term": "Contextual Embedding",
      "definition": "A word representation that varies depending on the surrounding context, unlike static embeddings, capturing polysemy and context-dependent meaning through models like ELMo, BERT, and GPT.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-contextual-few-shot-selection",
      "term": "Contextual Few-Shot Selection",
      "definition": "The practice of dynamically selecting the most relevant few-shot examples for each query based on semantic similarity, task characteristics, or diversity criteria rather than using a fixed set of demonstrations.",
      "tags": [
        "Prompt Engineering",
        "Example Selection"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-contextual-integrity",
      "term": "Contextual Integrity",
      "definition": "A theory of privacy that evaluates data flows against context-specific norms. Applied to AI to assess whether data collection and use respects the informational norms of the context in which data originated.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-contextual-retrieval",
      "term": "Contextual Retrieval",
      "definition": "A retrieval enhancement technique that prepends each chunk with a model-generated contextual summary explaining the chunk's place within the larger document, improving retrieval accuracy by providing disambiguation context for each embedded segment.",
      "tags": [
        "Retrieval",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-continual-learning",
      "term": "Continual Learning",
      "definition": "Training models incrementally on new data without forgetting previous knowledge. A challenge because neural networks tend to overwrite old information with new.",
      "tags": [
        "Training",
        "Research"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-continual-rl",
      "term": "Continual Reinforcement Learning",
      "definition": "RL settings where the agent must learn and adapt over a non-stationary sequence of tasks without forgetting earlier knowledge. Continual RL combines aspects of lifelong learning, transfer, and plasticity maintenance.",
      "tags": [
        "Reinforcement Learning",
        "Training Paradigms"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-continued-fraction-algorithm",
      "term": "Continued Fraction Algorithm",
      "definition": "A method for representing real numbers as nested fractions that provides optimal rational approximations. Used in number theory and for evaluating special functions with guaranteed convergence properties.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-continuous-batching",
      "term": "Continuous Batching",
      "definition": "A dynamic batching strategy where new requests are inserted into a running batch as soon as existing requests complete, eliminating idle GPU time caused by waiting for entire batches to finish.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-continuous-monitoring",
      "term": "Continuous Monitoring",
      "definition": "The ongoing observation and assessment of AI system behavior in production to detect performance degradation bias drift safety violations and emerging risks in real time.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-continuous-wavelet-transform",
      "term": "Continuous Wavelet Transform",
      "definition": "A time-frequency analysis method that convolves a signal with scaled and translated versions of a mother wavelet. Provides variable time-frequency resolution with fine frequency resolution at low frequencies.",
      "tags": [
        "Algorithms",
        "Technical",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-contractive-autoencoder",
      "term": "Contractive Autoencoder",
      "definition": "An autoencoder that adds a penalty term based on the Frobenius norm of the encoder's Jacobian matrix, encouraging the learned representation to be robust to small perturbations in the input.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-contractual-ai-accountability",
      "term": "Contractual AI Accountability",
      "definition": "Legal provisions in contracts between AI developers deployers and users that allocate responsibilities for safety performance and harm remediation. An emerging area of technology law.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-contrastive-chain-of-thought",
      "term": "Contrastive Chain-of-Thought",
      "definition": "A prompting approach that provides both correct and incorrect reasoning examples in demonstrations, helping the model learn not only the right reasoning patterns but also common mistakes to avoid during inference.",
      "tags": [
        "Prompt Engineering",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-contrastive-decoding",
      "term": "Contrastive Decoding",
      "definition": "A decoding method that improves generation quality by contrasting the output distributions of a large expert model and a smaller amateur model, suppressing tokens favored by the weaker model.",
      "tags": [
        "Generative AI",
        "Decoding"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-contrastive-learning",
      "term": "Contrastive Learning",
      "definition": "Training by comparing similar and dissimilar examples. The model learns to place similar items close together in embedding space and dissimilar items far apart.",
      "tags": [
        "Training",
        "Technique"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-contrastive-learning-vision",
      "term": "Contrastive Learning for Vision",
      "definition": "A self-supervised approach that trains visual encoders by pulling augmented views of the same image closer in embedding space while pushing different images apart, learning useful representations without labels.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-contrastive-loss",
      "term": "Contrastive Loss",
      "definition": "A loss function that trains models to pull similar (positive) pairs closer together and push dissimilar (negative) pairs further apart in the embedding space, based on a specified distance margin.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-contrastive-search",
      "term": "Contrastive Search",
      "definition": "A text generation method that selects tokens based on both probability and degeneration penalty. Balances the confidence of the model with the distinctiveness of the generated token relative to previous context. Reduces repetition in generated text.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-control-problem",
      "term": "Control Problem",
      "definition": "The challenge of ensuring that a highly capable AI system remains under meaningful human control and pursues objectives aligned with human values, even as its capabilities may exceed human oversight capacity.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-controllable-generation",
      "term": "Controllable Generation",
      "definition": "Techniques for steering AI output toward desired attributes like sentiment, style, or topic. Enables more precise control over generated content.",
      "tags": [
        "Technique",
        "Generation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-controlnet",
      "term": "ControlNet",
      "definition": "A neural network architecture that adds spatial conditioning controls to pre-trained diffusion models, enabling guided image generation from edge maps, depth maps, poses, and other structural inputs.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-convergence",
      "term": "Convergence",
      "definition": "The property of an optimization algorithm or iterative process where successive iterations produce results that approach a stable solution or fixed point. In ML, it indicates that training loss has stabilized.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-conversation-history",
      "term": "Conversation History",
      "definition": "The record of previous messages in a chat session. Provides context for AI responses. Managing history is important as it consumes context window space.",
      "tags": [
        "Feature",
        "Context"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-conversational-ai",
      "term": "Conversational AI",
      "definition": "AI systems designed for natural dialogue with humans. Includes chatbots, virtual assistants, and systems like ChatGPT and Claude that can maintain context across multiple exchanges.",
      "tags": [
        "Application",
        "NLP"
      ],
      "domain": "general",
      "link": "chatgpt-guide.html",
      "related": []
    },
    {
      "id": "term-conversational-ai-safety",
      "term": "Conversational AI Safety",
      "definition": "Safety measures specific to dialogue systems and chatbots including prevention of harmful responses manipulation detection and appropriate escalation to human operators.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-convnext",
      "term": "ConvNeXt",
      "definition": "A pure convolutional architecture that modernizes ResNet design by incorporating ideas from vision transformers such as larger kernel sizes and training recipes. Demonstrates that CNNs can match or exceed ViT performance when properly designed.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-convnext-v2",
      "term": "ConvNeXt V2",
      "definition": "A second-generation pure convolutional vision model that uses masked autoencoder pre-training with Global Response Normalization for improved representations.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-convolution",
      "term": "Convolution",
      "definition": "A mathematical operation that combines two functions to produce a third expressing how one modifies the other. In deep learning convolution layers apply learned filters to input data to detect local patterns and features across spatial or temporal dimensions.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-convolutional-filter",
      "term": "Convolutional Filter",
      "definition": "A learnable weight matrix (kernel) that slides across an input image or feature map, computing element-wise products and sums to detect specific patterns such as edges, textures, or shapes.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cnn-history",
      "term": "Convolutional Neural Network History",
      "definition": "The development of CNNs from Fukushima's Neocognitron in 1980 through LeCun's application to handwritten digit recognition in 1989, culminating in their dominance of computer vision following the 2012 ImageNet breakthrough.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-conways-game-of-life",
      "term": "Conway's Game of Life",
      "definition": "A cellular automaton devised by mathematician John Horton Conway in 1970. Despite having only simple rules (birth survival death based on neighbor counts) the Game of Life can simulate a Turing machine and exhibits complex emergent behavior from simple initial conditions.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cooks-distance",
      "term": "Cook's Distance",
      "definition": "A measure of the influence of each observation on the fitted values of a regression model, computed as the sum of changes in all predicted values when the observation is removed. High values indicate influential points.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cooperative-inverse-reinforcement-learning",
      "term": "Cooperative Inverse Reinforcement Learning",
      "definition": "A framework for human-AI alignment where a robot and human work together in a game where the robot tries to maximize the human's reward while being uncertain about what that reward is, learning through interaction.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-cooperative-rl",
      "term": "Cooperative Reinforcement Learning",
      "definition": "A multi-agent RL setting where agents share a common objective and must learn to coordinate their actions for mutual benefit. Cooperative RL addresses challenges like credit assignment and communication protocols among teammates.",
      "tags": [
        "Reinforcement Learning",
        "Multi-Agent"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-coordinate-descent",
      "term": "Coordinate Descent",
      "definition": "An optimization algorithm that minimizes along one coordinate direction at a time while holding others fixed. Particularly effective for problems with separable structure or when coordinate-wise updates have closed-form solutions like in Lasso regression.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-copa",
      "term": "COPA",
      "definition": "Choice of Plausible Alternatives a causal reasoning dataset where models choose the more plausible cause or effect of a premise. Part of SuperGLUE testing commonsense causal reasoning.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-copernicus-of-ai",
      "term": "Copernicus of AI",
      "definition": "An informal designation sometimes given to researchers whose work fundamentally shifted the paradigm of AI research. Often applied to Geoffrey Hinton for persisting with neural network research during decades when it was out of favor in mainstream AI.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-copilot",
      "term": "Copilot",
      "definition": "Microsoft's AI assistant integrated into their products. Originally focused on code completion (GitHub Copilot), now extended to general assistance across Microsoft 365.",
      "tags": [
        "Product",
        "Microsoft"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-coppersmith-winograd-algorithm",
      "term": "Coppersmith-Winograd Algorithm",
      "definition": "A theoretical matrix multiplication algorithm that achieves an exponent of approximately 2.376. While not practical due to large constant factors it established important bounds on the complexity of matrix multiplication.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical",
        "History"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-copula",
      "term": "Copula",
      "definition": "A multivariate probability distribution that captures the dependence structure between random variables independently of their marginal distributions. Copulas allow modeling complex dependency patterns beyond linear correlation.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-coqa",
      "term": "CoQA",
      "definition": "Conversational Question Answering a dataset of 127000 questions in conversational form where answers depend on conversation history. Tests a models ability to understand dialogue context.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-coqui-tts",
      "term": "Coqui TTS",
      "definition": "An open-source text-to-speech toolkit and model collection that supports multiple TTS architectures and languages with voice cloning capabilities.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cora",
      "term": "Cora",
      "definition": "A citation network dataset of 2708 scientific publications classified into 7 classes. One of the most widely used benchmarks for graph neural network node classification.",
      "tags": [
        "Benchmark",
        "Graph"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-coral-usb-accelerator",
      "term": "Coral USB Accelerator",
      "definition": "USB device containing a Google Edge TPU for adding AI inference capability to any Linux computer. Provides 4 TOPS of inference performance for TensorFlow Lite models.",
      "tags": [
        "Edge",
        "Google",
        "Inference"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-coreference-resolution",
      "term": "Coreference Resolution",
      "definition": "The task of identifying all expressions in a text that refer to the same real-world entity, linking pronouns, noun phrases, and other mentions to form coreference chains.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-coreference-resolution-algorithm",
      "term": "Coreference Resolution Algorithm",
      "definition": "An algorithm that identifies all expressions in text that refer to the same entity. Uses mention detection and pairwise scoring and clustering to link coreferent mentions across a document.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-corporate-ai-responsibility",
      "term": "Corporate AI Responsibility",
      "definition": "The obligation of companies that develop or deploy AI to manage the social and environmental impacts of their AI systems. Extends corporate social responsibility principles to artificial intelligence.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-corpus",
      "term": "Corpus",
      "definition": "A large collection of text used for training or evaluating language models. Quality corpora are essential for developing capable NLP systems and typically include diverse sources.",
      "tags": [
        "Data",
        "Training"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-corrective-rag",
      "term": "Corrective RAG",
      "definition": "A RAG variant that evaluates the relevance of retrieved documents and, if they are insufficient, triggers web search or query reformulation to correct the retrieval before generating a response.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-correlation-clustering",
      "term": "Correlation Clustering",
      "definition": "A clustering method that uses pairwise similarity and dissimilarity labels to partition data without specifying the number of clusters. Minimizes the number of disagreements with the pairwise labels.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-correlation-coefficient",
      "term": "Correlation Coefficient",
      "definition": "A statistical measure quantifying the strength and direction of the linear relationship between two variables, typically Pearson's r, ranging from -1 (perfect negative) to +1 (perfect positive correlation).",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-corrigibility",
      "term": "Corrigibility",
      "definition": "The property of an AI system that allows its operators to correct, modify, retrain, or shut it down without the system resisting or subverting these interventions. Ensuring corrigibility is a fundamental goal in AI safety.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-cosine-annealing",
      "term": "Cosine Annealing",
      "definition": "A learning rate schedule that decreases the learning rate following a cosine curve from its initial value to near zero over a training period, optionally with warm restarts to periodically reset the rate.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cosine-annealing-with-warm-restarts",
      "term": "Cosine Annealing with Warm Restarts",
      "definition": "An extension of cosine annealing that periodically resets the learning rate to its initial value creating a series of cosine decay cycles. Proposed by Loshchilov and Hutter in 2017. Enables exploration of different regions of the loss landscape.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cosine-similarity",
      "term": "Cosine Similarity",
      "definition": "A similarity metric that measures the cosine of the angle between two vectors, ranging from -1 (opposite) to 1 (identical direction). It captures orientation rather than magnitude and is widely used for comparing embeddings.",
      "tags": [
        "Machine Learning",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cosine-similarity-algorithm",
      "term": "Cosine Similarity Algorithm",
      "definition": "A measure of similarity between two non-zero vectors that computes the cosine of the angle between them. Widely used for comparing document vectors and word embeddings in information retrieval and NLP.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cosmopedia",
      "term": "Cosmopedia",
      "definition": "A large-scale synthetic dataset of textbook-style content generated by Mixtral covering diverse topics. Demonstrates the value of synthetic educational data for pretraining.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Synthetic"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cosql",
      "term": "CoSQL",
      "definition": "A conversational text-to-SQL dataset with 3000 dialogues over 200 databases. Tests the ability to translate multi-turn natural language conversations into SQL query sequences.",
      "tags": [
        "Benchmark",
        "NLP",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cost-function",
      "term": "Cost Function",
      "definition": "Another name for loss function - the metric being minimized during training. Different tasks use different cost functions: cross-entropy for classification, MSE for regression.",
      "tags": [
        "Training",
        "Math"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-costar",
      "term": "COSTAR",
      "definition": "A prompting framework: Context, Objective, Style, Tone, Audience, Response. Ideal for professional content creation with specific voice and audience requirements.",
      "tags": [
        "Framework",
        "Professional"
      ],
      "domain": "general",
      "link": "../learn/costar.html",
      "related": []
    },
    {
      "id": "term-cosyvoice",
      "term": "CosyVoice",
      "definition": "A large-scale multilingual text-to-speech model that uses flow matching and conditional language modeling for natural and expressive speech synthesis.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cotracker",
      "term": "CoTracker",
      "definition": "A Transformer-based model from Meta for tracking any number of points through video sequences using joint tracking of multiple points simultaneously.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-count-distinct-algorithm",
      "term": "Count Distinct Algorithm",
      "definition": "An algorithm for estimating the number of distinct elements in a data stream. Flajolet-Martin and LogLog and HyperLogLog are progressively improved probabilistic approaches using hash-based techniques.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-count-based-exploration",
      "term": "Count-Based Exploration",
      "definition": "An exploration strategy that provides bonus rewards inversely related to state visitation counts, encouraging the agent to visit less-explored regions. Pseudo-counts extend this idea to continuous or large state spaces via density models.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-count-min-sketch-algorithm",
      "term": "Count-Min Sketch Algorithm",
      "definition": "A probabilistic data structure that estimates the frequency of elements in a data stream using sub-linear space. Uses multiple hash functions and counters and provides frequency estimates with bounded one-sided error.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-count-min-log-sketch",
      "term": "Count-Min-Log Sketch",
      "definition": "A variant of the count-min sketch that uses logarithmic counters with probabilistic increments to trade accuracy for dramatically reduced space consumption. Suitable for frequency estimation of very large cardinality streams.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-counterfactual",
      "term": "Counterfactual",
      "definition": "\"What if\" reasoning about alternative scenarios. Used in explainability (\"the prediction would change if...\") and for evaluating causal relationships in data.",
      "tags": [
        "Concept",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-counterfactual-dataset",
      "term": "Counterfactual Dataset",
      "definition": "Datasets of minimally edited examples where small changes flip the correct answer. Used to evaluate whether models rely on spurious correlations versus genuine understanding.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-counterfactual-explanation",
      "term": "Counterfactual Explanation",
      "definition": "An explanation that describes the smallest change to the input features that would alter the model's prediction to a desired outcome, providing actionable insights about what would need to change.",
      "tags": [
        "Machine Learning",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-counterfactual-fairness",
      "term": "Counterfactual Fairness",
      "definition": "A fairness criterion requiring that a decision would remain the same in a counterfactual world where an individual's protected attribute had been different, grounded in causal reasoning.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-counterfactual-regret-minimization",
      "term": "Counterfactual Regret Minimization",
      "definition": "An algorithm for computing approximate Nash equilibria in large extensive-form games. Decomposes regret into counterfactual values for each information set and is the foundation of modern poker AI.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-counting-sort",
      "term": "Counting Sort",
      "definition": "A non-comparative integer sorting algorithm that counts the occurrences of each distinct value and uses arithmetic to determine positions. Runs in O(n + k) time where k is the range of input values.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Sorting"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-covariance",
      "term": "Covariance",
      "definition": "A measure of the joint variability of two random variables, indicating the direction of their linear relationship. Positive covariance means the variables tend to increase together, while negative means they move inversely.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-covariance-matrix",
      "term": "Covariance Matrix",
      "definition": "A symmetric matrix whose entries are the pairwise covariances between all pairs of variables in a dataset. The diagonal entries are the variances of individual variables.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-covariate-shift",
      "term": "Covariate Shift",
      "definition": "A type of dataset shift where the distribution of input features changes between training and deployment while the conditional distribution of the target given inputs remains the same.",
      "tags": [
        "Machine Learning",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cover-tree-algorithm",
      "term": "Cover Tree Algorithm",
      "definition": "A data structure for nearest-neighbor search in general metric spaces that provides provable guarantees on query time. The tree has bounded depth proportional to the doubling dimension of the dataset.",
      "tags": [
        "Algorithms",
        "Technical",
        "Searching",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-coverage",
      "term": "Coverage",
      "definition": "An evaluation metric that measures the proportion of reference content or ground truth items that are represented in the model's output, assessing completeness and the extent to which all relevant information is captured.",
      "tags": [
        "Evaluation",
        "Metrics"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-covost",
      "term": "CoVoST",
      "definition": "Common Voice Speech Translation a multilingual speech translation dataset derived from Common Voice. Covers translation from 21 languages into English and from English into 15 languages.",
      "tags": [
        "Benchmark",
        "Speech",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cowos",
      "term": "CoWoS",
      "definition": "Chip on Wafer on Substrate advanced packaging technology by TSMC placing multiple chiplets and HBM stacks on a silicon interposer. Used for packaging NVIDIA A100 H100 and AMD MI300 GPUs.",
      "tags": [
        "Fabrication",
        "Packaging",
        "TSMC"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cox-proportional-hazards",
      "term": "Cox Proportional Hazards",
      "definition": "A semi-parametric survival model that estimates the effect of covariates on the hazard rate without specifying the baseline hazard function. It assumes that covariate effects are multiplicative and constant over time.",
      "tags": [
        "Statistics",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cpu-inference",
      "term": "CPU Inference",
      "definition": "Running AI models on CPUs rather than GPUs. Slower but more accessible. Quantized models can run efficiently on CPUs for edge deployment.",
      "tags": [
        "Deployment",
        "Hardware"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-crafter",
      "term": "Crafter",
      "definition": "An open-world survival game benchmark for reinforcement learning testing 22 achievement-based skills. Designed to evaluate broad agent capabilities in a procedurally generated environment.",
      "tags": [
        "Benchmark",
        "Reinforcement Learning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cramer-rao-lower-bound",
      "term": "Cramer-Rao Lower Bound",
      "definition": "A theoretical lower bound on the variance of any unbiased estimator of a parameter, computed as the inverse of the Fisher information. No unbiased estimator can have variance below this bound.",
      "tags": [
        "Statistics",
        "Inference"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-crank-nicolson-method",
      "term": "Crank-Nicolson Method",
      "definition": "A numerical method for solving partial differential equations that averages the forward and backward Euler methods. Second-order accurate in time and unconditionally stable for the heat equation.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cray-supercomputers",
      "term": "Cray Supercomputers",
      "definition": "A series of supercomputers designed by Seymour Cray beginning with the Cray-1 in 1976. While not specifically AI systems Cray supercomputers provided the computational power needed for large-scale scientific simulations that laid groundwork for modern AI computing.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cray-x-mp",
      "term": "Cray X-MP",
      "definition": "Cray Research multiprocessor vector supercomputer from 1982 that succeeded the Cray-1. First shared-memory parallel vector computer and dominated scientific computing in the mid-1980s.",
      "tags": [
        "Historical",
        "Supercomputer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cray-1",
      "term": "Cray-1",
      "definition": "First commercially successful vector supercomputer designed by Seymour Cray and introduced in 1976. Its distinctive C-shape and 80 MHz clock speed made it the fastest computer of its era.",
      "tags": [
        "Historical",
        "Supercomputer",
        "Pioneer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cray-2",
      "term": "Cray-2",
      "definition": "Seymour Cray follow-up supercomputer from 1985 that was the fastest computer in the world. Featured immersion cooling in Fluorinert liquid and introduced multi-processor vector computing.",
      "tags": [
        "Historical",
        "Supercomputer"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-creative-prompting",
      "term": "Creative Prompting",
      "definition": "Prompting techniques specifically designed to elicit imaginative, original, and artistically expressive outputs from language models, often using higher temperature settings, open-ended instructions, and stylistic constraints to encourage novelty.",
      "tags": [
        "Prompt Engineering",
        "Creative"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-creative-writing",
      "term": "Creative Writing (AI)",
      "definition": "Using AI to generate fiction, poetry, scripts, and other creative content. Effective creative prompting often uses CRISPE with examples to establish tone and style.",
      "tags": [
        "Application",
        "Creative"
      ],
      "domain": "general",
      "link": "../learn/crispe.html",
      "related": []
    },
    {
      "id": "term-credible-interval",
      "term": "Credible Interval",
      "definition": "A Bayesian analog of the confidence interval, representing the range within which a parameter falls with a specified probability given the observed data. Unlike confidence intervals, it has a direct probabilistic interpretation.",
      "tags": [
        "Statistics",
        "Bayesian Methods"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-credit-assignment",
      "term": "Credit Assignment Problem",
      "definition": "The challenge of determining which actions in a sequence were responsible for a delayed reward signal. Credit assignment is fundamental to RL and becomes harder with longer time horizons and sparser rewards.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-crisp",
      "term": "CRISP",
      "definition": "A prompting framework: Context, Role, Instructions, Specifics, Parameters. A versatile method for everyday AI tasks and requests.",
      "tags": [
        "Framework",
        "General Purpose"
      ],
      "domain": "general",
      "link": "../learn/crisp.html",
      "related": []
    },
    {
      "id": "term-crispe",
      "term": "CRISPE",
      "definition": "An extension of CRISP that adds Examples for few-shot learning. Particularly useful for creative tasks where showing is better than telling.",
      "tags": [
        "Framework",
        "Creative"
      ],
      "domain": "general",
      "link": "../learn/crispe.html",
      "related": []
    },
    {
      "id": "term-crop-and-resize",
      "term": "Crop-and-Resize",
      "definition": "A spatial transformation operation used in object detection that extracts and resizes region proposals from feature maps using bilinear sampling, serving as a differentiable alternative to ROI pooling.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cross-attention",
      "term": "Cross-Attention",
      "definition": "An attention mechanism where queries come from one sequence and keys/values from another. Essential in encoder-decoder models and multimodal systems that combine different types of input.",
      "tags": [
        "Architecture",
        "Transformers"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cross-attention-conditioning",
      "term": "Cross-Attention Conditioning",
      "definition": "The mechanism in diffusion models where text embeddings influence image generation through cross-attention layers, allowing each spatial region of the generated image to attend to relevant prompt tokens.",
      "tags": [
        "Generative AI",
        "Image Processing"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cross-border-ai-governance",
      "term": "Cross-Border AI Governance",
      "definition": "International cooperation and coordination on AI regulation and standards across national jurisdictions. Addresses challenges of regulatory fragmentation and forum shopping in global AI deployment.",
      "tags": [
        "Safety",
        "Policy"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-cross-encoder",
      "term": "Cross-Encoder",
      "definition": "A text similarity model that processes both texts jointly through a single transformer encoder. Produces more accurate similarity scores than bi-encoders but is computationally expensive as it cannot precompute embeddings. Used for reranking.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cross-encoder-re-ranking",
      "term": "Cross-Encoder Re-Ranking",
      "definition": "A re-ranking approach that jointly encodes the query and each candidate document through a single transformer model, enabling rich cross-attention interactions that produce more accurate relevance scores than independent bi-encoder representations.",
      "tags": [
        "Retrieval",
        "Ranking"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-cross-entropy",
      "term": "Cross-Entropy",
      "definition": "A measure of the difference between two probability distributions. In machine learning used as a loss function measuring the divergence between predicted and true label distributions. Equivalent to negative log-likelihood for classification tasks.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cross-entropy-loss",
      "term": "Cross-Entropy Loss",
      "definition": "A loss function that measures the dissimilarity between the predicted probability distribution and the true label distribution. It is the standard loss for classification tasks and equals the negative log-likelihood of the correct class.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cross-entropy-method-rl",
      "term": "Cross-Entropy Method in RL",
      "definition": "An evolutionary optimization approach for RL that samples multiple policies, evaluates their returns, and updates the sampling distribution toward the elite (top-performing) samples. CEM is simple, parallelizable, and effective for short-horizon problems.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cross-layer-parameter-sharing",
      "term": "Cross-Layer Parameter Sharing",
      "definition": "A technique where multiple transformer layers share the same weight parameters, dramatically reducing model size while maintaining representation quality, as demonstrated in ALBERT.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cross-lingual-embedding",
      "term": "Cross-Lingual Embedding",
      "definition": "Word or sentence representations that map multiple languages into a shared vector space where semantically equivalent expressions are close together, enabling cross-lingual transfer.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-cross-validation",
      "term": "Cross-Validation",
      "definition": "A technique for evaluating model performance by splitting data into multiple subsets, training on some and testing on others. Provides more reliable estimates than single train-test splits.",
      "tags": [
        "Evaluation",
        "Training"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-crossbar-array",
      "term": "Crossbar Array",
      "definition": "Grid of memristors or similar devices that can perform matrix-vector multiplication in a single step through Ohm's law and Kirchhoff's current law. A promising architecture for analog AI.",
      "tags": [
        "Emerging",
        "Architecture",
        "Analog"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-crosscodeeval",
      "term": "CrossCodeEval",
      "definition": "A benchmark for evaluating cross-file code completion where models must use context from multiple source files to generate correct code completions.",
      "tags": [
        "Benchmark",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-crossfit",
      "term": "CrossFit",
      "definition": "A collection of 160 NLP tasks for studying few-shot cross-task generalization. Provides a unified framework for evaluating how well models transfer across diverse NLP tasks.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-crossformer",
      "term": "CrossFormer",
      "definition": "A cross-robot Transformer policy that enables zero-shot transfer of manipulation skills between different robot embodiments through shared representations.",
      "tags": [
        "Models",
        "Technical",
        "Robotics"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-crowd-counting",
      "term": "Crowd Counting",
      "definition": "The task of estimating the number of people in crowded scenes from images, typically using density map regression to handle extreme occlusion and perspective variation.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-crowdsourced-safety-testing",
      "term": "Crowdsourced Safety Testing",
      "definition": "The practice of engaging large numbers of external testers to identify safety issues in AI systems. Leverages diverse perspectives and use patterns that internal testing may miss.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-crowdsourcing",
      "term": "Crowdsourcing",
      "definition": "Gathering data labels or human feedback from many workers. Platforms like Amazon MTurk provide annotations for training data and RLHF preference collection.",
      "tags": [
        "Data",
        "Process"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-crows-pairs",
      "term": "CrowS-Pairs",
      "definition": "A crowdsourced dataset of 1508 sentence pairs measuring social biases in language models across 9 categories including race gender and religion.",
      "tags": [
        "Benchmark",
        "NLP",
        "Fairness"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-crud-rag",
      "term": "CRUD-RAG",
      "definition": "A benchmark for evaluating RAG systems on Create Read Update and Delete operations over a knowledge base. Tests dynamic knowledge management capabilities.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cruxeval",
      "term": "CRUXEval",
      "definition": "A code reasoning benchmark testing models ability to predict the output of Python programs and to generate inputs that produce given outputs. Tests code understanding rather than generation.",
      "tags": [
        "Benchmark",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cryogenic-computing",
      "term": "Cryogenic Computing",
      "definition": "Computing at extremely low temperatures near absolute zero where some materials exhibit superconductivity. Used in quantum computing and explored for ultra-low-power classical AI computation.",
      "tags": [
        "Emerging",
        "Cryogenic",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-crystalcoder",
      "term": "CrystalCoder",
      "definition": "An open-source 7B language model from LLM360 trained on balanced mixtures of English text and code data with full training transparency.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-csqa",
      "term": "CSQA",
      "definition": "CommonsenseQA a five-way multiple-choice QA benchmark requiring commonsense reasoning. Questions are constructed using ConceptNet subgraphs to ensure diverse commonsense knowledge is tested.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-ct-clip",
      "term": "CT-CLIP",
      "definition": "A contrastive language-image model trained on CT scan volumes paired with radiology reports for zero-shot classification of 3D medical images.",
      "tags": [
        "Models",
        "Technical",
        "Medical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-ctc-loss",
      "term": "CTC Loss",
      "definition": "Connectionist Temporal Classification is a loss function for training sequence-to-sequence models when the alignment between input and output is unknown. Marginalizes over all possible alignments. Widely used in speech recognition and handwriting recognition.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cublas",
      "term": "cuBLAS",
      "definition": "NVIDIA CUDA Basic Linear Algebra Subroutines library providing GPU-accelerated matrix operations. Underpins the high-performance matrix multiplications critical for neural network training.",
      "tags": [
        "Programming",
        "NVIDIA",
        "Library"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cuckoo-hashing-algorithm",
      "term": "Cuckoo Hashing Algorithm",
      "definition": "A hash table scheme that uses two hash functions and allows each element to reside in one of two possible positions. Resolves collisions by displacing existing elements in a cuckoo-like fashion achieving O(1) worst-case lookups.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cuckoo-search-algorithm",
      "term": "Cuckoo Search Algorithm",
      "definition": "A metaheuristic optimization algorithm inspired by the brood parasitism of cuckoo birds. Combines random walks with Levy flights to explore the search space and uses a fraction of worst nests for exploration.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cuda",
      "term": "CUDA",
      "definition": "NVIDIA's parallel computing platform that enables GPUs to accelerate AI training and inference. Essential infrastructure for deep learning, allowing models to train on thousands of cores simultaneously.",
      "tags": [
        "Hardware",
        "Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cuda-cores",
      "term": "CUDA Cores",
      "definition": "The general-purpose parallel processing units in NVIDIA GPUs that execute scalar floating-point and integer operations. While less specialized than Tensor Cores, CUDA cores handle the diverse computational tasks in AI workloads including activation functions, normalization, and data preprocessing.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cuda-programming",
      "term": "CUDA Programming",
      "definition": "NVIDIA's parallel computing platform and API that enables direct programming of GPU hardware using C/C++ extensions. CUDA provides thread hierarchy, memory management, and synchronization primitives for writing high-performance GPU kernels.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cuda-stream",
      "term": "CUDA Stream",
      "definition": "NVIDIA CUDA mechanism for expressing concurrency by queueing operations that execute sequentially within a stream but concurrently across streams. Used to overlap computation and data transfer.",
      "tags": [
        "Programming",
        "NVIDIA",
        "CUDA"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cudnn",
      "term": "cuDNN",
      "definition": "NVIDIA CUDA Deep Neural Network library providing optimized implementations of standard deep learning operations. Foundational library used by TensorFlow PyTorch and other AI frameworks on NVIDIA GPUs.",
      "tags": [
        "Programming",
        "NVIDIA",
        "Library"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cultural-algorithm",
      "term": "Cultural Algorithm",
      "definition": "An evolutionary algorithm that uses a belief space to store and share knowledge between generations. The population evolves through standard evolutionary operators while the belief space guides evolution using accumulated experience.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cultural-bias-in-ai",
      "term": "Cultural Bias in AI",
      "definition": "Bias in AI systems that reflects the cultural perspectives and values of the developers or training data while marginalizing other cultural viewpoints and practices.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-culturalqa",
      "term": "CulturaLQA",
      "definition": "A benchmark of culturally diverse questions testing whether language models have balanced knowledge across different cultures and regions of the world.",
      "tags": [
        "Benchmark",
        "NLP",
        "Multilingual",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-culturax",
      "term": "CulturaX",
      "definition": "A large multilingual dataset of 6.3 trillion tokens across 167 languages. Created by combining mC4 and OSCAR with additional quality filtering for improved pretraining data.",
      "tags": [
        "Training Corpus",
        "NLP",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cumulative-reasoning",
      "term": "Cumulative Reasoning",
      "definition": "A prompting paradigm where a proposer generates potential reasoning steps, a verifier checks each step's validity, and a reporter determines when sufficient reasoning has accumulated to produce a final answer, mimicking collaborative human reasoning.",
      "tags": [
        "Prompt Engineering",
        "Reasoning"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-cumulative-risk-in-ai",
      "term": "Cumulative Risk in AI",
      "definition": "The aggregate risk created by the deployment of many AI systems across society even when each individual system poses only modest risk. Important for systemic risk assessment and regulation.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-curatedtrec",
      "term": "CuratedTREC",
      "definition": "A collection of factoid question answering data from TREC QA tracks. Provides curated evaluation sets for open-domain question answering research.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cure-algorithm",
      "term": "CURE Algorithm",
      "definition": "Clustering Using Representatives selects a fixed number of well-scattered representative points per cluster and shrinks them toward the centroid. Handles non-spherical shapes and is robust to outliers in large datasets.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-curiosity-driven-exploration",
      "term": "Curiosity-Driven Exploration",
      "definition": "An exploration strategy that rewards the agent for encountering states where its predictive model has high error, encouraging visits to novel and informative regions of the environment. Curiosity provides dense intrinsic rewards in sparse-reward settings.",
      "tags": [
        "Reinforcement Learning",
        "Exploration"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-curriculum-learning",
      "term": "Curriculum Learning",
      "definition": "Training models on progressively harder examples, mimicking human education. Can improve learning efficiency and final performance compared to random ordering.",
      "tags": [
        "Training",
        "Technique"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-curriculum-learning-rl",
      "term": "Curriculum Learning in RL",
      "definition": "A training strategy that presents tasks to an RL agent in a structured order of increasing difficulty, enabling the agent to build skills progressively. Curriculum design can dramatically accelerate learning on hard tasks.",
      "tags": [
        "Reinforcement Learning",
        "Training Paradigms"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-curse-of-dimensionality",
      "term": "Curse of Dimensionality",
      "definition": "The phenomenon where the performance of many algorithms degrades as the number of features increases, because data becomes sparse in high-dimensional spaces and distances between points become less meaningful.",
      "tags": [
        "Machine Learning",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cursor",
      "term": "Cursor",
      "definition": "An AI-powered code editor built on VS Code, designed for AI-first development. Features include AI chat, code generation, and understanding of entire codebases.",
      "tags": [
        "Product",
        "IDE"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-curvilinear-component-analysis",
      "term": "Curvilinear Component Analysis",
      "definition": "A nonlinear dimensionality reduction technique that unfolds curved manifolds by preserving local distances while allowing distant points to move freely. Uses a distance-dependent weighting function to achieve this.",
      "tags": [
        "Algorithms",
        "Technical",
        "Dimensionality Reduction"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-custom-instructions",
      "term": "Custom Instructions",
      "definition": "Persistent preferences that shape all AI responses in ChatGPT and similar products. Set once and applied automatically to every conversation.",
      "tags": [
        "Feature",
        "Personalization"
      ],
      "domain": "general",
      "link": "chatgpt-guide.html",
      "related": []
    },
    {
      "id": "term-custom-silicon-for-ai",
      "term": "Custom Silicon for AI",
      "definition": "Trend of technology companies designing their own application-specific chips for AI workloads rather than relying solely on merchant silicon from NVIDIA AMD or Intel.",
      "tags": [
        "Trend",
        "Custom",
        "Design"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cutmix",
      "term": "CutMix",
      "definition": "An augmentation strategy that replaces a rectangular region of one training image with a patch from another image and proportionally mixes their labels, combining the benefits of Cutout and Mixup.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cutoff-date",
      "term": "Cutoff Date (Knowledge Cutoff)",
      "definition": "The date after which an AI model has no training data. Information after this date is unknown to the model unless provided in the prompt or accessed via tools.",
      "tags": [
        "Limitation",
        "LLM"
      ],
      "domain": "models",
      "link": "../tools/hallucination.html",
      "related": []
    },
    {
      "id": "term-cutout",
      "term": "Cutout",
      "definition": "A data augmentation technique that randomly masks square regions of input images during training. Forces the model to attend to less discriminative parts of the image improving robustness. Proposed by DeVries and Taylor in 2017.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cutout-augmentation",
      "term": "Cutout Augmentation",
      "definition": "A regularization technique that randomly masks out square regions of training images, forcing the model to learn from partial information and reducing overfitting to specific spatial features.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-cutting-plane-method",
      "term": "Cutting Plane Method",
      "definition": "An iterative algorithm for solving linear and integer programming problems that adds linear constraints (cuts) to tighten the feasible region. Gomory cuts and other families of cuts are used to eliminate fractional solutions.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cvalues",
      "term": "CValues",
      "definition": "A Chinese-language benchmark for evaluating safety and values alignment in language models. Tests adherence to human values across culturally relevant scenarios.",
      "tags": [
        "Benchmark",
        "NLP",
        "Safety",
        "Multilingual"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-cvpr",
      "term": "CVPR",
      "definition": "The IEEE/CVF Conference on Computer Vision and Pattern Recognition first held in 1983. The premier conference for computer vision research where many breakthrough results in image recognition object detection and generative models have been presented.",
      "tags": [
        "History",
        "Conferences"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cyber-physical-ai-safety",
      "term": "Cyber-Physical AI Safety",
      "definition": "Safety considerations for AI systems that interact with the physical world through sensors and actuators. Includes autonomous vehicles robots and industrial control systems where failures can cause physical harm.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-cybernetics",
      "term": "Cybernetics",
      "definition": "An interdisciplinary field founded by Norbert Wiener in 1948 studying regulatory systems their structures constraints and possibilities. Cybernetics examined feedback loops and self-regulating systems in both biological and mechanical contexts influencing early AI and robotics.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cybernetics-movement",
      "term": "Cybernetics Movement",
      "definition": "An interdisciplinary field founded in the 1940s by Norbert Wiener studying control, communication, and feedback in biological and mechanical systems, providing key conceptual foundations for artificial intelligence research.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cyc-project",
      "term": "Cyc Project",
      "definition": "A long-running AI project started by Douglas Lenat in 1984 to create a comprehensive knowledge base of common-sense facts and rules, representing one of the most ambitious attempts at symbolic AI and knowledge engineering.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-cycle-canceling-algorithm",
      "term": "Cycle-Canceling Algorithm",
      "definition": "A minimum-cost flow algorithm that starts with a feasible flow and repeatedly identifies and cancels negative-cost cycles in the residual network. Simple to implement but can be slow without careful cycle selection.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cyclegan",
      "term": "CycleGAN",
      "definition": "An unpaired image-to-image translation model using two generators and discriminators with cycle consistency loss, enabling domain transfer without requiring paired training examples.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-cyclic-learning-rate",
      "term": "Cyclic Learning Rate",
      "definition": "A learning rate schedule that oscillates the learning rate between minimum and maximum bounds during training. Proposed by Smith in 2017 and shown to improve convergence speed. Eliminates the need to find the optimal fixed learning rate.",
      "tags": [
        "Algorithms",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cyk-algorithm",
      "term": "CYK Algorithm",
      "definition": "The Cocke-Younger-Kasami algorithm parses context-free grammars in Chomsky normal form using dynamic programming. Runs in O(n^3 * |G|) time where n is the string length and |G| is the grammar size.",
      "tags": [
        "Algorithms",
        "Technical",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-cynthia-breazeal",
      "term": "Cynthia Breazeal",
      "definition": "American roboticist at MIT who pioneered social robotics and human-robot interaction. Created Kismet (1998) one of the first robots designed to recognize and simulate human emotions and later the Jibo social robot for consumer markets.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    }
  ]
}