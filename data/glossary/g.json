{
  "letter": "g",
  "count": 247,
  "terms": [
    {
      "id": "term-g-eval",
      "term": "G-Eval",
      "definition": "A framework that uses large language models with chain-of-thought prompting to evaluate natural language generation quality, achieving high correlation with human judgments by having the LLM score outputs on dimensions like coherence, fluency, and relevance.",
      "tags": [
        "Evaluation",
        "LLM-Based"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-g-means-algorithm",
      "term": "G-Means Algorithm",
      "definition": "A clustering algorithm that extends k-means by testing whether each cluster follows a Gaussian distribution using the Anderson-Darling test. Splits non-Gaussian clusters until all clusters pass the normality test.",
      "tags": [
        "Algorithms",
        "Technical",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gabor-filter",
      "term": "Gabor Filter",
      "definition": "A linear filter used in texture analysis and feature extraction that models the response of simple cells in the visual cortex. Defined by a Gaussian envelope modulated by a sinusoidal wave at a specific orientation and frequency.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaia",
      "term": "GAIA",
      "definition": "A benchmark for General AI Assistants testing real-world problem solving that requires web browsing multi-step reasoning and tool use. Designed to resist shortcuts and memorization.",
      "tags": [
        "Benchmark",
        "NLP",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaia-1",
      "term": "GAIA-1",
      "definition": "A generative world model from Wayve that creates realistic driving scenes by learning from video and text and action inputs for autonomous driving simulation.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "Autonomous"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-galactica",
      "term": "Galactica",
      "definition": "A large language model trained by Meta AI on 48 million scientific papers citations and other academic content. Designed for scientific knowledge tasks including citation prediction and mathematical reasoning.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-galactica-120b",
      "term": "Galactica-120B",
      "definition": "The largest variant of the Galactica scientific language model with 120B parameters trained on scientific papers and reference materials and knowledge bases.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gamengen",
      "term": "GameNGen",
      "definition": "A game engine powered by a neural model from Google that generates interactive game frames in real time by simulating DOOM through a diffusion model.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gamma-distribution",
      "term": "Gamma Distribution",
      "definition": "A two-parameter family of continuous probability distributions that generalizes the exponential distribution. It models the waiting time for a specified number of events and serves as a conjugate prior for the Poisson rate.",
      "tags": [
        "Statistics",
        "Probability"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gan",
      "term": "GAN (Generative Adversarial Network)",
      "definition": "A neural network architecture with two competing networks: a generator creating content and a discriminator evaluating it. Pioneered realistic image generation before diffusion models.",
      "tags": [
        "Architecture",
        "Generative"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gan-discriminator",
      "term": "GAN Discriminator",
      "definition": "The component of a generative adversarial network that learns to distinguish real data from generated samples, providing training signal to the generator through adversarial competition.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gan-generator",
      "term": "GAN Generator",
      "definition": "The component of a generative adversarial network that transforms random noise into synthetic data samples, trained to fool the discriminator into classifying its outputs as real.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gan-invention",
      "term": "GAN Invention",
      "definition": "The invention of Generative Adversarial Networks by Ian Goodfellow and colleagues in 2014. GANs train two neural networks (generator and discriminator) in competition enabling the generation of realistic synthetic data including images audio and text.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-gan-inversion",
      "term": "GAN Inversion",
      "definition": "The process of finding the latent code in a pre-trained GAN's latent space that best reconstructs a given real image, enabling GAN-based editing and manipulation of real photographs.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gate-all-around-transistor",
      "term": "Gate-All-Around Transistor",
      "definition": "Next-generation transistor design where the gate completely surrounds the channel from all sides. Succeeds FinFET at 3nm and below for improved electrostatic control and performance.",
      "tags": [
        "Fabrication",
        "Transistor",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gated-linear-unit",
      "term": "Gated Linear Unit",
      "definition": "An activation mechanism that multiplies a linear projection of the input by a sigmoid-gated linear projection, allowing the network to control information flow and commonly used in transformer feedforward layers.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gatortron",
      "term": "GatorTron",
      "definition": "A large clinical language model with up to 8.9B parameters trained on over 90 billion words of clinical text from the University of Florida Health system.",
      "tags": [
        "Models",
        "Technical",
        "Medical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gauss-newton-algorithm",
      "term": "Gauss-Newton Algorithm",
      "definition": "An iterative method for solving nonlinear least squares problems that approximates the Hessian using the Jacobian matrix. Converges quickly near the solution but may diverge if the initial guess is far from optimal.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gauss-seidel-method",
      "term": "Gauss-Seidel Method",
      "definition": "An iterative method for solving linear systems that improves upon the Jacobi method by using updated values as soon as they are available within each iteration. Generally converges faster than the Jacobi method.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaussian-elimination",
      "term": "Gaussian Elimination",
      "definition": "A method for solving systems of linear equations by performing row operations to transform the augmented matrix into row echelon form. Uses back substitution to find the solution and runs in O(n^3) time.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaussian-kernel",
      "term": "Gaussian Kernel",
      "definition": "A kernel function based on the Gaussian (normal) distribution, commonly used in kernel density estimation, smoothing, and SVMs. Its bandwidth parameter controls the width of the weighting function around each data point.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaussian-mechanism",
      "term": "Gaussian Mechanism",
      "definition": "A differential privacy mechanism that adds Gaussian noise calibrated to the sensitivity of a query. Provides approximate (epsilon-delta) differential privacy and is widely used for real-valued query outputs.",
      "tags": [
        "Algorithms",
        "Technical",
        "Privacy"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaussian-mixture-model",
      "term": "Gaussian Mixture Model",
      "definition": "A probabilistic model that represents data as generated from a mixture of a finite number of Gaussian distributions with unknown parameters, typically estimated via the EM algorithm. It supports soft cluster assignments.",
      "tags": [
        "Machine Learning",
        "Clustering"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaussian-mixture-model-algorithm",
      "term": "Gaussian Mixture Model Algorithm",
      "definition": "A probabilistic model that represents data as a mixture of multiple Gaussian distributions. Parameters are typically learned using expectation-maximization and the model provides soft cluster assignments.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Clustering"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaussian-process",
      "term": "Gaussian Process",
      "definition": "A non-parametric Bayesian model that defines a probability distribution over functions, where any finite collection of function values follows a multivariate Gaussian distribution. It provides uncertainty estimates alongside predictions.",
      "tags": [
        "Machine Learning",
        "Bayesian Methods"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaussian-quadrature",
      "term": "Gaussian Quadrature",
      "definition": "A family of numerical integration rules that select optimal evaluation points and weights to achieve maximum accuracy. An n-point Gaussian quadrature rule integrates polynomials of degree 2n-1 exactly.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaussian-splatting",
      "term": "Gaussian Splatting",
      "definition": "A 3D scene representation that models scenes as collections of 3D Gaussian primitives, enabling real-time rendering of photorealistic novel views through efficient rasterization rather than ray marching.",
      "tags": [
        "Computer Vision",
        "3D Vision"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaussiansplat",
      "term": "GaussianSplat",
      "definition": "A 3D scene representation method that uses anisotropic 3D Gaussians for real-time novel view synthesis and radiance field rendering.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gaze-estimation",
      "term": "Gaze Estimation",
      "definition": "The task of predicting where a person is looking based on their eye appearance and head pose in images or video, used in attention analysis, driver monitoring, and human-computer interaction.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gazetteer",
      "term": "Gazetteer",
      "definition": "A curated list of entity names organized by type, such as person names, locations, or organizations, used as a feature or lookup resource in named entity recognition systems.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-gddr5",
      "term": "GDDR5",
      "definition": "Fifth generation graphics double data rate memory used in GPUs from 2008 through the mid-2010s. Offered bandwidths up to 8 Gbps per pin for graphics and early AI workloads.",
      "tags": [
        "Memory",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gddr6",
      "term": "GDDR6",
      "definition": "Sixth generation graphics double data rate memory offering speeds up to 16 Gbps per pin. Standard memory type for consumer GPUs used in AI inference and smaller training tasks.",
      "tags": [
        "Memory",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gddr6x",
      "term": "GDDR6X",
      "definition": "Enhanced version of GDDR6 memory developed by Micron using PAM4 signaling to achieve speeds up to 23 Gbps per pin. Used in high-end NVIDIA consumer GPUs.",
      "tags": [
        "Memory",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gddr7",
      "term": "GDDR7",
      "definition": "Seventh generation graphics memory using PAM3 signaling to achieve speeds exceeding 32 Gbps per pin. Expected to power next-generation GPUs for both gaming and AI workloads.",
      "tags": [
        "Memory",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gdpr-ai-provisions",
      "term": "GDPR AI Provisions",
      "definition": "Provisions within the EU General Data Protection Regulation relevant to AI, including the right not to be subject to purely automated decisions, data protection impact assessments, and requirements for transparency.",
      "tags": [
        "Governance",
        "Regulation"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-gelu",
      "term": "GELU (Gaussian Error Linear Unit)",
      "definition": "An activation function commonly used in transformers that applies a smooth, probabilistic non-linearity. Outperforms ReLU in many language models.",
      "tags": [
        "Architecture",
        "Function"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gemini",
      "term": "Gemini",
      "definition": "Google's family of multimodal AI models that can process text, images, audio, and video. Powers Google's AI features including Bard and Workspace integrations.",
      "tags": [
        "Model",
        "Google"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gemini-ai",
      "term": "Gemini (AI)",
      "definition": "A multimodal AI model family developed by Google DeepMind announced in December 2023. Gemini was designed from the ground up to be natively multimodal understanding and generating text code images audio and video.",
      "tags": [
        "History",
        "Systems"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-gemini-flash",
      "term": "Gemini Flash",
      "definition": "A lightweight model in the Gemini family optimized for speed and efficiency. Designed for high-volume low-latency applications where fast responses are prioritized while maintaining good quality.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gemini-launch",
      "term": "Gemini Launch",
      "definition": "Google DeepMind's release of Gemini in December 2023, a family of multimodal large language models designed to process text, images, audio, and video, positioned as Google's most capable AI model.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-gemini-nano",
      "term": "Gemini Nano",
      "definition": "The smallest variant of Google Gemini designed to run on-device for mobile and edge applications with efficient multimodal reasoning capabilities.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gemini-pro",
      "term": "Gemini Pro",
      "definition": "A mid-tier model in Google's Gemini family designed for a wide range of tasks. Powers many Google AI products and is available through the Gemini API. Balances capability and efficiency.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gemini-ultra",
      "term": "Gemini Ultra",
      "definition": "The largest and most capable variant of Google Gemini designed for highly complex reasoning tasks across text and image and audio and video modalities.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gemma",
      "term": "Gemma",
      "definition": "A family of lightweight open models built by Google DeepMind from the same technology used to create Gemini. Available in 2B and 7B parameter sizes optimized for responsible AI development.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gemma-2",
      "term": "Gemma 2",
      "definition": "A second-generation family of lightweight open models by Google DeepMind with improved performance and efficiency across 2B and 9B and 27B parameter sizes using novel training techniques.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gemnet",
      "term": "GemNet",
      "definition": "A geometric message passing neural network for molecular property prediction that uses directional information through two-hop message passing with dihedral angles.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gen-2",
      "term": "Gen-2",
      "definition": "A multimodal AI model by Runway for generating and editing video from text images or existing video. One of the first commercially available AI video generation tools. Supports text-to-video image-to-video and video-to-video tasks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-genai-bench",
      "term": "GenAI-Bench",
      "definition": "A benchmark for evaluating generative AI models across multiple modalities including text-to-image and text-to-video generation. Tests complex compositional generation abilities.",
      "tags": [
        "Benchmark",
        "Multimodal",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-gencast",
      "term": "GenCast",
      "definition": "A diffusion-based probabilistic weather model from DeepMind that generates ensemble forecasts and outperforms operational weather prediction systems on many metrics.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gender-bias-in-ai",
      "term": "Gender Bias in AI",
      "definition": "Systematic unfairness in AI system behavior related to gender. Common in language models hiring tools and image generation systems due to historical gender imbalances in training data.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-general-problem-solver",
      "term": "General Problem Solver",
      "definition": "An AI program developed by Newell and Simon in 1957 that used means-ends analysis to solve a wide range of formalized problems, representing an early attempt at creating a general-purpose reasoning system.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-generalization",
      "term": "Generalization",
      "definition": "A model's ability to perform well on new, unseen data rather than just memorizing training examples. The fundamental goal of machine learning.",
      "tags": [
        "Concept",
        "Quality"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-generalized-advantage-estimation",
      "term": "Generalized Advantage Estimation (GAE)",
      "definition": "A technique that computes advantage function estimates using an exponentially-weighted average of multi-step TD errors, controlled by a lambda parameter. GAE provides a smooth tradeoff between bias and variance in advantage estimation.",
      "tags": [
        "Reinforcement Learning",
        "Policy Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-generalized-linear-model",
      "term": "Generalized Linear Model",
      "definition": "A flexible generalization of ordinary linear regression that allows the response variable to follow any distribution from the exponential family, using a link function to relate the linear predictor to the mean of the distribution.",
      "tags": [
        "Statistics",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-generalized-policy-iteration",
      "term": "Generalized Policy Iteration",
      "definition": "A framework describing how policy evaluation and policy improvement alternate and interact to converge to optimal policies. Nearly all reinforcement learning methods can be described as instances of this scheme.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-generated-knowledge-prompting",
      "term": "Generated Knowledge Prompting",
      "definition": "A technique where the model first generates relevant knowledge or facts about a topic, then uses that self-generated knowledge as additional context to answer a downstream question more accurately.",
      "tags": [
        "Prompt Engineering",
        "Knowledge Augmentation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-generation",
      "term": "Generation",
      "definition": "The process of producing new content from an AI model. Text generation works by predicting one token at a time; image generation uses diffusion or similar processes.",
      "tags": [
        "Process",
        "Core Concept"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-generative-adversarial-imitation-learning",
      "term": "Generative Adversarial Imitation Learning",
      "definition": "An imitation learning algorithm that uses a discriminator to distinguish between expert and agent trajectories. The agent is trained to fool the discriminator by matching the expert's occupancy measure.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gail",
      "term": "Generative Adversarial Imitation Learning (GAIL)",
      "definition": "An imitation learning algorithm that uses a GAN-like framework where a discriminator distinguishes between agent and expert trajectories while the policy learns to fool the discriminator. GAIL avoids explicit reward function recovery.",
      "tags": [
        "Reinforcement Learning",
        "Imitation"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-gan-history",
      "term": "Generative Adversarial Network History",
      "definition": "The development of GANs from Ian Goodfellow's 2014 invention through progressive improvements including DCGAN, StyleGAN, and BigGAN, which dominated image generation before being supplanted by diffusion models.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-generative-ai",
      "term": "Generative AI",
      "definition": "AI systems that can create new content (text, images, code, music, video) rather than just analyzing existing data. Includes chatbots, image generators, and coding assistants.",
      "tags": [
        "Field",
        "Category"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-generative-ai-era",
      "term": "Generative AI Era",
      "definition": "The period beginning approximately in 2022 with the release of ChatGPT DALL-E 2 and Stable Diffusion when generative AI models capable of creating text images code and other content became widely accessible to the public transforming creative industries and knowledge work.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-generative-ai-misuse",
      "term": "Generative AI Misuse",
      "definition": "The use of generative AI systems to create harmful content including disinformation non-consensual imagery fraud materials and spam. A growing challenge as generative capabilities improve.",
      "tags": [
        "Safety",
        "Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-generative-question-answering",
      "term": "Generative Question Answering",
      "definition": "A QA approach where the model generates a free-form answer in natural language rather than extracting a span, enabling responses that synthesize information or require reasoning.",
      "tags": [
        "NLP",
        "Text Processing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-genetic-algorithm",
      "term": "Genetic Algorithm",
      "definition": "An evolutionary optimization algorithm inspired by natural selection. Maintains a population of candidate solutions that undergo selection crossover and mutation over generations. Effective for black-box optimization and combinatorial problems.",
      "tags": [
        "Algorithms",
        "Fundamentals"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-genetic-algorithms",
      "term": "Genetic Algorithms",
      "definition": "Optimization algorithms inspired by natural selection, developed by John Holland in the 1960s-1970s, that evolve candidate solutions through selection, crossover, and mutation operators to find optimal or near-optimal solutions.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-geneval",
      "term": "GenEval",
      "definition": "A benchmark for evaluating compositional image generation testing object counting color binding spatial relationships and overall image quality.",
      "tags": [
        "Benchmark",
        "Multimodal",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-genie",
      "term": "Genie",
      "definition": "A generative interactive environment model from DeepMind that creates playable 2D worlds from single images or text descriptions using a latent action space.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-genie-2",
      "term": "Genie 2",
      "definition": "A large-scale world model from Google DeepMind that generates persistent and controllable 3D environments from single images for training embodied AI agents.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-geoffrey-hinton",
      "term": "Geoffrey Hinton",
      "definition": "British-Canadian computer scientist known as a godfather of deep learning, who co-developed backpropagation, Boltzmann machines, and deep belief networks. He won the 2024 Nobel Prize in Physics for foundational work on neural networks.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-geometric-augmentation",
      "term": "Geometric Augmentation",
      "definition": "Image augmentation techniques that modify the spatial arrangement of pixels including rotation, translation, scaling, shearing, flipping, and perspective transformations to improve model invariance.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-geoqa",
      "term": "GeoQA",
      "definition": "A geometric problem solving dataset requiring mathematical reasoning about geometric figures. Tests the ability to combine visual understanding with mathematical problem solving.",
      "tags": [
        "Benchmark",
        "Multimodal",
        "Reasoning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-georgetown-ibm-experiment",
      "term": "Georgetown-IBM Experiment",
      "definition": "A 1954 demonstration of automatic translation of Russian sentences into English using an IBM 701 computer. Though limited to 250 words and six grammar rules the experiment generated optimism about machine translation and increased government funding for NLP research.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-ges-algorithm",
      "term": "GES Algorithm",
      "definition": "Greedy Equivalence Search is a score-based causal discovery algorithm that searches over equivalence classes of directed acyclic graphs. Performs greedy forward and backward steps to optimize a scoring criterion.",
      "tags": [
        "Algorithms",
        "Technical",
        "Causal"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gguf",
      "term": "GGUF",
      "definition": "A binary file format designed for storing quantized language models optimized for CPU and hybrid CPU/GPU inference, commonly used with the llama.cpp ecosystem.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gh200",
      "term": "GH200 Grace Hopper Superchip",
      "definition": "NVIDIA's integrated CPU-GPU superchip combining a Grace ARM CPU with a Hopper H200 GPU connected by a high-bandwidth NVLink-C2C interconnect. The GH200 provides unified memory addressing and eliminates PCIe bottlenecks for AI workloads.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ghost-work",
      "term": "Ghost Work",
      "definition": "The often invisible human labor that powers AI systems, including data labeling, content moderation, and quality assurance, frequently performed by low-paid workers in developing countries under precarious conditions.",
      "tags": [
        "AI Ethics",
        "Fairness"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-gibbs-sampling",
      "term": "Gibbs Sampling",
      "definition": "An MCMC method that samples each variable in turn from its conditional distribution given the current values of all other variables. It is efficient when conditional distributions are easy to sample from.",
      "tags": [
        "Statistics",
        "Bayesian Methods"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gigaspeech",
      "term": "GigaSpeech",
      "definition": "A 10000-hour English speech recognition corpus from audiobooks podcasts and YouTube. Designed to provide large-scale speech data with accurate transcriptions for ASR research.",
      "tags": [
        "Training Corpus",
        "Speech"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-gigast",
      "term": "GigaST",
      "definition": "A large-scale speech translation dataset containing over 10000 hours of speech with translations. Created by aligning GigaSpeech audio with machine translations for speech translation research.",
      "tags": [
        "Training Corpus",
        "Speech",
        "Translation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-gini-impurity",
      "term": "Gini Impurity",
      "definition": "A measure of the probability that a randomly chosen sample would be misclassified if labeled according to the class distribution at a node. It is commonly used as a splitting criterion in decision tree algorithms.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-girvan-newman-algorithm",
      "term": "Girvan-Newman Algorithm",
      "definition": "A community detection method that identifies communities by progressively removing edges with the highest betweenness centrality. Recalculates betweenness after each removal and uses the resulting connected components as communities.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-github-code",
      "term": "GitHub Code",
      "definition": "Large-scale collections of source code from public GitHub repositories used to train code generation models. Various filtered versions exist including those used for Codex and CodeGen.",
      "tags": [
        "Training Corpus",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-github-copilot",
      "term": "GitHub Copilot",
      "definition": "An AI pair programmer integrated into code editors. Uses LLMs to suggest code completions, write functions, and explain code. One of the most successful AI developer tools.",
      "tags": [
        "Product",
        "Development"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-github-copilot-launch",
      "term": "GitHub Copilot Launch",
      "definition": "The public release of GitHub Copilot in June 2022 an AI pair programming tool powered by OpenAI Codex. Copilot generates code suggestions in real-time within code editors marking a milestone in AI-assisted software development.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-github-issues-dataset",
      "term": "GitHub Issues Dataset",
      "definition": "Collections of GitHub issue reports and discussions used for training models on software engineering tasks including bug reporting and feature requests.",
      "tags": [
        "Training Corpus",
        "Code"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-givens-rotation",
      "term": "Givens Rotation",
      "definition": "A rotation in the plane of two coordinate axes used to introduce zeros into a matrix. Applied sequentially to perform QR decomposition and is particularly efficient for sparse matrices and parallel computation.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gla",
      "term": "GLA",
      "definition": "Gated Linear Attention is a recurrent model that adds a data-dependent gating mechanism to linear attention for improved performance on language modeling tasks.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-glide",
      "term": "GLIDE",
      "definition": "Guided Language to Image Diffusion for Generation and Editing is an OpenAI model that uses classifier-free guidance for text-conditional image generation.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "History"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-glm",
      "term": "GLM",
      "definition": "General Language Model is an autoregressive blank infilling pre-training framework from Tsinghua University that unifies understanding and generation tasks.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-glm-4",
      "term": "GLM-4",
      "definition": "A fourth-generation general language model from Tsinghua that supports multi-turn dialogue and web browsing and code execution and multimodal inputs.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-glm-4v",
      "term": "GLM-4V",
      "definition": "A multimodal variant of the GLM-4 language model from Tsinghua University that supports visual understanding alongside text generation.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-global-average-pooling",
      "term": "Global Average Pooling",
      "definition": "A pooling operation that computes the mean of each feature map across all spatial dimensions, reducing the feature map to a single value per channel and often replacing fully connected layers.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-globalbench",
      "term": "GlobalBench",
      "definition": "A benchmark measuring NLP model performance and data availability across the worlds languages. Highlights the disparity between high-resource and low-resource language support.",
      "tags": [
        "Benchmark",
        "NLP",
        "Multilingual",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-globalfoundries",
      "term": "GlobalFoundries",
      "definition": "Major semiconductor foundry offering mature process nodes for automotive IoT and specialized chips. Exited the leading-edge race to focus on differentiated technology for specific markets.",
      "tags": [
        "Fabrication",
        "Foundry"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-glove",
      "term": "GloVe",
      "definition": "Global Vectors for Word Representation, a word embedding method that trains on aggregated word co-occurrence statistics from a corpus, combining global matrix factorization with local context window methods.",
      "tags": [
        "NLP",
        "Embeddings"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-glove-algorithm",
      "term": "GloVe Algorithm",
      "definition": "Global Vectors for Word Representation learns word embeddings by factorizing the log of the word co-occurrence matrix. Combines the advantages of global matrix factorization and local context window methods.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "NLP"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-glu",
      "term": "GLU",
      "definition": "Gated Linear Unit that splits input into two halves and applies a sigmoid gate to one half then multiplies element-wise. Introduced for language modeling by Dauphin et al. in 2017. Enables the network to control information flow through learned gating.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-glue",
      "term": "GLUE",
      "definition": "The General Language Understanding Evaluation benchmark containing nine natural language understanding tasks including sentiment analysis textual entailment and semantic similarity. Created by NYU and others in 2018.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-glue-benchmark",
      "term": "GLUE Benchmark",
      "definition": "The General Language Understanding Evaluation benchmark introduced in 2018 consisting of nine natural language understanding tasks. GLUE provided a standardized way to evaluate language models and was quickly surpassed by models like BERT leading to the harder SuperGLUE benchmark.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-gmflow",
      "term": "GMFlow",
      "definition": "A Transformer-based optical flow model that reformulates optical flow as a global matching problem using cross-attention for accurate motion estimation.",
      "tags": [
        "Models",
        "Technical",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gmres-algorithm",
      "term": "GMRES Algorithm",
      "definition": "Generalized Minimal Residual method is an iterative algorithm for solving large non-symmetric linear systems. Minimizes the residual over a Krylov subspace using Arnoldi iteration and is widely used in scientific computing.",
      "tags": [
        "Algorithms",
        "Technical",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gnome",
      "term": "GNoME",
      "definition": "Graph Networks for Materials Exploration from DeepMind that discovers stable crystal structures and predicts material properties for materials science.",
      "tags": [
        "Models",
        "Scientific"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gnome-sort",
      "term": "Gnome Sort",
      "definition": "A sorting algorithm that works by moving an element backward through the sorted portion until it finds its correct position then moving forward again. Conceptually similar to insertion sort but with a simpler loop structure.",
      "tags": [
        "Algorithms",
        "Technical",
        "Sorting"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-go-explore-algorithm",
      "term": "Go-Explore Algorithm",
      "definition": "An exploration algorithm for hard-exploration reinforcement learning problems that maintains an archive of interesting states and returns to them before exploring further. Solves environments with deceptive or sparse rewards.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-goal-misgeneralization",
      "term": "Goal Misgeneralization",
      "definition": "A failure mode where an AI system learns to pursue a proxy goal that correlates with the intended goal during training but diverges in deployment. A key concern in reinforcement learning safety.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-goal-conditioned-reinforcement-learning",
      "term": "Goal-Conditioned Reinforcement Learning",
      "definition": "A framework where the agent learns to achieve arbitrary goals specified as input. The policy is conditioned on both the current state and a goal enabling generalization across different objectives.",
      "tags": [
        "Algorithms",
        "Technical",
        "RL"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-goal-conditioned-rl",
      "term": "Goal-Conditioned RL",
      "definition": "An RL formulation where the agent's policy and value function are conditioned on a goal specifying what the agent should achieve. Goal-conditioned policies enable multi-task learning and generalization across different objectives.",
      "tags": [
        "Reinforcement Learning",
        "Training Paradigms"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-goedel-escher-bach",
      "term": "Goedel Escher Bach",
      "definition": "A 1979 book by Douglas Hofstadter exploring common themes in the works of mathematician Kurt Goedel artist M.C. Escher and composer Johann Sebastian Bach. The book examines self-reference recursion and the nature of intelligence winning the Pulitzer Prize.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-goedels-incompleteness-theorems",
      "term": "Goedel's Incompleteness Theorems",
      "definition": "Two theorems published by Kurt Goedel in 1931 showing that any consistent formal system capable of expressing basic arithmetic contains statements that are true but unprovable within the system. These results have philosophical implications for the limits of AI reasoning.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-goertzel-algorithm",
      "term": "Goertzel Algorithm",
      "definition": "An efficient algorithm for computing individual terms of the discrete Fourier transform. More efficient than FFT when only a few frequency bins are needed and used in DTMF tone detection.",
      "tags": [
        "Algorithms",
        "Technical",
        "Signal Processing"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gofai-good-old-fashioned-ai",
      "term": "GOFAI (Good Old-Fashioned AI)",
      "definition": "A term coined by philosopher John Haugeland in 1985 referring to classical symbolic AI approaches based on physical symbol systems. GOFAI relies on explicit knowledge representation logical reasoning and search as opposed to the statistical learning methods that later became dominant.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-golden-section-search",
      "term": "Golden Section Search",
      "definition": "A technique for finding the extremum of a unimodal function by successively narrowing the interval using the golden ratio. Similar to binary search but for continuous functions and does not require derivatives.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-golomb-coding-algorithm",
      "term": "Golomb Coding Algorithm",
      "definition": "A family of optimal codes for geometric distributions that divides each integer by a parameter m and encodes the quotient and remainder separately. Used in lossless image compression and data storage.",
      "tags": [
        "Algorithms",
        "Technical",
        "Information Theory"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-goodharts-law-in-ai",
      "term": "Goodhart's Law in AI",
      "definition": "The principle that when a proxy measure becomes the target for optimization, it ceases to be a good measure. In AI, this manifests when models over-optimize a proxy reward, diverging from the true intended goal.",
      "tags": [
        "AI Safety",
        "Alignment"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-google-brain",
      "term": "Google Brain",
      "definition": "A deep learning research project founded at Google in 2011 by Andrew Ng and Jeff Dean that demonstrated unsupervised learning on YouTube videos and became a major center for neural network research before merging into Google DeepMind in 2023.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-google-brain-founded",
      "term": "Google Brain Founded",
      "definition": "The founding of Google Brain as a deep learning research project within Google in 2011 by Andrew Ng and Jeff Dean. The team achieved a breakthrough when their neural network autonomously learned to recognize cats in YouTube videos demonstrating unsupervised feature learning at scale.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-google-cloud-a3-instance",
      "term": "Google Cloud A3 Instance",
      "definition": "Google Cloud virtual machine type powered by NVIDIA H100 GPUs with high-bandwidth networking for AI training. Optimized for training large language models and generative AI.",
      "tags": [
        "Cloud",
        "Google",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-google-cloud-tpu",
      "term": "Google Cloud TPU",
      "definition": "Cloud service providing access to Google TPU accelerators for AI training and inference. Users can provision TPU Pods through Google Cloud for large-scale model training.",
      "tags": [
        "Cloud",
        "Google",
        "TPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-google-coral-dev-board",
      "term": "Google Coral Dev Board",
      "definition": "Single-board computer from Google featuring an Edge TPU for local AI inference. Designed for prototyping edge AI products with support for TensorFlow Lite models.",
      "tags": [
        "Edge",
        "Google",
        "Platform"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-google-deepmind",
      "term": "Google DeepMind",
      "definition": "An AI research laboratory formed in April 2023 by merging Google Brain and DeepMind, created from the original DeepMind Technologies founded by Demis Hassabis, Shane Legg, and Mustafa Suleyman in 2010.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-google-landmarks",
      "term": "Google Landmarks",
      "definition": "A large-scale dataset of landmark images for instance recognition and retrieval containing over 5 million images of 200000 landmarks worldwide.",
      "tags": [
        "Benchmark",
        "Computer Vision"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-google-sycamore",
      "term": "Google Sycamore",
      "definition": "Google 53-qubit quantum processor that demonstrated quantum supremacy in 2019 by performing a calculation in 200 seconds that would take classical supercomputers thousands of years.",
      "tags": [
        "Quantum",
        "Google",
        "Processor"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-google-tensor-chip",
      "term": "Google Tensor Chip",
      "definition": "Custom system-on-chip designed by Google for Pixel smartphones integrating a dedicated TPU core for on-device AI tasks like speech recognition photo processing and language models.",
      "tags": [
        "Mobile",
        "Google",
        "SoC"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-tpu-v5",
      "term": "Google TPU v5",
      "definition": "The fifth generation of Google's Tensor Processing Unit featuring improved matrix multiply units, increased memory bandwidth, and better inter-chip interconnect. TPU v5 pods scale to thousands of chips for training the largest foundation models.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-google-translate-neural-mt",
      "term": "Google Translate Neural MT",
      "definition": "Google's 2016 transition from statistical to neural machine translation using sequence-to-sequence models with attention, dramatically improving translation quality and bringing neural networks to a product used by billions.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-google-willow",
      "term": "Google Willow",
      "definition": "Google quantum computing chip that achieved below-threshold quantum error correction in 2024. Demonstrated that adding more qubits can reduce rather than increase errors.",
      "tags": [
        "Quantum",
        "Google",
        "Processor"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-googlenet",
      "term": "GoogLeNet",
      "definition": "The winner of the 2014 ImageNet competition also known as Inception v1. Introduced the inception module that processes input through multiple filter sizes in parallel. Achieved state-of-the-art accuracy with significantly fewer parameters than VGG.",
      "tags": [
        "Models",
        "History"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gopher",
      "term": "Gopher",
      "definition": "A 280 billion parameter language model by DeepMind that advanced understanding of language model scaling. Provided comprehensive analysis of model behavior across 152 diverse tasks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gorilla",
      "term": "Gorilla",
      "definition": "A large language model fine-tuned for API call generation that reduces hallucination and accurately generates function calls for thousands of APIs.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gorilla-apibench",
      "term": "Gorilla APIBench",
      "definition": "A benchmark of over 1600 API calls testing the ability of LLMs to generate accurate and up-to-date API function calls from natural language descriptions.",
      "tags": [
        "Benchmark",
        "NLP",
        "Code",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-gossip-protocol-algorithm",
      "term": "Gossip Protocol Algorithm",
      "definition": "A communication protocol inspired by epidemic spreading where nodes periodically exchange information with random peers. Eventually disseminates information to all nodes with probabilistic guarantees and high fault tolerance.",
      "tags": [
        "Algorithms",
        "Technical",
        "Data Structure"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-got-ocr",
      "term": "GOT-OCR",
      "definition": "General OCR Theory is a unified end-to-end OCR model that handles diverse optical character recognition scenarios including scene text and documents and formulas.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-govreport",
      "term": "GovReport",
      "definition": "A dataset of long government reports paired with expert-written summaries for evaluating long document summarization. Reports average 9000 words testing models ability to handle lengthy inputs.",
      "tags": [
        "Benchmark",
        "NLP"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpfs",
      "term": "GPFS",
      "definition": "IBM General Parallel File System now called Spectrum Scale providing high-performance distributed storage. Widely used in HPC and AI clusters for shared access to large training datasets.",
      "tags": [
        "Storage",
        "IBM",
        "Distributed"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpqa",
      "term": "GPQA",
      "definition": "Graduate-Level Google-Proof Question Answering, an extremely difficult benchmark of expert-crafted questions across biology, physics, and chemistry that even domain experts struggle with, designed to evaluate advanced reasoning beyond what search engines can resolve.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpqa-diamond",
      "term": "GPQA Diamond",
      "definition": "The most challenging subset of GPQA containing expert-validated graduate-level questions. Tests the frontier of AI reasoning on problems that challenge domain experts.",
      "tags": [
        "Benchmark",
        "NLP",
        "Reasoning",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt",
      "term": "GPT (Generative Pre-trained Transformer)",
      "definition": "OpenAI's series of large language models. GPT-4 is the latest major version, known for strong reasoning, multimodal capabilities, and broad knowledge.",
      "tags": [
        "Model",
        "OpenAI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-scaling-laws",
      "term": "GPT Scaling Laws",
      "definition": "Empirical power-law relationships discovered by Kaplan et al. at OpenAI in 2020 showing that language model performance improves predictably with increases in model size, dataset size, and training compute.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-1",
      "term": "GPT-1",
      "definition": "The first Generative Pre-trained Transformer model released by OpenAI in June 2018, demonstrating that unsupervised pre-training on large text corpora followed by task-specific fine-tuning could achieve strong NLP performance.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-2",
      "term": "GPT-2",
      "definition": "A 1.5-billion parameter autoregressive language model by OpenAI that demonstrated strong text generation capabilities and was initially withheld from full release due to concerns about misuse.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-3",
      "term": "GPT-3",
      "definition": "A 175-billion parameter autoregressive transformer model by OpenAI that popularized few-shot and zero-shot learning through in-context prompting without fine-tuning.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-35",
      "term": "GPT-3.5",
      "definition": "An improved version of GPT-3 fine-tuned with reinforcement learning from human feedback. Powers the initial release of ChatGPT. Demonstrates significant improvements in following instructions and producing helpful safe responses.",
      "tags": [
        "Models",
        "Fundamentals"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-4",
      "term": "GPT-4",
      "definition": "OpenAI's multimodal large language model released in March 2023, capable of processing both text and images, demonstrating human-level performance on many professional and academic benchmarks.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-4-turbo",
      "term": "GPT-4 Turbo",
      "definition": "An optimized version of GPT-4 from OpenAI with a 128K context window and reduced cost and improved instruction following and knowledge cutoff.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Products"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-4o",
      "term": "GPT-4o",
      "definition": "A multimodal model from OpenAI that natively processes text audio and images. Features faster response times and improved capabilities across modalities compared to previous GPT-4 variants. Designed for real-time conversational applications.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-4o-mini",
      "term": "GPT-4o mini",
      "definition": "A compact and cost-efficient variant of GPT-4o from OpenAI designed for lightweight applications while retaining multimodal understanding capabilities.",
      "tags": [
        "Models",
        "Technical",
        "NLP",
        "Products"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-4v",
      "term": "GPT-4V",
      "definition": "GPT-4 with Vision extends GPT-4 with the ability to understand and reason about images. Accepts interleaved text and image inputs enabling visual question answering image analysis and multimodal reasoning tasks.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-driver",
      "term": "GPT-Driver",
      "definition": "A motion planning approach for autonomous driving that repurposes a language model to reason about driving scenarios and generate vehicle trajectories.",
      "tags": [
        "Models",
        "Technical",
        "Autonomous",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-j",
      "term": "GPT-J",
      "definition": "A 6-billion parameter open-source autoregressive language model created by EleutherAI, notable for being one of the first performant open-source alternatives to GPT-3.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-neox",
      "term": "GPT-NeoX",
      "definition": "A 20-billion parameter autoregressive language model by EleutherAI that uses rotary positional embeddings and parallel attention-feedforward computation for improved efficiency.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-score",
      "term": "GPT-Score",
      "definition": "An evaluation framework that leverages generative pre-trained models to score text quality by computing conditional generation probabilities, assessing how likely a model would generate the candidate text given a quality-indicating prompt template.",
      "tags": [
        "Evaluation",
        "LLM-Based"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt-sovits",
      "term": "GPT-SoVITS",
      "definition": "A few-shot voice cloning and text-to-speech system that combines GPT-style language modeling with SoVITS for high-quality speech synthesis from brief audio samples.",
      "tags": [
        "Models",
        "Technical",
        "Audio"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpt4ts",
      "term": "GPT4TS",
      "definition": "A method that repurposes frozen GPT-2 backbones for time series tasks by treating time series patches as token embeddings for zero-shot forecasting.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gptq",
      "term": "GPTQ",
      "definition": "A post-training quantization method for large language models that uses approximate second-order information to compress weights to lower bit precision (typically 4-bit) with minimal accuracy loss.",
      "tags": [
        "LLM",
        "Inference"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu",
      "term": "GPU (Graphics Processing Unit)",
      "definition": "Hardware originally designed for graphics that excels at the parallel computations needed for AI. NVIDIA GPUs are the dominant hardware for training and running large AI models.",
      "tags": [
        "Hardware",
        "Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu-architecture",
      "term": "GPU Architecture for AI",
      "definition": "The parallel processing design of graphics processing units optimized for AI workloads, featuring thousands of cores organized in streaming multiprocessors with shared memory hierarchies. Modern GPU architectures include specialized tensor processing units alongside general-purpose cores.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu-clock-speed",
      "term": "GPU Clock Speed",
      "definition": "The operating frequency of a GPU processor measured in megahertz or gigahertz. Higher clock speeds enable more computations per second but increase power consumption and heat generation.",
      "tags": [
        "GPU",
        "Performance"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu-cluster",
      "term": "GPU Cluster",
      "definition": "Collection of interconnected GPU-equipped servers working together for distributed AI training. Clusters range from a few nodes to thousands of servers for training frontier AI models.",
      "tags": [
        "Infrastructure",
        "GPU",
        "Cluster"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu-computing-revolution",
      "term": "GPU Computing Revolution",
      "definition": "The adoption of graphics processing units for general-purpose computing and machine learning beginning around 2007-2012. NVIDIA CUDA (2007) and cuDNN (2014) enabled massive parallelization of neural network training catalyzing the deep learning revolution.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu-direct",
      "term": "GPU Direct",
      "definition": "NVIDIA's technology suite enabling direct data transfers between GPUs and network adapters or storage without staging through CPU memory. GPU Direct RDMA eliminates extra copy operations, reducing communication latency in distributed training.",
      "tags": [
        "Distributed Computing",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu-memory-bandwidth",
      "term": "GPU Memory Bandwidth",
      "definition": "The rate at which data can be read from or written to GPU memory measured in gigabytes per second. A critical bottleneck for memory-bound AI operations like attention computation.",
      "tags": [
        "GPU",
        "Memory",
        "Performance"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu-memory-hierarchy",
      "term": "GPU Memory Hierarchy",
      "definition": "The layered memory system in GPUs consisting of registers, shared memory (SRAM), L2 cache, and global memory (HBM/GDDR). Understanding and optimizing data placement across this hierarchy is critical for AI workload performance.",
      "tags": [
        "Hardware",
        "GPU"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu-passthrough",
      "term": "GPU Passthrough",
      "definition": "Virtualization technique that gives a virtual machine direct access to a physical GPU. Enables bare-metal GPU performance for AI workloads running in virtualized cloud environments.",
      "tags": [
        "Virtualization",
        "GPU",
        "Cloud"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu-profiling",
      "term": "GPU Profiling",
      "definition": "Process of measuring and analyzing GPU resource utilization memory access patterns and kernel execution to identify performance bottlenecks. Essential for optimizing AI training throughput.",
      "tags": [
        "Programming",
        "Performance",
        "Development"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu-thermal-throttling",
      "term": "GPU Thermal Throttling",
      "definition": "Automatic reduction of GPU clock speeds when temperature exceeds safe limits. Impacts AI training throughput in poorly cooled systems or during extended heavy workloads.",
      "tags": [
        "GPU",
        "Performance",
        "Cooling"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpu-utilization",
      "term": "GPU Utilization",
      "definition": "Percentage of time the GPU compute engines are actively processing during a given period. Low utilization during AI training indicates bottlenecks in data loading or communication.",
      "tags": [
        "Performance",
        "GPU",
        "Metric"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpudirect-rdma",
      "term": "GPUDirect RDMA",
      "definition": "NVIDIA technology enabling direct data transfer between GPU memory and network adapters bypassing CPU and system memory. Reduces latency for inter-node GPU communication in AI clusters.",
      "tags": [
        "Networking",
        "NVIDIA",
        "Performance"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gpudirect-storage",
      "term": "GPUDirect Storage",
      "definition": "NVIDIA technology enabling direct data transfer between GPU memory and storage devices bypassing CPU. Accelerates AI data loading by eliminating unnecessary data copies through system memory.",
      "tags": [
        "Storage",
        "NVIDIA",
        "Performance"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gqa",
      "term": "GQA",
      "definition": "A visual question answering dataset with 22 million questions grounded in scene graphs from Visual Genome. Designed for real-world visual reasoning with reduced language bias.",
      "tags": [
        "Benchmark",
        "Multimodal"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-grabcut-algorithm",
      "term": "GrabCut Algorithm",
      "definition": "An interactive foreground extraction algorithm that iteratively estimates foreground and background using Gaussian mixture models and graph cuts. Requires minimal user input to produce accurate segmentation results.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-grace-cpu",
      "term": "Grace CPU",
      "definition": "NVIDIA ARM-based data center CPU designed for AI and HPC workloads. Features LPDDR5X memory with high bandwidth and low power paired with Hopper GPUs in the Grace Hopper Superchip.",
      "tags": [
        "Processor",
        "NVIDIA",
        "ARM"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-grace-hopper",
      "term": "Grace Hopper",
      "definition": "American computer scientist and United States Navy rear admiral who developed the first compiler (A-0 System) in 1952. Pioneered the concept of machine-independent programming languages and contributed to the development of COBOL. Popularized the term debugging.",
      "tags": [
        "History",
        "Pioneers"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-grad-cam",
      "term": "Grad-CAM",
      "definition": "Gradient-weighted Class Activation Mapping, a visualization method that uses gradients flowing into the final convolutional layer to produce a heatmap highlighting important regions for any CNN prediction.",
      "tags": [
        "Computer Vision",
        "Image Processing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient",
      "term": "Gradient",
      "definition": "A vector indicating the direction and magnitude of change needed to reduce a model's error. The foundation of gradient descent optimization used in training neural networks.",
      "tags": [
        "Training",
        "Math"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient-accumulation",
      "term": "Gradient Accumulation",
      "definition": "A technique that simulates larger batch sizes by accumulating gradients over multiple forward-backward passes before performing a parameter update. Gradient accumulation enables training with effective batch sizes larger than GPU memory allows.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient-boosted-trees-model",
      "term": "Gradient Boosted Trees Model",
      "definition": "An ensemble method that sequentially adds decision trees where each new tree corrects the residual errors of the previous ensemble.",
      "tags": [
        "Models",
        "Fundamentals"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient-boosting",
      "term": "Gradient Boosting",
      "definition": "An ensemble technique that builds models sequentially, with each new model trained to correct the residual errors of the combined ensemble so far, using gradient descent in function space to minimize a specified loss.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient-boosting-history",
      "term": "Gradient Boosting History",
      "definition": "The development of gradient boosting from the work of Jerome Friedman (2001) through XGBoost (Chen and Guestrin 2016) LightGBM (Ke et al. 2017) and CatBoost. Gradient boosted trees became dominant in structured data competitions and production ML systems.",
      "tags": [
        "History",
        "Fundamentals"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient-checkpointing",
      "term": "Gradient Checkpointing",
      "definition": "A memory optimization technique that trades computation for memory by only storing activations at selected checkpoints during the forward pass and recomputing intermediate activations during backpropagation.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient-clipping",
      "term": "Gradient Clipping",
      "definition": "A technique that rescales or truncates gradients when their norm exceeds a specified threshold, preventing the exploding gradient problem that can destabilize training in deep networks and recurrent architectures.",
      "tags": [
        "Machine Learning",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient-descent",
      "term": "Gradient Descent",
      "definition": "The optimization algorithm that trains neural networks by iteratively adjusting weights in the direction that reduces error. Variants include SGD, Adam, and AdaGrad.",
      "tags": [
        "Algorithm",
        "Training"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient-leakage",
      "term": "Gradient Leakage",
      "definition": "An attack that reconstructs private training data from model gradients shared during federated learning or collaborative training. Demonstrates that sharing model updates alone does not guarantee data privacy.",
      "tags": [
        "Safety",
        "Technical"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient-projection-method",
      "term": "Gradient Projection Method",
      "definition": "An optimization algorithm for constrained problems that projects the gradient onto the feasible set at each iteration. Effective for problems with simple constraint sets where projection can be computed efficiently.",
      "tags": [
        "Algorithms",
        "Technical",
        "Optimization"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient-surgery",
      "term": "Gradient Surgery",
      "definition": "A technique for multi-task learning that modifies conflicting gradients from different tasks to reduce interference. Projects conflicting gradients so they do not oppose each other enabling better optimization across all tasks simultaneously.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gradient-synchronization",
      "term": "Gradient Synchronization",
      "definition": "The process of aggregating gradients across multiple GPUs or nodes in distributed training, typically via all-reduce. Synchronous methods wait for all workers while asynchronous methods allow stale gradients for faster iteration.",
      "tags": [
        "Distributed Computing",
        "Model Optimization"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gram-schmidt-orthogonalization",
      "term": "Gram-Schmidt Orthogonalization",
      "definition": "A procedure for orthonormalizing a set of vectors in an inner product space. Produces an orthonormal basis from a linearly independent set but can suffer from numerical instability in its classical form.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-grammar-constrained-decoding",
      "term": "Grammar-Constrained Decoding",
      "definition": "A decoding approach that restricts token generation to sequences valid under a formal grammar (such as BNF or regex), ensuring outputs always conform to specified structural formats.",
      "tags": [
        "Generative AI",
        "Decoding"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-granger-causality",
      "term": "Granger Causality",
      "definition": "A statistical concept where a time series X is said to Granger-cause Y if past values of X provide statistically significant information about future values of Y beyond what past values of Y alone provide.",
      "tags": [
        "Statistics",
        "Data Science"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-granger-causality-test",
      "term": "Granger Causality Test",
      "definition": "A statistical test that determines whether one time series is useful for forecasting another. Tests if past values of one variable improve predictions of another beyond what past values of the target alone provide.",
      "tags": [
        "Algorithms",
        "Fundamentals",
        "Causal"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-granite",
      "term": "Granite",
      "definition": "A family of enterprise-grade language models from IBM trained on curated business and code data with strong governance and compliance features.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-granite-code",
      "term": "Granite Code",
      "definition": "A family of code-generation models from IBM Granite series trained on permissively licensed code data for enterprise software development tasks.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-granite-code-instruct",
      "term": "Granite Code Instruct",
      "definition": "Instruction-tuned variants of IBM Granite Code models for following complex coding instructions and generating well-documented solutions.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-graph-attention",
      "term": "Graph Attention",
      "definition": "An attention mechanism applied to graph-structured data that learns to weight the importance of different neighbor nodes. Introduced in Graph Attention Networks allowing nodes to attend to their neighbors with different importance weights.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gat",
      "term": "Graph Attention Network",
      "definition": "A graph neural network that uses attention mechanisms to weight the importance of neighboring nodes' features during aggregation, learning to focus on the most relevant connections.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-graph-coloring-algorithm",
      "term": "Graph Coloring Algorithm",
      "definition": "An algorithm that assigns colors to vertices of a graph such that no two adjacent vertices share the same color. The goal is typically to minimize the number of colors used which is known as the chromatic number.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-graph-convolution",
      "term": "Graph Convolution",
      "definition": "An operation that extends convolution to graph-structured data by aggregating features from neighboring nodes. Spectral approaches use graph Fourier transforms while spatial approaches directly aggregate neighbor features. Core operation in GCNs.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gcn",
      "term": "Graph Convolutional Network",
      "definition": "A neural network that operates on graph-structured data by aggregating features from neighboring nodes through learnable convolutional operations defined on the graph topology.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-graph-isomorphism-algorithm",
      "term": "Graph Isomorphism Algorithm",
      "definition": "An algorithm that determines whether two graphs are structurally identical by finding a bijection between their vertex sets that preserves adjacency. Babai's quasipolynomial-time algorithm was a major breakthrough in 2015.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gin",
      "term": "Graph Isomorphism Network",
      "definition": "A graph neural network provably as powerful as the Weisfeiler-Lehman graph isomorphism test, using a sum aggregator and MLP update function to maximize discriminative power on graph structures.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-graph-laplacian-algorithm",
      "term": "Graph Laplacian Algorithm",
      "definition": "A method that constructs the Laplacian matrix of a graph from its adjacency and degree matrices. The eigenvalues and eigenvectors of the Laplacian reveal structural properties such as connectivity and clustering.",
      "tags": [
        "Algorithms",
        "Technical",
        "Graph",
        "Numerical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-graph-neural-network",
      "term": "Graph Neural Network",
      "definition": "A class of neural networks designed to operate on graph-structured data. Learns node edge or graph-level representations by aggregating information from local neighborhoods. Applied to social networks molecules and knowledge graphs.",
      "tags": [
        "Models",
        "Fundamentals"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-graph-neural-network-history",
      "term": "Graph Neural Network History",
      "definition": "The development of neural networks for graph-structured data from early spectral approaches (Bruna et al. 2013) through Graph Convolutional Networks (Kipf and Welling 2017) to modern message-passing frameworks and their applications in chemistry and social networks.",
      "tags": [
        "History",
        "Milestones"
      ],
      "domain": "history",
      "link": null,
      "related": []
    },
    {
      "id": "term-graph-rag",
      "term": "Graph RAG",
      "definition": "A retrieval-augmented generation approach that builds a knowledge graph from source documents and uses graph traversal to retrieve structured, interconnected context for more coherent multi-hop reasoning.",
      "tags": [
        "LLM",
        "Generative AI"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-graph-based-index",
      "term": "Graph-Based Index",
      "definition": "A vector index structure that organizes vectors as nodes in a proximity graph where edges connect similar vectors, enabling efficient nearest neighbor search by navigating the graph from entry points toward the query's neighborhood.",
      "tags": [
        "Vector Database",
        "Index Structure"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-graph-based-parsing",
      "term": "Graph-Based Parsing",
      "definition": "A parsing approach that scores all possible dependency edges simultaneously and finds the highest-scoring tree using algorithms like maximum spanning tree, typically more accurate but slower than transition-based methods.",
      "tags": [
        "NLP",
        "Parsing"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-graphcast",
      "term": "GraphCast",
      "definition": "A graph neural network-based weather forecasting model from DeepMind that predicts 10-day global weather faster and more accurately than traditional numerical methods.",
      "tags": [
        "Models",
        "Scientific",
        "Fundamentals"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-graphcore",
      "term": "Graphcore",
      "definition": "A semiconductor company that developed the Intelligence Processing Unit (IPU), featuring a massive number of independent processor cores with large distributed on-chip SRAM. Graphcore's bulk synchronous parallel programming model targets both training and inference workloads.",
      "tags": [
        "Hardware",
        "Distributed Computing"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-graphcore-ipu",
      "term": "Graphcore IPU",
      "definition": "Intelligence Processing Unit designed by Graphcore using a unique bulk synchronous parallel architecture optimized for machine learning workloads with massive on-chip SRAM and fine-grained parallelism.",
      "tags": [
        "Accelerator",
        "Architecture"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-graphsage",
      "term": "GraphSAGE",
      "definition": "A framework for inductive representation learning on graphs that samples and aggregates features from a node's local neighborhood, enabling generalization to unseen nodes without retraining.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-grasp-algorithm",
      "term": "GRASP Algorithm",
      "definition": "Greedy Randomized Adaptive Search Procedure is a multi-start metaheuristic that alternates between construction and local search phases. The construction phase builds a solution using a randomized greedy heuristic.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gravitational-search-algorithm",
      "term": "Gravitational Search Algorithm",
      "definition": "A physics-inspired optimization algorithm where agents are treated as objects with masses proportional to their fitness. Objects attract each other through gravitational forces causing better solutions to attract others.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-greedy-decoding",
      "term": "Greedy Decoding",
      "definition": "A deterministic text generation strategy that always selects the token with the highest probability at each step, producing the most likely sequence but often lacking diversity.",
      "tags": [
        "Generative AI",
        "Decoding"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-green-ai",
      "term": "Green AI",
      "definition": "Movement advocating for energy-efficient AI research that minimizes computational and environmental costs. Promotes reporting compute budgets and developing more efficient algorithms alongside hardware.",
      "tags": [
        "Sustainability",
        "Research"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-green500",
      "term": "Green500",
      "definition": "Ranking of the most energy-efficient supercomputers measuring performance per watt. Highlights the growing importance of power efficiency in large-scale computing for AI and science.",
      "tags": [
        "Benchmark",
        "Supercomputer",
        "Efficiency"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-grey-wolf-optimizer",
      "term": "Grey Wolf Optimizer",
      "definition": "A swarm intelligence algorithm inspired by the social hierarchy and hunting behavior of grey wolves. Models alpha and beta and delta wolves to guide the search toward promising regions of the solution space.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-grid-search",
      "term": "Grid Search",
      "definition": "A hyperparameter tuning method that exhaustively evaluates all combinations of specified parameter values, typically combined with cross-validation to select the combination yielding the best performance.",
      "tags": [
        "Machine Learning",
        "Model Selection"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-grievance-mechanism-for-ai",
      "term": "Grievance Mechanism for AI",
      "definition": "A formal process through which individuals can raise complaints about harm caused by AI systems and seek remediation. Required by various governance frameworks including the UN Guiding Principles on Business and Human Rights.",
      "tags": [
        "Safety",
        "Governance"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-griffin",
      "term": "Griffin",
      "definition": "A hybrid model by Google DeepMind that combines recurrent layers based on linear recurrences with local attention. Achieves strong performance with efficient inference for long sequences while using less compute than pure transformers.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-grok",
      "term": "Grok",
      "definition": "An AI assistant developed by xAI (Elon Musk's AI company). Integrated with X (Twitter) and known for real-time information access and less restrictive conversation style.",
      "tags": [
        "Product",
        "Model"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-grok-1",
      "term": "Grok-1",
      "definition": "A 314 billion parameter mixture-of-experts language model from xAI with 25 percent of weights active per token during inference.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-grok-15",
      "term": "Grok-1.5",
      "definition": "An improved version of Grok with enhanced reasoning capabilities and a 128K context window for processing long documents and complex problems.",
      "tags": [
        "Models",
        "Technical",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-groot",
      "term": "GROOT",
      "definition": "A humanoid robot learning framework from NVIDIA that trains generalist robot policies using video demonstrations and language instructions.",
      "tags": [
        "Models",
        "Technical",
        "Robotics",
        "Vision"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-groq",
      "term": "Groq",
      "definition": "An AI hardware company that developed the Language Processing Unit (LPU), a deterministic architecture using software-defined scheduling to achieve extremely low-latency LLM inference. Groq's architecture eliminates dynamic scheduling overhead for predictable, high-speed token generation.",
      "tags": [
        "Hardware",
        "Inference Infrastructure"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-ground-truth",
      "term": "Ground Truth",
      "definition": "The correct answer or label used to evaluate model predictions. Obtained through human annotation, measurement, or other authoritative sources.",
      "tags": [
        "Data",
        "Evaluation"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-grounded-sam",
      "term": "Grounded SAM",
      "definition": "A combination of Grounding DINO and Segment Anything Model that enables text-prompted segmentation of arbitrary objects in images.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-grounding",
      "term": "Grounding",
      "definition": "Connecting AI outputs to verified information sources to reduce hallucinations and increase accuracy. Often involves retrieval-augmented generation (RAG) or real-time search.",
      "tags": [
        "Technique",
        "Accuracy"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-grounding-dino",
      "term": "Grounding DINO",
      "definition": "An open-set object detection model that combines a DINO-based detector with grounded pre-training, enabling detection of arbitrary objects specified by text descriptions without category-specific training.",
      "tags": [
        "Computer Vision",
        "Object Detection"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-grounding-sam-2",
      "term": "Grounding SAM 2",
      "definition": "A combination of Grounding DINO with SAM 2 that enables text-prompted object segmentation and tracking across video sequences.",
      "tags": [
        "Models",
        "Technical",
        "Vision",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-group-fairness",
      "term": "Group Fairness",
      "definition": "Fairness criteria that require statistical parity of outcomes or error rates across demographic groups defined by protected attributes, including demographic parity, equalized odds, and predictive parity.",
      "tags": [
        "Fairness",
        "AI Ethics"
      ],
      "domain": "safety",
      "link": null,
      "related": []
    },
    {
      "id": "term-group-normalization",
      "term": "Group Normalization",
      "definition": "A normalization method that divides channels into groups and normalizes within each group independently, providing stable performance regardless of batch size unlike batch normalization.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-group-relative-policy-optimization",
      "term": "Group Relative Policy Optimization",
      "definition": "A reinforcement learning algorithm for language model alignment that uses group-based normalization of advantages rather than a separate critic model. Simplifies the RLHF pipeline while maintaining alignment quality. Used in DeepSeek models.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-grouped-query-attention",
      "term": "Grouped Query Attention",
      "definition": "An attention mechanism that groups multiple query heads to share a single key-value head, interpolating between multi-head and multi-query attention to balance quality and inference speed.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gru",
      "term": "GRU",
      "definition": "Gated Recurrent Unit, a recurrent neural network variant that uses reset and update gates to control information flow, offering similar performance to LSTM with fewer parameters and simpler computation.",
      "tags": [
        "Neural Networks",
        "Architecture"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gshard",
      "term": "GShard",
      "definition": "A framework for scaling giant models across thousands of devices using conditional computation. Uses top-2 gating in mixture-of-experts layers with auxiliary load balancing loss. Demonstrated 600 billion parameter translation models.",
      "tags": [
        "Models",
        "Technical"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gsm8k",
      "term": "GSM8K",
      "definition": "Grade School Math 8K, a benchmark of 8,500 linguistically diverse grade-school-level math word problems requiring multi-step arithmetic reasoning, widely used to evaluate mathematical problem-solving capabilities of language models.",
      "tags": [
        "Evaluation",
        "Benchmarks"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    },
    {
      "id": "term-gte",
      "term": "GTE",
      "definition": "General Text Embeddings is a family of text embedding models from Alibaba that achieve strong performance on semantic textual similarity and retrieval benchmarks.",
      "tags": [
        "Models",
        "Technical",
        "Embedding",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-gtr",
      "term": "GTR",
      "definition": "Generalizable T5-based dense Retrievers are text embedding models fine-tuned from T5 encoders for large-scale information retrieval tasks.",
      "tags": [
        "Models",
        "Technical",
        "Embedding",
        "NLP"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-guardrails",
      "term": "Guardrails",
      "definition": "Safety mechanisms that constrain AI behavior to prevent harmful outputs. Include content filters, output validators, and behavioral restrictions built into AI systems.",
      "tags": [
        "Safety",
        "Constraint"
      ],
      "domain": "safety",
      "link": "ai-safety.html",
      "related": []
    },
    {
      "id": "term-guided-filter-algorithm",
      "term": "Guided Filter Algorithm",
      "definition": "An edge-preserving filter that uses a guidance image to compute filter output through local linear models. Faster than bilateral filtering and avoids gradient reversal artifacts near strong edges.",
      "tags": [
        "Algorithms",
        "Technical",
        "Vision"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-guided-generation",
      "term": "Guided Generation",
      "definition": "Techniques that constrain language model output to conform to a specified format (such as JSON schema or grammar rules) by masking invalid tokens during the decoding process.",
      "tags": [
        "Generative AI",
        "Decoding"
      ],
      "domain": "models",
      "link": null,
      "related": []
    },
    {
      "id": "term-guided-local-search",
      "term": "Guided Local Search",
      "definition": "A metaheuristic penalty-based method that escapes local optima by augmenting the objective function with penalty terms on frequently occurring solution features. Encourages diversification in the search process.",
      "tags": [
        "Algorithms",
        "Technical",
        "Metaheuristic"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gumbel-max-trick",
      "term": "Gumbel-Max Trick",
      "definition": "A method for sampling from categorical distributions using Gumbel noise. Adds independent Gumbel noise to log-probabilities and takes the argmax. Enables efficient sampling and is the basis for the Gumbel-Softmax relaxation.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gumbel-softmax",
      "term": "Gumbel-Softmax",
      "definition": "A continuous relaxation of categorical sampling that allows gradient-based optimization of discrete variables. Uses the Gumbel-Max trick with a temperature-controlled softmax to produce approximately one-hot vectors that are differentiable.",
      "tags": [
        "Algorithms",
        "Technical"
      ],
      "domain": "algorithms",
      "link": null,
      "related": []
    },
    {
      "id": "term-gustafsons-law",
      "term": "Gustafson's Law",
      "definition": "Principle stating that parallel speedup scales with problem size because larger problems have proportionally more parallelizable work. Offers a more optimistic view than Amdahl's Law for AI scaling.",
      "tags": [
        "Architecture",
        "Principle",
        "Fundamentals"
      ],
      "domain": "hardware",
      "link": null,
      "related": []
    },
    {
      "id": "term-gym-environment",
      "term": "Gym Environment",
      "definition": "An interface standard and collection of benchmark environments originally developed by OpenAI for RL research. The Gym API defines a common protocol for environment interaction including reset, step, and observation/action spaces.",
      "tags": [
        "Reinforcement Learning",
        "Core Concepts"
      ],
      "domain": "general",
      "link": null,
      "related": []
    },
    {
      "id": "term-gymnasium",
      "term": "Gymnasium",
      "definition": "The maintained successor to OpenAI Gym providing standardized RL environment interfaces. Managed by the Farama Foundation with improved documentation and compatibility.",
      "tags": [
        "Benchmark",
        "Reinforcement Learning"
      ],
      "domain": "datasets",
      "link": null,
      "related": []
    }
  ]
}