<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Anthropic AI Benchmarks: Track the Claude model family from Claude 3 Opus to Claude Opus 4.6. Verified performance data across MMLU, GPQA Diamond, HumanEval, AIME, and MMMU benchmarks.">
    <!-- SEO Meta -->
    <meta name="robots" content="index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1">
    <meta name="author" content="Praxis Library">
    <meta name="theme-color" content="#DC3545">
    <link rel="canonical" href="https://praxislibrary.com/benchmarks/anthropic.html">
    <!-- Open Graph -->
    <meta property="og:type" content="article">
    <meta property="og:title" content="Anthropic: Claude Model Benchmarks - Praxis">
    <meta property="og:description" content="Anthropic AI Benchmarks: Track the Claude model family from Claude 1 to Claude Opus 4.6. Performance data across MMLU-Pro, GPQA, HumanEval, AIME, MMMU, and IFEval benchmarks.">
    <meta property="og:url" content="https://praxislibrary.com/benchmarks/anthropic.html">
    <meta property="og:image" content="https://praxislibrary.com/assets/images/praxishome.png">
    <meta property="og:site_name" content="Praxis Library">
    <meta property="og:locale" content="en_US">
    <!-- Social Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Anthropic: Claude Model Benchmarks - Praxis">
    <meta name="twitter:description" content="Anthropic AI Benchmarks: Track the Claude model family from Claude 1 to Claude Opus 4.6. Performance data across MMLU-Pro, GPQA, HumanEval, AIME, MMMU, and IFEval benchmarks.">
    <meta name="twitter:image" content="https://praxislibrary.com/assets/images/praxishome.png">
    <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@type": [
        "LearningResource",
        "Article"
      ],
      "headline": "Anthropic: Claude Model Benchmarks",
      "name": "Anthropic: Claude Model Benchmarks",
      "description": "Track the Claude model family from Claude 1 to Claude Opus 4.6. Performance data across knowledge, reasoning, coding, math, multimodal, and instruction following benchmarks.",
      "url": "https://praxislibrary.com/benchmarks/anthropic.html",
      "inLanguage": "en-US",
      "isAccessibleForFree": true,
      "publisher": {
        "@type": "EducationalOrganization",
        "name": "Praxis Library",
        "alternateName": "The Open Standard in AI Literacy",
        "url": "https://praxislibrary.com",
        "logo": "https://praxislibrary.com/favicon.svg",
        "description": "A comprehensive, living library of 5,000+ AI terms, 177 techniques & frameworks, and interactive tools. The definitive open resource for AI literacy, prompt engineering, and human-AI communication.",
        "sameAs": [
          "https://www.tiktok.com/@thepraxislibrary",
          "https://www.facebook.com/profile.php?id=61587612308104",
          "https://github.com/PowerOfPraxis/PraxisLibrary"
        ],
        "knowsAbout": [
          "Artificial Intelligence",
          "AI Literacy",
          "Prompt Engineering",
          "AI Prompting Techniques",
          "AI Glossary",
          "Large Language Models",
          "Chain-of-Thought Prompting",
          "AI Education",
          "Human-AI Communication",
          "Neurodivergence and AI",
          "AI Safety",
          "AI Ethics"
        ]
      },
      "isPartOf": {
        "@type": "WebSite",
        "name": "Praxis Library",
        "url": "https://praxislibrary.com"
      }
    },
    {
      "@type": "BreadcrumbList",
      "itemListElement": [
        {
          "@type": "ListItem",
          "position": 1,
          "name": "Home",
          "item": "https://praxislibrary.com"
        },
        {
          "@type": "ListItem",
          "position": 2,
          "name": "AI Benchmarks",
          "item": "https://praxislibrary.com/benchmarks/"
        },
        {
          "@type": "ListItem",
          "position": 3,
          "name": "Anthropic"
        }
      ]
    }
  ]
}
    </script>
    <!-- /SEO -->

<title>Anthropic: Claude Model Benchmarks - Praxis</title>
    <link rel="icon" type="image/svg+xml" href="../favicon.svg">
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <a href="#main-content" class="skip-link">Skip to main content</a>

        <header class="header" id="header">
        <div class="header-container">
            <a href="../index.html" class="logo">&lt;/Praxis <span>Library</span>&gt;</a>
            <nav class="nav" id="nav" aria-label="Main navigation">
                <a href="../foundations/index.html" class="nav-link">History</a>
                <div class="nav-item has-dropdown">
                    <a href="../learn/index.html" class="nav-link" aria-expanded="false">Discover</a>
                                        <div class="mega-menu mega-menu--categories">
                        <div class="mega-menu-quick-links">
                            <a href="../learn/index.html">Prompt Engineering</a>
                            <a href="../learn/prompt-basics.html">Prompt Basics</a>
                            <a href="../learn/facts-fictions.html">Facts &amp; Fictions</a>
                            <a href="../pages/glossary.html">Glossary</a>
                        </div>
                    </div>
                </div>
                <div class="nav-item has-dropdown">
                    <a href="../tools/index.html" class="nav-link" aria-expanded="false">Readiness</a>
                    <div class="mega-menu">
                        <div class="mega-menu-section">
                            <h4>Tools</h4>
                            <a href="../quiz/index.html">Readiness Quiz</a>
                            <a href="../tools/analyzer.html">Prompt Analyzer</a>
                            <a href="../tools/guidance.html">Prompt Builder</a>
                            <a href="../tools/matcher.html">Technique Finder</a>
                            <a href="../tools/checklist.html">Preflight Checklist</a>
                            <a href="../tools/persona.html">Persona Architect</a>
                            <a href="../tools/hallucination.html">Hallucination Spotter</a>
                            <a href="../patterns/index.html">Patterns Library</a>
                            <a href="../pages/ai-safety.html">AI Safety</a>
                        </div>
                    </div>
                </div>
                <div class="nav-item has-dropdown">
                    <a href="../pages/resources.html" class="nav-link active" aria-expanded="false">Resources</a>
                    <div class="mega-menu mega-menu--categories">
                        <div class="mega-menu-quick-links">
                            <a href="../pages/responsible-ai.html">Responsible AI</a>
                            <a href="../neurodivergence/resources.html">ND Resources</a>
                            <a href="../benchmarks/index.html">AI Benchmarks</a>
                            <a href="../pages/audit-report.html">Audit Report</a>
                            <a href="../pages/about.html">About Praxis</a>
                            <a href="../pages/faq.html">FAQs</a>
                        </div>
                    </div>
                </div>
            </nav>
            <button class="menu-toggle" id="menuToggle" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>
    </header>

    <!-- === PAGE HERO === -->
    <section class="page-hero">
        <canvas id="page-hero-neural-bg" class="page-hero-neural-bg"></canvas>
        <div class="container">
            <nav class="breadcrumb fade-in" aria-label="Breadcrumb">
                <a href="../index.html">Home</a>
                <span class="separator">/</span>
                <a href="index.html">AI Benchmarks</a>
                <span class="separator">/</span>
                <span class="current">Anthropic</span>
            </nav>
            <div class="hero-badge" data-aos="fade-down">
                <span class="hero-badge__icon">
                    <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M18 20V10"/>
                        <path d="M12 20V4"/>
                        <path d="M6 20V14"/>
                    </svg>
                </span>
                <span class="hero-badge__text">Verified Performance Data</span>
            </div>
            <h1 class="page-title fade-in">Anthropic</h1>
            <p class="page-subtitle fade-in">The Claude model family: From Claude 3 Opus to Claude Opus 4.6. Verified benchmark performance across knowledge, reasoning, coding, and math.</p>
        </div>
    </section>
    <!-- /PAGE HERO -->

    <!-- === ACCENT BAR === -->
    <div class="accent-bar accent-bar--gradient"></div>

    <!-- === MAIN CONTENT === -->
    <main id="main-content">

        <!-- === COMPANY OVERVIEW === -->
        <section class="benchmark-section section-alt">
            <div class="container">
                <div class="benchmark-stats">
                    <div class="benchmark-stat provider-border--anthropic">
                        <div class="benchmark-stat__value provider-color--anthropic">10</div>
                        <div class="benchmark-stat__label">Models Tracked</div>
                    </div>
                    <div class="benchmark-stat">
                        <div class="benchmark-stat__value">2021</div>
                        <div class="benchmark-stat__label">Founded</div>
                    </div>
                    <div class="benchmark-stat">
                        <div class="benchmark-stat__value">91.3</div>
                        <div class="benchmark-stat__label">Best Reasoning</div>
                    </div>
                    <div class="benchmark-stat">
                        <div class="benchmark-stat__value">91.1</div>
                        <div class="benchmark-stat__label">Best Knowledge</div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /COMPANY OVERVIEW -->

        <!-- === ABOUT ANTHROPIC === -->
        <section class="benchmark-section">
            <div class="container">
                <h2 class="benchmark-section__title">About Anthropic</h2>
                <p>Anthropic is an AI safety company founded in 2021 by Dario Amodei, Daniela Amodei, and former members of OpenAI. The company builds the Claude family of AI assistants, with a mission centered on AI safety research and developing reliable, interpretable AI systems. Anthropic pioneered Constitutional AI (CAI), a technique where AI systems are guided by a set of principles rather than purely human feedback.</p>
                <p>The Claude model family has evolved rapidly from Claude 3 Opus (2024) through Claude Opus 4.6 (2026), consistently ranking among the top models in reasoning, knowledge, and balanced multi-domain performance. Anthropic is known for its cautious, safety-first approach to capability advancement.</p>
            </div>
        </section>
        <!-- /ABOUT ANTHROPIC -->

        <!-- === MODEL TIMELINE === -->
        <section class="benchmark-section section-alt">
            <div class="container">
                <h2 class="benchmark-section__title">Claude Model Timeline</h2>
                <p class="benchmark-section__subtitle">The evolution of Anthropic&rsquo;s Claude family from 2024 to 2026. All scores from <a href="https://www.anthropic.com/news/claude-4" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">official Anthropic announcements</a>.</p>

                <div class="model-timeline">
                    <div class="model-timeline__item model-timeline__item--current">
                        <div class="model-timeline__date">February 2026</div>
                        <h3 class="model-timeline__title">Claude Opus 4.6</h3>
                        <p class="model-timeline__description">The latest and most capable Claude model. Claude Opus 4.6 achieves 91.3% on GPQA Diamond and 91.1% on MMMLU, making it one of the highest-scoring models in both reasoning and knowledge. It also achieves 80.8% on SWE-bench Verified for real-world software engineering tasks. Source: <a href="https://www.anthropic.com/news/claude-opus-4-6" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">Anthropic announcement</a>.</p>
                        <div class="model-timeline__benchmarks">
                            <span class="model-timeline__benchmark-tag">MMMLU <span>91.1</span></span>
                            <span class="model-timeline__benchmark-tag">GPQA <span>91.3</span></span>
                            <span class="model-timeline__benchmark-tag">SWE-bench <span>80.8</span></span>
                        </div>
                    </div>

                    <div class="model-timeline__item">
                        <div class="model-timeline__date">January 2026</div>
                        <h3 class="model-timeline__title">Claude Opus 4.5</h3>
                        <p class="model-timeline__description">A major step forward in reasoning capability. Claude Opus 4.5 achieves 91.3% on GPQA Diamond&mdash;matching Opus 4.6&mdash;and 80.9% on SWE-bench Verified, the highest coding score in the Claude family at time of release.</p>
                        <div class="model-timeline__benchmarks">
                            <span class="model-timeline__benchmark-tag">GPQA <span>91.3</span></span>
                            <span class="model-timeline__benchmark-tag">SWE-bench <span>80.9</span></span>
                        </div>
                    </div>

                    <div class="model-timeline__item">
                        <div class="model-timeline__date">October 2025</div>
                        <h3 class="model-timeline__title">Claude Sonnet 4.5</h3>
                        <p class="model-timeline__description">The balanced workhorse of the 4.5 generation. Claude Sonnet 4.5 delivers strong performance at faster response times and lower cost than Opus. It achieves 89.1% on MMLU and 83.4% on GPQA Diamond, with 77.2% on SWE-bench Verified for real-world coding tasks.</p>
                        <div class="model-timeline__benchmarks">
                            <span class="model-timeline__benchmark-tag">MMLU <span>89.1</span></span>
                            <span class="model-timeline__benchmark-tag">GPQA <span>83.4</span></span>
                            <span class="model-timeline__benchmark-tag">SWE-bench <span>77.2</span></span>
                        </div>
                    </div>

                    <div class="model-timeline__item">
                        <div class="model-timeline__date">August 2025</div>
                        <h3 class="model-timeline__title">Claude Opus 4.1</h3>
                        <p class="model-timeline__description">An incremental Opus update building on the Claude 4 architecture with improved reliability and enhanced agentic capabilities.</p>
                        <div class="model-timeline__benchmarks">
                        </div>
                    </div>

                    <div class="model-timeline__item">
                        <div class="model-timeline__date">June 2025</div>
                        <h3 class="model-timeline__title">Claude Opus 4</h3>
                        <p class="model-timeline__description">A major generational leap that introduced advanced agentic capabilities&mdash;the ability to use tools, browse documents, and execute multi-step workflows autonomously. Achieves 87.4% on MMMLU, 76.9% on GPQA Diamond (with extended thinking), and 72.5% on SWE-bench Verified. AIME 2024 score: 33.9%. Source: <a href="https://www.anthropic.com/news/claude-4" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">Anthropic announcement</a>.</p>
                        <div class="model-timeline__benchmarks">
                            <span class="model-timeline__benchmark-tag">MMMLU <span>87.4</span></span>
                            <span class="model-timeline__benchmark-tag">GPQA <span>76.9</span></span>
                            <span class="model-timeline__benchmark-tag">SWE-bench <span>72.5</span></span>
                            <span class="model-timeline__benchmark-tag">AIME <span>33.9</span></span>
                            <span class="model-timeline__benchmark-tag">MMMU <span>73.7</span></span>
                        </div>
                    </div>

                    <div class="model-timeline__item">
                        <div class="model-timeline__date">May 2025</div>
                        <h3 class="model-timeline__title">Claude Sonnet 4</h3>
                        <p class="model-timeline__description">The first model in the Claude 4 generation. Claude Sonnet 4 delivered substantial improvements in reasoning and agentic tasks while maintaining the fast response times Sonnet users expected. Achieves 85.4% on MMMLU, 72.3% on GPQA Diamond (with extended thinking), and 72.7% on SWE-bench Verified. Source: <a href="https://www.anthropic.com/news/claude-4" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">Anthropic announcement</a>.</p>
                        <div class="model-timeline__benchmarks">
                            <span class="model-timeline__benchmark-tag">MMMLU <span>85.4</span></span>
                            <span class="model-timeline__benchmark-tag">GPQA <span>72.3</span></span>
                            <span class="model-timeline__benchmark-tag">SWE-bench <span>72.7</span></span>
                            <span class="model-timeline__benchmark-tag">AIME <span>33.1</span></span>
                            <span class="model-timeline__benchmark-tag">MMMU <span>72.6</span></span>
                        </div>
                    </div>

                    <div class="model-timeline__item">
                        <div class="model-timeline__date">February 2025</div>
                        <h3 class="model-timeline__title">Claude Sonnet 3.7</h3>
                        <p class="model-timeline__description">A significant update to the 3.5 architecture. Claude Sonnet 3.7 introduced extended thinking capabilities to the Sonnet tier for the first time, allowing the model to reason through complex problems before responding.</p>
                        <div class="model-timeline__benchmarks">
                        </div>
                    </div>

                    <div class="model-timeline__item">
                        <div class="model-timeline__date">October 2024</div>
                        <h3 class="model-timeline__title">Claude 3.5 Haiku</h3>
                        <p class="model-timeline__description">The speed-optimized member of the 3.5 family. Claude 3.5 Haiku was designed for high-throughput, low-latency applications where cost efficiency matters most&mdash;chatbots, classification tasks, content moderation, and real-time data extraction. Source: <a href="https://assets.anthropic.com/m/1cd9d098ac3e6467/original/Claude-3-Model-Card-October-Addendum.pdf" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">Anthropic model card (PDF)</a>.</p>
                        <div class="model-timeline__benchmarks">
                        </div>
                    </div>

                    <div class="model-timeline__item">
                        <div class="model-timeline__date">June 2024</div>
                        <h3 class="model-timeline__title">Claude 3.5 Sonnet</h3>
                        <p class="model-timeline__description">A breakout hit that reshaped industry expectations. Claude 3.5 Sonnet demonstrated that a mid-tier model could match or exceed competitors&rsquo; flagship offerings. At 90.4% on MMLU and 92.0% on HumanEval, it outperformed GPT-4 Turbo on several key metrics while running faster and costing less. Source: <a href="https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">Anthropic model card (PDF)</a>.</p>
                        <div class="model-timeline__benchmarks">
                            <span class="model-timeline__benchmark-tag">MMLU <span>90.4</span></span>
                            <span class="model-timeline__benchmark-tag">GPQA <span>59.4</span></span>
                            <span class="model-timeline__benchmark-tag">HumanEval <span>92.0</span></span>
                            <span class="model-timeline__benchmark-tag">AIME <span>16.0</span></span>
                        </div>
                    </div>

                    <div class="model-timeline__item">
                        <div class="model-timeline__date">March 2024</div>
                        <h3 class="model-timeline__title">Claude 3 Opus</h3>
                        <p class="model-timeline__description">Anthropic&rsquo;s first true frontier model and the release that established the Claude family as a serious competitor to GPT-4. Claude 3 Opus launched with a 200K context window&mdash;the largest in the industry at the time. It scored 88.2% on MMLU (5-shot CoT), 50.4% on GPQA Diamond, and 84.9% on HumanEval. Source: <a href="https://www-cdn.anthropic.com/fed9cc193a14b84131812372d8d5857f8f304c52/Model_Card_Claude_3_Addendum.pdf" target="_blank" rel="noopener noreferrer" data-added="2026-02-10">Anthropic model card (PDF)</a>.</p>
                        <div class="model-timeline__benchmarks">
                            <span class="model-timeline__benchmark-tag">MMLU <span>88.2</span></span>
                            <span class="model-timeline__benchmark-tag">GPQA <span>50.4</span></span>
                            <span class="model-timeline__benchmark-tag">HumanEval <span>84.9</span></span>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- /MODEL TIMELINE -->

        <!-- === BENCHMARK CHARTS === -->
        <section class="benchmark-section" data-benchmark-company="anthropic">
            <div class="container">
                <h2 class="benchmark-section__title">Benchmark Performance</h2>
                <p class="benchmark-section__subtitle">Claude Opus 4.6 scores across verified benchmark categories.</p>
            </div>
        </section>
        <!-- /BENCHMARK CHARTS -->

        <!-- === KEY STRENGTHS === -->
        <section class="benchmark-section section-alt">
            <div class="container">
                <h2 class="benchmark-section__title">Key Strengths</h2>
                <div class="benchmark-explainer">
                    <div class="benchmark-explainer__card">
                        <div class="benchmark-explainer__name">Reasoning Leadership</div>
                        <p class="benchmark-explainer__desc">Claude Opus 4.6 achieves 91.3% on GPQA Diamond, one of the highest reasoning scores among all AI models. Extended thinking mode enables deep, multi-step scientific reasoning.</p>
                    </div>
                    <div class="benchmark-explainer__card">
                        <div class="benchmark-explainer__name">Real-World Coding</div>
                        <p class="benchmark-explainer__desc">With 80.8% on SWE-bench Verified, Claude Opus 4.6 demonstrates strong ability to solve real-world software engineering problems from GitHub repositories.</p>
                    </div>
                    <div class="benchmark-explainer__card">
                        <div class="benchmark-explainer__name">Safety-First Design</div>
                        <p class="benchmark-explainer__desc">Built with Constitutional AI principles, Claude models are designed to be helpful, harmless, and honest. Anthropic prioritizes responsible development alongside capability advances.</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- /KEY STRENGTHS -->

        <!-- === DISCLAIMER === -->
        <section class="benchmark-section">
            <div class="container">
                <div class="callout callout--tip">
                    <h3>About This Data</h3>
                    <p>All benchmark scores are sourced from Anthropic&rsquo;s official announcements and model cards. MMMLU (Multilingual MMLU) is used for Claude 4+ models where standard MMLU is not separately reported. GPQA Diamond scores for Claude 4+ include extended thinking. Scores represent performance at time of release.</p>
                </div>
            </div>
        </section>
        <!-- /DISCLAIMER -->

        <!-- === NAVIGATION === -->
        <section class="benchmark-section benchmark-section--dark">
            <canvas class="footer-neural-bg" aria-hidden="true"></canvas>
            <div class="container">
                <div class="cta-content">
                    <h2 class="benchmark-section__title">Explore More Providers</h2>
                    <p class="benchmark-section__subtitle">Compare Anthropic&rsquo;s Claude models against other frontier AI systems.</p>
                    <div class="hero-actions">
                        <a href="index.html" class="btn btn-primary">Back to Leaderboard</a>
                        <a href="openai.html" class="btn btn-secondary">Next: OpenAI</a>
                    </div>
                </div>
            </div>
        </section>
        <!-- /NAVIGATION -->

    </main>
    <!-- /MAIN CONTENT -->

    <!-- === FOOTER === -->
        <footer class="footer">
    <canvas id="footer-neural-bg" class="footer-neural-bg"></canvas>
    <div class="container">
        <div class="footer-grid">
            <div class="footer-brand">
                <a href="../index.html" class="footer-logo">&lt;/Praxis <span>Library</span>&gt;</a>
                <p>From Prompting to Production. Built on Proven Techniques &amp; Frameworks.</p>
            </div>

            <div class="footer-links">
                <h4>Techniques</h4>
                <a href="../learn/prompt-basics.html">Prompt Basics</a>
                <a href="../learn/crisp.html">CRISP Framework</a>
                <a href="../learn/crispe.html">CRISPE Framework</a>
                <a href="../learn/costar.html">CO-STAR Framework</a>
                <a href="../learn/react.html">ReAct Framework</a>
                <a href="../learn/flipped-interaction.html">Flipped Interaction</a>
                <a href="../learn/chain-of-thought.html">Chain-of-Thought</a>
            </div>

            <div class="footer-links">
                <h4>AI Readiness Tools</h4>
                <a href="../tools/analyzer.html">Prompt Analyzer</a>
                <a href="../tools/matcher.html">Technique Finder</a>
                <a href="../tools/checklist.html">Preflight Checklist</a>
                <a href="../tools/guidance.html">Prompt Builder</a>
                <a href="../tools/persona.html">Persona Architect</a>
                <a href="../tools/hallucination.html">Hallucination Spotter</a>
                <a href="../quiz/index.html">Readiness Quiz</a>
                <a href="../patterns/index.html">Patterns Library</a>
                <a href="../pages/ai-safety.html">AI Safety</a>
            </div>

            <div class="footer-links">
                <h4>Resources</h4>
                <a href="../pages/responsible-ai.html">Responsible AI</a>
                <a href="../neurodivergence/resources.html">ND Resources</a>
                <a href="../benchmarks/index.html">AI Benchmarks</a>
                <a href="../pages/audit-report.html">Audit Report</a>
                <a href="../pages/about.html">About Praxis</a>
                <a href="../pages/faq.html">FAQs</a>
            </div>
        </div>

        <div class="footer-bottom">
            <p>AI for Everyone</p>
            <p class="footer-quote">&ldquo;True innovation in AI isn&rsquo;t just about companies adopting AI as a new technology&mdash;it&rsquo;s about people learning about, adapting to, and adopting Artificial Intelligence into their daily lives to empower and unlock their own human potential.&rdquo; <span class="footer-quote-author">&mdash; Basiliso (Bas) Rosario</span></p>
        </div>

        <div class="footer-policies">
            <a href="../pages/responsible-ai.html">Responsible AI</a>
            <a href="../pages/use-policy.html">Use Policy</a>
            <a href="../pages/site-policy.html">Site Policy</a>
            <a href="../pages/security-policy.html">Security Policy</a>
            <a href="../pages/data-retention-policy.html">Data Retention</a>
        </div>
    </div>
</footer>
    <!-- /FOOTER -->

    <!-- Back to Top Bar -->
    <button class="back-to-top-bar" aria-label="Back to top">
        <span class="back-to-top-arrow">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M18 15l-6-6-6 6"/>
            </svg>
        </span>
        <span class="back-to-top-text">Back to Top</span>
    </button>

    <!-- === BADGE LIGHTBOX === -->
    <div class="badge-lightbox-overlay" aria-hidden="true"></div>
    <div class="badge-lightbox" role="dialog" aria-modal="true" aria-labelledby="badge-lightbox-title">
        <header class="badge-lightbox-header">
            <h2 class="badge-lightbox-title" id="badge-lightbox-title"></h2>
            <button class="badge-lightbox-close" aria-label="Close dialog">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor">
                    <path d="M18 6L6 18M6 6l12 12" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
            </button>
        </header>
        <div class="badge-lightbox-content"></div>
    </div>
    <!-- /BADGE LIGHTBOX -->

    <!-- === ACCESSIBILITY DASHBOARD === -->
    <div class="adl-dim-overlay" aria-hidden="true"></div>
    <button class="adl-toggle" aria-label="Accessibility options" aria-expanded="false" aria-controls="adl-panel">
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <circle cx="12" cy="12" r="10"/>
            <circle cx="12" cy="10" r="3"/>
            <path d="M12 13v6M9 17l3 3 3-3"/>
        </svg>
    </button>
    <div class="adl-panel" id="adl-panel" role="dialog" aria-label="Accessibility Settings">
        <div class="adl-panel-header">
            <span class="adl-panel-title">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <circle cx="12" cy="12" r="10"/>
                    <circle cx="12" cy="10" r="3"/>
                    <path d="M12 13v6M9 17l3 3 3-3"/>
                </svg>
                Accessibility
            </span>
            <button class="adl-close" aria-label="Close accessibility panel">
                <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M18 6L6 18M6 6l12 12"/>
                </svg>
            </button>
        </div>
        <div class="adl-control">
            <span class="adl-label">Text Size</span>
            <div class="adl-btn-group">
                <button class="adl-btn is-active" data-scale="1" aria-label="Normal text size">1x</button>
                <button class="adl-btn" data-scale="2" aria-label="Large text size">2x</button>
                <button class="adl-btn" data-scale="3" aria-label="Extra large text size">3x</button>
            </div>
        </div>
        <div class="adl-control">
            <div class="adl-switch-wrapper">
                <span class="adl-switch-label">High Contrast</span>
                <label class="adl-switch">
                    <input type="checkbox" id="adl-contrast-toggle" aria-label="Toggle high contrast mode">
                    <span class="adl-switch-track"></span>
                </label>
            </div>
        </div>
        <div class="adl-control adl-readaloud">
            <span class="adl-label">Read Aloud</span>
            <div class="adl-readaloud-controls">
                <button class="adl-play-btn" aria-label="Play or pause reading">
                    <svg class="play-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M8 5v14l11-7z"/></svg>
                    <svg class="pause-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M6 4h4v16H6V4zm8 0h4v16h-4V4z"/></svg>
                </button>
                <div class="adl-speed-group">
                    <button class="adl-speed-btn" data-speed="slow">Slow</button>
                    <button class="adl-speed-btn is-active" data-speed="normal">Normal</button>
                    <button class="adl-speed-btn" data-speed="fast">Fast</button>
                </div>
            </div>
            <div class="adl-reading-indicator"></div>
        </div>
        <div class="adl-control">
            <span class="adl-label">Screen Dimming</span>
            <div class="adl-range-wrapper">
                <input type="range" class="adl-range" id="adl-dim-slider" min="0" max="50" value="0" aria-label="Screen dimming level">
                <span class="adl-range-value">0%</span>
            </div>
        </div>
        <button class="adl-reset" aria-label="Reset accessibility settings to defaults">Reset to Defaults</button>
    </div>
    <!-- /ACCESSIBILITY DASHBOARD -->

    <script src="../app.js" defer></script>
</body>
</html>